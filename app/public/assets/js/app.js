/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/tone/Tone/component/AmplitudeEnvelope.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/Tone/component/AmplitudeEnvelope.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Envelope */ \"./node_modules/tone/Tone/component/Envelope.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n\t *          Unlike Tone.Envelope, which outputs the envelope's value, Tone.AmplitudeEnvelope accepts\n\t *          an audio signal as the input and will apply the envelope to the amplitude\n\t *          of the signal. Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Envelope}\n\t *  @param {Time|Object} [attack] The amount of time it takes for the envelope to go from\n\t *                               0 to it's maximum value.\n\t *  @param {Time} [decay]\tThe period of time after the attack that it takes for the envelope\n\t *                       \tto fall to the sustain value.\n\t *  @param {NormalRange} [sustain]\tThe percent of the maximum value that the envelope rests at until\n\t *                                \tthe release is triggered.\n\t *  @param {Time} [release]\tThe amount of time after the release is triggered it takes to reach 0.\n\t *  @example\n\t * var ampEnv = new Tone.AmplitudeEnvelope({\n\t * \t\"attack\": 0.1,\n\t * \t\"decay\": 0.2,\n\t * \t\"sustain\": 1.0,\n\t * \t\"release\": 0.8\n\t * }).toMaster();\n\t * //create an oscillator and connect it\n\t * var osc = new Tone.Oscillator().connect(ampEnv).start();\n\t * //trigger the envelopes attack and release \"8t\" apart\n\t * ampEnv.triggerAttackRelease(\"8t\");\n\t */\n\tTone.AmplitudeEnvelope = function(){\n\n\t\tTone.Envelope.apply(this, arguments);\n\n\t\t/**\n\t\t *  the input node\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.input = this.output = new Tone.Gain();\n\n\t\tthis._sig.connect(this.output.gain);\n\t};\n\n\tTone.extend(Tone.AmplitudeEnvelope, Tone.Envelope);\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.AmplitudeEnvelope}  this\n\t */\n\tTone.AmplitudeEnvelope.prototype.dispose = function(){\n\t\tTone.Envelope.prototype.dispose.call(this);\n\t\treturn this;\n\t};\n\n\treturn Tone.AmplitudeEnvelope;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/AmplitudeEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Analyser.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/component/Analyser.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\"), __webpack_require__(/*! ../shim/AnalyserNode */ \"./node_modules/tone/Tone/shim/AnalyserNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Wrapper around the native Web Audio's\n\t *          [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n\t *          Extracts FFT or Waveform data from the incoming signal.\n\t *  @extends {Tone.AudioNode}\n\t *  @param {String=} type The return type of the analysis, either \"fft\", or \"waveform\".\n\t *  @param {Number=} size The size of the FFT. Value must be a power of\n\t *                       two in the range 32 to 32768.\n\t */\n\tTone.Analyser = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"type\", \"size\"], Tone.Analyser);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The analyser node.\n\t\t *  @private\n\t\t *  @type {AnalyserNode}\n\t\t */\n\t\tthis._analyser = this.input = this.output = this.context.createAnalyser();\n\n\t\t/**\n\t\t *  The analysis type\n\t\t *  @type {String}\n\t\t *  @private\n\t\t */\n\t\tthis._type = options.type;\n\n\t\t/**\n\t\t *  The buffer that the FFT data is written to\n\t\t *  @type {TypedArray}\n\t\t *  @private\n\t\t */\n\t\tthis._buffer = null;\n\n\t\t//set the values initially\n\t\tthis.size = options.size;\n\t\tthis.type = options.type;\n\t};\n\n\tTone.extend(Tone.Analyser, Tone.AudioNode);\n\n\t/**\n\t *  The default values.\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.Analyser.defaults = {\n\t\t\"size\" : 1024,\n\t\t\"type\" : \"fft\",\n\t\t\"smoothing\" : 0.8\n\t};\n\n\t/**\n\t *  Possible return types of analyser.getValue()\n\t *  @enum {String}\n\t */\n\tTone.Analyser.Type = {\n\t\tWaveform : \"waveform\",\n\t\tFFT : \"fft\"\n\t};\n\n\t/**\n\t *  Run the analysis given the current settings and return the\n\t *  result as a TypedArray.\n\t *  @returns {TypedArray}\n\t */\n\tTone.Analyser.prototype.getValue = function(){\n\t\tif (this._type === Tone.Analyser.Type.FFT){\n\t\t\tthis._analyser.getFloatFrequencyData(this._buffer);\n\t\t} else if (this._type === Tone.Analyser.Type.Waveform){\n\t\t\tthis._analyser.getFloatTimeDomainData(this._buffer);\n\t\t}\n\t\treturn this._buffer;\n\t};\n\n\t/**\n\t *  The size of analysis. This must be a power of two in the range 32 to 32768.\n\t *  @memberOf Tone.Analyser#\n\t *  @type {Number}\n\t *  @name size\n\t */\n\tObject.defineProperty(Tone.Analyser.prototype, \"size\", {\n\t\tget : function(){\n\t\t\treturn this._analyser.frequencyBinCount;\n\t\t},\n\t\tset : function(size){\n\t\t\tthis._analyser.fftSize = size * 2;\n\t\t\tthis._buffer = new Float32Array(size);\n\t\t}\n\t});\n\n\t/**\n\t *  The analysis function returned by analyser.getValue(), either \"fft\" or \"waveform\".\n\t *  @memberOf Tone.Analyser#\n\t *  @type {String}\n\t *  @name type\n\t */\n\tObject.defineProperty(Tone.Analyser.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tif (type !== Tone.Analyser.Type.Waveform && type !== Tone.Analyser.Type.FFT){\n\t\t\t\tthrow new TypeError(\"Tone.Analyser: invalid type: \"+type);\n\t\t\t}\n\t\t\tthis._type = type;\n\t\t}\n\t});\n\n\t/**\n\t *  0 represents no time averaging with the last analysis frame.\n\t *  @memberOf Tone.Analyser#\n\t *  @type {NormalRange}\n\t *  @name smoothing\n\t */\n\tObject.defineProperty(Tone.Analyser.prototype, \"smoothing\", {\n\t\tget : function(){\n\t\t\treturn this._analyser.smoothingTimeConstant;\n\t\t},\n\t\tset : function(val){\n\t\t\tthis._analyser.smoothingTimeConstant = val;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Analyser}  this\n\t */\n\tTone.Analyser.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._analyser.disconnect();\n\t\tthis._analyser = null;\n\t\tthis._buffer = null;\n\t};\n\n\treturn Tone.Analyser;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Analyser.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Channel.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/component/Channel.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/PanVol */ \"./node_modules/tone/Tone/component/PanVol.js\"), __webpack_require__(/*! ../component/Solo */ \"./node_modules/tone/Tone/component/Solo.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Channel provides a channel strip interface with \n\t *  volume, pan, solo and mute controls. \n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Decibels} volume The output volume.\n\t *  @param {AudioRange} pan the initial pan\n\t *  @example\n\t * //pan the incoming signal left and drop the volume\n\t * var channel = new Tone.Channel(-0.25, -12);\n\t */\n\tTone.Channel = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"volume\", \"pan\"], Tone.PanVol);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The soloing interface\n\t\t *  @type {Tone.Solo}\n\t\t *  @private\n\t\t */\n\t\tthis._solo = this.input = new Tone.Solo(options.solo);\n\n\t\t/**\n\t\t *  The panning and volume node\n\t\t *  @type {Tone.PanVol}\n\t\t *  @private\n\t\t */\n\t\tthis._panVol = this.output = new Tone.PanVol({\n\t\t\t\"pan\" : options.pan, \n\t\t\t\"volume\" : options.volume,\n\t\t\t\"mute\" : options.mute\n\t\t});\n\n\t\t/**\n\t\t *  The L/R panning control.\n\t\t *  @type {AudioRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.pan = this._panVol.pan;\n\n\t\t/**\n\t\t *  The volume control in decibels.\n\t\t *  @type {Decibels}\n\t\t *  @signal\n\t\t */\n\t\tthis.volume = this._panVol.volume;\n\n\t\tthis._solo.connect(this._panVol);\n\t\tthis._readOnly([\"pan\", \"volume\"]);\n\t};\n\n\tTone.extend(Tone.Channel, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @type  {Object}\n\t *  @const\n\t *  @static\n\t */\n\tTone.Channel.defaults = {\n\t\t\"pan\" : 0,\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false,\n\t\t\"solo\" : false\n\t};\n\n\t/**\n\t * Solo/unsolo the channel. Soloing is only relative to other\n\t * Tone.Channels and Tone.Solos. \n\t * @memberOf Tone.Channel#\n\t * @name solo\n\t * @type {Boolean}\n\t */\n\tObject.defineProperty(Tone.Channel.prototype, \"solo\", {\n\t\tget : function(){\n\t\t\treturn this._solo.solo;\n\t\t},\n\t\tset : function(solo){\n\t\t\tthis._solo.solo = solo;\n\t\t}\n\t});\n\n\t/**\n\t *  If the current instance is muted, i.e. another instance is soloed,\n\t *  or the channel is muted\n\t *  @memberOf Tone.Channel#\n\t *  @type {Boolean}\n\t *  @name muted\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Channel.prototype, \"muted\", {\n\t\tget : function(){\n\t\t\treturn this._solo.muted || this.mute;\n\t\t}\n\t});\n\n\t/**\n\t * Mute/unmute the volume\n\t * @memberOf Tone.Channel#\n\t * @name mute\n\t * @type {Boolean}\n\t */\n\tObject.defineProperty(Tone.Channel.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._panVol.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._panVol.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Channel} this\n\t */\n\tTone.Channel.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"pan\", \"volume\"]);\n\t\tthis._panVol.dispose();\n\t\tthis._panVol = null;\n\t\tthis.pan = null;\n\t\tthis.volume = null;\n\t\tthis._solo.dispose();\n\t\tthis._solo = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Channel;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Channel.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Compressor.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/component/Compressor.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Compressor is a thin wrapper around the Web Audio\n\t *         [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n\t *         Compression reduces the volume of loud sounds or amplifies quiet sounds\n\t *         by narrowing or \"compressing\" an audio signal's dynamic range.\n\t *         Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Decibels|Object} [threshold] The value above which the compression starts to be applied.\n\t *  @param {Positive} [ratio] The gain reduction ratio.\n\t *  @example\n\t * var comp = new Tone.Compressor(-30, 3);\n\t */\n\tTone.Compressor = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"threshold\", \"ratio\"], Tone.Compressor);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the compressor node\n\t\t *  @type {DynamicsCompressorNode}\n\t\t *  @private\n\t\t */\n\t\tthis._compressor = this.input = this.output = this.context.createDynamicsCompressor();\n\n\t\t/**\n\t\t *  the threshold vaue\n\t\t *  @type {Decibels}\n\t\t *  @signal\n\t\t */\n\t\tthis.threshold = new Tone.Param({\n\t\t\t\"param\" : this._compressor.threshold,\n\t\t\t\"units\" : Tone.Type.Decibels,\n\t\t\t\"convert\" : false\n\t\t});\n\n\t\t/**\n\t\t *  The attack parameter\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.attack = new Tone.Param(this._compressor.attack, Tone.Type.Time);\n\n\t\t/**\n\t\t *  The release parameter\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.release = new Tone.Param(this._compressor.release, Tone.Type.Time);\n\n\t\t/**\n\t\t *  The knee parameter\n\t\t *  @type {Decibels}\n\t\t *  @signal\n\t\t */\n\t\tthis.knee = new Tone.Param({\n\t\t\t\"param\" : this._compressor.knee,\n\t\t\t\"units\" : Tone.Type.Decibels,\n\t\t\t\"convert\" : false\n\t\t});\n\n\t\t/**\n\t\t *  The ratio value\n\t\t *  @type {Number}\n\t\t *  @signal\n\t\t */\n\t\tthis.ratio = new Tone.Param({\n\t\t\t\"param\" : this._compressor.ratio,\n\t\t\t\"convert\" : false\n\t\t});\n\n\t\t//set the defaults\n\t\tthis._readOnly([\"knee\", \"release\", \"attack\", \"ratio\", \"threshold\"]);\n\t\tthis.set(options);\n\t};\n\n\tTone.extend(Tone.Compressor, Tone.AudioNode);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Compressor.defaults = {\n\t\t\"ratio\" : 12,\n\t\t\"threshold\" : -24,\n\t\t\"release\" : 0.25,\n\t\t\"attack\" : 0.003,\n\t\t\"knee\" : 30\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Compressor} this\n\t */\n\tTone.Compressor.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"knee\", \"release\", \"attack\", \"ratio\", \"threshold\"]);\n\t\tthis._compressor.disconnect();\n\t\tthis._compressor = null;\n\t\tthis.attack.dispose();\n\t\tthis.attack = null;\n\t\tthis.release.dispose();\n\t\tthis.release = null;\n\t\tthis.threshold.dispose();\n\t\tthis.threshold = null;\n\t\tthis.ratio.dispose();\n\t\tthis.ratio = null;\n\t\tthis.knee.dispose();\n\t\tthis.knee = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Compressor;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Compressor.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/CrossFade.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/component/CrossFade.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"),\n\t__webpack_require__(/*! ../signal/EqualPowerGain */ \"./node_modules/tone/Tone/signal/EqualPowerGain.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t * @class  Tone.Crossfade provides equal power fading between two inputs.\n\t *         More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).\n\t *\n\t * @constructor\n\t * @extends {Tone.AudioNode}\n\t * @param {NormalRange} [initialFade=0.5]\n\t * @example\n\t * var crossFade = new Tone.CrossFade(0.5);\n\t * //connect effect A to crossfade from\n\t * //effect output 0 to crossfade input 0\n\t * effectA.connect(crossFade, 0, 0);\n\t * //connect effect B to crossfade from\n\t * //effect output 0 to crossfade input 1\n\t * effectB.connect(crossFade, 0, 1);\n\t * crossFade.fade.value = 0;\n\t * // ^ only effectA is output\n\t * crossFade.fade.value = 1;\n\t * // ^ only effectB is output\n\t * crossFade.fade.value = 0.5;\n\t * // ^ the two signals are mixed equally.\n\t */\n\tTone.CrossFade = function(initialFade){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(2, 1);\n\n\t\t/**\n\t\t *  Alias for <code>input[0]</code>.\n\t\t *  @type {Tone.Gain}\n\t\t */\n\t\tthis.a = this.input[0] = new Tone.Gain();\n\n\t\t/**\n\t\t *  Alias for <code>input[1]</code>.\n\t\t *  @type {Tone.Gain}\n\t\t */\n\t\tthis.b = this.input[1] = new Tone.Gain();\n\n\t\t/**\n\t\t * \tThe mix between the two inputs. A fade value of 0\n\t\t * \twill output 100% <code>input[0]</code> and\n\t\t * \ta value of 1 will output 100% <code>input[1]</code>.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.fade = new Tone.Signal(Tone.defaultArg(initialFade, 0.5), Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  equal power gain cross fade\n\t\t *  @private\n\t\t *  @type {Tone.EqualPowerGain}\n\t\t */\n\t\tthis._equalPowerA = new Tone.EqualPowerGain();\n\n\t\t/**\n\t\t *  equal power gain cross fade\n\t\t *  @private\n\t\t *  @type {Tone.EqualPowerGain}\n\t\t */\n\t\tthis._equalPowerB = new Tone.EqualPowerGain();\n\n\t\t/**\n\t\t *  invert the incoming signal\n\t\t *  @private\n\t\t *  @type {Tone}\n\t\t */\n\t\tthis._one = this.context.getConstant(1);\n\n\t\t/**\n\t\t *  invert the incoming signal\n\t\t *  @private\n\t\t *  @type {Tone.Subtract}\n\t\t */\n\t\tthis._invert = new Tone.Subtract();\n\n\t\t//connections\n\t\tthis.a.connect(this.output);\n\t\tthis.b.connect(this.output);\n\t\tthis.fade.chain(this._equalPowerB, this.b.gain);\n\t\tthis._one.connect(this._invert, 0, 0);\n\t\tthis.fade.connect(this._invert, 0, 1);\n\t\tthis._invert.chain(this._equalPowerA, this.a.gain);\n\t\tthis._readOnly(\"fade\");\n\t};\n\n\tTone.extend(Tone.CrossFade, Tone.AudioNode);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.CrossFade} this\n\t */\n\tTone.CrossFade.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable(\"fade\");\n\t\tthis._equalPowerA.dispose();\n\t\tthis._equalPowerA = null;\n\t\tthis._equalPowerB.dispose();\n\t\tthis._equalPowerB = null;\n\t\tthis.fade.dispose();\n\t\tthis.fade = null;\n\t\tthis._invert.dispose();\n\t\tthis._invert = null;\n\t\tthis._one = null;\n\t\tthis.a.dispose();\n\t\tthis.a = null;\n\t\tthis.b.dispose();\n\t\tthis.b = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.CrossFade;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/CrossFade.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/EQ3.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/component/EQ3.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/MultibandSplit */ \"./node_modules/tone/Tone/component/MultibandSplit.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.EQ3 is a three band EQ with control over low, mid, and high gain as\n\t *         well as the low and high crossover frequencies.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *\n\t *  @param {Decibels|Object} [lowLevel] The gain applied to the lows.\n\t *  @param {Decibels} [midLevel] The gain applied to the mid.\n\t *  @param {Decibels} [highLevel] The gain applied to the high.\n\t *  @example\n\t * var eq = new Tone.EQ3(-10, 3, -20);\n\t */\n\tTone.EQ3 = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"low\", \"mid\", \"high\"], Tone.EQ3);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the output node\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  the multiband split\n\t\t *  @type {Tone.MultibandSplit}\n\t\t *  @private\n\t\t */\n\t\tthis._multibandSplit = this.input = new Tone.MultibandSplit({\n\t\t\t\"lowFrequency\" : options.lowFrequency,\n\t\t\t\"highFrequency\" : options.highFrequency\n\t\t});\n\n\t\t/**\n\t\t *  The gain for the lower signals\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._lowGain = new Tone.Gain(options.low, Tone.Type.Decibels);\n\n\t\t/**\n\t\t *  The gain for the mid signals\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._midGain = new Tone.Gain(options.mid, Tone.Type.Decibels);\n\n\t\t/**\n\t\t * The gain in decibels of the high part\n\t\t * @type {Tone.Gain}\n\t\t * @private\n\t\t */\n\t\tthis._highGain = new Tone.Gain(options.high, Tone.Type.Decibels);\n\n\t\t/**\n\t\t * The gain in decibels of the low part\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t */\n\t\tthis.low = this._lowGain.gain;\n\n\t\t/**\n\t\t * The gain in decibels of the mid part\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t */\n\t\tthis.mid = this._midGain.gain;\n\n\t\t/**\n\t\t * The gain in decibels of the high part\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t */\n\t\tthis.high = this._highGain.gain;\n\n\t\t/**\n\t\t *  The Q value for all of the filters.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t */\n\t\tthis.Q = this._multibandSplit.Q;\n\n\t\t/**\n\t\t *  The low/mid crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.lowFrequency = this._multibandSplit.lowFrequency;\n\n\t\t/**\n\t\t *  The mid/high crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.highFrequency = this._multibandSplit.highFrequency;\n\n\t\t//the frequency bands\n\t\tthis._multibandSplit.low.chain(this._lowGain, this.output);\n\t\tthis._multibandSplit.mid.chain(this._midGain, this.output);\n\t\tthis._multibandSplit.high.chain(this._highGain, this.output);\n\t\tthis._readOnly([\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n\t};\n\n\tTone.extend(Tone.EQ3, Tone.AudioNode);\n\n\t/**\n\t *  the default values\n\t */\n\tTone.EQ3.defaults = {\n\t\t\"low\" : 0,\n\t\t\"mid\" : 0,\n\t\t\"high\" : 0,\n\t\t\"lowFrequency\" : 400,\n\t\t\"highFrequency\" : 2500\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.EQ3} this\n\t */\n\tTone.EQ3.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n\t\tthis._multibandSplit.dispose();\n\t\tthis._multibandSplit = null;\n\t\tthis.lowFrequency = null;\n\t\tthis.highFrequency = null;\n\t\tthis._lowGain.dispose();\n\t\tthis._lowGain = null;\n\t\tthis._midGain.dispose();\n\t\tthis._midGain = null;\n\t\tthis._highGain.dispose();\n\t\tthis._highGain = null;\n\t\tthis.low = null;\n\t\tthis.mid = null;\n\t\tthis.high = null;\n\t\tthis.Q = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.EQ3;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/EQ3.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Envelope.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/component/Envelope.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"),\n\t__webpack_require__(/*! ../signal/Pow */ \"./node_modules/tone/Tone/signal/Pow.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n\t *          envelope generator. Tone.Envelope outputs a signal which\n\t *          can be connected to an AudioParam or Tone.Signal.\n\t *          <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ea/ADSR_parameter.svg\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Time} [attack] The amount of time it takes for the envelope to go from\n\t *                         0 to it's maximum value.\n\t *  @param {Time} [decay]\tThe period of time after the attack that it takes for the envelope\n\t *                       \tto fall to the sustain value. Value must be greater than 0.\n\t *  @param {NormalRange} [sustain]\tThe percent of the maximum value that the envelope rests at until\n\t *                                \tthe release is triggered.\n\t *  @param {Time} [release]\tThe amount of time after the release is triggered it takes to reach 0.\n\t *                         \tValue must be greater than 0.\n\t *  @example\n\t * //an amplitude envelope\n\t * var gainNode = Tone.context.createGain();\n\t * var env = new Tone.Envelope({\n\t * \t\"attack\" : 0.1,\n\t * \t\"decay\" : 0.2,\n\t * \t\"sustain\" : 1,\n\t * \t\"release\" : 0.8,\n\t * });\n\t * env.connect(gainNode.gain);\n\t */\n\tTone.Envelope = function(){\n\n\t\t//get all of the defaults\n\t\tvar options = Tone.defaults(arguments, [\"attack\", \"decay\", \"sustain\", \"release\"], Tone.Envelope);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  When triggerAttack is called, the attack time is the amount of\n\t\t *  time it takes for the envelope to reach it's maximum value.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.attack = options.attack;\n\n\t\t/**\n\t\t *  After the attack portion of the envelope, the value will fall\n\t\t *  over the duration of the decay time to it's sustain value.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.decay = options.decay;\n\n\t\t/**\n\t\t * \tThe sustain value is the value\n\t\t * \twhich the envelope rests at after triggerAttack is\n\t\t * \tcalled, but before triggerRelease is invoked.\n\t\t *  @type {NormalRange}\n\t\t */\n\t\tthis.sustain = options.sustain;\n\n\t\t/**\n\t\t *  After triggerRelease is called, the envelope's\n\t\t *  value will fall to it's miminum value over the\n\t\t *  duration of the release time.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.release = options.release;\n\n\t\t/**\n\t\t *  the next time the envelope is at standby\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._attackCurve = \"linear\";\n\n\t\t/**\n\t\t *  the next time the envelope is at standby\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._releaseCurve = \"exponential\";\n\n\t\t/**\n\t\t *  the signal\n\t\t *  @type {Tone.Signal}\n\t\t *  @private\n\t\t */\n\t\tthis._sig = this.output = new Tone.Signal(0);\n\n\t\t//set the attackCurve initially\n\t\tthis.attackCurve = options.attackCurve;\n\t\tthis.releaseCurve = options.releaseCurve;\n\t\tthis.decayCurve = options.decayCurve;\n\t};\n\n\tTone.extend(Tone.Envelope, Tone.AudioNode);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t */\n\tTone.Envelope.defaults = {\n\t\t\"attack\" : 0.01,\n\t\t\"decay\" : 0.1,\n\t\t\"sustain\" : 0.5,\n\t\t\"release\" : 1,\n\t\t\"attackCurve\" : \"linear\",\n\t\t\"decayCurve\" : \"exponential\",\n\t\t\"releaseCurve\" : \"exponential\",\n\t};\n\n\t/**\n\t * Read the current value of the envelope. Useful for\n\t * syncronizing visual output to the envelope.\n\t * @memberOf Tone.Envelope#\n\t * @type {Number}\n\t * @name value\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Envelope.prototype, \"value\", {\n\t\tget : function(){\n\t\t\treturn this.getValueAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Get the curve\n\t *  @param  {Array|String}  curve\n\t *  @param  {String}  direction  In/Out\n\t *  @return  {String}  The curve name\n\t *  @private\n\t */\n\tTone.Envelope.prototype._getCurve = function(curve, direction){\n\t\tif (Tone.isString(curve)){\n\t\t\treturn curve;\n\t\t} else if (Tone.isArray(curve)){\n\t\t\t//look up the name in the curves array\n\t\t\tfor (var t in Tone.Envelope.Type){\n\t\t\t\tif (Tone.Envelope.Type[t][direction] === curve){\n\t\t\t\t\treturn t;\n\t\t\t\t}\n\t\t\t}\n\t\t\t//otherwise just return the array\n\t\t\treturn curve;\n\t\t}\n\t};\n\n\t/**\n\t *  Assign a the curve to the given name using the direction\n\t *  @param  {String}  name\n\t *  @param  {String}  direction In/Out\n\t *  @param  {Array}  curve\n\t *  @private\n\t */\n\tTone.Envelope.prototype._setCurve = function(name, direction, curve){\n\t\t//check if it's a valid type\n\t\tif (Tone.Envelope.Type.hasOwnProperty(curve)){\n\t\t\tvar curveDef = Tone.Envelope.Type[curve];\n\t\t\tif (Tone.isObject(curveDef)){\n\t\t\t\tthis[name] = curveDef[direction];\n\t\t\t} else {\n\t\t\t\tthis[name] = curveDef;\n\t\t\t}\n\t\t} else if (Tone.isArray(curve)){\n\t\t\tthis[name] = curve;\n\t\t} else {\n\t\t\tthrow new Error(\"Tone.Envelope: invalid curve: \" + curve);\n\t\t}\n\t};\n\n\t/**\n\t * The shape of the attack.\n\t * Can be any of these strings:\n\t * <ul>\n\t *   <li>linear</li>\n\t *   <li>exponential</li>\n\t *   <li>sine</li>\n\t *   <li>cosine</li>\n\t *   <li>bounce</li>\n\t *   <li>ripple</li>\n\t *   <li>step</li>\n\t * </ul>\n\t * Can also be an array which describes the curve. Values\n\t * in the array are evenly subdivided and linearly\n\t * interpolated over the duration of the attack.\n\t * @memberOf Tone.Envelope#\n\t * @type {String|Array}\n\t * @name attackCurve\n\t * @example\n\t * env.attackCurve = \"linear\";\n\t * @example\n\t * //can also be an array\n\t * env.attackCurve = [0, 0.2, 0.3, 0.4, 1]\n\t */\n\tObject.defineProperty(Tone.Envelope.prototype, \"attackCurve\", {\n\t\tget : function(){\n\t\t\treturn this._getCurve(this._attackCurve, \"In\");\n\t\t},\n\t\tset : function(curve){\n\t\t\tthis._setCurve(\"_attackCurve\", \"In\", curve);\n\t\t}\n\t});\n\n\t/**\n\t * The shape of the release. See the attack curve types.\n\t * @memberOf Tone.Envelope#\n\t * @type {String|Array}\n\t * @name releaseCurve\n\t * @example\n\t * env.releaseCurve = \"linear\";\n\t */\n\tObject.defineProperty(Tone.Envelope.prototype, \"releaseCurve\", {\n\t\tget : function(){\n\t\t\treturn this._getCurve(this._releaseCurve, \"Out\");\n\t\t},\n\t\tset : function(curve){\n\t\t\tthis._setCurve(\"_releaseCurve\", \"Out\", curve);\n\t\t}\n\t});\n\n\t/**\n\t * The shape of the decay either \"linear\" or \"exponential\"\n\t * @memberOf Tone.Envelope#\n\t * @type {String}\n\t * @name decayCurve\n\t * @example\n\t * env.decayCurve = \"linear\";\n\t */\n\tObject.defineProperty(Tone.Envelope.prototype, \"decayCurve\", {\n\t\tget : function(){\n\t\t\treturn this._decayCurve;\n\t\t},\n\t\tset : function(curve){\n\t\t\tvar curves = [\"linear\", \"exponential\"];\n\t\t\tif (!curves.includes(curve)){\n\t\t\t\tthrow new Error(\"Tone.Envelope: invalid curve: \" + curve);\n\t\t\t} else {\n\t\t\t\tthis._decayCurve = curve;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Trigger the attack/decay portion of the ADSR envelope.\n\t *  @param  {Time} [time=now] When the attack should start.\n\t *  @param {NormalRange} [velocity=1] The velocity of the envelope scales the vales.\n\t *                               number between 0-1\n\t *  @returns {Tone.Envelope} this\n\t *  @example\n\t *  //trigger the attack 0.5 seconds from now with a velocity of 0.2\n\t *  env.triggerAttack(\"+0.5\", 0.2);\n\t */\n\tTone.Envelope.prototype.triggerAttack = function(time, velocity){\n\t\tthis.log(\"triggerAttack\", time, velocity);\n\t\ttime = this.toSeconds(time);\n\t\tvar originalAttack = this.toSeconds(this.attack);\n\t\tvar attack = originalAttack;\n\t\tvar decay = this.toSeconds(this.decay);\n\t\tvelocity = Tone.defaultArg(velocity, 1);\n\t\t//check if it's not a complete attack\n\t\tvar currentValue = this.getValueAtTime(time);\n\t\tif (currentValue > 0){\n\t\t\t//subtract the current value from the attack time\n\t\t\tvar attackRate = 1 / attack;\n\t\t\tvar remainingDistance = 1 - currentValue;\n\t\t\t//the attack is now the remaining time\n\t\t\tattack = remainingDistance / attackRate;\n\t\t}\n\t\t//attack\n\t\tif (this._attackCurve === \"linear\"){\n\t\t\tthis._sig.linearRampTo(velocity, attack, time);\n\t\t} else if (this._attackCurve === \"exponential\"){\n\t\t\tthis._sig.targetRampTo(velocity, attack, time);\n\t\t} else if (attack > 0){\n\t\t\tthis._sig.cancelAndHoldAtTime(time);\n\t\t\tvar curve = this._attackCurve;\n\t\t\t//find the starting position in the curve\n\t\t\tfor (var i = 1; i < curve.length; i++){\n\t\t\t\t//the starting index is between the two values\n\t\t\t\tif (curve[i-1] <= currentValue && currentValue <= curve[i]){\n\t\t\t\t\tcurve = this._attackCurve.slice(i);\n\t\t\t\t\t//the first index is the current value\n\t\t\t\t\tcurve[0] = currentValue;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._sig.setValueCurveAtTime(curve, time, attack, velocity);\n\t\t}\n\t\t//decay\n\t\tif (decay){\n\t\t\tvar decayValue = velocity * this.sustain;\n\t\t\tvar decayStart = time + attack;\n\t\t\tthis.log(\"decay\", decayStart);\n\t\t\tif (this._decayCurve === \"linear\"){\n\t\t\t\tthis._sig.linearRampTo(decayValue, decay, decayStart+this.sampleTime);\n\t\t\t} else if (this._decayCurve === \"exponential\"){\n\t\t\t\tthis._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Triggers the release of the envelope.\n\t *  @param  {Time} [time=now] When the release portion of the envelope should start.\n\t *  @returns {Tone.Envelope} this\n\t *  @example\n\t *  //trigger release immediately\n\t *  env.triggerRelease();\n\t */\n\tTone.Envelope.prototype.triggerRelease = function(time){\n\t\tthis.log(\"triggerRelease\", time);\n\t\ttime = this.toSeconds(time);\n\t\tvar currentValue = this.getValueAtTime(time);\n\t\tif (currentValue > 0){\n\t\t\tvar release = this.toSeconds(this.release);\n\t\t\tif (this._releaseCurve === \"linear\"){\n\t\t\t\tthis._sig.linearRampTo(0, release, time);\n\t\t\t} else if (this._releaseCurve === \"exponential\"){\n\t\t\t\tthis._sig.targetRampTo(0, release, time);\n\t\t\t} else {\n\t\t\t\tvar curve = this._releaseCurve;\n\t\t\t\tif (Tone.isArray(curve)){\n\t\t\t\t\tthis._sig.cancelAndHoldAtTime(time);\n\t\t\t\t\tthis._sig.setValueCurveAtTime(curve, time, release, currentValue);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the scheduled value at the given time. This will\n\t *  return the unconverted (raw) value.\n\t *  @param  {Number}  time  The time in seconds.\n\t *  @return  {Number}  The scheduled value at the given time.\n\t */\n\tTone.Envelope.prototype.getValueAtTime = function(time){\n\t\treturn this._sig.getValueAtTime(time);\n\t};\n\n\t/**\n\t *  triggerAttackRelease is shorthand for triggerAttack, then waiting\n\t *  some duration, then triggerRelease.\n\t *  @param {Time} duration The duration of the sustain.\n\t *  @param {Time} [time=now] When the attack should be triggered.\n\t *  @param {number} [velocity=1] The velocity of the envelope.\n\t *  @returns {Tone.Envelope} this\n\t *  @example\n\t * //trigger the attack and then the release after 0.6 seconds.\n\t * env.triggerAttackRelease(0.6);\n\t */\n\tTone.Envelope.prototype.triggerAttackRelease = function(duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tthis.triggerAttack(time, velocity);\n\t\tthis.triggerRelease(time + this.toSeconds(duration));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancels all scheduled envelope changes after the given time.\n\t *  @param  {Time} after\n\t *  @returns {Tone.Envelope} this\n\t */\n\tTone.Envelope.prototype.cancel = function(after){\n\t\tthis._sig.cancelScheduledValues(after);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Borrows the connect method from Tone.Signal.\n\t *  @function\n\t *  @private\n\t */\n\tTone.Envelope.prototype.connect = Tone.SignalBase.prototype.connect;\n\n\t/**\n \t *  Generate some complex envelope curves.\n \t */\n\t(function _createCurves(){\n\n\t\tvar curveLen = 128;\n\n\t\tvar i, k;\n\n\t\t//cosine curve\n\t\tvar cosineCurve = [];\n\t\tfor (i = 0; i < curveLen; i++){\n\t\t\tcosineCurve[i] = Math.sin((i / (curveLen - 1)) * (Math.PI / 2));\n\t\t}\n\n\t\t//ripple curve\n\t\tvar rippleCurve = [];\n\t\tvar rippleCurveFreq = 6.4;\n\t\tfor (i = 0; i < curveLen - 1; i++){\n\t\t\tk = (i / (curveLen - 1));\n\t\t\tvar sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;\n\t\t\trippleCurve[i] = sineWave/10 + k * 0.83;\n\t\t}\n\t\trippleCurve[curveLen - 1] = 1;\n\n\t\t//stairs curve\n\t\tvar stairsCurve = [];\n\t\tvar steps = 5;\n\t\tfor (i = 0; i < curveLen; i++){\n\t\t\tstairsCurve[i] = Math.ceil((i / (curveLen - 1)) * steps) / steps;\n\t\t}\n\n\t\t//in-out easing curve\n\t\tvar sineCurve = [];\n\t\tfor (i = 0; i < curveLen; i++){\n\t\t\tk = i / (curveLen - 1);\n\t\t\tsineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));\n\t\t}\n\n\t\t//a bounce curve\n\t\tvar bounceCurve = [];\n\t\tfor (i = 0; i < curveLen; i++){\n\t\t\tk = i / (curveLen - 1);\n\t\t\tvar freq = Math.pow(k, 3) * 4 + 0.2;\n\t\t\tvar val = Math.cos(freq * Math.PI * 2 * k);\n\t\t\tbounceCurve[i] = Math.abs(val * (1 - k));\n\t\t}\n\n\t\t/**\n\t\t *  Invert a value curve to make it work for the release\n\t\t *  @private\n\t\t */\n\t\tfunction invertCurve(curve){\n\t\t\tvar out = new Array(curve.length);\n\t\t\tfor (var j = 0; j < curve.length; j++){\n\t\t\t\tout[j] = 1 - curve[j];\n\t\t\t}\n\t\t\treturn out;\n\t\t}\n\n\t\t/**\n\t\t *  reverse the curve\n\t\t *  @private\n\t\t */\n\t\tfunction reverseCurve(curve){\n\t\t\treturn curve.slice(0).reverse();\n\t\t}\n\n\t\t/**\n\t\t *  attack and release curve arrays\n\t\t *  @type  {Object}\n\t\t *  @private\n\t\t */\n\t\tTone.Envelope.Type = {\n\t\t\t\"linear\" : \"linear\",\n\t\t\t\"exponential\" : \"exponential\",\n\t\t\t\"bounce\" : {\n\t\t\t\tIn : invertCurve(bounceCurve),\n\t\t\t\tOut : bounceCurve\n\t\t\t},\n\t\t\t\"cosine\" : {\n\t\t\t\tIn : cosineCurve,\n\t\t\t\tOut : reverseCurve(cosineCurve)\n\t\t\t},\n\t\t\t\"step\" : {\n\t\t\t\tIn : stairsCurve,\n\t\t\t\tOut : invertCurve(stairsCurve)\n\t\t\t},\n\t\t\t\"ripple\" : {\n\t\t\t\tIn : rippleCurve,\n\t\t\t\tOut : invertCurve(rippleCurve)\n\t\t\t},\n\t\t\t\"sine\" : {\n\t\t\t\tIn : sineCurve,\n\t\t\t\tOut : invertCurve(sineCurve)\n\t\t\t}\n\t\t};\n\n\t})();\n\n\t/**\n\t *  Disconnect and dispose.\n\t *  @returns {Tone.Envelope} this\n\t */\n\tTone.Envelope.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._sig.dispose();\n\t\tthis._sig = null;\n\t\tthis._attackCurve = null;\n\t\tthis._releaseCurve = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Envelope;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Envelope.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/FFT.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/component/FFT.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Analyser */ \"./node_modules/tone/Tone/component/Analyser.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class  Get the current waveform data of the connected audio source.\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Number=} size The size of the FFT. Value must be a power of\n\t *                       two in the range 32 to 32768.\n\t */\n\tTone.FFT = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"size\"], Tone.FFT);\n\t\toptions.type = Tone.Analyser.Type.FFT;\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The analyser node.\n\t\t *  @private\n\t\t *  @type {Tone.Analyser}\n\t\t */\n\t\tthis._analyser = this.input = this.output = new Tone.Analyser(options);\n\t};\n\n\tTone.extend(Tone.FFT, Tone.AudioNode);\n\n\t/**\n\t *  The default values.\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.FFT.defaults = {\n\t\t\"size\" : 1024\n\t};\n\n\t/**\n\t *  Gets the waveform of the audio source. Returns the waveform data\n\t *  of length [size](#size) as a Float32Array with values between -1 and 1.\n\t *  @returns {TypedArray}\n\t */\n\tTone.FFT.prototype.getValue = function(){\n\t\treturn this._analyser.getValue();\n\t};\n\n\t/**\n\t *  The size of analysis. This must be a power of two in the range 32 to 32768.\n\t *  @memberOf Tone.FFT#\n\t *  @type {Number}\n\t *  @name size\n\t */\n\tObject.defineProperty(Tone.FFT.prototype, \"size\", {\n\t\tget : function(){\n\t\t\treturn this._analyser.size;\n\t\t},\n\t\tset : function(size){\n\t\t\tthis._analyser.size = size;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.FFT}  this\n\t */\n\tTone.FFT.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._analyser.dispose();\n\t\tthis._analyser = null;\n\t};\n\n\treturn Tone.FFT;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/FFT.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/FeedbackCombFilter.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/Tone/component/FeedbackCombFilter.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/ScaleExp */ \"./node_modules/tone/Tone/signal/ScaleExp.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"),\n\t__webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Comb filters are basic building blocks for physical modeling. Read more\n\t *         about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Time|Object} [delayTime] The delay time of the filter.\n\t *  @param {NormalRange=} resonance The amount of feedback the filter has.\n\t */\n\tTone.FeedbackCombFilter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"delayTime\", \"resonance\"], Tone.FeedbackCombFilter);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the delay node\n\t\t *  @type {DelayNode}\n\t\t *  @private\n\t\t */\n\t\tthis._delay = this.input = this.output = new Tone.Delay(options.delayTime);\n\n\t\t/**\n\t\t *  The amount of delay of the comb filter.\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = this._delay.delayTime;\n\n\t\t/**\n\t\t *  the feedback node\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis._feedback = new Tone.Gain(options.resonance, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  The amount of feedback of the delayed signal.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.resonance = this._feedback.gain;\n\n\t\tthis._delay.chain(this._feedback, this._delay);\n\t\tthis._readOnly([\"resonance\", \"delayTime\"]);\n\t};\n\n\tTone.extend(Tone.FeedbackCombFilter, Tone.AudioNode);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.FeedbackCombFilter.defaults = {\n\t\t\"delayTime\" : 0.1,\n\t\t\"resonance\" : 0.5\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.FeedbackCombFilter} this\n\t */\n\tTone.FeedbackCombFilter.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"resonance\", \"delayTime\"]);\n\t\tthis._delay.dispose();\n\t\tthis._delay = null;\n\t\tthis.delayTime = null;\n\t\tthis._feedback.dispose();\n\t\tthis._feedback = null;\n\t\tthis.resonance = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FeedbackCombFilter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/FeedbackCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Filter.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/component/Filter.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Filter is a filter which allows for all of the same native methods\n\t *          as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n\t *          Tone.Filter has the added ability to set the filter rolloff at -12\n\t *          (default), -24 and -48.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Frequency|Object} [frequency] The cutoff frequency of the filter.\n\t *  @param {string=} type The type of filter.\n\t *  @param {number=} rolloff The drop in decibels per octave after the cutoff frequency.\n\t *                            3 choices: -12, -24, and -48\n\t *  @example\n\t *  var filter = new Tone.Filter(200, \"highpass\");\n\t */\n\tTone.Filter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\", \"rolloff\"], Tone.Filter);\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(1, 1);\n\n\t\t/**\n\t\t *  the filter(s)\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._filters = [];\n\n\t\t/**\n\t\t *  The cutoff frequency of the filter.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune parameter\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(0, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  The gain of the filter, only used in certain filter types\n\t\t *  @type {Number}\n\t\t *  @signal\n\t\t */\n\t\tthis.gain = new Tone.Signal({\n\t\t\t\"value\" : options.gain,\n\t\t\t\"convert\" : true,\n\t\t\t\"type\" : Tone.Type.Decibels\n\t\t});\n\n\t\t/**\n\t\t *  The Q or Quality of the filter\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t */\n\t\tthis.Q = new Tone.Signal(options.Q);\n\n\t\t/**\n\t\t *  the type of the filter\n\t\t *  @type {string}\n\t\t *  @private\n\t\t */\n\t\tthis._type = options.type;\n\n\t\t/**\n\t\t *  the rolloff value of the filter\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._rolloff = options.rolloff;\n\n\t\t//set the rolloff;\n\t\tthis.rolloff = options.rolloff;\n\t\tthis._readOnly([\"detune\", \"frequency\", \"gain\", \"Q\"]);\n\t};\n\n\tTone.extend(Tone.Filter, Tone.AudioNode);\n\n\t/**\n\t *  the default parameters\n\t *\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Filter.defaults = {\n\t\t\"type\" : \"lowpass\",\n\t\t\"frequency\" : 350,\n\t\t\"rolloff\" : -12,\n\t\t\"Q\" : 1,\n\t\t\"gain\" : 0,\n\t};\n\n\t/**\n\t * The type of the filter. Types: \"lowpass\", \"highpass\",\n\t * \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", or \"peaking\".\n\t * @memberOf Tone.Filter#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.Filter.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tvar types = [\"lowpass\", \"highpass\", \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n\t\t\tif (types.indexOf(type)=== -1){\n\t\t\t\tthrow new TypeError(\"Tone.Filter: invalid type \"+type);\n\t\t\t}\n\t\t\tthis._type = type;\n\t\t\tfor (var i = 0; i < this._filters.length; i++){\n\t\t\t\tthis._filters[i].type = type;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The rolloff of the filter which is the drop in db\n\t * per octave. Implemented internally by cascading filters.\n\t * Only accepts the values -12, -24, -48 and -96.\n\t * @memberOf Tone.Filter#\n\t * @type {number}\n\t * @name rolloff\n\t */\n\tObject.defineProperty(Tone.Filter.prototype, \"rolloff\", {\n\t\tget : function(){\n\t\t\treturn this._rolloff;\n\t\t},\n\t\tset : function(rolloff){\n\t\t\trolloff = parseInt(rolloff, 10);\n\t\t\tvar possibilities = [-12, -24, -48, -96];\n\t\t\tvar cascadingCount = possibilities.indexOf(rolloff);\n\t\t\t//check the rolloff is valid\n\t\t\tif (cascadingCount === -1){\n\t\t\t\tthrow new RangeError(\"Tone.Filter: rolloff can only be -12, -24, -48 or -96\");\n\t\t\t}\n\t\t\tcascadingCount += 1;\n\t\t\tthis._rolloff = rolloff;\n\t\t\t//first disconnect the filters and throw them away\n\t\t\tthis.input.disconnect();\n\t\t\tfor (var i = 0; i < this._filters.length; i++){\n\t\t\t\tthis._filters[i].disconnect();\n\t\t\t\tthis._filters[i] = null;\n\t\t\t}\n\t\t\tthis._filters = new Array(cascadingCount);\n\t\t\tfor (var count = 0; count < cascadingCount; count++){\n\t\t\t\tvar filter = this.context.createBiquadFilter();\n\t\t\t\tfilter.type = this._type;\n\t\t\t\tthis.frequency.connect(filter.frequency);\n\t\t\t\tthis.detune.connect(filter.detune);\n\t\t\t\tthis.Q.connect(filter.Q);\n\t\t\t\tthis.gain.connect(filter.gain);\n\t\t\t\tthis._filters[count] = filter;\n\t\t\t}\n\t\t\t//connect them up\n\t\t\tvar connectionChain = [this.input].concat(this._filters).concat([this.output]);\n\t\t\tTone.connectSeries.apply(Tone, connectionChain);\n\t\t}\n\t});\n\n\t/**\n\t * Get the frequency response curve. This curve represets how the filter\n\t * responses to frequencies between 20hz-20khz. \n\t * @param  {Number} [len=128] The number of values to return\n\t * @return {Float32Array}     The frequency response curve between 20-20k\n\t */\n\tTone.Filter.prototype.getFrequencyResponse = function(len){\n\t\tlen = Tone.defaultArg(len, 128);\n\t\t//start with all 1s\n\t\tvar totalResponse = new Float32Array(len).map(function(){\n\t\t\treturn 1;\n\t\t});\n\t\tvar freqValues = new Float32Array(len);\n\t\tfor (var i = 0; i < len; i++){\n\t\t\tconst norm = Math.pow(i / len, 2);\n\t\t\tvar freq = norm * (20000 - 20) + 20;\n\t\t\tfreqValues[i] = freq;\n\t\t}\n\t\tvar magValues = new Float32Array(len);\n\t\tvar phaseValues = new Float32Array(len);\n\t\tthis._filters.forEach(function(){\n\t\t\tvar filterClone = this.context.createBiquadFilter();\n\t\t\tfilterClone.type = this._type;\n\t\t\tfilterClone.Q.value = this.Q.value;\n\t\t\tfilterClone.frequency.value = this.frequency.value;\n\t\t\tfilterClone.gain.value = this.gain.value;\n\t\t\tfilterClone.getFrequencyResponse(freqValues, magValues, phaseValues);\n\t\t\tmagValues.forEach(function(val, i){\n\t\t\t\ttotalResponse[i] *= val;\n\t\t\t});\n\t\t}.bind(this));\n\t\treturn totalResponse;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.Filter} this\n\t */\n\tTone.Filter.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tfor (var i = 0; i < this._filters.length; i++){\n\t\t\tthis._filters[i].disconnect();\n\t\t\tthis._filters[i] = null;\n\t\t}\n\t\tthis._filters = null;\n\t\tthis._writable([\"detune\", \"frequency\", \"gain\", \"Q\"]);\n\t\tthis.frequency.dispose();\n\t\tthis.Q.dispose();\n\t\tthis.frequency = null;\n\t\tthis.Q = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis.gain.dispose();\n\t\tthis.gain = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Filter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Filter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Follower.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/component/Follower.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Abs */ \"./node_modules/tone/Tone/signal/Abs.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"), \n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Follower is a  crude envelope follower which will follow\n\t *          the amplitude of an incoming signal. Read more about envelope followers (also known\n\t *          as envelope detectors) on [Wikipedia](https://en.wikipedia.org/wiki/Envelope_detector).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Time} [smoothing=0.05] The rate of change of the follower.\n\t *  @example\n\t * var follower = new Tone.Follower(0.3);\n\t */\n\tTone.Follower = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"smoothing\"], Tone.Follower);\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(1, 1);\n\n\t\t/**\n\t\t *  @type {Tone.Abs}\n\t\t *  @private\n\t\t */\n\t\tthis._abs = new Tone.Abs();\n\n\t\t/**\n\t\t *  the lowpass filter which smooths the input\n\t\t *  @type {BiquadFilterNode}\n\t\t *  @private\n\t\t */\n\t\tthis._filter = this.context.createBiquadFilter();\n\t\tthis._filter.type = \"lowpass\";\n\t\tthis._filter.frequency.value = 0;\n\t\tthis._filter.Q.value = 0;\n\n\t\t/**\n\t\t *  @type {Tone.Subtract}\n\t\t *  @private\n\t\t */\n\t\tthis._sub = new Tone.Subtract();\n\n\t\t/**\n\t\t *  delay node to compare change over time\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._delay = new Tone.Delay(this.blockTime);\n\n\t\t/**\n\t\t *  the smoothing value\n\t\t *  @private\n\t\t *  @type {Number}\n\t\t */\n\t\tthis._smoothing = options.smoothing;\n\n\t\tthis.input.connect(this._delay, this._sub);\n\t\tthis.input.connect(this._sub, 0, 1);\n\t\tthis._sub.chain(this._abs, this._filter, this.output);\n\n\t\t//set the smoothing initially\n\t\tthis.smoothing = options.smoothing;\n\t};\n\n\tTone.extend(Tone.Follower, Tone.AudioNode);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Follower.defaults = {\n\t\t\"smoothing\" : 0.05,\n\t};\n\n\t/**\n\t * The attack time.\n\t * @memberOf Tone.Follower#\n\t * @type {Time}\n\t * @name smoothing\n\t */\n\tObject.defineProperty(Tone.Follower.prototype, \"smoothing\", {\n\t\tget : function(){\n\t\t\treturn this._smoothing;\n\t\t},\n\t\tset : function(smoothing){\n\t\t\tthis._smoothing = smoothing;\n\t\t\tthis._filter.frequency.value = Tone.Time(smoothing).toFrequency() * 0.5;\n\t\t}\n\t});\n\n\t/**\n\t *  Borrows the connect method from Signal so that the output can be used\n\t *  as a Tone.Signal control signal.\n\t *  @function\n\t */\n\tTone.Follower.prototype.connect = Tone.SignalBase.prototype.connect;\n\n\t/**\n\t *  dispose\n\t *  @returns {Tone.Follower} this\n\t */\n\tTone.Follower.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._filter.disconnect();\n\t\tthis._filter = null;\n\t\tthis._delay.dispose();\n\t\tthis._delay = null;\n\t\tthis._sub.disconnect();\n\t\tthis._sub = null;\n\t\tthis._abs.dispose();\n\t\tthis._abs = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Follower;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Follower.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/FrequencyEnvelope.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/Tone/component/FrequencyEnvelope.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/ScaledEnvelope */ \"./node_modules/tone/Tone/component/ScaledEnvelope.js\"), __webpack_require__(/*! ../component/Envelope */ \"./node_modules/tone/Tone/component/Envelope.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.FrequencyEnvelope is a Tone.ScaledEnvelope, but instead of `min` and `max`\n\t *         it's got a `baseFrequency` and `octaves` parameter.\n\t *\n\t *  @extends {Tone.Envelope}\n\t *  @constructor\n\t *  @param {Time|Object} [attack]\tthe attack time in seconds\n\t *  @param {Time} [decay]\tthe decay time in seconds\n\t *  @param {number} [sustain] \ta percentage (0-1) of the full amplitude\n\t *  @param {Time} [release]\tthe release time in seconds\n\t *  @example\n\t *  var freqEnv = new Tone.FrequencyEnvelope({\n\t *  \t\"attack\" : 0.2,\n\t *  \t\"baseFrequency\" : \"C2\",\n\t *  \t\"octaves\" : 4\n\t *  });\n\t *  freqEnv.connect(oscillator.frequency);\n\t */\n\tTone.FrequencyEnvelope = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"attack\", \"decay\", \"sustain\", \"release\"], Tone.Envelope);\n\t\t//merge it with the frequency envelope defaults\n\t\toptions = Tone.defaultArg(options, Tone.FrequencyEnvelope.defaults);\n\t\tTone.ScaledEnvelope.call(this, options);\n\n\t\t/**\n\t\t *  Stores the octave value\n\t\t *  @type {Positive}\n\t\t *  @private\n\t\t */\n\t\tthis._octaves = options.octaves;\n\n\t\t//setup\n\t\tthis.baseFrequency = options.baseFrequency;\n\t\tthis.octaves = options.octaves;\n\t\tthis.exponent = options.exponent;\n\t};\n\n\tTone.extend(Tone.FrequencyEnvelope, Tone.Envelope);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t */\n\tTone.FrequencyEnvelope.defaults = {\n\t\t\"baseFrequency\" : 200,\n\t\t\"octaves\" : 4,\n\t\t\"exponent\" : 1\n\t};\n\n\t/**\n\t * The envelope's mininum output value. This is the value which it\n\t * starts at.\n\t * @memberOf Tone.FrequencyEnvelope#\n\t * @type {Frequency}\n\t * @name baseFrequency\n\t */\n\tObject.defineProperty(Tone.FrequencyEnvelope.prototype, \"baseFrequency\", {\n\t\tget : function(){\n\t\t\treturn this._scale.min;\n\t\t},\n\t\tset : function(min){\n\t\t\tthis._scale.min = this.toFrequency(min);\n\t\t\t//also update the octaves\n\t\t\tthis.octaves = this._octaves;\n\t\t}\n\t});\n\n\t/**\n\t * The number of octaves above the baseFrequency that the\n\t * envelope will scale to.\n\t * @memberOf Tone.FrequencyEnvelope#\n\t * @type {Positive}\n\t * @name octaves\n\t */\n\tObject.defineProperty(Tone.FrequencyEnvelope.prototype, \"octaves\", {\n\t\tget : function(){\n\t\t\treturn this._octaves;\n\t\t},\n\t\tset : function(octaves){\n\t\t\tthis._octaves = octaves;\n\t\t\tthis._scale.max = this.baseFrequency * Math.pow(2, octaves);\n\t\t}\n\t});\n\n\t/**\n\t * The envelope's exponent value.\n\t * @memberOf Tone.FrequencyEnvelope#\n\t * @type {number}\n\t * @name exponent\n\t */\n\tObject.defineProperty(Tone.FrequencyEnvelope.prototype, \"exponent\", {\n\t\tget : function(){\n\t\t\treturn this._exp.value;\n\t\t},\n\t\tset : function(exp){\n\t\t\tthis._exp.value = exp;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.FrequencyEnvelope} this\n\t */\n\tTone.FrequencyEnvelope.prototype.dispose = function(){\n\t\tTone.ScaledEnvelope.prototype.dispose.call(this);\n\t\treturn this;\n\t};\n\n\treturn Tone.FrequencyEnvelope;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/FrequencyEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Gate.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/component/Gate.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Follower */ \"./node_modules/tone/Tone/component/Follower.js\"), __webpack_require__(/*! ../signal/GreaterThan */ \"./node_modules/tone/Tone/signal/GreaterThan.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Gate only passes a signal through when the incoming\n\t *          signal exceeds a specified threshold. To do this, Gate uses\n\t *          a Tone.Follower to follow the amplitude of the incoming signal.\n\t *          A common implementation of this class is a [Noise Gate](https://en.wikipedia.org/wiki/Noise_gate).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Decibels|Object} [threshold] The threshold above which the gate will open.\n\t *  @param {Time=} smoothing The follower's smoothing time\n\t *  @example\n\t * var gate = new Tone.Gate(-30, 0.2, 0.3).toMaster();\n\t * var mic = new Tone.UserMedia().connect(gate);\n\t * //the gate will only pass through the incoming\n\t * //signal when it's louder than -30db\n\t */\n\tTone.Gate = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"threshold\", \"smoothing\"], Tone.Gate);\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(1, 1);\n\n\t\t/**\n\t\t *  @type {Tone.Follower}\n\t\t *  @private\n\t\t */\n\t\tthis._follower = new Tone.Follower(options.smoothing);\n\n\t\t/**\n\t\t *  @type {Tone.GreaterThan}\n\t\t *  @private\n\t\t */\n\t\tthis._gt = new Tone.GreaterThan(Tone.dbToGain(options.threshold));\n\n\t\t//the connections\n\t\tthis.input.connect(this.output);\n\t\t//the control signal\n\t\tthis.input.chain(this._follower, this._gt, this.output.gain);\n\t};\n\n\tTone.extend(Tone.Gate, Tone.AudioNode);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Gate.defaults = {\n\t\t\"smoothing\" : 0.1,\n\t\t\"threshold\" : -40\n\t};\n\n\t/**\n\t * The threshold of the gate in decibels\n\t * @memberOf Tone.Gate#\n\t * @type {Decibels}\n\t * @name threshold\n\t */\n\tObject.defineProperty(Tone.Gate.prototype, \"threshold\", {\n\t\tget : function(){\n\t\t\treturn Tone.gainToDb(this._gt.value);\n\t\t},\n\t\tset : function(thresh){\n\t\t\tthis._gt.value = Tone.dbToGain(thresh);\n\t\t}\n\t});\n\n\t/**\n\t * The attack/decay speed of the gate\n\t * @memberOf Tone.Gate#\n\t * @type {Time}\n\t * @name smoothing\n\t */\n\tObject.defineProperty(Tone.Gate.prototype, \"smoothing\", {\n\t\tget : function(){\n\t\t\treturn this._follower.smoothing;\n\t\t},\n\t\tset : function(smoothingTime){\n\t\t\tthis._follower.smoothing = smoothingTime;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Gate} this\n\t */\n\tTone.Gate.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._follower.dispose();\n\t\tthis._gt.dispose();\n\t\tthis._follower = null;\n\t\tthis._gt = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Gate;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Gate.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/LFO.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/component/LFO.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"), __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/Tone/signal/Scale.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../signal/Zero */ \"./node_modules/tone/Tone/signal/Zero.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  LFO stands for low frequency oscillator. Tone.LFO produces an output signal\n\t *          which can be attached to an AudioParam or Tone.Signal\n\t *          in order to modulate that parameter with an oscillator. The LFO can\n\t *          also be synced to the transport to start/stop and change when the tempo changes.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Frequency|Object} [frequency] The frequency of the oscillation. Typically, LFOs will be\n\t *                               in the frequency range of 0.1 to 10 hertz.\n\t *  @param {number=} min The minimum output value of the LFO.\n\t *  @param {number=} max The maximum value of the LFO.\n\t *  @example\n\t * var lfo = new Tone.LFO(\"4n\", 400, 4000);\n\t * lfo.connect(filter.frequency);\n\t */\n\tTone.LFO = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"min\", \"max\"], Tone.LFO);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The oscillator.\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillator = new Tone.Oscillator({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"type\" : options.type,\n\t\t});\n\n\t\t/**\n\t\t *  the lfo's frequency\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._oscillator.frequency;\n\n\t\t/**\n\t\t * The amplitude of the LFO, which controls the output range between\n\t\t * the min and max output. For example if the min is -10 and the max\n\t\t * is 10, setting the amplitude to 0.5 would make the LFO modulate\n\t\t * between -5 and 5.\n\t\t * @type {Number}\n\t\t * @signal\n\t\t */\n\t\tthis.amplitude = this._oscillator.volume;\n\t\tthis.amplitude.units = Tone.Type.NormalRange;\n\t\tthis.amplitude.value = options.amplitude;\n\n\t\t/**\n\t\t *  The signal which is output when the LFO is stopped\n\t\t *  @type  {Tone.Signal}\n\t\t *  @private\n\t\t */\n\t\tthis._stoppedSignal = new Tone.Signal(0, Tone.Type.AudioRange);\n\n\t\t/**\n\t\t *  Just outputs zeros.\n\t\t *  @type {Tone.Zero}\n\t\t *  @private\n\t\t */\n\t\tthis._zeros = new Tone.Zero();\n\n\t\t/**\n\t\t *  The value that the LFO outputs when it's stopped\n\t\t *  @type {AudioRange}\n\t\t *  @private\n\t\t */\n\t\tthis._stoppedValue = 0;\n\n\t\t/**\n\t\t *  @type {Tone.AudioToGain}\n\t\t *  @private\n\t\t */\n\t\tthis._a2g = new Tone.AudioToGain();\n\n\t\t/**\n\t\t *  @type {Tone.Scale}\n\t\t *  @private\n\t\t */\n\t\tthis._scaler = this.output = new Tone.Scale(options.min, options.max);\n\n\t\t/**\n\t\t *  the units of the LFO (used for converting)\n\t\t *  @type {Tone.Type}\n\t\t *  @private\n\t\t */\n\t\tthis._units = Tone.Type.Default;\n\t\tthis.units = options.units;\n\n\t\t//connect it up\n\t\tthis._oscillator.chain(this._a2g, this._scaler);\n\t\tthis._zeros.connect(this._a2g);\n\t\tthis._stoppedSignal.connect(this._a2g);\n\t\tthis._readOnly([\"amplitude\", \"frequency\"]);\n\t\tthis.phase = options.phase;\n\t};\n\n\tTone.extend(Tone.LFO, Tone.AudioNode);\n\n\t/**\n\t *  the default parameters\n\t *\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.LFO.defaults = {\n\t\t\"type\" : \"sine\",\n\t\t\"min\" : 0,\n\t\t\"max\" : 1,\n\t\t\"phase\" : 0,\n\t\t\"frequency\" : \"4n\",\n\t\t\"amplitude\" : 1,\n\t\t\"units\" : Tone.Type.Default\n\t};\n\n\t/**\n\t *  Start the LFO.\n\t *  @param  {Time} [time=now] the time the LFO will start\n\t *  @returns {Tone.LFO} this\n\t */\n\tTone.LFO.prototype.start = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._stoppedSignal.setValueAtTime(0, time);\n\t\tthis._oscillator.start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the LFO.\n\t *  @param  {Time} [time=now] the time the LFO will stop\n\t *  @returns {Tone.LFO} this\n\t */\n\tTone.LFO.prototype.stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._stoppedSignal.setValueAtTime(this._stoppedValue, time);\n\t\tthis._oscillator.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sync the start/stop/pause to the transport\n\t *  and the frequency to the bpm of the transport\n\t *  @returns {Tone.LFO} this\n\t *  @example\n\t *  lfo.frequency.value = \"8n\";\n\t *  lfo.sync().start(0)\n\t *  //the rate of the LFO will always be an eighth note,\n\t *  //even as the tempo changes\n\t */\n\tTone.LFO.prototype.sync = function(){\n\t\tthis._oscillator.sync();\n\t\tthis._oscillator.syncFrequency();\n\t\treturn this;\n\t};\n\n\t/**\n\t *  unsync the LFO from transport control\n\t *  @returns {Tone.LFO} this\n\t */\n\tTone.LFO.prototype.unsync = function(){\n\t\tthis._oscillator.unsync();\n\t\tthis._oscillator.unsyncFrequency();\n\t\treturn this;\n\t};\n\n\t/**\n\t * The miniumum output of the LFO.\n\t * @memberOf Tone.LFO#\n\t * @type {number}\n\t * @name min\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"min\", {\n\t\tget : function(){\n\t\t\treturn this._toUnits(this._scaler.min);\n\t\t},\n\t\tset : function(min){\n\t\t\tmin = this._fromUnits(min);\n\t\t\tthis._scaler.min = min;\n\t\t}\n\t});\n\n\t/**\n\t * The maximum output of the LFO.\n\t * @memberOf Tone.LFO#\n\t * @type {number}\n\t * @name max\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"max\", {\n\t\tget : function(){\n\t\t\treturn this._toUnits(this._scaler.max);\n\t\t},\n\t\tset : function(max){\n\t\t\tmax = this._fromUnits(max);\n\t\t\tthis._scaler.max = max;\n\t\t}\n\t});\n\n\t/**\n\t * The type of the oscillator: sine, square, sawtooth, triangle.\n\t * @memberOf Tone.LFO#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._oscillator.type = type;\n\t\t\tthis._stoppedValue = this._oscillator._getInitialValue();\n\t\t\tthis._stoppedSignal.value = this._stoppedValue;\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the LFO.\n\t * @memberOf Tone.LFO#\n\t * @type {number}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._oscillator.phase = phase;\n\t\t\tthis._stoppedValue = this._oscillator._getInitialValue();\n\t\t\tthis._stoppedSignal.value = this._stoppedValue;\n\t\t}\n\t});\n\n\t/**\n\t * The output units of the LFO.\n\t * @memberOf Tone.LFO#\n\t * @type {Tone.Type}\n\t * @name units\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"units\", {\n\t\tget : function(){\n\t\t\treturn this._units;\n\t\t},\n\t\tset : function(val){\n\t\t\tvar currentMin = this.min;\n\t\t\tvar currentMax = this.max;\n\t\t\t//convert the min and the max\n\t\t\tthis._units = val;\n\t\t\tthis.min = currentMin;\n\t\t\tthis.max = currentMax;\n\t\t}\n\t});\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.LFO#\n\t * @type {Boolean}\n\t * @name mute\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._oscillator.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\" or \"stopped\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.LFO#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.LFO.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.state;\n\t\t}\n\t});\n\n\t/**\n\t *  Connect the output of the LFO to an AudioParam, AudioNode, or Tone Node.\n\t *  Tone.LFO will automatically convert to the destination units of the\n\t *  will get the units from the connected node.\n\t *  @param  {Tone | AudioParam | AudioNode} node\n\t *  @param {number} [outputNum=0] optionally which output to connect from\n\t *  @param {number} [inputNum=0] optionally which input to connect to\n\t *  @returns {Tone.LFO} this\n\t *  @private\n\t */\n\tTone.LFO.prototype.connect = function(node){\n\t\tif (node.constructor === Tone.Signal || node.constructor === Tone.Param){\n\t\t\tthis.convert = node.convert;\n\t\t\tthis.units = node.units;\n\t\t}\n\t\tTone.SignalBase.prototype.connect.apply(this, arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  private method borrowed from Param converts\n\t *  units from their destination value\n\t *  @function\n\t *  @private\n\t */\n\tTone.LFO.prototype._fromUnits = Tone.Param.prototype._fromUnits;\n\n\t/**\n\t *  private method borrowed from Param converts\n\t *  units to their destination value\n\t *  @function\n\t *  @private\n\t */\n\tTone.LFO.prototype._toUnits = Tone.Param.prototype._toUnits;\n\n\t/**\n\t *  disconnect and dispose\n\t *  @returns {Tone.LFO} this\n\t */\n\tTone.LFO.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"amplitude\", \"frequency\"]);\n\t\tthis._oscillator.dispose();\n\t\tthis._oscillator = null;\n\t\tthis._stoppedSignal.dispose();\n\t\tthis._stoppedSignal = null;\n\t\tthis._zeros.dispose();\n\t\tthis._zeros = null;\n\t\tthis._scaler.dispose();\n\t\tthis._scaler = null;\n\t\tthis._a2g.dispose();\n\t\tthis._a2g = null;\n\t\tthis.frequency = null;\n\t\tthis.amplitude = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.LFO;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/LFO.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Limiter.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/component/Limiter.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Compressor */ \"./node_modules/tone/Tone/component/Compressor.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Limiter will limit the loudness of an incoming signal.\n\t *         It is composed of a Tone.Compressor with a fast attack\n\t *         and release. Limiters are commonly used to safeguard against\n\t *         signal clipping. Unlike a compressor, limiters do not provide\n\t *         smooth gain reduction and almost completely prevent\n\t *         additional gain above the threshold.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {number} threshold The theshold above which the limiting is applied.\n\t *  @example\n\t *  var limiter = new Tone.Limiter(-6);\n\t */\n\tTone.Limiter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"threshold\"], Tone.Limiter);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the compressor\n\t\t *  @private\n\t\t *  @type {Tone.Compressor}\n\t\t */\n\t\tthis._compressor = this.input = this.output = new Tone.Compressor({\n\t\t\t\"attack\" : 0.001,\n\t\t\t\"decay\" : 0.001,\n\t\t\t\"threshold\" : options.threshold\n\t\t});\n\n\t\t/**\n\t\t * The threshold of of the limiter\n\t\t * @type {Decibel}\n\t\t * @signal\n\t\t */\n\t\tthis.threshold = this._compressor.threshold;\n\n\t\tthis._readOnly(\"threshold\");\n\t};\n\n\tTone.extend(Tone.Limiter, Tone.AudioNode);\n\n\t/**\n\t *  The default value\n\t *  @type {Object}\n\t *  @const\n\t *  @static\n\t */\n\tTone.Limiter.defaults = {\n\t\t\"threshold\" : -12\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Limiter} this\n\t */\n\tTone.Limiter.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._compressor.dispose();\n\t\tthis._compressor = null;\n\t\tthis._writable(\"threshold\");\n\t\tthis.threshold = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Limiter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Limiter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/LowpassCombFilter.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/Tone/component/LowpassCombFilter.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\"), __webpack_require__(/*! ../component/FeedbackCombFilter */ \"./node_modules/tone/Tone/component/FeedbackCombFilter.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Lowpass is a lowpass feedback comb filter. It is similar to\n\t *         Tone.FeedbackCombFilter, but includes a lowpass filter.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Time|Object} [delayTime] The delay time of the comb filter\n\t *  @param {NormalRange=} resonance The resonance (feedback) of the comb filter\n\t *  @param {Frequency=} dampening The cutoff of the lowpass filter dampens the\n\t *                                signal as it is fedback.\n\t */\n\tTone.LowpassCombFilter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"delayTime\", \"resonance\", \"dampening\"], Tone.LowpassCombFilter);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the delay node\n\t\t *  @type {DelayNode}\n\t\t *  @private\n\t\t */\n\t\tthis._combFilter = this.output = new Tone.FeedbackCombFilter(options.delayTime, options.resonance);\n\n\t\t/**\n\t\t *  The delayTime of the comb filter.\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = this._combFilter.delayTime;\n\n\t\t/**\n\t\t *  the lowpass filter\n\t\t *  @type  {BiquadFilterNode}\n\t\t *  @private\n\t\t */\n\t\tthis._lowpass = this.input = new Tone.Filter({\n\t\t\t\"frequency\" : options.dampening,\n\t\t\t\"type\" : \"lowpass\",\n\t\t\t\"Q\" : 0,\n\t\t\t\"rolloff\" : -12\n\t\t});\n\n\t\t/**\n\t\t *  The dampening control of the feedback\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.dampening = this._lowpass.frequency;\n\t\t\n\t\t/**\n\t\t *  The amount of feedback of the delayed signal.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.resonance = this._combFilter.resonance;\n\n\t\t//connections\n\t\tthis._lowpass.connect(this._combFilter);\n\t\tthis._readOnly([\"dampening\", \"resonance\", \"delayTime\"]);\n\t};\n\n\tTone.extend(Tone.LowpassCombFilter, Tone.AudioNode);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.LowpassCombFilter.defaults = {\n\t\t\"delayTime\" : 0.1,\n\t\t\"resonance\" : 0.5,\n\t\t\"dampening\" : 3000\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.LowpassCombFilter} this\n\t */\n\tTone.LowpassCombFilter.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"dampening\", \"resonance\", \"delayTime\"]);\n\t\tthis._combFilter.dispose();\n\t\tthis._combFilter = null;\n\t\tthis.resonance = null;\n\t\tthis.delayTime = null;\n\t\tthis._lowpass.dispose();\n\t\tthis._lowpass = null;\n\t\tthis.dampening = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.LowpassCombFilter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/LowpassCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Merge.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/component/Merge.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Merge brings two signals into the left and right\n\t *          channels of a single stereo channel.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @example\n\t * var merge = new Tone.Merge().toMaster();\n\t * //routing a sine tone in the left channel\n\t * //and noise in the right channel\n\t * var osc = new Tone.Oscillator().connect(merge.left);\n\t * var noise = new Tone.Noise().connect(merge.right);\n\t * //starting our oscillators\n\t * noise.start();\n\t * osc.start();\n\t */\n\tTone.Merge = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  The left input channel.\n\t\t *  Alias for <code>input[0]</code>\n\t\t *  @type {GainNode}\n\t\t */\n\t\tthis.left = this.input[0] = new Tone.Gain();\n\n\t\t/**\n\t\t *  The right input channel.\n\t\t *  Alias for <code>input[1]</code>.\n\t\t *  @type {GainNode}\n\t\t */\n\t\tthis.right = this.input[1] = new Tone.Gain();\n\n\t\t/**\n\t\t *  the merger node for the two channels\n\t\t *  @type {ChannelMergerNode}\n\t\t *  @private\n\t\t */\n\t\tthis._merger = this.output = this.context.createChannelMerger(2);\n\n\t\t//connections\n\t\tthis.left.connect(this._merger, 0, 0);\n\t\tthis.right.connect(this._merger, 0, 1);\n\n\t\tthis.left.channelCount = 1;\n\t\tthis.right.channelCount = 1;\n\t\tthis.left.channelCountMode = \"explicit\";\n\t\tthis.right.channelCountMode = \"explicit\";\n\t};\n\n\tTone.extend(Tone.Merge, Tone.AudioNode);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Merge} this\n\t */\n\tTone.Merge.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.left.dispose();\n\t\tthis.left = null;\n\t\tthis.right.dispose();\n\t\tthis.right = null;\n\t\tthis._merger.disconnect();\n\t\tthis._merger = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Merge;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Merge.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Meter.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/component/Meter.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Analyser */ \"./node_modules/tone/Tone/component/Analyser.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n\t *          of an input signal. It can also get the raw\n\t *          value of the input signal.\n\t *\n\t *  @constructor\n\t *  @param {Number} smoothing The amount of smoothing applied between frames.\n\t *  @extends {Tone.AudioNode}\n\t *  @example\n\t * var meter = new Tone.Meter();\n\t * var mic = new Tone.UserMedia().open();\n\t * //connect mic to the meter\n\t * mic.connect(meter);\n\t * //the current level of the mic input in decibels\n\t * var level = meter.getLevel();\n\t */\n\tTone.Meter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"smoothing\"], Tone.Meter);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t * A value from 0 -> 1 where 0 represents no time averaging with the last analysis frame.\n\t\t * @type {Number}\n\t\t */\n\t\tthis.smoothing = options.smoothing;\n\n\t\t/**\n\t\t * The previous frame's value\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._rms = 0;\n\n\t\t/**\n\t\t *  The analyser node which computes the levels.\n\t\t *  @private\n\t\t *  @type  {Tone.Analyser}\n\t\t */\n\t\tthis.input = this.output = this._analyser = new Tone.Analyser(\"waveform\", 256);\n\t};\n\n\tTone.extend(Tone.Meter, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @type {Object}\n\t *  @static\n\t *  @const\n\t */\n\tTone.Meter.defaults = {\n\t\t\"smoothing\" : 0.8,\n\t};\n\n\t/**\n\t *  Get the current decibel value of the incoming signal\n\t *  @returns {Decibels}\n\t */\n\tTone.Meter.prototype.getLevel = function(){\n\t\tvar values = this._analyser.getValue();\n\t\tvar totalSquared = 0;\n\t\tfor (var i = 0; i < values.length; i++){\n\t\t\tvar value = values[i];\n\t\t\ttotalSquared += value * value;\n\t\t}\n\t\tvar rms = Math.sqrt(totalSquared / values.length);\n\n\t\t//the rms can only fall at the rate of the smoothing\n\t\t//but can jump up instantly\n\t\tthis._rms = Math.max(rms, this._rms * this.smoothing);\n\n\t\treturn Tone.gainToDb(this._rms);\n\t};\n\n\t/**\n\t *  Get the signal value of the incoming signal\n\t *  @returns {Number}\n\t */\n\tTone.Meter.prototype.getValue = function(){\n\t\tvar value = this._analyser.getValue();\n\t\treturn value[0];\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Meter} this\n\t */\n\tTone.Meter.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._analyser.dispose();\n\t\tthis._analyser = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Meter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Meter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/MidSideCompressor.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/Tone/component/MidSideCompressor.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/MidSideSplit */ \"./node_modules/tone/Tone/component/MidSideSplit.js\"), __webpack_require__(/*! ../component/MidSideMerge */ \"./node_modules/tone/Tone/component/MidSideMerge.js\"),\n\t__webpack_require__(/*! ../component/Compressor */ \"./node_modules/tone/Tone/component/Compressor.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.MidSideCompressor applies two different compressors to the mid\n\t *         and side signal components. See Tone.MidSideSplit.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Object} options The options that are passed to the mid and side\n\t *                          compressors.\n\t *  @constructor\n\t */\n\tTone.MidSideCompressor = function(options){\n\n\t\tTone.AudioNode.call(this);\n\t\toptions = Tone.defaultArg(options, Tone.MidSideCompressor.defaults);\n\n\t\t/**\n\t\t *  the mid/side split\n\t\t *  @type  {Tone.MidSideSplit}\n\t\t *  @private\n\t\t */\n\t\tthis._midSideSplit = this.input = new Tone.MidSideSplit();\n\n\t\t/**\n\t\t *  the mid/side recombination\n\t\t *  @type  {Tone.MidSideMerge}\n\t\t *  @private\n\t\t */\n\t\tthis._midSideMerge = this.output = new Tone.MidSideMerge();\n\n\t\t/**\n\t\t *  The compressor applied to the mid signal\n\t\t *  @type  {Tone.Compressor}\n\t\t */\n\t\tthis.mid = new Tone.Compressor(options.mid);\n\n\t\t/**\n\t\t *  The compressor applied to the side signal\n\t\t *  @type  {Tone.Compressor}\n\t\t */\n\t\tthis.side = new Tone.Compressor(options.side);\n\n\t\tthis._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);\n\t\tthis._midSideSplit.side.chain(this.side, this._midSideMerge.side);\n\t\tthis._readOnly([\"mid\", \"side\"]);\n\t};\n\n\tTone.extend(Tone.MidSideCompressor, Tone.AudioNode);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.MidSideCompressor.defaults = {\n\t\t\"mid\" : {\n\t\t\t\"ratio\" : 3,\n\t\t\t\"threshold\" : -24,\n\t\t\t\"release\" : 0.03,\n\t\t\t\"attack\" : 0.02,\n\t\t\t\"knee\" : 16\n\t\t},\n\t\t\"side\" : {\n\t\t\t\"ratio\" : 6,\n\t\t\t\"threshold\" : -30,\n\t\t\t\"release\" : 0.25,\n\t\t\t\"attack\" : 0.03,\n\t\t\t\"knee\" : 10\n\t\t}\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.MidSideCompressor} this\n\t */\n\tTone.MidSideCompressor.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"mid\", \"side\"]);\n\t\tthis.mid.dispose();\n\t\tthis.mid = null;\n\t\tthis.side.dispose();\n\t\tthis.side = null;\n\t\tthis._midSideSplit.dispose();\n\t\tthis._midSideSplit = null;\n\t\tthis._midSideMerge.dispose();\n\t\tthis._midSideMerge = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MidSideCompressor;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/MidSideCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/MidSideMerge.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/Tone/component/MidSideMerge.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"), __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/Tone/signal/Add.js\"),\n\t__webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Mid/Side processing separates the the 'mid' signal\n\t *         (which comes out of both the left and the right channel)\n\t *         and the 'side' (which only comes out of the the side channels).\n\t *         MidSideMerge merges the mid and side signal after they've been seperated\n\t *         by Tone.MidSideSplit.<br><br>\n\t *         <code>\n\t *         Left = (Mid+Side)/sqrt(2);   // obtain left signal from mid and side<br>\n\t *         Right = (Mid-Side)/sqrt(2);   // obtain right signal from mid and side<br>\n\t *         </code>\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t */\n\tTone.MidSideMerge = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  The mid signal input. Alias for\n\t\t *  <code>input[0]</code>\n\t\t *  @type  {Tone.Gain}\n\t\t */\n\t\tthis.mid = this.input[0] = new Tone.Gain();\n\n\t\t/**\n\t\t *  recombine the mid/side into Left\n\t\t *  @type {Tone.Add}\n\t\t *  @private\n\t\t */\n\t\tthis._left = new Tone.Add();\n\n\t\t/**\n\t\t * Multiply the left by sqrt(1/2)\n\t\t * @type {Tone.Multiply}\n\t\t */\n\t\tthis._timesTwoLeft = new Tone.Multiply(Math.SQRT1_2);\n\n\t\t/**\n\t\t *  The side signal input. Alias for\n\t\t *  <code>input[1]</code>\n\t\t *  @type  {Tone.Gain}\n\t\t */\n\t\tthis.side = this.input[1] = new Tone.Gain();\n\n\t\t/**\n\t\t *  recombine the mid/side into Right\n\t\t *  @type {Tone.Subtract}\n\t\t *  @private\n\t\t */\n\t\tthis._right = new Tone.Subtract(/*\"($0 - $1) * $2\"*/);\n\n\t\t/**\n\t\t * Multiply the right by sqrt(1/2)\n\t\t * @type {Tone.Multiply}\n\t\t */\n\t\tthis._timesTwoRight = new Tone.Multiply(Math.SQRT1_2);\n\n\t\t/**\n\t\t *  Merge the left/right signal back into a stereo signal.\n\t\t *  @type {Tone.Merge}\n\t\t *  @private\n\t\t */\n\t\tthis._merge = this.output = new Tone.Merge();\n\n\t\tthis.mid.connect(this._left, 0, 0);\n\t\tthis.side.connect(this._left, 0, 1);\n\t\tthis.mid.connect(this._right, 0, 0);\n\t\tthis.side.connect(this._right, 0, 1);\n\t\tthis._left.connect(this._timesTwoLeft);\n\t\tthis._right.connect(this._timesTwoRight);\n\t\tthis._timesTwoLeft.connect(this._merge, 0, 0);\n\t\tthis._timesTwoRight.connect(this._merge, 0, 1);\n\t};\n\n\tTone.extend(Tone.MidSideMerge, Tone.AudioNode);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.MidSideMerge} this\n\t */\n\tTone.MidSideMerge.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.mid.dispose();\n\t\tthis.mid = null;\n\t\tthis.side.dispose();\n\t\tthis.side = null;\n\t\tthis._left.dispose();\n\t\tthis._left = null;\n\t\tthis._timesTwoLeft.dispose();\n\t\tthis._timesTwoLeft = null;\n\t\tthis._right.dispose();\n\t\tthis._right = null;\n\t\tthis._timesTwoRight.dispose();\n\t\tthis._timesTwoRight = null;\n\t\tthis._merge.dispose();\n\t\tthis._merge = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MidSideMerge;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/MidSideMerge.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/MidSideSplit.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/Tone/component/MidSideSplit.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/Tone/signal/Add.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"),\n\t__webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Mid/Side processing separates the the 'mid' signal\n\t *         (which comes out of both the left and the right channel)\n\t *         and the 'side' (which only comes out of the the side channels). <br><br>\n\t *         <code>\n\t *         Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right<br>\n\t *         Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and righ<br>\n\t *         </code>\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t */\n\tTone.MidSideSplit = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(0, 2);\n\n\t\t/**\n\t\t *  split the incoming signal into left and right channels\n\t\t *  @type  {Tone.Split}\n\t\t *  @private\n\t\t */\n\t\tthis._split = this.input = new Tone.Split();\n\n\t\t/**\n\t\t *  The mid send. Connect to mid processing. Alias for\n\t\t *  <code>output[0]</code>\n\t\t *  @type {Tone.Add}\n\t\t */\n\t\tthis._midAdd = new Tone.Add();\n\n\t\t/**\n\t\t * Multiply the _midAdd by sqrt(1/2)\n\t\t * @type {Tone.Multiply}\n\t\t */\n\t\tthis.mid = this.output[0] = new Tone.Multiply(Math.SQRT1_2);\n\n\t\t/**\n\t\t *  The side output. Connect to side processing. Also Output 1\n\t\t *  @type {Tone.Subtract}\n\t\t */\n\t\tthis._sideSubtract = new Tone.Subtract();\n\n\t\t/**\n\t\t * Multiply the _midAdd by sqrt(1/2)\n\t\t * @type {Tone.Multiply}\n\t\t */\n\t\tthis.side = this.output[1] = new Tone.Multiply(Math.SQRT1_2);\n\n\t\tthis._split.connect(this._midAdd, 0, 0);\n\t\tthis._split.connect(this._midAdd, 1, 1);\n\t\tthis._split.connect(this._sideSubtract, 0, 0);\n\t\tthis._split.connect(this._sideSubtract, 1, 1);\n\t\tthis._midAdd.connect(this.mid);\n\t\tthis._sideSubtract.connect(this.side);\n\t};\n\n\tTone.extend(Tone.MidSideSplit, Tone.AudioNode);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.MidSideSplit} this\n\t */\n\tTone.MidSideSplit.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.mid.dispose();\n\t\tthis.mid = null;\n\t\tthis.side.dispose();\n\t\tthis.side = null;\n\t\tthis._midAdd.dispose();\n\t\tthis._midAdd = null;\n\t\tthis._sideSubtract.dispose();\n\t\tthis._sideSubtract = null;\n\t\tthis._split.dispose();\n\t\tthis._split = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MidSideSplit;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/MidSideSplit.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Mono.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/component/Mono.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Mono coerces the incoming mono or stereo signal into a mono signal\n\t *         where both left and right channels have the same value. This can be useful\n\t *         for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t */\n\tTone.Mono = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(1, 0);\n\n\t\t/**\n\t\t *  merge the signal\n\t\t *  @type {Tone.Merge}\n\t\t *  @private\n\t\t */\n\t\tthis._merge = this.output = new Tone.Merge();\n\n\t\tthis.input.connect(this._merge, 0, 0);\n\t\tthis.input.connect(this._merge, 0, 1);\n\t};\n\n\tTone.extend(Tone.Mono, Tone.AudioNode);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Mono} this\n\t */\n\tTone.Mono.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._merge.dispose();\n\t\tthis._merge = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Mono;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Mono.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/MultibandCompressor.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/Tone/component/MultibandCompressor.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/MultibandSplit */ \"./node_modules/tone/Tone/component/MultibandSplit.js\"), __webpack_require__(/*! ../component/Compressor */ \"./node_modules/tone/Tone/component/Compressor.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class A compressor with seperate controls over low/mid/high dynamics\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Object} options The low/mid/high compressor settings.\n\t *  @example\n\t *  var multiband = new Tone.MultibandCompressor({\n\t *  \t\"lowFrequency\" : 200,\n\t *  \t\"highFrequency\" : 1300\n\t *  \t\"low\" : {\n\t *  \t\t\"threshold\" : -12\n\t *  \t}\n\t *  })\n\t */\n\tTone.MultibandCompressor = function(options){\n\n\t\tTone.AudioNode.call(this);\n\t\toptions = Tone.defaultArg(arguments, Tone.MultibandCompressor.defaults);\n\n\t\t/**\n\t\t *  split the incoming signal into high/mid/low\n\t\t *  @type {Tone.MultibandSplit}\n\t\t *  @private\n\t\t */\n\t\tthis._splitter = this.input = new Tone.MultibandSplit({\n\t\t\t\"lowFrequency\" : options.lowFrequency,\n\t\t\t\"highFrequency\" : options.highFrequency\n\t\t});\n\n\t\t/**\n\t\t *  low/mid crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.lowFrequency = this._splitter.lowFrequency;\n\n\t\t/**\n\t\t *  mid/high crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.highFrequency = this._splitter.highFrequency;\n\n\t\t/**\n\t\t *  the output\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  The compressor applied to the low frequencies.\n\t\t *  @type {Tone.Compressor}\n\t\t */\n\t\tthis.low = new Tone.Compressor(options.low);\n\n\t\t/**\n\t\t *  The compressor applied to the mid frequencies.\n\t\t *  @type {Tone.Compressor}\n\t\t */\n\t\tthis.mid = new Tone.Compressor(options.mid);\n\n\t\t/**\n\t\t *  The compressor applied to the high frequencies.\n\t\t *  @type {Tone.Compressor}\n\t\t */\n\t\tthis.high = new Tone.Compressor(options.high);\n\n\t\t//connect the compressor\n\t\tthis._splitter.low.chain(this.low, this.output);\n\t\tthis._splitter.mid.chain(this.mid, this.output);\n\t\tthis._splitter.high.chain(this.high, this.output);\n\n\t\tthis._readOnly([\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n\t};\n\n\tTone.extend(Tone.MultibandCompressor, Tone.AudioNode);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.MultibandCompressor.defaults = {\n\t\t\"low\" : Tone.Compressor.defaults,\n\t\t\"mid\" : Tone.Compressor.defaults,\n\t\t\"high\" : Tone.Compressor.defaults,\n\t\t\"lowFrequency\" : 250,\n\t\t\"highFrequency\" : 2000\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.MultibandCompressor} this\n\t */\n\tTone.MultibandCompressor.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._splitter.dispose();\n\t\tthis._writable([\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n\t\tthis.low.dispose();\n\t\tthis.mid.dispose();\n\t\tthis.high.dispose();\n\t\tthis._splitter = null;\n\t\tthis.low = null;\n\t\tthis.mid = null;\n\t\tthis.high = null;\n\t\tthis.lowFrequency = null;\n\t\tthis.highFrequency = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MultibandCompressor;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/MultibandCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/MultibandSplit.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/Tone/component/MultibandSplit.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Split the incoming signal into three bands (low, mid, high)\n\t *         with two crossover frequency controls.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Frequency|Object} [lowFrequency] the low/mid crossover frequency\n\t *  @param {Frequency} [highFrequency] the mid/high crossover frequency\n\t */\n\tTone.MultibandSplit = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"lowFrequency\", \"highFrequency\"], Tone.MultibandSplit);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  the input\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis.input = new Tone.Gain();\n\n\t\t/**\n\t\t *  the outputs\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis.output = new Array(3);\n\n\t\t/**\n\t\t *  The low band. Alias for <code>output[0]</code>\n\t\t *  @type {Tone.Filter}\n\t\t */\n\t\tthis.low = this.output[0] = new Tone.Filter(0, \"lowpass\");\n\n\t\t/**\n\t\t *  the lower filter of the mid band\n\t\t *  @type {Tone.Filter}\n\t\t *  @private\n\t\t */\n\t\tthis._lowMidFilter = new Tone.Filter(0, \"highpass\");\n\n\t\t/**\n\t\t *  The mid band output. Alias for <code>output[1]</code>\n\t\t *  @type {Tone.Filter}\n\t\t */\n\t\tthis.mid = this.output[1] = new Tone.Filter(0, \"lowpass\");\n\n\t\t/**\n\t\t *  The high band output. Alias for <code>output[2]</code>\n\t\t *  @type {Tone.Filter}\n\t\t */\n\t\tthis.high = this.output[2] = new Tone.Filter(0, \"highpass\");\n\n\t\t/**\n\t\t *  The low/mid crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.lowFrequency = new Tone.Signal(options.lowFrequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The mid/high crossover frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.highFrequency = new Tone.Signal(options.highFrequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The quality of all the filters\n\t\t *  @type {Number}\n\t\t *  @signal\n\t\t */\n\t\tthis.Q = new Tone.Signal(options.Q);\n\n\t\tthis.input.fan(this.low, this.high);\n\t\tthis.input.chain(this._lowMidFilter, this.mid);\n\t\t//the frequency control signal\n\t\tthis.lowFrequency.connect(this.low.frequency);\n\t\tthis.lowFrequency.connect(this._lowMidFilter.frequency);\n\t\tthis.highFrequency.connect(this.mid.frequency);\n\t\tthis.highFrequency.connect(this.high.frequency);\n\t\t//the Q value\n\t\tthis.Q.connect(this.low.Q);\n\t\tthis.Q.connect(this._lowMidFilter.Q);\n\t\tthis.Q.connect(this.mid.Q);\n\t\tthis.Q.connect(this.high.Q);\n\n\t\tthis._readOnly([\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n\t};\n\n\tTone.extend(Tone.MultibandSplit, Tone.AudioNode);\n\n\t/**\n\t *  @private\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.MultibandSplit.defaults = {\n\t\t\"lowFrequency\" : 400,\n\t\t\"highFrequency\" : 2500,\n\t\t\"Q\" : 1,\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.MultibandSplit} this\n\t */\n\tTone.MultibandSplit.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n\t\tthis.low.dispose();\n\t\tthis.low = null;\n\t\tthis._lowMidFilter.dispose();\n\t\tthis._lowMidFilter = null;\n\t\tthis.mid.dispose();\n\t\tthis.mid = null;\n\t\tthis.high.dispose();\n\t\tthis.high = null;\n\t\tthis.lowFrequency.dispose();\n\t\tthis.lowFrequency = null;\n\t\tthis.highFrequency.dispose();\n\t\tthis.highFrequency = null;\n\t\tthis.Q.dispose();\n\t\tthis.Q = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MultibandSplit;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/MultibandSplit.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/PanVol.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/component/PanVol.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Panner */ \"./node_modules/tone/Tone/component/Panner.js\"), __webpack_require__(/*! ../component/Volume */ \"./node_modules/tone/Tone/component/Volume.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.PanVol is a Tone.Panner and Tone.Volume in one.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {AudioRange} pan the initial pan\n\t *  @param {number} volume The output volume.\n\t *  @example\n\t * //pan the incoming signal left and drop the volume\n\t * var panVol = new Tone.PanVol(-0.25, -12);\n\t */\n\tTone.PanVol = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"pan\", \"volume\"], Tone.PanVol);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The panning node\n\t\t *  @type {Tone.Panner}\n\t\t *  @private\n\t\t */\n\t\tthis._panner = this.input = new Tone.Panner(options.pan);\n\n\t\t/**\n\t\t *  The L/R panning control.\n\t\t *  @type {AudioRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.pan = this._panner.pan;\n\n\t\t/**\n\t\t *  The volume node\n\t\t *  @type {Tone.Volume}\n\t\t *  @private\n\t\t */\n\t\tthis._volume = this.output = new Tone.Volume(options.volume);\n\n\t\t/**\n\t\t *  The volume control in decibels.\n\t\t *  @type {Decibels}\n\t\t *  @signal\n\t\t */\n\t\tthis.volume = this._volume.volume;\n\n\t\t//connections\n\t\tthis._panner.connect(this._volume);\n\t\tthis.mute = options.mute;\n\n\t\tthis._readOnly([\"pan\", \"volume\"]);\n\t};\n\n\tTone.extend(Tone.PanVol, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @type  {Object}\n\t *  @const\n\t *  @static\n\t */\n\tTone.PanVol.defaults = {\n\t\t\"pan\" : 0,\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t * Mute/unmute the volume\n\t * @memberOf Tone.PanVol#\n\t * @name mute\n\t * @type {Boolean}\n\t */\n\tObject.defineProperty(Tone.PanVol.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._volume.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._volume.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.PanVol} this\n\t */\n\tTone.PanVol.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable([\"pan\", \"volume\"]);\n\t\tthis._panner.dispose();\n\t\tthis._panner = null;\n\t\tthis.pan = null;\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis.volume = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PanVol;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/PanVol.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Panner.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/component/Panner.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"), __webpack_require__(/*! ../shim/StereoPannerNode */ \"./node_modules/tone/Tone/shim/StereoPannerNode.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\"), __webpack_require__(/*! ../signal/Zero */ \"./node_modules/tone/Tone/signal/Zero.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Panner is an equal power Left/Right Panner and does not\n\t *          support 3D. Panner uses the StereoPannerNode when available.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {NormalRange} [initialPan=0] The initail panner value (center).\n\t *  @example\n\t *  //pan the input signal hard right.\n\t *  var panner = new Tone.Panner(1);\n\t */\n\tTone.Panner = function(initialPan){\n\n\t\tTone.AudioNode.call(this);\n\t\t/**\n\t\t*  the panner node\n\t\t*  @type {StereoPannerNode}\n\t\t*  @private\n\t\t*/\n\t\tthis._panner = this.input = this.output = this.context.createStereoPanner();\n\n\t\t/**\n\t\t*  The pan control. -1 = hard left, 1 = hard right.\n\t\t*  @type {AudioRange}\n\t\t*  @signal\n\t\t*/\n\t\tthis.pan = this._panner.pan;\n\n\t\t//initial value\n\t\tthis.pan.value = Tone.defaultArg(initialPan, 0);\n\t\tthis._readOnly(\"pan\");\n\t};\n\n\tTone.extend(Tone.Panner, Tone.AudioNode);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Panner} this\n\t */\n\tTone.Panner.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable(\"pan\");\n\t\tthis._panner.disconnect();\n\t\tthis._panner = null;\n\t\tthis.pan = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Panner;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Panner.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Panner3D.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/component/Panner3D.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\"), __webpack_require__(/*! ../signal/Zero */ \"./node_modules/tone/Tone/signal/Zero.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  A spatialized panner node which supports equalpower or HRTF panning.\n\t *          Tries to normalize the API across various browsers. See Tone.Listener\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Number} positionX The initial x position.\n\t *  @param {Number} positionY The initial y position.\n\t *  @param {Number} positionZ The initial z position.\n\t */\n\tTone.Panner3D = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"positionX\", \"positionY\", \"positionZ\"], Tone.Panner3D);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The panner node\n\t\t *  @type {PannerNode}\n\t\t *  @private\n\t\t */\n\t\tthis._panner = this.input = this.output = this.context.createPanner();\n\t\t//set some values\n\t\tthis._panner.panningModel = options.panningModel;\n\t\tthis._panner.maxDistance = options.maxDistance;\n\t\tthis._panner.distanceModel = options.distanceModel;\n\t\tthis._panner.coneOuterGain = options.coneOuterGain;\n\t\tthis._panner.coneOuterAngle = options.coneOuterAngle;\n\t\tthis._panner.coneInnerAngle = options.coneInnerAngle;\n\t\tthis._panner.refDistance = options.refDistance;\n\t\tthis._panner.rolloffFactor = options.rolloffFactor;\n\n\t\t/**\n\t\t *  Holds the current orientation\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._orientation = [options.orientationX, options.orientationY, options.orientationZ];\n\n\t\t/**\n\t\t *  Holds the current position\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._position = [options.positionX, options.positionY, options.positionZ];\n\n\t\t// set the default position/orientation\n\t\tthis.orientationX = options.orientationX;\n\t\tthis.orientationY = options.orientationY;\n\t\tthis.orientationZ = options.orientationZ;\n\t\tthis.positionX = options.positionX;\n\t\tthis.positionY = options.positionY;\n\t\tthis.positionZ = options.positionZ;\n\t};\n\n\tTone.extend(Tone.Panner3D, Tone.AudioNode);\n\n\t/**\n\t *  Defaults according to the specification\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Panner3D.defaults = {\n\t\t\"positionX\" : 0,\n\t\t\"positionY\" : 0,\n\t\t\"positionZ\" : 0,\n\t\t\"orientationX\" : 0,\n\t\t\"orientationY\" : 0,\n\t\t\"orientationZ\" : 0,\n\t\t\"panningModel\" : \"equalpower\",\n\t\t\"maxDistance\" : 10000,\n\t\t\"distanceModel\" : \"inverse\",\n\t\t\"coneOuterGain\" : 0,\n\t\t\"coneOuterAngle\" : 360,\n\t\t\"coneInnerAngle\" : 360,\n\t\t\"refDistance\" : 1,\n\t\t\"rolloffFactor\" : 1\n\t};\n\n\t/**\n\t * The ramp time which is applied to the setTargetAtTime\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.Panner3D.prototype._rampTimeConstant = 0.01;\n\n\t/**\n\t *  Sets the position of the source in 3d space.\n\t *  @param  {Number}  x\n\t *  @param  {Number}  y\n\t *  @param  {Number}  z\n\t *  @return {Tone.Panner3D} this\n\t */\n\tTone.Panner3D.prototype.setPosition = function(x, y, z){\n\t\tif (this._panner.positionX){\n\t\t\tvar now = this.now();\n\t\t\tthis._panner.positionX.setTargetAtTime(x, now, this._rampTimeConstant);\n\t\t\tthis._panner.positionY.setTargetAtTime(y, now, this._rampTimeConstant);\n\t\t\tthis._panner.positionZ.setTargetAtTime(z, now, this._rampTimeConstant);\n\t\t} else {\n\t\t\tthis._panner.setPosition(x, y, z);\n\t\t}\n\t\tthis._position = Array.prototype.slice.call(arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sets the orientation of the source in 3d space.\n\t *  @param  {Number}  x\n\t *  @param  {Number}  y\n\t *  @param  {Number}  z\n\t *  @return {Tone.Panner3D} this\n\t */\n\tTone.Panner3D.prototype.setOrientation = function(x, y, z){\n\t\tif (this._panner.orientationX){\n\t\t\tvar now = this.now();\n\t\t\tthis._panner.orientationX.setTargetAtTime(x, now, this._rampTimeConstant);\n\t\t\tthis._panner.orientationY.setTargetAtTime(y, now, this._rampTimeConstant);\n\t\t\tthis._panner.orientationZ.setTargetAtTime(z, now, this._rampTimeConstant);\n\t\t} else {\n\t\t\tthis._panner.setOrientation(x, y, z);\n\t\t}\n\t\tthis._orientation = Array.prototype.slice.call(arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The x position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name positionX\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"positionX\", {\n\t\tset : function(pos){\n\t\t\tthis._position[0] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[0];\n\t\t}\n\t});\n\n\t/**\n\t *  The y position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name positionY\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"positionY\", {\n\t\tset : function(pos){\n\t\t\tthis._position[1] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[1];\n\t\t}\n\t});\n\n\t/**\n\t *  The z position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name positionZ\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"positionZ\", {\n\t\tset : function(pos){\n\t\t\tthis._position[2] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[2];\n\t\t}\n\t});\n\n\t/**\n\t *  The x orientation of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name orientationX\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"orientationX\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[0] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[0];\n\t\t}\n\t});\n\n\t/**\n\t *  The y orientation of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name orientationY\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"orientationY\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[1] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[1];\n\t\t}\n\t});\n\n\t/**\n\t *  The z orientation of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name orientationZ\n\t */\n\tObject.defineProperty(Tone.Panner3D.prototype, \"orientationZ\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[2] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[2];\n\t\t}\n\t});\n\n\t/**\n\t *  Proxy a property on the panner to an exposed public propery\n\t *  @param  {String}  prop\n\t *  @private\n\t */\n\tTone.Panner3D._aliasProperty = function(prop){\n\t\tObject.defineProperty(Tone.Panner3D.prototype, prop, {\n\t\t\tset : function(val){\n\t\t\t\tthis._panner[prop] = val;\n\t\t\t},\n\t\t\tget : function(){\n\t\t\t\treturn this._panner[prop];\n\t\t\t}\n\t\t});\n\t};\n\n\t/**\n\t *  The panning model. Either \"equalpower\" or \"HRTF\".\n\t *  @type {String}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name panningModel\n\t */\n\tTone.Panner3D._aliasProperty(\"panningModel\");\n\n\t/**\n\t *  A reference distance for reducing volume as source move further from the listener\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name refDistance\n\t */\n\tTone.Panner3D._aliasProperty(\"refDistance\");\n\n\t/**\n\t *  Describes how quickly the volume is reduced as source moves away from listener.\n\t *  @type {Number}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name rolloffFactor\n\t */\n\tTone.Panner3D._aliasProperty(\"rolloffFactor\");\n\n\t/**\n\t *  The distance model used by,  \"linear\", \"inverse\", or \"exponential\".\n\t *  @type {String}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name distanceModel\n\t */\n\tTone.Panner3D._aliasProperty(\"distanceModel\");\n\n\t/**\n\t *  The angle, in degrees, inside of which there will be no volume reduction\n\t *  @type {Degrees}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name coneInnerAngle\n\t */\n\tTone.Panner3D._aliasProperty(\"coneInnerAngle\");\n\n\t/**\n\t *  The angle, in degrees, outside of which the volume will be reduced\n\t *  to a constant value of coneOuterGain\n\t *  @type {Degrees}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name coneOuterAngle\n\t */\n\tTone.Panner3D._aliasProperty(\"coneOuterAngle\");\n\n\t/**\n\t *  The gain outside of the coneOuterAngle\n\t *  @type {Gain}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name coneOuterGain\n\t */\n\tTone.Panner3D._aliasProperty(\"coneOuterGain\");\n\n\t/**\n\t *  The maximum distance between source and listener,\n\t *  after which the volume will not be reduced any further.\n\t *  @type {Positive}\n\t *  @memberOf Tone.Panner3D#\n\t *  @name maxDistance\n\t */\n\tTone.Panner3D._aliasProperty(\"maxDistance\");\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Panner3D} this\n\t */\n\tTone.Panner3D.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._panner.disconnect();\n\t\tthis._panner = null;\n\t\tthis._orientation = null;\n\t\tthis._position = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Panner3D;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Panner3D.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/ScaledEnvelope.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/Tone/component/ScaledEnvelope.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Envelope */ \"./node_modules/tone/Tone/component/Envelope.js\"), __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/Tone/signal/Scale.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.ScaledEnvelop is an envelope which can be scaled\n\t *         to any range. It's useful for applying an envelope\n\t *         to a frequency or any other non-NormalRange signal\n\t *         parameter.\n\t *\n\t *  @extends {Tone.Envelope}\n\t *  @constructor\n\t *  @param {Time|Object} [attack]\tthe attack time in seconds\n\t *  @param {Time} [decay]\tthe decay time in seconds\n\t *  @param {number} [sustain] \ta percentage (0-1) of the full amplitude\n\t *  @param {Time} [release]\tthe release time in seconds\n\t *  @example\n\t *  var scaledEnv = new Tone.ScaledEnvelope({\n\t *  \t\"attack\" : 0.2,\n\t *  \t\"min\" : 200,\n\t *  \t\"max\" : 2000\n\t *  });\n\t *  scaledEnv.connect(oscillator.frequency);\n\t */\n\tTone.ScaledEnvelope = function(){\n\n\t\t//get all of the defaults\n\t\tvar options = Tone.defaults(arguments, [\"attack\", \"decay\", \"sustain\", \"release\"], Tone.Envelope);\n\t\tTone.Envelope.call(this, options);\n\t\toptions = Tone.defaultArg(options, Tone.ScaledEnvelope.defaults);\n\n\t\t/**\n\t\t *  scale the incoming signal by an exponent\n\t\t *  @type {Tone.Pow}\n\t\t *  @private\n\t\t */\n\t\tthis._exp = this.output = new Tone.Pow(options.exponent);\n\n\t\t/**\n\t\t *  scale the signal to the desired range\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._scale = this.output = new Tone.Scale(options.min, options.max);\n\n\t\tthis._sig.chain(this._exp, this._scale);\n\t};\n\n\tTone.extend(Tone.ScaledEnvelope, Tone.Envelope);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t */\n\tTone.ScaledEnvelope.defaults = {\n\t\t\"min\" : 0,\n\t\t\"max\" : 1,\n\t\t\"exponent\" : 1\n\t};\n\n\t/**\n\t * The envelope's min output value. This is the value which it\n\t * starts at.\n\t * @memberOf Tone.ScaledEnvelope#\n\t * @type {number}\n\t * @name min\n\t */\n\tObject.defineProperty(Tone.ScaledEnvelope.prototype, \"min\", {\n\t\tget : function(){\n\t\t\treturn this._scale.min;\n\t\t},\n\t\tset : function(min){\n\t\t\tthis._scale.min = min;\n\t\t}\n\t});\n\n\t/**\n\t * The envelope's max output value. In other words, the value\n\t * at the peak of the attack portion of the envelope.\n\t * @memberOf Tone.ScaledEnvelope#\n\t * @type {number}\n\t * @name max\n\t */\n\tObject.defineProperty(Tone.ScaledEnvelope.prototype, \"max\", {\n\t\tget : function(){\n\t\t\treturn this._scale.max;\n\t\t},\n\t\tset : function(max){\n\t\t\tthis._scale.max = max;\n\t\t}\n\t});\n\n\t/**\n\t * The envelope's exponent value.\n\t * @memberOf Tone.ScaledEnvelope#\n\t * @type {number}\n\t * @name exponent\n\t */\n\tObject.defineProperty(Tone.ScaledEnvelope.prototype, \"exponent\", {\n\t\tget : function(){\n\t\t\treturn this._exp.value;\n\t\t},\n\t\tset : function(exp){\n\t\t\tthis._exp.value = exp;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.ScaledEnvelope} this\n\t */\n\tTone.ScaledEnvelope.prototype.dispose = function(){\n\t\tTone.Envelope.prototype.dispose.call(this);\n\t\tthis._scale.dispose();\n\t\tthis._scale = null;\n\t\tthis._exp.dispose();\n\t\tthis._exp = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.ScaledEnvelope;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/ScaledEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Solo.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/component/Solo.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Solo lets you isolate a specific audio stream. When\n\t *         an instance is set to `solo=true`, it will mute all other instances.\n\t *  @extends {Tone.AudioNode}\n\t *  @example\n\t * var soloA = new Tone.Solo()\n\t * var soloB = new Tone.Solo()\n\t * soloA.solo = true\n\t * //no audio will pass through soloB\n\t */\n\tTone.Solo = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"solo\"], Tone.Solo);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The input and output node\n\t\t *  @type  {Tone.Gain}\n\t\t */\n\t\tthis.input = this.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  A bound _soloed method\n\t\t *  @type  {Function}\n\t\t *  @private\n\t\t */\n\t\tthis._soloBind = this._soloed.bind(this);\n\n\t\t//listen for solo events class-wide.\n\t\tthis.context.on(\"solo\", this._soloBind);\n\t\t//set initially\n\t\tthis.solo = options.solo;\n\t};\n\n\tTone.extend(Tone.Solo, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @type  {Object}\n\t *  @static\n\t */\n\tTone.Solo.defaults = {\n\t\tsolo : false,\n\t};\n\n\t/**\n\t *  Isolates this instance and mutes all other instances of Tone.Solo.\n\t *  Only one instance can be soloed at a time. A soloed\n\t *  instance will report `solo=false` when another instance is soloed.\n\t *  @memberOf Tone.Solo#\n\t *  @type {Boolean}\n\t *  @name solo\n\t */\n\tObject.defineProperty(Tone.Solo.prototype, \"solo\", {\n\t\tget : function(){\n\t\t\treturn this._isSoloed();\n\t\t},\n\t\tset : function(solo){\n\t\t\tif (solo){\n\t\t\t\tthis._addSolo();\n\t\t\t} else {\n\t\t\t\tthis._removeSolo();\n\t\t\t}\n\t\t\tthis.context.emit(\"solo\", this);\n\t\t}\n\t});\n\n\t/**\n\t *  If the current instance is muted, i.e. another instance is soloed\n\t *  @memberOf Tone.Solo#\n\t *  @type {Boolean}\n\t *  @name muted\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Solo.prototype, \"muted\", {\n\t\tget : function(){\n\t\t\treturn this.input.gain.value === 0;\n\t\t}\n\t});\n\n\t/**\n\t * Add this to the soloed array\n\t * @private\n\t */\n\tTone.Solo.prototype._addSolo = function(){\n\t\tif (!Tone.isArray(this.context._currentSolo)){\n\t\t\tthis.context._currentSolo = [];\n\t\t}\n\t\tif (!this._isSoloed()){\n\t\t\tthis.context._currentSolo.push(this);\n\t\t}\n\t};\n\n\t/**\n\t * Remove this from the soloed array\n\t * @private\n\t */\n\tTone.Solo.prototype._removeSolo = function(){\n\t\tif (this._isSoloed()){\n\t\t\tvar index = this.context._currentSolo.indexOf(this);\n\t\t\tthis.context._currentSolo.splice(index, 1);\n\t\t}\n\t};\n\n\t/**\n\t * @return {Boolean} Is this on the soloed array\n\t * @private\n\t */\n\tTone.Solo.prototype._isSoloed = function(){\n\t\tif (Tone.isArray(this.context._currentSolo)){\n\t\t\treturn this.context._currentSolo.length !== 0 && this.context._currentSolo.indexOf(this) !== -1;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t};\n\n\t/**\n\t * @return {Boolean} Returns true if no one is soloed\n\t * @private\n\t */\n\tTone.Solo.prototype._noSolos = function(){\n\t\treturn !Tone.isArray(this.context._currentSolo) || this.context._currentSolo.length === 0;\n\t};\n\n\t/**\n\t *  Solo the current instance and unsolo all other instances.\n\t *  @param  {Tone.Solo}  instance  The instance which is being soloed/unsoloed.\n\t *  @private\n\t */\n\tTone.Solo.prototype._soloed = function(){\n\t\tif (this._isSoloed()){\n\t\t\tthis.input.gain.value = 1;\n\t\t} else if (this._noSolos()){\n\t\t\t//no one is soloed\n\t\t\tthis.input.gain.value = 1;\n\t\t} else {\n\t\t\tthis.input.gain.value = 0;\n\t\t}\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Solo}  this\n\t */\n\tTone.Solo.prototype.dispose = function(){\n\t\tthis.context.off(\"solo\", this._soloBind);\n\t\tthis._removeSolo();\n\t\tthis._soloBind = null;\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\treturn this;\n\t};\n\n\treturn Tone.Solo;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Solo.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Split.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/component/Split.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *\t@class  Tone.Split splits an incoming signal into left and right channels.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @example\n\t * var split = new Tone.Split();\n\t * stereoSignal.connect(split);\n\t */\n\tTone.Split = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(0, 2);\n\n\t\t/**\n\t\t *  @type {ChannelSplitterNode}\n\t\t *  @private\n\t\t */\n\t\tthis._splitter = this.input = this.context.createChannelSplitter(2);\n\n\t\t/**\n\t\t *  Left channel output.\n\t\t *  Alias for <code>output[0]</code>\n\t\t *  @type {Tone.Gain}\n\t\t */\n\t\tthis.left = this.output[0] = new Tone.Gain();\n\n\t\t/**\n\t\t *  Right channel output.\n\t\t *  Alias for <code>output[1]</code>\n\t\t *  @type {Tone.Gain}\n\t\t */\n\t\tthis.right = this.output[1] = new Tone.Gain();\n\n\t\t//connections\n\t\tthis._splitter.connect(this.left, 0, 0);\n\t\tthis._splitter.connect(this.right, 1, 0);\n\t};\n\n\tTone.extend(Tone.Split, Tone.AudioNode);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Split} this\n\t */\n\tTone.Split.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._splitter.disconnect();\n\t\tthis.left.dispose();\n\t\tthis.left = null;\n\t\tthis.right.dispose();\n\t\tthis.right = null;\n\t\tthis._splitter = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Split;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Split.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Volume.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/component/Volume.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Volume is a simple volume node, useful for creating a volume fader.\n\t *\n\t *  @extends {Tone.AudioNode}\n\t *  @constructor\n\t *  @param {Decibels} [volume=0] the initial volume\n\t *  @example\n\t * var vol = new Tone.Volume(-12);\n\t * instrument.chain(vol, Tone.Master);\n\t */\n\tTone.Volume = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"volume\"], Tone.Volume);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t * the output node\n\t\t * @type {GainNode}\n\t\t * @private\n\t\t */\n\t\tthis.output = this.input = new Tone.Gain(options.volume, Tone.Type.Decibels);\n\n\t\t/**\n\t\t * The unmuted volume\n\t\t * @type {Decibels}\n\t\t * @private\n\t\t */\n\t\tthis._unmutedVolume = options.volume;\n\n\t\t/**\n\t\t *  The volume control in decibels.\n\t\t *  @type {Decibels}\n\t\t *  @signal\n\t\t */\n\t\tthis.volume = this.output.gain;\n\n\t\tthis._readOnly(\"volume\");\n\n\t\t//set the mute initially\n\t\tthis.mute = options.mute;\n\t};\n\n\tTone.extend(Tone.Volume, Tone.AudioNode);\n\n\t/**\n\t *  Defaults\n\t *  @type  {Object}\n\t *  @const\n\t *  @static\n\t */\n\tTone.Volume.defaults = {\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.Volume#\n\t * @type {boolean}\n\t * @name mute\n\t * @example\n\t * //mute the output\n\t * volume.mute = true;\n\t */\n\tObject.defineProperty(Tone.Volume.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this.volume.value === -Infinity;\n\t\t},\n\t\tset : function(mute){\n\t\t\tif (!this.mute && mute){\n\t\t\t\tthis._unmutedVolume = this.volume.value;\n\t\t\t\t//maybe it should ramp here?\n\t\t\t\tthis.volume.value = -Infinity;\n\t\t\t} else if (this.mute && !mute){\n\t\t\t\tthis.volume.value = this._unmutedVolume;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Volume} this\n\t */\n\tTone.Volume.prototype.dispose = function(){\n\t\tthis.input.dispose();\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable(\"volume\");\n\t\tthis.volume.dispose();\n\t\tthis.volume = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Volume;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Volume.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/component/Waveform.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/component/Waveform.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Analyser */ \"./node_modules/tone/Tone/component/Analyser.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class  Get the current waveform data of the connected audio source.\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Number=} size The size of the FFT. Value must be a power of\n\t *                       two in the range 32 to 32768.\n\t */\n\tTone.Waveform = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"size\"], Tone.Waveform);\n\t\toptions.type = Tone.Analyser.Type.Waveform;\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The analyser node.\n\t\t *  @private\n\t\t *  @type {Tone.Analyser}\n\t\t */\n\t\tthis._analyser = this.input = this.output = new Tone.Analyser(options);\n\t};\n\n\tTone.extend(Tone.Waveform, Tone.AudioNode);\n\n\t/**\n\t *  The default values.\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.Waveform.defaults = {\n\t\t\"size\" : 1024\n\t};\n\n\t/**\n\t *  Gets the waveform of the audio source. Returns the waveform data\n\t *  of length [size](#size) as a Float32Array with values between -1 and 1.\n\t *  @returns {TypedArray}\n\t */\n\tTone.Waveform.prototype.getValue = function(){\n\t\treturn this._analyser.getValue();\n\t};\n\n\t/**\n\t *  The size of analysis. This must be a power of two in the range 32 to 32768.\n\t *  @memberOf Tone.Waveform#\n\t *  @type {Number}\n\t *  @name size\n\t */\n\tObject.defineProperty(Tone.Waveform.prototype, \"size\", {\n\t\tget : function(){\n\t\t\treturn this._analyser.size;\n\t\t},\n\t\tset : function(size){\n\t\t\tthis._analyser.size = size;\n\t\t}\n\t});\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Waveform}  this\n\t */\n\tTone.Waveform.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._analyser.dispose();\n\t\tthis._analyser = null;\n\t};\n\n\treturn Tone.Waveform;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/component/Waveform.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/control/CtrlInterpolate.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/Tone/control/CtrlInterpolate.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.CtrlInterpolate will interpolate between given values based\n\t *         on the \"index\" property. Passing in an array or object literal\n\t *         will interpolate each of the parameters. Note (i.e. \"C3\")\n\t *         and Time (i.e. \"4n + 2\") can be interpolated. All other values are\n\t *         assumed to be numbers. \n\t *  @example\n\t * var interp = new Tone.CtrlInterpolate([0, 2, 9, 4]);\n\t * interp.index = 0.75;\n\t * interp.value; //returns 1.5\n\t *\n\t *  @example\n\t * var interp = new Tone.CtrlInterpolate([\n\t * \t[2, 4, 5],\n\t * \t[9, 3, 2],\n\t * ]);\n\t * @param {Array} values The array of values to interpolate over\n\t * @param {Positive} index The initial interpolation index.\n\t * @extends {Tone}\n\t */\n\tTone.CtrlInterpolate = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"values\", \"index\"], Tone.CtrlInterpolate);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The values to interpolate between\n\t\t *  @type  {Array}\n\t\t */\n\t\tthis.values = options.values;\n\n\t\t/**\n\t\t *  The interpolated index between values. For example: a value of 1.5\n\t\t *  would interpolate equally between the value at index 1\n\t\t *  and the value at index 2. \n\t\t *  @example\n\t\t * interp.index = 0; \n\t\t * interp.value; //returns the value at 0\n\t\t * interp.index = 0.5;\n\t\t * interp.value; //returns the value between indices 0 and 1. \n\t\t *  @type  {Positive}\n\t\t */\n\t\tthis.index = options.index;\n\t};\n\n\tTone.extend(Tone.CtrlInterpolate);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.CtrlInterpolate.defaults = {\n\t\t\"index\" : 0,\n\t\t\"values\" : []\n\t};\n\n\t/**\n\t *  The current interpolated value based on the index\n\t *  @readOnly\n\t *  @memberOf Tone.CtrlInterpolate#\n\t *  @type {*}\n\t *  @name value\n\t */\n\tObject.defineProperty(Tone.CtrlInterpolate.prototype, \"value\", {\n\t\tget : function(){\n\t\t\tvar index = this.index;\n\t\t\tindex = Math.min(index, this.values.length - 1);\n\t\t\tvar lowerPosition = Math.floor(index);\n\t\t\tvar lower = this.values[lowerPosition];\n\t\t\tvar upper = this.values[Math.ceil(index)];\n\t\t\treturn this._interpolate(index - lowerPosition, lower, upper);\n\t\t}\n\t});\n\n\t/**\n\t *  Internal interpolation routine\n\t *  @param  {NormalRange}  index  The index between the lower and upper\n\t *  @param  {*}  lower \n\t *  @param  {*}  upper \n\t *  @return  {*}  The interpolated value\n\t *  @private\n\t */\n\tTone.CtrlInterpolate.prototype._interpolate = function(index, lower, upper){\n\t\tif (Tone.isArray(lower)){\n\t\t\tvar retArray = [];\n\t\t\tfor (var i = 0; i < lower.length; i++){\n\t\t\t\tretArray[i] = this._interpolate(index, lower[i], upper[i]);\n\t\t\t}\n\t\t\treturn retArray;\n\t\t} else if (Tone.isObject(lower)){\n\t\t\tvar retObj = {};\n\t\t\tfor (var attr in lower){\n\t\t\t\tretObj[attr] = this._interpolate(index, lower[attr], upper[attr]);\n\t\t\t}\n\t\t\treturn retObj;\n\t\t} else {\n\t\t\tlower = this._toNumber(lower);\n\t\t\tupper = this._toNumber(upper);\n\t\t\treturn (1 - index) * lower + index * upper;\n\t\t}\n\t};\n\n\t/**\n\t *  Convert from the given type into a number\n\t *  @param  {Number|String}  value\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.CtrlInterpolate.prototype._toNumber = function(val){\n\t\tif (Tone.isNumber(val)){\n\t\t\treturn val;\n\t\t} else {\n\t\t\t//otherwise assume that it's Time...\n\t\t\treturn this.toSeconds(val);\n\t\t}\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.CtrlInterpolate}  this\n\t */\n\tTone.CtrlInterpolate.prototype.dispose = function(){\n\t\tthis.values = null;\n\t};\n\n\treturn Tone.CtrlInterpolate;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/control/CtrlInterpolate.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/control/CtrlMarkov.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/control/CtrlMarkov.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.CtrlMarkov represents a Markov Chain where each call\n\t *         to Tone.CtrlMarkov.next will move to the next state. If the next\n\t *         state choice is an array, the next state is chosen randomly with\n\t *         even probability for all of the choices. For a weighted probability\n\t *         of the next choices, pass in an object with \"state\" and \"probability\" attributes. \n\t *         The probabilities will be normalized and then chosen. If no next options\n\t *         are given for the current state, the state will stay there. \n\t *  @extends {Tone}\n\t *  @example\n\t * var chain = new Tone.CtrlMarkov({\n\t * \t\"beginning\" : [\"end\", \"middle\"],\n\t * \t\"middle\" : \"end\"\n\t * });\n\t * chain.value = \"beginning\";\n\t * chain.next(); //returns \"end\" or \"middle\" with 50% probability\n\t *\n\t *  @example\n\t * var chain = new Tone.CtrlMarkov({\n\t * \t\"beginning\" : [{\"value\" : \"end\", \"probability\" : 0.8}, \n\t * \t\t\t\t\t{\"value\" : \"middle\", \"probability\" : 0.2}],\n\t * \t\"middle\" : \"end\"\n\t * });\n\t * chain.value = \"beginning\";\n\t * chain.next(); //returns \"end\" with 80% probability or \"middle\" with 20%.\n\t *  @param {Object} values An object with the state names as the keys\n\t *                         and the next state(s) as the values. \n\t */\n\tTone.CtrlMarkov = function(values, initial){\n\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The Markov values with states as the keys\n\t\t *  and next state(s) as the values. \n\t\t *  @type {Object}\n\t\t */\n\t\tthis.values = Tone.defaultArg(values, {});\n\t\t\n\t\t/**\n\t\t *  The current state of the Markov values. The next\n\t\t *  state will be evaluated and returned when Tone.CtrlMarkov.next\n\t\t *  is invoked.\n\t\t *  @type {String}\n\t\t */\n\t\tthis.value = Tone.defaultArg(initial, Object.keys(this.values)[0]);\n\t};\n\n\tTone.extend(Tone.CtrlMarkov);\n\n\t/**\n\t *  Returns the next state of the Markov values. \n\t *  @return  {String}\n\t */\n\tTone.CtrlMarkov.prototype.next = function(){\n\t\tif (this.values.hasOwnProperty(this.value)){\n\t\t\tvar next = this.values[this.value];\n\t\t\tif (Tone.isArray(next)){\n\t\t\t\tvar distribution = this._getProbDistribution(next);\n\t\t\t\tvar rand = Math.random();\n\t\t\t\tvar total = 0;\n\t\t\t\tfor (var i = 0; i < distribution.length; i++){\n\t\t\t\t\tvar dist = distribution[i];\n\t\t\t\t\tif (rand > total && rand < total + dist){\n\t\t\t\t\t\tvar chosen = next[i];\n\t\t\t\t\t\tif (Tone.isObject(chosen)){\n\t\t\t\t\t\t\tthis.value = chosen.value;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tthis.value = chosen;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttotal += dist;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis.value = next;\n\t\t\t}\n\t\t} \n\t\treturn this.value;\n\t};\n\n\t/**\n\t *  Choose randomly from an array weighted options in the form \n\t *  {\"state\" : string, \"probability\" : number} or an array of values\n\t *  @param  {Array}  options \n\t *  @return  {Array}  The randomly selected choice\n\t *  @private\n\t */\n\tTone.CtrlMarkov.prototype._getProbDistribution = function(options){\n\t\tvar distribution = [];\n\t\tvar total = 0;\n\t\tvar needsNormalizing = false;\n\t\tfor (var i = 0; i < options.length; i++){\n\t\t\tvar option = options[i];\n\t\t\tif (Tone.isObject(option)){\n\t\t\t\tneedsNormalizing = true;\n\t\t\t\tdistribution[i] = option.probability;\n\t\t\t} else {\n\t\t\t\tdistribution[i] = 1 / options.length;\n\t\t\t}\n\t\t\ttotal += distribution[i];\n\t\t}\n\t\tif (needsNormalizing){\n\t\t\t//normalize the values\n\t\t\tfor (var j = 0; j < distribution.length; j++){\n\t\t\t\tdistribution[j] = distribution[j] / total;\n\t\t\t}\n\t\t}\n\t\treturn distribution;\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.CtrlMarkov}  this\n\t */\n\tTone.CtrlMarkov.prototype.dispose = function(){\n\t\tthis.values = null;\n\t};\n\n\treturn Tone.CtrlMarkov;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/control/CtrlMarkov.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/control/CtrlPattern.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/control/CtrlPattern.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Generate patterns from an array of values.\n\t *         Has a number of arpeggiation and randomized\n\t *         selection patterns. \n\t *           <ul>\n\t *  \t        <li>\"up\" - cycles upward</li>\n\t *  \t\t\t<li>\"down\" - cycles downward</li>\n\t *  \t\t\t<li>\"upDown\" - up then and down</li>\n\t *  \t\t\t<li>\"downUp\" - cycles down then and up</li>\n\t *  \t\t\t<li>\"alternateUp\" - jump up two and down one</li>\n\t *  \t\t\t<li>\"alternateDown\" - jump down two and up one</li>\n\t *  \t\t\t<li>\"random\" - randomly select an index</li>\n\t *  \t\t\t<li>\"randomWalk\" - randomly moves one index away from the current position</li>\n\t *  \t\t\t<li>\"randomOnce\" - randomly select an index without repeating until all values have been chosen.</li>\n\t *     \t\t</ul>\n\t *  @param  {Array}  values   An array of options to choose from.\n\t *  @param  {Tone.CtrlPattern.Type=}  type  The name of the pattern.\n\t *  @extends {Tone}\n\t */\n\tTone.CtrlPattern = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"values\", \"type\"], Tone.CtrlPattern);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The array of values to arpeggiate over\n\t\t *  @type {Array}\n\t\t */\n\t\tthis.values = options.values;\n\t\t\n\t\t/**\n\t\t *  The current position in the values array\n\t\t *  @type  {Number}\n\t\t */\n\t\tthis.index = 0;\n\n\t\t/**\n\t\t *  The type placeholder\n\t\t *  @type {Tone.CtrlPattern.Type}\n\t\t *  @private\n\t\t */\n\t\tthis._type = null;\n\n\t\t/**\n\t\t *  Shuffled values for the RandomOnce type\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._shuffled = null;\n\n\t\t/**\n\t\t *  The direction of the movement\n\t\t *  @type {String}\n\t\t *  @private\n\t\t */\n\t\tthis._direction = null;\n\n\t\tthis.type = options.type;\n\t};\n\n\tTone.extend(Tone.CtrlPattern);\n\n\t/**\n\t *  The Control Patterns\n\t *  @type  {Object}\n\t *  @static\n\t */\n\tTone.CtrlPattern.Type = {\n\t\tUp : \"up\",\n\t\tDown : \"down\",\n\t\tUpDown : \"upDown\",\n\t\tDownUp : \"downUp\",\n\t\tAlternateUp : \"alternateUp\",\n\t\tAlternateDown : \"alternateDown\",\n\t\tRandom : \"random\",\n\t\tRandomWalk : \"randomWalk\",\n\t\tRandomOnce : \"randomOnce\",\n\t};\n\n\t/**\n\t *  The default values. \n\t *  @type  {Object}\n\t */\n\tTone.CtrlPattern.defaults = {\n\t\t\"type\" : Tone.CtrlPattern.Type.Up,\n\t\t\"values\" : []\n\t};\n\n\t/**\n\t *  The value at the current index of the pattern.\n\t *  @readOnly\n\t *  @memberOf Tone.CtrlPattern#\n\t *  @type {*}\n\t *  @name value\n\t */\n\tObject.defineProperty(Tone.CtrlPattern.prototype, \"value\", {\n\t\tget : function(){\n\t\t\t//some safeguards\n\t\t\tif (this.values.length === 0){\n\t\t\t\treturn;\n\t\t\t} else if (this.values.length === 1){\n\t\t\t\treturn this.values[0];\n\t\t\t} \n\t\t\tthis.index = Math.min(this.index, this.values.length - 1);\n\t\t\tvar val = this.values[this.index];\n\t\t\tif (this.type === Tone.CtrlPattern.Type.RandomOnce){\n\t\t\t\tif (this.values.length !== this._shuffled.length){\n\t\t\t\t\tthis._shuffleValues();\n\t\t\t\t}\n\t\t\t\tval = this.values[this._shuffled[this.index]];\n\t\t\t}\n\t\t\treturn val;\n\t\t}\n\t});\n\n\t/**\n\t *  The pattern used to select the next\n\t *  item from the values array\n\t *  @memberOf Tone.CtrlPattern#\n\t *  @type {Tone.CtrlPattern.Type}\n\t *  @name type\n\t */\n\tObject.defineProperty(Tone.CtrlPattern.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._type = type;\n\t\t\tthis._shuffled = null;\n\n\t\t\t//the first index\n\t\t\tif (this._type === Tone.CtrlPattern.Type.Up ||\n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.UpDown || \n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.RandomOnce ||\n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.AlternateUp){\n\t\t\t\tthis.index = 0;\n\t\t\t} else if (this._type === Tone.CtrlPattern.Type.Down ||\n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.DownUp || \n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.AlternateDown){\n\t\t\t\tthis.index = this.values.length - 1;\n\t\t\t}\n\n\t\t\t//the direction\n\t\t\tif (this._type === Tone.CtrlPattern.Type.UpDown || \n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.AlternateUp){\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Up;\n\t\t\t} else if (this._type === Tone.CtrlPattern.Type.DownUp || \n\t\t\t\t\tthis._type === Tone.CtrlPattern.Type.AlternateDown){\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Down;\n\t\t\t}\n\n\t\t\t//randoms\n\t\t\tif (this._type === Tone.CtrlPattern.Type.RandomOnce){\n\t\t\t\tthis._shuffleValues();\n\t\t\t} else if (this._type === Tone.CtrlPattern.Random){\n\t\t\t\tthis.index = Math.floor(Math.random() * this.values.length);\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Return the next value given the current position\n\t *  and pattern.\n\t *  @return {*} The next value\n\t */\n\tTone.CtrlPattern.prototype.next = function(){\n\t\t\n\t\tvar type = this.type;\n\n\t\t//choose the next index\n\t\tif (type === Tone.CtrlPattern.Type.Up){\n\t\t\tthis.index++;\n\t\t\tif (this.index >= this.values.length){\n\t\t\t\tthis.index = 0;\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.Down){\n\t\t\tthis.index--;\n\t\t\tif (this.index < 0){\n\t\t\t\tthis.index = this.values.length - 1;\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.UpDown ||\n\t\t\t\t\ttype === Tone.CtrlPattern.Type.DownUp){\n\t\t\tif (this._direction === Tone.CtrlPattern.Type.Up){\n\t\t\t\tthis.index++;\n\t\t\t} else {\n\t\t\t\tthis.index--;\n\t\t\t}\n\t\t\tif (this.index < 0){\n\t\t\t\tthis.index = 1;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Up;\n\t\t\t} else if (this.index >= this.values.length){\n\t\t\t\tthis.index = this.values.length - 2;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Down;\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.Random){\n\t\t\tthis.index = Math.floor(Math.random() * this.values.length);\n\t\t} else if (type === Tone.CtrlPattern.Type.RandomWalk){\n\t\t\tif (Math.random() < 0.5){\n\t\t\t\tthis.index--;\n\t\t\t\tthis.index = Math.max(this.index, 0);\n\t\t\t} else {\n\t\t\t\tthis.index++;\n\t\t\t\tthis.index = Math.min(this.index, this.values.length - 1);\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.RandomOnce){\n\t\t\tthis.index++;\n\t\t\tif (this.index >= this.values.length){\n\t\t\t\tthis.index = 0;\n\t\t\t\t//reshuffle the values for next time\n\t\t\t\tthis._shuffleValues();\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.AlternateUp){\n\t\t\tif (this._direction === Tone.CtrlPattern.Type.Up){\n\t\t\t\tthis.index += 2;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Down;\n\t\t\t} else {\n\t\t\t\tthis.index -= 1;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Up;\n\t\t\t}\n\t\t\tif (this.index >= this.values.length){\n\t\t\t\tthis.index = 0;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Up;\n\t\t\t}\n\t\t} else if (type === Tone.CtrlPattern.Type.AlternateDown){\n\t\t\tif (this._direction === Tone.CtrlPattern.Type.Up){\n\t\t\t\tthis.index += 1;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Down;\n\t\t\t} else {\n\t\t\t\tthis.index -= 2;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Up;\n\t\t\t}\n\t\t\tif (this.index < 0){\n\t\t\t\tthis.index = this.values.length - 1;\n\t\t\t\tthis._direction = Tone.CtrlPattern.Type.Down;\n\t\t\t}\n\t\t}\n\t\treturn this.value;\n\t};\n\n\t/**\n\t *  Shuffles the values and places the results into the _shuffled\n\t *  @private\n\t */\n\tTone.CtrlPattern.prototype._shuffleValues = function(){\n\t\tvar copy = [];\n\t\tthis._shuffled = [];\n\t\tfor (var i = 0; i < this.values.length; i++){\n\t\t\tcopy[i] = i;\n\t\t}\n\t\twhile (copy.length > 0){\n\t\t\tvar randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);\n\t\t\tthis._shuffled.push(randVal[0]);\n\t\t}\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @returns {Tone.CtrlPattern} this\n\t */\n\tTone.CtrlPattern.prototype.dispose = function(){\n\t\tthis._shuffled = null;\n\t\tthis.values = null;\n\t};\n\n\treturn Tone.CtrlPattern;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/control/CtrlPattern.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/control/CtrlRandom.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/control/CtrlRandom.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Choose a random value.\n\t *  @extends {Tone}\n\t *  @example\n\t * var randomWalk = new Tone.CtrlRandom({\n\t * \t\"min\" : 0,\n\t * \t\"max\" : 10,\n\t * \t\"integer\" : true\n\t * });\n\t * randomWalk.eval();\n\t *\n\t *  @param {Number|Time=} min The minimum return value.\n\t *  @param {Number|Time=} max The maximum return value.\n\t */\n\tTone.CtrlRandom = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"min\", \"max\"], Tone.CtrlRandom);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The minimum return value\n\t\t *  @type  {Number|Time}\n\t\t */\n\t\tthis.min = options.min;\n\n\t\t/**\n\t\t *  The maximum return value\n\t\t *  @type  {Number|Time}\n\t\t */\n\t\tthis.max = options.max;\n\n\t\t/**\n\t\t *  If the return value should be an integer\n\t\t *  @type  {Boolean}\n\t\t */\n\t\tthis.integer = options.integer;\n\t};\n\n\tTone.extend(Tone.CtrlRandom);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.CtrlRandom.defaults = {\n\t\t\"min\" : 0,\n\t\t\"max\" : 1,\n\t\t\"integer\" : false\n\t};\n\n\t/**\n\t *  Return a random value between min and max. \n\t *  @readOnly\n\t *  @memberOf Tone.CtrlRandom#\n\t *  @type {*}\n\t *  @name value\n\t */\n\tObject.defineProperty(Tone.CtrlRandom.prototype, \"value\", {\n\t\tget : function(){\n\t\t\tvar min = this.toSeconds(this.min);\n\t\t\tvar max = this.toSeconds(this.max);\n\t\t\tvar rand = Math.random(); \n\t\t\tvar val = rand * min + (1 - rand) * max;\n\t\t\tif (this.integer){\n\t\t\t\tval = Math.floor(val);\n\t\t\t}\n\t\t\treturn val;\n\t\t}\n\t});\n\n\treturn Tone.CtrlRandom;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/control/CtrlRandom.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/AudioNode.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/core/AudioNode.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.AudioNode is the base class for classes which process audio.\n\t *         AudioNodes have inputs and outputs.\n\t *  @param\t{AudioContext=} context\tThe audio context to use with the class\n\t *  @extends {Tone}\n\t */\n\tTone.AudioNode = function(){\n\t\tTone.call(this);\n\n\t\t//use the default context if one is not passed in\n\t\tvar options = Tone.defaults(arguments, [\"context\"], {\n\t\t\t\"context\" : Tone.context\n\t\t});\n\n\t\t/**\n\t\t * The AudioContext of this instance\n\t\t * @private\n\t\t * @type {AudioContext}\n\t\t */\n\t\tthis._context = options.context;\n\t};\n\n\tTone.extend(Tone.AudioNode);\n\n\t/**\n\t * Get the audio context belonging to this instance.\n\t * @type {Tone.Context}\n\t * @memberOf Tone.AudioNode#\n\t * @name context\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"context\", {\n\t\tget : function(){\n\t\t\treturn this._context;\n\t\t}\n\t});\n\n\t/**\n\t *  Create input and outputs for this object.\n\t *  @param  {Number}  [input=0]   The number of inputs\n\t *  @param  {Number}  [outputs=0]  The number of outputs\n\t *  @return  {Tone.AudioNode}  this\n\t *  @private\n\t */\n\tTone.AudioNode.prototype.createInsOuts = function(inputs, outputs){\n\n\t\tif (inputs === 1){\n\t\t\tthis.input = this.context.createGain();\n\t\t} else if (inputs > 1){\n\t\t\tthis.input = new Array(inputs);\n\t\t}\n\n\t\tif (outputs === 1){\n\t\t\tthis.output = this.context.createGain();\n\t\t} else if (outputs > 1){\n\t\t\tthis.output = new Array(outputs);\n\t\t}\n\t};\n\n\t/**\n\t *  channelCount is the number of channels used when up-mixing and down-mixing\n\t *  connections to any inputs to the node. The default value is 2 except for\n\t *  specific nodes where its value is specially determined.\n\t *\n\t *  @memberof Tone.AudioNode#\n\t *  @type {Number}\n\t *  @name channelCount\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"channelCount\", {\n\t\tget : function(){\n\t\t\treturn this.output.channelCount;\n\t\t},\n\t\tset : function(c){\n\t\t\treturn this.output.channelCount = c;\n\t\t}\n\t});\n\n\t/**\n\t *  channelCountMode determines how channels will be counted when up-mixing and\n\t *  down-mixing connections to any inputs to the node.\n\t *  The default value is \"max\". This attribute has no effect for nodes with no inputs.\n\t *  @memberof Tone.AudioNode#\n\t *  @type {String}\n\t *  @name channelCountMode\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"channelCountMode\", {\n\t\tget : function(){\n\t\t\treturn this.output.channelCountMode;\n\t\t},\n\t\tset : function(m){\n\t\t\treturn this.output.channelCountMode = m;\n\t\t}\n\t});\n\n\t/**\n\t *  channelInterpretation determines how individual channels will be treated\n\t *  when up-mixing and down-mixing connections to any inputs to the node.\n\t *  The default value is \"speakers\".\n\t *  @memberof Tone.AudioNode#\n\t *  @type {String}\n\t *  @name channelInterpretation\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"channelInterpretation\", {\n\t\tget : function(){\n\t\t\treturn this.output.channelInterpretation;\n\t\t},\n\t\tset : function(i){\n\t\t\treturn this.output.channelInterpretation = i;\n\t\t}\n\t});\n\n\t/**\n\t *  The number of inputs feeding into the AudioNode.\n\t *  For source nodes, this will be 0.\n\t *  @type {Number}\n\t *  @name numberOfInputs\n\t *  @memberof Tone.AudioNode#\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"numberOfInputs\", {\n\t\tget : function(){\n\t\t\tif (this.input){\n\t\t\t\tif (Tone.isArray(this.input)){\n\t\t\t\t\treturn this.input.length;\n\t\t\t\t} else {\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The number of outputs coming out of the AudioNode.\n\t *  @type {Number}\n\t *  @name numberOfOutputs\n\t *  @memberof Tone.AudioNode#\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.AudioNode.prototype, \"numberOfOutputs\", {\n\t\tget : function(){\n\t\t\tif (this.output){\n\t\t\t\tif (Tone.isArray(this.output)){\n\t\t\t\t\treturn this.output.length;\n\t\t\t\t} else {\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  connect the output of a ToneNode to an AudioParam, AudioNode, or ToneNode\n\t *  @param  {Tone | AudioParam | AudioNode} unit\n\t *  @param {number} [outputNum=0] optionally which output to connect from\n\t *  @param {number} [inputNum=0] optionally which input to connect to\n\t *  @returns {Tone.AudioNode} this\n\t */\n\tTone.AudioNode.prototype.connect = function(unit, outputNum, inputNum){\n\t\tif (Tone.isArray(this.output)){\n\t\t\toutputNum = Tone.defaultArg(outputNum, 0);\n\t\t\tthis.output[outputNum].connect(unit, 0, inputNum);\n\t\t} else {\n\t\t\tthis.output.connect(unit, outputNum, inputNum);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  disconnect the output\n\t *  @param {Number|AudioNode} output Either the output index to disconnect\n\t *                                   if the output is an array, or the\n\t *                                   node to disconnect from.\n\t *  @returns {Tone.AudioNode} this\n\t */\n\tTone.AudioNode.prototype.disconnect = function(destination, outputNum, inputNum){\n\t\tif (Tone.isArray(this.output)){\n\t\t\tif (Tone.isNumber(destination)){\n\t\t\t\tthis.output[destination].disconnect();\n\t\t\t} else {\n\t\t\t\toutputNum = Tone.defaultArg(outputNum, 0);\n\t\t\t\tthis.output[outputNum].disconnect(destination, 0, inputNum);\n\t\t\t}\n\t\t} else {\n\t\t\tthis.output.disconnect.apply(this.output, arguments);\n\t\t}\n\t};\n\n\t/**\n\t *  Connect the output of this node to the rest of the nodes in series.\n\t *  @example\n\t *  //connect a node to an effect, panVol and then to the master output\n\t *  node.chain(effect, panVol, Tone.Master);\n\t *  @param {...AudioParam|Tone|AudioNode} nodes\n\t *  @returns {Tone.AudioNode} this\n\t */\n\tTone.AudioNode.prototype.chain = function(){\n\t\tvar currentUnit = this;\n\t\tfor (var i = 0; i < arguments.length; i++){\n\t\t\tvar toUnit = arguments[i];\n\t\t\tcurrentUnit.connect(toUnit);\n\t\t\tcurrentUnit = toUnit;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  connect the output of this node to the rest of the nodes in parallel.\n\t *  @param {...AudioParam|Tone|AudioNode} nodes\n\t *  @returns {Tone.AudioNode} this\n\t */\n\tTone.AudioNode.prototype.fan = function(){\n\t\tfor (var i = 0; i < arguments.length; i++){\n\t\t\tthis.connect(arguments[i]);\n\t\t}\n\t\treturn this;\n\t};\n\n\tif (Tone.global.AudioNode){\n\t\t//give native nodes chain and fan methods\n\t\tAudioNode.prototype.chain = Tone.AudioNode.prototype.chain;\n\t\tAudioNode.prototype.fan = Tone.AudioNode.prototype.fan;\n\t}\n\n\t/**\n\t * Dispose and disconnect\n\t * @return {Tone.AudioNode} this\n\t */\n\tTone.AudioNode.prototype.dispose = function(){\n\t\tif (Tone.isDefined(this.input)){\n\t\t\tif (this.input instanceof AudioNode){\n\t\t\t\tthis.input.disconnect();\n\t\t\t}\n\t\t\tthis.input = null;\n\t\t}\n\t\tif (Tone.isDefined(this.output)){\n\t\t\tif (this.output instanceof AudioNode){\n\t\t\t\tthis.output.disconnect();\n\t\t\t}\n\t\t\tthis.output = null;\n\t\t}\n\t\tthis._context = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AudioNode;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/AudioNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Buffer.js":
/*!***********************************************!*\
  !*** ./node_modules/tone/Tone/core/Buffer.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Emitter */ \"./node_modules/tone/Tone/core/Emitter.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../shim/AudioBuffer */ \"./node_modules/tone/Tone/shim/AudioBuffer.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Buffer loading and storage. Tone.Buffer is used internally by all\n\t *          classes that make requests for audio files such as Tone.Player,\n\t *          Tone.Sampler and Tone.Convolver.\n\t *\n\t *          Aside from load callbacks from individual buffers, Tone.Buffer\n\t *  \t\tprovides events which keep track of the loading progress\n\t *  \t\tof _all_ of the buffers. These are Tone.Buffer.on(\"load\" / \"progress\" / \"error\")\n\t *\n\t *  @constructor\n\t *  @extends {Tone}\n\t *  @param {AudioBuffer|String} url The url to load, or the audio buffer to set.\n\t *  @param {Function=} onload A callback which is invoked after the buffer is loaded.\n\t *                            It's recommended to use `Tone.Buffer.on('load', callback)` instead\n\t *                            since it will give you a callback when _all_ buffers are loaded.\n\t *  @param {Function=} onerror The callback to invoke if there is an error\n\t *  @example\n\t * var buffer = new Tone.Buffer(\"path/to/sound.mp3\", function(){\n\t * \t//the buffer is now available.\n\t * \tvar buff = buffer.get();\n\t * });\n\t *  @example\n\t * //can load provide fallback extension types if the first type is not supported.\n\t * var buffer = new Tone.Buffer(\"path/to/sound.[mp3|ogg|wav]\");\n\t */\n\tTone.Buffer = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"url\", \"onload\", \"onerror\"], Tone.Buffer);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  stores the loaded AudioBuffer\n\t\t *  @type {AudioBuffer}\n\t\t *  @private\n\t\t */\n\t\tthis._buffer = null;\n\n\t\t/**\n\t\t *  indicates if the buffer should be reversed or not\n\t\t *  @type {Boolean}\n\t\t *  @private\n\t\t */\n\t\tthis._reversed = options.reverse;\n\n\t\t/**\n\t\t *  The XHR\n\t\t *  @type  {XMLHttpRequest}\n\t\t *  @private\n\t\t */\n\t\tthis._xhr = null;\n\n\t\t/**\n\t\t * Private callback when the buffer is loaded.\n\t\t * @type {Function}\n\t\t * @private\n\t\t */\n\t\tthis.onload = Tone.noOp;\n\n\t\tif (options.url instanceof AudioBuffer || options.url instanceof Tone.Buffer){\n\t\t\tthis.set(options.url);\n\t\t\tif (!this.loaded){\n\t\t\t\tthis.onload = options.onload;\n\t\t\t}\n\t\t} else if (Tone.isString(options.url)){\n\t\t\tthis.load(options.url).then(options.onload).catch(options.onerror);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Buffer);\n\n\t/**\n\t *  the default parameters\n\t *  @type {Object}\n\t */\n\tTone.Buffer.defaults = {\n\t\t\"url\" : undefined,\n\t\t\"reverse\" : false,\n\t\t\"onload\" : Tone.noOp,\n\t\t\"onerror\" : Tone.noOp\n\t};\n\n\t/**\n\t *  Pass in an AudioBuffer or Tone.Buffer to set the value\n\t *  of this buffer.\n\t *  @param {AudioBuffer|Tone.Buffer} buffer the buffer\n\t *  @returns {Tone.Buffer} this\n\t */\n\tTone.Buffer.prototype.set = function(buffer){\n\t\tif (buffer instanceof Tone.Buffer){\n\t\t\t//if it's loaded, set it\n\t\t\tif (buffer.loaded){\n\t\t\t\tthis._buffer = buffer.get();\n\t\t\t} else {\n\t\t\t\t//otherwise when it's loaded, invoke it's callback\n\t\t\t\tbuffer.onload = function(){\n\t\t\t\t\tthis.set(buffer);\n\t\t\t\t\tthis.onload(this);\n\t\t\t\t}.bind(this);\n\t\t\t}\n\t\t} else {\n\t\t\tthis._buffer = buffer;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  @return {AudioBuffer} The audio buffer stored in the object.\n\t */\n\tTone.Buffer.prototype.get = function(){\n\t\treturn this._buffer;\n\t};\n\n\t/**\n\t *  Makes an xhr reqest for the selected url then decodes\n\t *  the file as an audio buffer. Invokes\n\t *  the callback once the audio buffer loads.\n\t *  @param {String} url The url of the buffer to load.\n\t *                      filetype support depends on the\n\t *                      browser.\n\t *  @returns {Promise} returns a Promise which resolves with the Tone.Buffer\n\t */\n\tTone.Buffer.prototype.load = function(url, onload, onerror){\n\n\t\tvar promise = new Promise(function(load, error){\n\n\t\t\tthis._xhr = Tone.Buffer.load(url,\n\n\t\t\t\t//success\n\t\t\t\tfunction(buff){\n\t\t\t\t\tthis._xhr = null;\n\t\t\t\t\tthis.set(buff);\n\t\t\t\t\tload(this);\n\t\t\t\t\tthis.onload(this);\n\t\t\t\t\tif (onload){\n\t\t\t\t\t\tonload(this);\n\t\t\t\t\t}\n\t\t\t\t}.bind(this),\n\n\t\t\t\t//error\n\t\t\t\tfunction(err){\n\t\t\t\t\tthis._xhr = null;\n\t\t\t\t\terror(err);\n\t\t\t\t\tif (onerror){\n\t\t\t\t\t\tonerror(err);\n\t\t\t\t\t}\n\t\t\t\t}.bind(this));\n\n\t\t}.bind(this));\n\n\t\treturn promise;\n\t};\n\n\t/**\n\t *  dispose and disconnect\n\t *  @returns {Tone.Buffer} this\n\t */\n\tTone.Buffer.prototype.dispose = function(){\n\t\tTone.prototype.dispose.call(this);\n\t\tthis._buffer = null;\n\t\tif (this._xhr){\n\t\t\tTone.Buffer._removeFromDownloadQueue(this._xhr);\n\t\t\tthis._xhr.abort();\n\t\t\tthis._xhr = null;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * If the buffer is loaded or not\n\t * @memberOf Tone.Buffer#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Buffer.prototype, \"loaded\", {\n\t\t\"get\" : function(){\n\t\t\treturn this.length > 0;\n\t\t},\n\t});\n\n\t/**\n\t * The duration of the buffer.\n\t * @memberOf Tone.Buffer#\n\t * @type {Number}\n\t * @name duration\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Buffer.prototype, \"duration\", {\n\t\t\"get\" : function(){\n\t\t\tif (this._buffer){\n\t\t\t\treturn this._buffer.duration;\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t},\n\t});\n\n\t/**\n\t * The length of the buffer in samples\n\t * @memberOf Tone.Buffer#\n\t * @type {Number}\n\t * @name length\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Buffer.prototype, \"length\", {\n\t\t\"get\" : function(){\n\t\t\tif (this._buffer){\n\t\t\t\treturn this._buffer.length;\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t},\n\t});\n\n\t/**\n\t * The number of discrete audio channels. Returns 0 if no buffer\n\t * is loaded.\n\t * @memberOf Tone.Buffer#\n\t * @type {Number}\n\t * @name numberOfChannels\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Buffer.prototype, \"numberOfChannels\", {\n\t\t\"get\" : function(){\n\t\t\tif (this._buffer){\n\t\t\t\treturn this._buffer.numberOfChannels;\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t},\n\t});\n\n\t/**\n\t *  Set the audio buffer from the array. To create a multichannel AudioBuffer,\n\t *  pass in a multidimensional array.\n\t *  @param {Float32Array} array The array to fill the audio buffer\n\t *  @return {Tone.Buffer} this\n\t */\n\tTone.Buffer.prototype.fromArray = function(array){\n\t\tvar isMultidimensional = array[0].length > 0;\n\t\tvar channels = isMultidimensional ? array.length : 1;\n\t\tvar len = isMultidimensional ? array[0].length : array.length;\n\t\tvar buffer = this.context.createBuffer(channels, len, this.context.sampleRate);\n\t\tif (!isMultidimensional && channels === 1){\n\t\t\tarray = [array];\n\t\t}\n\t\tfor (var c = 0; c < channels; c++){\n\t\t\tbuffer.copyToChannel(array[c], c);\n\t\t}\n\t\tthis._buffer = buffer;\n\t\treturn this;\n\t};\n\n\t/**\n\t * \tSums muliple channels into 1 channel\n\t *  @param {Number=} channel Optionally only copy a single channel from the array.\n\t *  @return {Array}\n\t */\n\tTone.Buffer.prototype.toMono = function(chanNum){\n\t\tif (Tone.isNumber(chanNum)){\n\t\t\tthis.fromArray(this.toArray(chanNum));\n\t\t} else {\n\t\t\tvar outputArray = new Float32Array(this.length);\n\t\t\tvar numChannels = this.numberOfChannels;\n\t\t\tfor (var channel = 0; channel < numChannels; channel++){\n\t\t\t\tvar channelArray = this.toArray(channel);\n\t\t\t\tfor (var i = 0; i < channelArray.length; i++){\n\t\t\t\t\toutputArray[i] += channelArray[i];\n\t\t\t\t}\n\t\t\t}\n\t\t\t//divide by the number of channels\n\t\t\toutputArray = outputArray.map(function(sample){\n\t\t\t\treturn sample / numChannels;\n\t\t\t});\n\t\t\tthis.fromArray(outputArray);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * \tGet the buffer as an array. Single channel buffers will return a 1-dimensional\n\t * \tFloat32Array, and multichannel buffers will return multidimensional arrays.\n\t *  @param {Number=} channel Optionally only copy a single channel from the array.\n\t *  @return {Array}\n\t */\n\tTone.Buffer.prototype.toArray = function(channel){\n\t\tif (Tone.isNumber(channel)){\n\t\t\treturn this.getChannelData(channel);\n\t\t} else if (this.numberOfChannels === 1){\n\t\t\treturn this.toArray(0);\n\t\t} else {\n\t\t\tvar ret = [];\n\t\t\tfor (var c = 0; c < this.numberOfChannels; c++){\n\t\t\t\tret[c] = this.getChannelData(c);\n\t\t\t}\n\t\t\treturn ret;\n\t\t}\n\t};\n\n\t/**\n\t *  Returns the Float32Array representing the PCM audio data for the specific channel.\n\t *  @param  {Number}  channel  The channel number to return\n\t *  @return  {Float32Array}  The audio as a TypedArray\n\t */\n\tTone.Buffer.prototype.getChannelData = function(channel){\n\t\treturn this._buffer.getChannelData(channel);\n\t};\n\n\t/**\n\t *  Cut a subsection of the array and return a buffer of the\n\t *  subsection. Does not modify the original buffer\n\t *  @param {Time} start The time to start the slice\n\t *  @param {Time=} end The end time to slice. If none is given\n\t *                     will default to the end of the buffer\n\t *  @return {Tone.Buffer} this\n\t */\n\tTone.Buffer.prototype.slice = function(start, end){\n\t\tend = Tone.defaultArg(end, this.duration);\n\t\tvar startSamples = Math.floor(this.context.sampleRate * this.toSeconds(start));\n\t\tvar endSamples = Math.floor(this.context.sampleRate * this.toSeconds(end));\n\t\tvar replacement = [];\n\t\tfor (var i = 0; i < this.numberOfChannels; i++){\n\t\t\treplacement[i] = this.toArray(i).slice(startSamples, endSamples);\n\t\t}\n\t\tvar retBuffer = new Tone.Buffer().fromArray(replacement);\n\t\treturn retBuffer;\n\t};\n\n\t/**\n\t *  Reverse the buffer.\n\t *  @private\n\t *  @return {Tone.Buffer} this\n\t */\n\tTone.Buffer.prototype._reverse = function(){\n\t\tif (this.loaded){\n\t\t\tfor (var i = 0; i < this.numberOfChannels; i++){\n\t\t\t\tArray.prototype.reverse.call(this.getChannelData(i));\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Reverse the buffer.\n\t * @memberOf Tone.Buffer#\n\t * @type {Boolean}\n\t * @name reverse\n\t */\n\tObject.defineProperty(Tone.Buffer.prototype, \"reverse\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._reversed;\n\t\t},\n\t\t\"set\" : function(rev){\n\t\t\tif (this._reversed !== rev){\n\t\t\t\tthis._reversed = rev;\n\t\t\t\tthis._reverse();\n\t\t\t}\n\t\t},\n\t});\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// STATIC METHODS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t//statically inherits Emitter methods\n\tTone.Emitter.mixin(Tone.Buffer);\n\n\t/**\n\t *  the static queue for all of the xhr requests\n\t *  @type {Array}\n\t *  @private\n\t */\n\tTone.Buffer._downloadQueue = [];\n\n\t/**\n\t *  A path which is prefixed before every url.\n\t *  @type  {String}\n\t *  @static\n\t */\n\tTone.Buffer.baseUrl = \"\";\n\n\t/**\n\t *  Create a Tone.Buffer from the array. To create a multichannel AudioBuffer,\n\t *  pass in a multidimensional array.\n\t *  @param {Float32Array} array The array to fill the audio buffer\n\t *  @return {Tone.Buffer} A Tone.Buffer created from the array\n\t */\n\tTone.Buffer.fromArray = function(array){\n\t\treturn (new Tone.Buffer()).fromArray(array);\n\t};\n\n\t/**\n\t * Creates a Tone.Buffer from a URL, returns a promise\n\t * which resolves to a Tone.Buffer\n\t * @param  {String} url The url to load.\n\t * @return {Promise<Tone.Buffer>}     A promise which resolves to a Tone.Buffer\n\t */\n\tTone.Buffer.fromUrl = function(url){\n\t\tvar buffer = new Tone.Buffer();\n\t\treturn buffer.load(url).then(function(){\n\t\t\treturn buffer;\n\t\t});\n\t};\n\n\t/**\n\t * Remove an xhr request from the download queue\n\t * @private\n\t */\n\tTone.Buffer._removeFromDownloadQueue = function(request){\n\t\tvar index = Tone.Buffer._downloadQueue.indexOf(request);\n\t\tif (index !== -1){\n\t\t\tTone.Buffer._downloadQueue.splice(index, 1);\n\t\t}\n\t};\n\n\t/**\n\t *  Loads a url using XMLHttpRequest.\n\t *  @param {String} url\n\t *  @param {Function} onload\n\t *  @param {Function} onerror\n\t *  @param {Function} onprogress\n\t *  @return {XMLHttpRequest}\n\t */\n\tTone.Buffer.load = function(url, onload, onerror){\n\t\t//default\n\t\tonload = Tone.defaultArg(onload, Tone.noOp);\n\n\t\t// test if the url contains multiple extensions\n\t\tvar matches = url.match(/\\[(.+\\|?)+\\]$/);\n\t\tif (matches){\n\t\t\tvar extensions = matches[1].split(\"|\");\n\t\t\tvar extension = extensions[0];\n\t\t\tfor (var i = 0; i < extensions.length; i++){\n\t\t\t\tif (Tone.Buffer.supportsType(extensions[i])){\n\t\t\t\t\textension = extensions[i];\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\turl = url.replace(matches[0], extension);\n\t\t}\n\n\t\tfunction onError(e){\n\t\t\tTone.Buffer._removeFromDownloadQueue(request);\n\t\t\tTone.Buffer.emit(\"error\", e);\n\t\t\tif (onerror){\n\t\t\t\tonerror(e);\n\t\t\t} else {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\n\t\tfunction onProgress(){\n\t\t\t//calculate the progress\n\t\t\tvar totalProgress = 0;\n\t\t\tfor (var i = 0; i < Tone.Buffer._downloadQueue.length; i++){\n\t\t\t\ttotalProgress += Tone.Buffer._downloadQueue[i].progress;\n\t\t\t}\n\t\t\tTone.Buffer.emit(\"progress\", totalProgress / Tone.Buffer._downloadQueue.length);\n\t\t}\n\n\t\tvar request = new XMLHttpRequest();\n\t\trequest.open(\"GET\", Tone.Buffer.baseUrl + url, true);\n\t\trequest.responseType = \"arraybuffer\";\n\t\t//start out as 0\n\t\trequest.progress = 0;\n\n\t\tTone.Buffer._downloadQueue.push(request);\n\n\t\trequest.addEventListener(\"load\", function(){\n\n\t\t\tif (request.status === 200){\n\t\t\t\tTone.context.decodeAudioData(request.response).then(function(buff){\n\n\t\t\t\t\trequest.progress = 1;\n\t\t\t\t\tonProgress();\n\t\t\t\t\tonload(buff);\n\n\t\t\t\t\tTone.Buffer._removeFromDownloadQueue(request);\n\t\t\t\t\tif (Tone.Buffer._downloadQueue.length === 0){\n\t\t\t\t\t\t//emit the event at the end\n\t\t\t\t\t\tTone.Buffer.emit(\"load\");\n\t\t\t\t\t}\n\t\t\t\t}).catch(function(){\n\t\t\t\t\tTone.Buffer._removeFromDownloadQueue(request);\n\t\t\t\t\tonError(\"Tone.Buffer: could not decode audio data: \"+url);\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\tonError(\"Tone.Buffer: could not locate file: \"+url);\n\t\t\t}\n\t\t});\n\t\trequest.addEventListener(\"error\", onError);\n\n\t\trequest.addEventListener(\"progress\", function(event){\n\t\t\tif (event.lengthComputable){\n\t\t\t\t//only go to 95%, the last 5% is when the audio is decoded\n\t\t\t\trequest.progress = (event.loaded / event.total) * 0.95;\n\t\t\t\tonProgress();\n\t\t\t}\n\t\t});\n\n\t\trequest.send();\n\n\t\treturn request;\n\t};\n\n\t/**\n\t *  Stop all of the downloads in progress\n\t *  @return {Tone.Buffer}\n\t *  @static\n\t */\n\tTone.Buffer.cancelDownloads = function(){\n\t\tTone.Buffer._downloadQueue.slice().forEach(function(request){\n\t\t\tTone.Buffer._removeFromDownloadQueue(request);\n\t\t\trequest.abort();\n\t\t});\n\t\treturn Tone.Buffer;\n\t};\n\n\t/**\n\t *  Checks a url's extension to see if the current browser can play that file type.\n\t *  @param {String} url The url/extension to test\n\t *  @return {Boolean} If the file extension can be played\n\t *  @static\n\t *  @example\n\t * Tone.Buffer.supportsType(\"wav\"); //returns true\n\t * Tone.Buffer.supportsType(\"path/to/file.wav\"); //returns true\n\t */\n\tTone.Buffer.supportsType = function(url){\n\t\tvar extension = url.split(\".\");\n\t\textension = extension[extension.length - 1];\n\t\tvar response = document.createElement(\"audio\").canPlayType(\"audio/\"+extension);\n\t\treturn response !== \"\";\n\t};\n\n\t/**\n\t *  Returns a Promise which resolves when all of the buffers have loaded\n\t *  @return {Promise}\n\t */\n\tTone.loaded = function(){\n\t\tvar onload, onerror;\n\t\tfunction removeEvents(){\n\t\t\t//remove the events when it's resolved\n\t\t\tTone.Buffer.off(\"load\", onload);\n\t\t\tTone.Buffer.off(\"error\", onerror);\n\t\t}\n\t\treturn new Promise(function(success, fail){\n\t\t\tonload = function(){\n\t\t\t\tsuccess();\n\t\t\t};\n\t\t\tonerror = function(){\n\t\t\t\tfail();\n\t\t\t};\n\t\t\t//add the event listeners\n\t\t\tTone.Buffer.on(\"load\", onload);\n\t\t\tTone.Buffer.on(\"error\", onerror);\n\t\t}).then(removeEvents).catch(function(e){\n\t\t\tremoveEvents();\n\t\t\tthrow new Error(e);\n\t\t});\n\t};\n\n\treturn Tone.Buffer;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Buffer.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Buffers.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/core/Buffers.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class A data structure for holding multiple buffers.\n\t *  \n\t *  @param  {Object|Array}    urls      An object literal or array\n\t *                                      of urls to load.\n\t *  @param  {Function=}  callback  The callback to invoke when\n\t *                                 the buffers are loaded. \n\t *  @extends {Tone}\n\t *  @example\n\t * //load a whole bank of piano samples\n\t * var pianoSamples = new Tone.Buffers({\n\t * \t\"C4\" : \"path/to/C4.mp3\"\n\t * \t\"C#4\" : \"path/to/C#4.mp3\"\n\t * \t\"D4\" : \"path/to/D4.mp3\"\n\t * \t\"D#4\" : \"path/to/D#4.mp3\"\n\t * \t...\n\t * }, function(){\n\t * \t//play one of the samples when they all load\n\t * \tplayer.buffer = pianoSamples.get(\"C4\");\n\t * \tplayer.start();\n\t * });\n\t * \t@example\n\t * //To pass in additional parameters in the second parameter\n\t * var buffers = new Tone.Buffers(urls, {\n\t * \t\"onload\" : callback,\n\t * \t\"baseUrl\" : \"../path/to/audio/\"\n\t * })\n\t */\n\tTone.Buffers = function(urls){\n\n\t\t//remove the urls from the options\n\t\tvar args = Array.prototype.slice.call(arguments);\n\t\targs.shift();\n\t\tvar options = Tone.defaults(args, [\"onload\", \"baseUrl\"], Tone.Buffers);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  All of the buffers\n\t\t *  @type  {Object}\n\t\t *  @private\n\t\t */\n\t\tthis._buffers = {};\n\n\t\t/**\n\t\t *  A path which is prefixed before every url.\n\t\t *  @type  {String}\n\t\t */\n\t\tthis.baseUrl = options.baseUrl;\n\n\t\tthis._loadingCount = 0;\n\t\t//add each one\n\t\tfor (var key in urls){\n\t\t\tthis._loadingCount++;\n\t\t\tthis.add(key, urls[key], this._bufferLoaded.bind(this, options.onload));\n\t\t}\n\t};\n\n\tTone.extend(Tone.Buffers);\n\n\t/**\n\t *  Defaults\n\t *  @type  {Object}\n\t */\n\tTone.Buffers.defaults = {\n\t\t\"onload\" : Tone.noOp,\n\t\t\"baseUrl\" : \"\"\n\t};\n\n\t/**\n\t *  True if the buffers object has a buffer by that name.\n\t *  @param  {String|Number}  name  The key or index of the \n\t *                                 buffer.\n\t *  @return  {Boolean}\n\t */\n\tTone.Buffers.prototype.has = function(name){\n\t\treturn this._buffers.hasOwnProperty(name);\n\t};\n\n\t/**\n\t *  Get a buffer by name. If an array was loaded, \n\t *  then use the array index.\n\t *  @param  {String|Number}  name  The key or index of the \n\t *                                 buffer.\n\t *  @return  {Tone.Buffer}\n\t */\n\tTone.Buffers.prototype.get = function(name){\n\t\tif (this.has(name)){\n\t\t\treturn this._buffers[name];\n\t\t} else {\n\t\t\tthrow new Error(\"Tone.Buffers: no buffer named \"+name);\n\t\t}\n\t};\n\n\t/**\n\t *  A buffer was loaded. decrement the counter.\n\t *  @param  {Function}  callback \n\t *  @private\n\t */\n\tTone.Buffers.prototype._bufferLoaded = function(callback){\n\t\tthis._loadingCount--;\n\t\tif (this._loadingCount === 0 && callback){\n\t\t\tcallback(this);\n\t\t}\n\t};\n\n\t/**\n\t * If the buffers are loaded or not\n\t * @memberOf Tone.Buffers#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Buffers.prototype, \"loaded\", {\n\t\tget : function(){\n\t\t\tvar isLoaded = true;\n\t\t\tfor (var buffName in this._buffers){\n\t\t\t\tvar buff = this.get(buffName);\n\t\t\t\tisLoaded = isLoaded && buff.loaded;\n\t\t\t}\n\t\t\treturn isLoaded;\n\t\t}\n\t});\n\n\t/**\n\t *  Add a buffer by name and url to the Buffers\n\t *  @param  {String}    name      A unique name to give\n\t *                                the buffer\n\t *  @param  {String|Tone.Buffer|Audiobuffer}  url  Either the url of the bufer, \n\t *                                                 or a buffer which will be added\n\t *                                                 with the given name.\n\t *  @param  {Function=}  callback  The callback to invoke \n\t *                                 when the url is loaded.\n\t */\n\tTone.Buffers.prototype.add = function(name, url, callback){\n\t\tcallback = Tone.defaultArg(callback, Tone.noOp);\n\t\tif (url instanceof Tone.Buffer){\n\t\t\tthis._buffers[name] = url;\n\t\t\tcallback(this);\n\t\t} else if (url instanceof AudioBuffer){\n\t\t\tthis._buffers[name] = new Tone.Buffer(url);\n\t\t\tcallback(this);\n\t\t} else if (Tone.isString(url)){\n\t\t\tthis._buffers[name] = new Tone.Buffer(this.baseUrl + url, callback);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Buffers} this\n\t */\n\tTone.Buffers.prototype.dispose = function(){\n\t\tTone.prototype.dispose.call(this);\n\t\tfor (var name in this._buffers){\n\t\t\tthis._buffers[name].dispose();\n\t\t}\n\t\tthis._buffers = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Buffers;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Buffers.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Bus.js":
/*!********************************************!*\
  !*** ./node_modules/tone/Tone/core/Bus.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  buses are another way of routing audio\n\t *\n\t *  augments Tone.prototype to include send and receive\n\t */\n\n\t/**\n\t *  All of the routes\n\t *\n\t *  @type {Object}\n\t *  @static\n\t *  @private\n\t */\n\tvar Buses = {};\n\n\t/**\n\t *  Send this signal to the channel name.\n\t *  @param  {String} channelName A named channel to send the signal to.\n\t *  @param  {Decibels} amount The amount of the source to send to the bus.\n\t *  @return {GainNode} The gain node which connects this node to the desired channel.\n\t *                     Can be used to adjust the levels of the send.\n\t *  @example\n\t * source.send(\"reverb\", -12);\n\t */\n\tTone.prototype.send = function(channelName, amount){\n\t\tif (!Buses.hasOwnProperty(channelName)){\n\t\t\tBuses[channelName] = this.context.createGain();\n\t\t}\n\t\tamount = Tone.defaultArg(amount, 0);\n\t\tvar sendKnob = new Tone.Gain(amount, Tone.Type.Decibels);\n\t\tthis.connect(sendKnob);\n\t\tsendKnob.connect(Buses[channelName]);\n\t\treturn sendKnob;\n\t};\n\n\t/**\n\t *  Receive the input from the desired channelName to the input\n\t *\n\t *  @param  {String} channelName A named channel to send the signal to.\n\t *  @param  {Number=} channelNumber The channel to connect to\n\t *  @returns {Tone} this\n\t *  @example\n\t * reverbEffect.receive(\"reverb\");\n\t */\n\tTone.prototype.receive = function(channelName, inputNum){\n\t\tif (!Buses.hasOwnProperty(channelName)){\n\t\t\tBuses[channelName] = this.context.createGain();\n\t\t}\n\t\tBuses[channelName].connect(this, 0, inputNum);\n\t\treturn this;\n\t};\n\n\t//remove all the send/receives when a new audio context is passed in\n\tTone.Context.on(\"init\", function(context){\n\t\tif (context.buses){\n\t\t\tBuses = context.buses;\n\t\t} else {\n\t\t\tBuses = {};\n\t\t\tcontext.buses = Buses;\n\t\t}\n\t});\n\n\treturn Tone;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Bus.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Clock.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/core/Clock.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/TickSource */ \"./node_modules/tone/Tone/source/TickSource.js\"), __webpack_require__(/*! ../core/TimelineState */ \"./node_modules/tone/Tone/core/TimelineState.js\"),\n\t__webpack_require__(/*! ../core/Emitter */ \"./node_modules/tone/Tone/core/Emitter.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  A sample accurate clock which provides a callback at the given rate.\n\t *          While the callback is not sample-accurate (it is still susceptible to\n\t *          loose JS timing), the time passed in as the argument to the callback\n\t *          is precise. For most applications, it is better to use Tone.Transport\n\t *          instead of the Clock by itself since you can synchronize multiple callbacks.\n\t *\n\t * \t@constructor\n\t *  @extends {Tone.Emitter}\n\t * \t@param {function} callback The callback to be invoked with the time of the audio event\n\t * \t@param {Frequency} frequency The rate of the callback\n\t * \t@example\n\t * //the callback will be invoked approximately once a second\n\t * //and will print the time exactly once a second apart.\n\t * var clock = new Tone.Clock(function(time){\n\t * \tconsole.log(time);\n\t * }, 1);\n\t */\n\tTone.Clock = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"frequency\"], Tone.Clock);\n\t\tTone.Emitter.call(this);\n\n\t\t/**\n\t\t *  The callback function to invoke at the scheduled tick.\n\t\t *  @type  {Function}\n\t\t */\n\t\tthis.callback = options.callback;\n\n\t\t/**\n\t\t *  The next time the callback is scheduled.\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._nextTick = 0;\n\n\t\t/**\n\t\t *  The tick counter\n\t\t *  @type  {Tone.TickSource}\n\t\t *  @private\n\t\t */\n\t\tthis._tickSource = new Tone.TickSource(options.frequency);\n\n\t\t/**\n\t\t *  The last time the loop callback was invoked\n\t\t *  @private\n\t\t *  @type {Number}\n\t\t */\n\t\tthis._lastUpdate = 0;\n\n\t\t/**\n\t\t *  The rate the callback function should be invoked.\n\t\t *  @type  {BPM}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._tickSource.frequency;\n\t\tthis._readOnly(\"frequency\");\n\n\t\t/**\n\t\t *  The state timeline\n\t\t *  @type {Tone.TimelineState}\n\t\t *  @private\n\t\t */\n\t\tthis._state = new Tone.TimelineState(Tone.State.Stopped);\n\t\t//add an initial state\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, 0);\n\n\t\t/**\n\t\t *  The loop function bound to its context.\n\t\t *  This is necessary to remove the event in the end.\n\t\t *  @type {Function}\n\t\t *  @private\n\t\t */\n\t\tthis._boundLoop = this._loop.bind(this);\n\n\t\t//bind a callback to the worker thread\n\t\tthis.context.on(\"tick\", this._boundLoop);\n\t};\n\n\tTone.extend(Tone.Clock, Tone.Emitter);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Clock.defaults = {\n\t\t\"callback\" : Tone.noOp,\n\t\t\"frequency\" : 1,\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.Clock#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.Clock.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._state.getValueAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Start the clock at the given time. Optionally pass in an offset\n\t *  of where to start the tick counter from.\n\t *  @param  {Time=}  time    The time the clock should start\n\t *  @param  {Ticks=}  offset  Where the tick counter starts counting from.\n\t *  @return  {Tone.Clock}  this\n\t */\n\tTone.Clock.prototype.start = function(time, offset){\n\t\t//make sure the context is started\n\t\tthis.context.resume();\n\t\t//start the loop\n\t\ttime = this.toSeconds(time);\n\t\tif (this._state.getValueAtTime(time) !== Tone.State.Started){\n\t\t\tthis._state.setStateAtTime(Tone.State.Started, time);\n\t\t\tthis._tickSource.start(time, offset);\n\t\t\tif (time < this._lastUpdate){\n\t\t\t\tthis.emit(\"start\", time, offset);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the clock. Stopping the clock resets the tick counter to 0.\n\t *  @param {Time} [time=now] The time when the clock should stop.\n\t *  @returns {Tone.Clock} this\n\t *  @example\n\t * clock.stop();\n\t */\n\tTone.Clock.prototype.stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._state.cancel(time);\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, time);\n\t\tthis._tickSource.stop(time);\n\t\tif (time < this._lastUpdate){\n\t\t\tthis.emit(\"stop\", time);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Pause the clock. Pausing does not reset the tick counter.\n\t *  @param {Time} [time=now] The time when the clock should stop.\n\t *  @returns {Tone.Clock} this\n\t */\n\tTone.Clock.prototype.pause = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Started){\n\t\t\tthis._state.setStateAtTime(Tone.State.Paused, time);\n\t\t\tthis._tickSource.pause(time);\n\t\t\tif (time < this._lastUpdate){\n\t\t\t\tthis.emit(\"pause\", time);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The number of times the callback was invoked. Starts counting at 0\n\t *  and increments after the callback was invoked.\n\t *  @type {Ticks}\n\t */\n\tObject.defineProperty(Tone.Clock.prototype, \"ticks\", {\n\t\tget : function(){\n\t\t\treturn Math.ceil(this.getTicksAtTime(this.now()));\n\t\t},\n\t\tset : function(t){\n\t\t\tthis._tickSource.ticks = t;\n\t\t}\n\t});\n\n\t/**\n\t *  The time since ticks=0 that the Clock has been running. Accounts\n\t *  for tempo curves\n\t *  @type {Seconds}\n\t */\n\tObject.defineProperty(Tone.Clock.prototype, \"seconds\", {\n\t\tget : function(){\n\t\t\treturn this._tickSource.seconds;\n\t\t},\n\t\tset : function(s){\n\t\t\tthis._tickSource.seconds = s;\n\t\t}\n\t});\n\n\t/**\n\t *  Return the elapsed seconds at the given time.\n\t *  @param  {Time}  time  When to get the elapsed seconds\n\t *  @return  {Seconds}  The number of elapsed seconds\n\t */\n\tTone.Clock.prototype.getSecondsAtTime = function(time){\n\t\treturn this._tickSource.getSecondsAtTime(time);\n\t};\n\n\t/**\n\t * Set the clock's ticks at the given time.\n\t * @param  {Ticks} ticks The tick value to set\n\t * @param  {Time} time  When to set the tick value\n\t * @return {Tone.Clock}       this\n\t */\n\tTone.Clock.prototype.setTicksAtTime = function(ticks, time){\n\t\tthis._tickSource.setTicksAtTime(ticks, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Get the clock's ticks at the given time.\n\t * @param  {Time} time  When to get the tick value\n\t * @return {Ticks}       The tick value at the given time.\n\t */\n\tTone.Clock.prototype.getTicksAtTime = function(time){\n\t\treturn this._tickSource.getTicksAtTime(time);\n\t};\n\n\t/**\n\t * Get the time of the next tick\n\t * @param  {Ticks} ticks The tick number.\n\t * @param  {Time} before \n\t * @return {Tone.Clock}       this\n\t */\n\tTone.Clock.prototype.nextTickTime = function(offset, when){\n\t\twhen = this.toSeconds(when);\n\t\tvar currentTick = this.getTicksAtTime(when);\n\t\treturn this._tickSource.getTimeOfTick(currentTick+offset, when);\n\t};\n\n\t/**\n\t *  The scheduling loop.\n\t *  @private\n\t */\n\tTone.Clock.prototype._loop = function(){\n\n\t\tvar startTime = this._lastUpdate;\n\t\tvar endTime = this.now();\n\t\tthis._lastUpdate = endTime;\n\n\t\tif (startTime !== endTime){\n\t\t\t//the state change events\n\t\t\tthis._state.forEachBetween(startTime, endTime, function(e){\n\t\t\t\tswitch (e.state){\n\t\t\t\t\tcase Tone.State.Started : \n\t\t\t\t\t\tvar offset = this._tickSource.getTicksAtTime(e.time);\n\t\t\t\t\t\tthis.emit(\"start\", e.time, offset);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase Tone.State.Stopped : \n\t\t\t\t\t\tif (e.time !== 0){\n\t\t\t\t\t\t\tthis.emit(\"stop\", e.time);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase Tone.State.Paused :\n\t\t\t\t\t\tthis.emit(\"pause\", e.time); \n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}.bind(this));\n\t\t\t//the tick callbacks\n\t\t\tthis._tickSource.forEachTickBetween(startTime, endTime, function(time, ticks){\n\t\t\t\tthis.callback(time, ticks);\n\t\t\t}.bind(this));\n\t\t}\n\t};\n\n\t/**\n\t *  Returns the scheduled state at the given time.\n\t *  @param  {Time}  time  The time to query.\n\t *  @return  {String}  The name of the state input in setStateAtTime.\n\t *  @example\n\t * clock.start(\"+0.1\");\n\t * clock.getStateAtTime(\"+0.1\"); //returns \"started\"\n\t */\n\tTone.Clock.prototype.getStateAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\treturn this._state.getValueAtTime(time);\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @returns {Tone.Clock} this\n\t */\n\tTone.Clock.prototype.dispose = function(){\n\t\tTone.Emitter.prototype.dispose.call(this);\n\t\tthis.context.off(\"tick\", this._boundLoop);\n\t\tthis._writable(\"frequency\");\n\t\tthis._tickSource.dispose();\n\t\tthis._tickSource = null;\n\t\tthis.frequency = null;\n\t\tthis._boundLoop = null;\n\t\tthis._nextTick = Infinity;\n\t\tthis.callback = null;\n\t\tthis._state.dispose();\n\t\tthis._state = null;\n\t};\n\n\treturn Tone.Clock;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Clock.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Context.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/core/Context.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Emitter */ \"./node_modules/tone/Tone/core/Emitter.js\"), __webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\"), __webpack_require__(/*! ../shim/AudioContext */ \"./node_modules/tone/Tone/shim/AudioContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Wrapper around the native AudioContext.\n\t *  @extends {Tone.Emitter}\n\t *  @param {AudioContext=} context optionally pass in a context\n\t */\n\tTone.Context = function(){\n\n\t\tTone.Emitter.call(this);\n\n\t\tvar options = Tone.defaults(arguments, [\"context\"], Tone.Context);\n\n\t\tif (!options.context){\n\t\t\toptions.context = new Tone.global.AudioContext();\n\t\t\tif (!options.context){\n\t\t\t\tthrow new Error(\"could not create AudioContext. Possibly too many AudioContexts running already.\");\n\t\t\t}\n\t\t}\n\t\tthis._context = options.context;\n\t\t//make sure it's not an AudioContext wrapper\n\t\twhile (this._context.rawContext){\n\t\t\tthis._context = this._context.rawContext;\n\t\t}\n\t\t// extend all of the methods\n\t\tfor (var prop in this._context){\n\t\t\tthis._defineProperty(this._context, prop);\n\t\t}\n\n\t\t/**\n\t\t *  The default latency hint\n\t\t *  @type  {String}\n\t\t *  @private\n\t\t */\n\t\tthis._latencyHint = options.latencyHint;\n\n\t\t/**\n\t\t *  An object containing all of the constants AudioBufferSourceNodes\n\t\t *  @type  {Object}\n\t\t *  @private\n\t\t */\n\t\tthis._constants = {};\n\n\t\t///////////////////////////////////////////////////////////////////////\n\t\t// WORKER\n\t\t///////////////////////////////////////////////////////////////////////\n\n\t\t/**\n\t\t *  The amount of time events are scheduled\n\t\t *  into the future\n\t\t *  @type  {Number}\n\t\t */\n\t\tthis.lookAhead = options.lookAhead;\n\n\t\t/**\n\t\t *  A reference to the actual computed update interval\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._computedUpdateInterval = 0;\n\n\t\t/**\n\t\t *  A reliable callback method\n\t\t *  @private\n\t\t *  @type  {Ticker}\n\t\t */\n\t\tthis._ticker = new Ticker(this.emit.bind(this, \"tick\"), options.clockSource, options.updateInterval);\n\n\t\t///////////////////////////////////////////////////////////////////////\n\t\t// TIMEOUTS\n\t\t///////////////////////////////////////////////////////////////////////\n\n\t\t/**\n\t\t *  All of the setTimeout events.\n\t\t *  @type  {Tone.Timeline}\n\t\t *  @private\n\t\t */\n\t\tthis._timeouts = new Tone.Timeline();\n\n\t\t/**\n\t\t *  The timeout id counter\n\t\t *  @private\n\t\t *  @type {Number}\n\t\t */\n\t\tthis._timeoutIds = 0;\n\n\t\tthis.on(\"tick\", this._timeoutLoop.bind(this));\n\n\t\t//forward state change events\n\t\tthis._context.onstatechange = function(e){\n\t\t\tthis.emit(\"statechange\", e);\n\t\t}.bind(this);\n\t};\n\n\tTone.extend(Tone.Context, Tone.Emitter);\n\tTone.Emitter.mixin(Tone.Context);\n\n\t/**\n\t * defaults\n\t * @static\n\t * @type {Object}\n\t */\n\tTone.Context.defaults = {\n\t\t\"clockSource\" : \"worker\",\n\t\t\"latencyHint\" : \"interactive\",\n\t\t\"lookAhead\" : 0.1,\n\t\t\"updateInterval\" : 0.03\n\t};\n\n\t/**\n\t * Is an instanceof Tone.Context\n\t * @type {Boolean}\n\t */\n\tTone.Context.prototype.isContext = true;\n\n\t/**\n\t *  Define a property on this Tone.Context.\n\t *  This is used to extend the native AudioContext\n\t *  @param  {AudioContext}  context\n\t *  @param  {String}  prop\n\t *  @private\n\t */\n\tTone.Context.prototype._defineProperty = function(context, prop){\n\t\tif (Tone.isUndef(this[prop])){\n\t\t\tObject.defineProperty(this, prop, {\n\t\t\t\t\"get\" : function(){\n\t\t\t\t\tif (typeof context[prop] === \"function\"){\n\t\t\t\t\t\treturn context[prop].bind(context);\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn context[prop];\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t\"set\" : function(val){\n\t\t\t\t\tcontext[prop] = val;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t};\n\n\t/**\n\t *  The current audio context time\n\t *  @return  {Number}\n\t */\n\tTone.Context.prototype.now = function(){\n\t\treturn this._context.currentTime + this.lookAhead;\n\t};\n\n\t/**\n\t *  The audio output destination. Alias for Tone.Master\n\t *  @readyOnly\n\t *  @type  {Tone.Master}\n\t */\n\tObject.defineProperty(Tone.Context.prototype, \"destination\", {\n\t\t\"get\" : function(){\n\t\t\tif (!this.master){\n\t\t\t\treturn this._context.destination;\n\t\t\t} else {\n\t\t\t\treturn this.master;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Starts the audio context from a suspended state. This is required\n\t *  to initially start the AudioContext.\n\t *  @return  {Promise}\n\t */\n\tTone.Context.prototype.resume = function(){\n\t\tif (this._context.state === \"suspended\" && this._context instanceof AudioContext){\n\t\t\treturn this._context.resume();\n\t\t} else {\n\t\t\treturn Promise.resolve();\n\t\t}\n\t};\n\n\t/**\n\t *  Promise which is invoked when the context is running.\n\t *  Tries to resume the context if it's not started.\n\t *  @return  {Promise}\n\t */\n\tTone.Context.prototype.close = function(){\n\t\tvar closePromise = Promise.resolve();\n\t\t//never close the global Tone.Context\n\t\tif (this !== Tone.global.TONE_AUDIO_CONTEXT){\n\t\t\tclosePromise = this.rawContext.close();\n\t\t}\n\t\treturn closePromise.then(function(){\n\t\t\tTone.Context.emit(\"close\", this);\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Generate a looped buffer at some constant value.\n\t *  @param  {Number}  val\n\t *  @return  {BufferSourceNode}\n\t */\n\tTone.Context.prototype.getConstant = function(val){\n\t\tif (this._constants[val]){\n\t\t\treturn this._constants[val];\n\t\t} else {\n\t\t\tvar buffer = this._context.createBuffer(1, 128, this._context.sampleRate);\n\t\t\tvar arr = buffer.getChannelData(0);\n\t\t\tfor (var i = 0; i < arr.length; i++){\n\t\t\t\tarr[i] = val;\n\t\t\t}\n\t\t\tvar constant = this._context.createBufferSource();\n\t\t\tconstant.channelCount = 1;\n\t\t\tconstant.channelCountMode = \"explicit\";\n\t\t\tconstant.buffer = buffer;\n\t\t\tconstant.loop = true;\n\t\t\tconstant.start(0);\n\t\t\tthis._constants[val] = constant;\n\t\t\treturn constant;\n\t\t}\n\t};\n\n\t/**\n\t *  The private loop which keeps track of the context scheduled timeouts\n\t *  Is invoked from the clock source\n\t *  @private\n\t */\n\tTone.Context.prototype._timeoutLoop = function(){\n\t\tvar now = this.now();\n\t\twhile (this._timeouts && this._timeouts.length && this._timeouts.peek().time <= now){\n\t\t\tthis._timeouts.shift().callback();\n\t\t}\n\t};\n\n\t/**\n\t *  A setTimeout which is gaurenteed by the clock source.\n\t *  Also runs in the offline context.\n\t *  @param  {Function}  fn       The callback to invoke\n\t *  @param  {Seconds}    timeout  The timeout in seconds\n\t *  @returns {Number} ID to use when invoking Tone.Context.clearTimeout\n\t */\n\tTone.Context.prototype.setTimeout = function(fn, timeout){\n\t\tthis._timeoutIds++;\n\t\tvar now = this.now();\n\t\tthis._timeouts.add({\n\t\t\t\"callback\" : fn,\n\t\t\t\"time\" : now + timeout,\n\t\t\t\"id\" : this._timeoutIds\n\t\t});\n\t\treturn this._timeoutIds;\n\t};\n\n\t/**\n\t *  Clears a previously scheduled timeout with Tone.context.setTimeout\n\t *  @param  {Number}  id  The ID returned from setTimeout\n\t *  @return  {Tone.Context}  this\n\t */\n\tTone.Context.prototype.clearTimeout = function(id){\n\t\tthis._timeouts.forEach(function(event){\n\t\t\tif (event.id === id){\n\t\t\t\tthis.remove(event);\n\t\t\t}\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t *  How often the Web Worker callback is invoked.\n\t *  This number corresponds to how responsive the scheduling\n\t *  can be. Context.updateInterval + Context.lookAhead gives you the\n\t *  total latency between scheduling an event and hearing it.\n\t *  @type {Number}\n\t *  @memberOf Tone.Context#\n\t *  @name updateInterval\n\t */\n\tObject.defineProperty(Tone.Context.prototype, \"updateInterval\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._ticker.updateInterval;\n\t\t},\n\t\t\"set\" : function(interval){\n\t\t\tthis._ticker.updateInterval = interval;\n\t\t}\n\t});\n\n\t/**\n\t *  The unwrapped AudioContext.\n\t *  @type {AudioContext}\n\t *  @memberOf Tone.Context#\n\t *  @name rawContext\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Context.prototype, \"rawContext\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._context;\n\t\t}\n\t});\n\n\t/**\n\t *  What the source of the clock is, either \"worker\" (Web Worker [default]),\n\t *  \"timeout\" (setTimeout), or \"offline\" (none).\n\t *  @type {String}\n\t *  @memberOf Tone.Context#\n\t *  @name clockSource\n\t */\n\tObject.defineProperty(Tone.Context.prototype, \"clockSource\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._ticker.type;\n\t\t},\n\t\t\"set\" : function(type){\n\t\t\tthis._ticker.type = type;\n\t\t}\n\t});\n\n\t/**\n\t *  The type of playback, which affects tradeoffs between audio\n\t *  output latency and responsiveness.\n\t *\n\t *  In addition to setting the value in seconds, the latencyHint also\n\t *  accepts the strings \"interactive\" (prioritizes low latency),\n\t *  \"playback\" (prioritizes sustained playback), \"balanced\" (balances\n\t *  latency and performance), and \"fastest\" (lowest latency, might glitch more often).\n\t *  @type {String|Seconds}\n\t *  @memberOf Tone.Context#\n\t *  @name latencyHint\n\t *  @example\n\t * //set the lookAhead to 0.3 seconds\n\t * Tone.context.latencyHint = 0.3;\n\t */\n\tObject.defineProperty(Tone.Context.prototype, \"latencyHint\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._latencyHint;\n\t\t},\n\t\t\"set\" : function(hint){\n\t\t\tvar lookAhead = hint;\n\t\t\tthis._latencyHint = hint;\n\t\t\tif (Tone.isString(hint)){\n\t\t\t\tswitch (hint){\n\t\t\t\t\tcase \"interactive\" :\n\t\t\t\t\t\tlookAhead = 0.1;\n\t\t\t\t\t\tthis._context.latencyHint = hint;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"playback\" :\n\t\t\t\t\t\tlookAhead = 0.8;\n\t\t\t\t\t\tthis._context.latencyHint = hint;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"balanced\" :\n\t\t\t\t\t\tlookAhead = 0.25;\n\t\t\t\t\t\tthis._context.latencyHint = hint;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"fastest\" :\n\t\t\t\t\t\tthis._context.latencyHint = \"interactive\";\n\t\t\t\t\t\tlookAhead = 0.01;\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.lookAhead = lookAhead;\n\t\t\tthis.updateInterval = lookAhead/3;\n\t\t}\n\t});\n\n\t/**\n\t *  Unlike other dispose methods, this returns a Promise\n\t *  which executes when the context is closed and disposed\n\t *  @returns {Promise} this\n\t */\n\tTone.Context.prototype.dispose = function(){\n\t\treturn this.close().then(function(){\n\t\t\tTone.Emitter.prototype.dispose.call(this);\n\t\t\tthis._ticker.dispose();\n\t\t\tthis._ticker = null;\n\t\t\tthis._timeouts.dispose();\n\t\t\tthis._timeouts = null;\n\t\t\tfor (var con in this._constants){\n\t\t\t\tthis._constants[con].disconnect();\n\t\t\t}\n\t\t\tthis._constants = null;\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t * @class A class which provides a reliable callback using either\n\t *        a Web Worker, or if that isn't supported, falls back to setTimeout.\n\t * @private\n\t */\n\tvar Ticker = function(callback, type, updateInterval){\n\n\t\t/**\n\t\t * Either \"worker\" or \"timeout\"\n\t\t * @type {String}\n\t\t * @private\n\t\t */\n\t\tthis._type = type;\n\n\t\t/**\n\t\t * The update interval of the worker\n\t\t * @private\n\t\t * @type {Number}\n\t\t */\n\t\tthis._updateInterval = updateInterval;\n\n\t\t/**\n\t\t * The callback to invoke at regular intervals\n\t\t * @type {Function}\n\t\t * @private\n\t\t */\n\t\tthis._callback = Tone.defaultArg(callback, Tone.noOp);\n\n\t\t//create the clock source for the first time\n\t\tthis._createClock();\n\t};\n\n\t/**\n\t * The possible ticker types\n\t * @private\n\t * @type {Object}\n\t */\n\tTicker.Type = {\n\t\t\"Worker\" : \"worker\",\n\t\t\"Timeout\" : \"timeout\",\n\t\t\"Offline\" : \"offline\"\n\t};\n\n\t/**\n\t *  Generate a web worker\n\t *  @return  {WebWorker}\n\t *  @private\n\t */\n\tTicker.prototype._createWorker = function(){\n\n\t\t//URL Shim\n\t\tTone.global.URL = Tone.global.URL || Tone.global.webkitURL;\n\n\t\tvar blob = new Blob([\n\t\t\t//the initial timeout time\n\t\t\t\"var timeoutTime = \"+(this._updateInterval * 1000).toFixed(1)+\";\" +\n\t\t\t//onmessage callback\n\t\t\t\"self.onmessage = function(msg){\" +\n\t\t\t\"\ttimeoutTime = parseInt(msg.data);\" +\n\t\t\t\"};\" +\n\t\t\t//the tick function which posts a message\n\t\t\t//and schedules a new tick\n\t\t\t\"function tick(){\" +\n\t\t\t\"\tsetTimeout(tick, timeoutTime);\" +\n\t\t\t\"\tself.postMessage('tick');\" +\n\t\t\t\"}\" +\n\t\t\t//call tick initially\n\t\t\t\"tick();\"\n\t\t]);\n\t\tvar blobUrl = URL.createObjectURL(blob);\n\t\tvar worker = new Worker(blobUrl);\n\n\t\tworker.onmessage = this._callback.bind(this);\n\n\t\tthis._worker = worker;\n\t};\n\n\t/**\n\t * Create a timeout loop\n\t * @private\n\t */\n\tTicker.prototype._createTimeout = function(){\n\t\tthis._timeout = setTimeout(function(){\n\t\t\tthis._createTimeout();\n\t\t\tthis._callback();\n\t\t}.bind(this), this._updateInterval * 1000);\n\t};\n\n\t/**\n\t * Create the clock source.\n\t * @private\n\t */\n\tTicker.prototype._createClock = function(){\n\t\tif (this._type === Ticker.Type.Worker){\n\t\t\ttry {\n\t\t\t\tthis._createWorker();\n\t\t\t} catch (e){\n\t\t\t\t// workers not supported, fallback to timeout\n\t\t\t\tthis._type = Ticker.Type.Timeout;\n\t\t\t\tthis._createClock();\n\t\t\t}\n\t\t} else if (this._type === Ticker.Type.Timeout){\n\t\t\tthis._createTimeout();\n\t\t}\n\t};\n\n\t/**\n\t * @memberOf Ticker#\n\t * @type {Number}\n\t * @name updateInterval\n\t * @private\n\t */\n\tObject.defineProperty(Ticker.prototype, \"updateInterval\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._updateInterval;\n\t\t},\n\t\t\"set\" : function(interval){\n\t\t\tthis._updateInterval = Math.max(interval, 128/44100);\n\t\t\tif (this._type === Ticker.Type.Worker){\n\t\t\t\tthis._worker.postMessage(Math.max(interval * 1000, 1));\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The type of the ticker, either a worker or a timeout\n\t * @memberOf Ticker#\n\t * @type {Number}\n\t * @name type\n\t * @private\n\t */\n\tObject.defineProperty(Ticker.prototype, \"type\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\t\"set\" : function(type){\n\t\t\tthis._disposeClock();\n\t\t\tthis._type = type;\n\t\t\tthis._createClock();\n\t\t}\n\t});\n\n\t/**\n\t * Clean up the current clock source\n\t * @private\n\t */\n\tTicker.prototype._disposeClock = function(){\n\t\tif (this._timeout){\n\t\t\tclearTimeout(this._timeout);\n\t\t\tthis._timeout = null;\n\t\t}\n\t\tif (this._worker){\n\t\t\tthis._worker.terminate();\n\t\t\tthis._worker.onmessage = null;\n\t\t\tthis._worker = null;\n\t\t}\n\t};\n\n\t/**\n\t * Clean up\n\t * @private\n\t */\n\tTicker.prototype.dispose = function(){\n\t\tthis._disposeClock();\n\t\tthis._callback = null;\n\t};\n\n\t/**\n\t *  Adds connect/disconnect methods\n\t *  @private\n\t */\n\tTone.getContext(function(){\n\n\t\tvar nativeConnect = AudioNode.prototype.connect;\n\t\tvar nativeDisconnect = AudioNode.prototype.disconnect;\n\n\t\t//replace the old connect method\n\t\tfunction toneConnect(B, outNum, inNum){\n\t\t\tif (B.input){\n\t\t\t\tinNum = Tone.defaultArg(inNum, 0);\n\t\t\t\tif (Tone.isArray(B.input)){\n\t\t\t\t\treturn this.connect(B.input[inNum]);\n\t\t\t\t} else {\n\t\t\t\t\treturn this.connect(B.input, outNum, inNum);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tif (B instanceof AudioNode){\n\t\t\t\t\t\tnativeConnect.call(this, B, outNum, inNum);\n\t\t\t\t\t\treturn B;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnativeConnect.call(this, B, outNum);\n\t\t\t\t\t\treturn B;\n\t\t\t\t\t}\n\t\t\t\t} catch (e){\n\t\t\t\t\tthrow new Error(\"error connecting to node: \"+B+\"\\n\"+e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t//replace the old disconnect method\n\t\tfunction toneDisconnect(B, outNum, inNum){\n\t\t\tif (B && B.input && Tone.isArray(B.input)){\n\t\t\t\tinNum = Tone.defaultArg(inNum, 0);\n\t\t\t\tthis.disconnect(B.input[inNum], outNum, 0);\n\t\t\t} else if (B && B.input){\n\t\t\t\tthis.disconnect(B.input, outNum, inNum);\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tif (B instanceof AudioParam){\n\t\t\t\t\t\tnativeDisconnect.call(this, B, outNum);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tnativeDisconnect.apply(this, arguments);\n\t\t\t\t\t}\n\t\t\t\t} catch (e){\n\t\t\t\t\tthrow new Error(\"error disconnecting node: \"+B+\"\\n\"+e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (AudioNode.prototype.connect !== toneConnect){\n\t\t\tAudioNode.prototype.connect = toneConnect;\n\t\t\tAudioNode.prototype.disconnect = toneDisconnect;\n\t\t}\n\t});\n\n\t// set the audio context initially, and if one is not already created\n\tif (Tone.supported && !Tone.initialized){\t\t\t\n\t\tif (!Tone.global.TONE_AUDIO_CONTEXT){\n\t\t\tTone.global.TONE_AUDIO_CONTEXT = new Tone.Context();\n\t\t}\n\t\tTone.context = Tone.global.TONE_AUDIO_CONTEXT;\n\n\t\t// log on first initialization\n\t\t// allow optional silencing of this log\n\t\tif (!Tone.global.TONE_SILENCE_VERSION_LOGGING){\n\t\t\tvar prefix = \"v\";\n\t\t\tif (Tone.version === \"dev\"){\n\t\t\t\tprefix = \"\";\n\t\t\t}\n\t\t\tvar printString = \" * Tone.js \" + prefix + Tone.version + \" * \"; \n\t\t\t// eslint-disable-next-line no-console\n\t\t\tconsole.log(\"%c\" + printString, \"background: #000; color: #fff\");\n\t\t}\n\t} else if (!Tone.supported){\n\t\t// eslint-disable-next-line no-console\n\t\tconsole.warn(\"This browser does not support Tone.js\");\n\t}\n\n\treturn Tone.Context;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Context.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Delay.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/core/Delay.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).\n\t *  @extends {Tone}\n\t *  @param {Time=} delayTime The delay applied to the incoming signal.\n\t *  @param {Time=} maxDelay The maximum delay time.\n\t */\n\tTone.Delay = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"delayTime\", \"maxDelay\"], Tone.Delay);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t * The maximum delay time initialized with the node\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._maxDelay = Math.max(this.toSeconds(options.maxDelay), this.toSeconds(options.delayTime));\n\t\t\n\t\t/**\n\t\t *  The native delay node\n\t\t *  @type {DelayNode}\n\t\t *  @private\n\t\t */\n\t\tthis._delayNode = this.input = this.output = this.context.createDelay(this._maxDelay);\n\n\t\t/**\n\t\t *  The amount of time the incoming signal is\n\t\t *  delayed.\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = new Tone.Param({\n\t\t\t\"param\" : this._delayNode.delayTime,\n\t\t\t\"units\" : Tone.Type.Time,\n\t\t\t\"value\" : options.delayTime\n\t\t});\n\n\t\tthis._readOnly(\"delayTime\");\n\t};\n\n\tTone.extend(Tone.Delay, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Delay.defaults = {\n\t\t\"maxDelay\" : 1,\n\t\t\"delayTime\" : 0\n\t};\n\n\t/**\n\t * The maximum delay time. This cannot be changed. The value is passed into the constructor.\n\t * @memberof Tone.Delay#\n\t * @type {Time}\n\t * @name maxDelay\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Delay.prototype, \"maxDelay\", {\n\t\tget : function(){\n\t\t\treturn this._maxDelay;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Delay}  this\n\t */\n\tTone.Delay.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._delayNode.disconnect();\n\t\tthis._delayNode = null;\n\t\tthis._writable(\"delayTime\");\n\t\tthis.delayTime = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Delay;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Delay.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Draw.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/core/Draw.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Draw is useful for synchronizing visuals and audio events.\n\t *         Callbacks from Tone.Transport or any of the Tone.Event classes\n\t *         always happen _before_ the scheduled time and are not synchronized\n\t *         to the animation frame so they are not good for triggering tightly\n\t *         synchronized visuals and sound. Tone.Draw makes it easy to schedule\n\t *         callbacks using the AudioContext time and uses requestAnimationFrame.\n\t *         \n\t *  @singleton\n\t *  @extends {Tone}\n\t *  @example\n\t * Tone.Transport.schedule(function(time){\n\t * \t//use the time argument to schedule a callback with Tone.Draw\n\t * \tTone.Draw.schedule(function(){\n\t * \t\t//do drawing or DOM manipulation here\n\t * \t}, time)\n\t * }, \"+0.5\")\n\t */\n\tTone.Draw = function(){\n\n\t\tTone.call(this);\n\t\t\n\t\t/**\n\t\t *  All of the events.\n\t\t *  @type  {Tone.Timeline}\n\t\t *  @private\n\t\t */\n\t\tthis._events = new Tone.Timeline();\n\n\t\t/**\n\t\t *  The duration after which events are not invoked.\n\t\t *  @type  {Number}\n\t\t *  @default 0.25\n\t\t */\n\t\tthis.expiration = 0.25;\n\n\t\t/**\n\t\t *  The amount of time before the scheduled time \n\t\t *  that the callback can be invoked. Default is\n\t\t *  half the time of an animation frame (0.008 seconds).\n\t\t *  @type  {Number}\n\t\t *  @default 0.008\n\t\t */\n\t\tthis.anticipation = 0.008;\n\n\t\t/**\n\t\t *  The draw loop\n\t\t *  @type  {Function}\n\t\t *  @private\n\t\t */\n\t\tthis._boundDrawLoop = this._drawLoop.bind(this);\n\t};\n\n\tTone.extend(Tone.Draw);\n\n\t/**\n\t *  Schedule a function at the given time to be invoked\n\t *  on the nearest animation frame.\n\t *  @param  {Function}  callback  Callback is invoked at the given time.\n\t *  @param  {Time}    time      The time relative to the AudioContext time\n\t *                              to invoke the callback.\n\t *  @return  {Tone.Draw}    this\n\t */\n\tTone.Draw.prototype.schedule = function(callback, time){\n\t\tthis._events.add({\n\t\t\tcallback : callback,\n\t\t\ttime : this.toSeconds(time)\n\t\t});\n\t\t//start the draw loop on the first event\n\t\tif (this._events.length === 1){\n\t\t\trequestAnimationFrame(this._boundDrawLoop);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel events scheduled after the given time\n\t *  @param  {Time=}  after  Time after which scheduled events will \n\t *                          be removed from the scheduling timeline.\n\t *  @return  {Tone.Draw}  this\n\t */\n\tTone.Draw.prototype.cancel = function(after){\n\t\tthis._events.cancel(this.toSeconds(after));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The draw loop\n\t *  @private\n\t */\n\tTone.Draw.prototype._drawLoop = function(){\n\t\tvar now = Tone.context.currentTime;\n\t\twhile (this._events.length && this._events.peek().time - this.anticipation <= now){\n\t\t\tvar event = this._events.shift();\n\t\t\tif (now - event.time <= this.expiration){\n\t\t\t\tevent.callback();\n\t\t\t}\n\t\t}\n\t\tif (this._events.length > 0){\n\t\t\trequestAnimationFrame(this._boundDrawLoop);\n\t\t}\n\t};\n\n\t//make a singleton\n\tTone.Draw = new Tone.Draw();\n\n\treturn Tone.Draw;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Draw.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Emitter.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/core/Emitter.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Emitter gives classes which extend it\n\t *         the ability to listen for and emit events.\n\t *         Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n\t *         MIT (c) 2011 Jerome Etienne.\n\t *\n\t *  @extends {Tone}\n\t */\n\tTone.Emitter = function(){\n\t\tTone.call(this);\n\t\t/**\n\t\t *  Contains all of the events.\n\t\t *  @private\n\t\t *  @type  {Object}\n\t\t */\n\t\tthis._events = {};\n\t};\n\n\tTone.extend(Tone.Emitter);\n\n\t/**\n\t *  Bind a callback to a specific event.\n\t *  @param  {String}    event     The name of the event to listen for.\n\t *  @param  {Function}  callback  The callback to invoke when the\n\t *                                event is emitted\n\t *  @return  {Tone.Emitter}    this\n\t */\n\tTone.Emitter.prototype.on = function(event, callback){\n\t\t//split the event\n\t\tvar events = event.split(/\\W+/);\n\t\tfor (var i = 0; i < events.length; i++){\n\t\t\tvar eventName = events[i];\n\t\t\tif (!this._events.hasOwnProperty(eventName)){\n\t\t\t\tthis._events[eventName] = [];\n\t\t\t}\n\t\t\tthis._events[eventName].push(callback);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Bind a callback which is only invoked once\n\t *  @param  {String}    event     The name of the event to listen for.\n\t *  @param  {Function}  callback  The callback to invoke when the\n\t *                                event is emitted\n\t *  @return  {Tone.Emitter}    this\n\t */\n\tTone.Emitter.prototype.once = function(event, callback){\n\t\tvar boundCallback = function(){\n\t\t\t//invoke the callback\n\t\t\tcallback.apply(this, arguments);\n\t\t\tthis.off(event, boundCallback);\n\t\t}.bind(this);\n\t\tthis.on(event, boundCallback);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Remove the event listener.\n\t *  @param  {String}    event     The event to stop listening to.\n\t *  @param  {Function=}  callback  The callback which was bound to\n\t *                                the event with Tone.Emitter.on.\n\t *                                If no callback is given, all callbacks\n\t *                                events are removed.\n\t *  @return  {Tone.Emitter}    this\n\t */\n\tTone.Emitter.prototype.off = function(event, callback){\n\t\tvar events = event.split(/\\W+/);\n\t\tfor (var ev = 0; ev < events.length; ev++){\n\t\t\tevent = events[ev];\n\t\t\tif (this._events.hasOwnProperty(event)){\n\t\t\t\tif (Tone.isUndef(callback)){\n\t\t\t\t\tthis._events[event] = [];\n\t\t\t\t} else {\n\t\t\t\t\tvar eventList = this._events[event];\n\t\t\t\t\tfor (var i = 0; i < eventList.length; i++){\n\t\t\t\t\t\tif (eventList[i] === callback){\n\t\t\t\t\t\t\teventList.splice(i, 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Invoke all of the callbacks bound to the event\n\t *  with any arguments passed in.\n\t *  @param  {String}  event  The name of the event.\n\t *  @param {*} args... The arguments to pass to the functions listening.\n\t *  @return  {Tone.Emitter}  this\n\t */\n\tTone.Emitter.prototype.emit = function(event){\n\t\tif (this._events){\n\t\t\tvar args = Array.apply(null, arguments).slice(1);\n\t\t\tif (this._events.hasOwnProperty(event)){\n\t\t\t\tvar eventList = this._events[event].slice(0);\n\t\t\t\tfor (var i = 0, len = eventList.length; i < len; i++){\n\t\t\t\t\teventList[i].apply(this, args);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Add Emitter functions (on/off/emit) to the object\n\t *  @param  {Object|Function}  object  The object or class to extend.\n\t *  @returns {Tone.Emitter}\n\t */\n\tTone.Emitter.mixin = function(object){\n\t\tvar functions = [\"on\", \"once\", \"off\", \"emit\"];\n\t\tobject._events = {};\n\t\tfor (var i = 0; i < functions.length; i++){\n\t\t\tvar func = functions[i];\n\t\t\tvar emitterFunc = Tone.Emitter.prototype[func];\n\t\t\tobject[func] = emitterFunc;\n\t\t}\n\t\treturn Tone.Emitter;\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Emitter}  this\n\t */\n\tTone.Emitter.prototype.dispose = function(){\n\t\tTone.prototype.dispose.call(this);\n\t\tthis._events = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Emitter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Emitter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Gain.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/core/Gain.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class A thin wrapper around the Native Web Audio GainNode.\n\t *         The GainNode is a basic building block of the Web Audio\n\t *         API and is useful for routing audio and adjusting gains.\n\t *  @extends {Tone.AudioNode}\n\t *  @param  {Number=}  gain  The initial gain of the GainNode\n\t *  @param {Tone.Type=} units The units of the gain parameter.\n\t */\n\tTone.Gain = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"gain\", \"units\"], Tone.Gain);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The GainNode\n\t\t *  @type  {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.input = this.output = this._gainNode = this.context.createGain();\n\n\t\t/**\n\t\t *  The gain parameter of the gain node.\n\t\t *  @type {Gain}\n\t\t *  @signal\n\t\t */\n\t\tthis.gain = new Tone.Param({\n\t\t\t\"param\" : this._gainNode.gain,\n\t\t\t\"units\" : options.units,\n\t\t\t\"value\" : options.gain,\n\t\t\t\"convert\" : options.convert\n\t\t});\n\t\tthis._readOnly(\"gain\");\n\t};\n\n\tTone.extend(Tone.Gain, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Gain.defaults = {\n\t\t\"gain\" : 1,\n\t\t\"convert\" : true,\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Gain}  this\n\t */\n\tTone.Gain.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._gainNode.disconnect();\n\t\tthis._gainNode = null;\n\t\tthis._writable(\"gain\");\n\t\tthis.gain.dispose();\n\t\tthis.gain = null;\n\t};\n\n\treturn Tone.Gain;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Gain.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/IntervalTimeline.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/core/IntervalTimeline.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Similar to Tone.Timeline, but all events represent\n\t *         intervals with both \"time\" and \"duration\" times. The\n\t *         events are placed in a tree structure optimized\n\t *         for querying an intersection point with the timeline\n\t *         events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n\t *         to represent the data.\n\t *  @extends {Tone}\n\t */\n\tTone.IntervalTimeline = function(){\n\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The root node of the inteval tree\n\t\t *  @type  {IntervalNode}\n\t\t *  @private\n\t\t */\n\t\tthis._root = null;\n\n\t\t/**\n\t\t *  Keep track of the length of the timeline.\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._length = 0;\n\t};\n\n\tTone.extend(Tone.IntervalTimeline);\n\n\t/**\n\t *  The event to add to the timeline. All events must\n\t *  have a time and duration value\n\t *  @param  {Object}  event  The event to add to the timeline\n\t *  @return  {Tone.IntervalTimeline}  this\n\t */\n\tTone.IntervalTimeline.prototype.add = function(event){\n\t\tif (Tone.isUndef(event.time) || Tone.isUndef(event.duration)){\n\t\t\tthrow new Error(\"Tone.IntervalTimeline: events must have time and duration parameters\");\n\t\t}\n\t\tevent.time = event.time.valueOf();\n\t\tvar node = new IntervalNode(event.time, event.time + event.duration, event);\n\t\tif (this._root === null){\n\t\t\tthis._root = node;\n\t\t} else {\n\t\t\tthis._root.insert(node);\n\t\t}\n\t\tthis._length++;\n\t\t// Restructure tree to be balanced\n\t\twhile (node !== null){\n\t\t\tnode.updateHeight();\n\t\t\tnode.updateMax();\n\t\t\tthis._rebalance(node);\n\t\t\tnode = node.parent;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Remove an event from the timeline.\n\t *  @param  {Object}  event  The event to remove from the timeline\n\t *  @return  {Tone.IntervalTimeline}  this\n\t */\n\tTone.IntervalTimeline.prototype.remove = function(event){\n\t\tif (this._root !== null){\n\t\t\tvar results = [];\n\t\t\tthis._root.search(event.time, results);\n\t\t\tfor (var i = 0; i < results.length; i++){\n\t\t\t\tvar node = results[i];\n\t\t\t\tif (node.event === event){\n\t\t\t\t\tthis._removeNode(node);\n\t\t\t\t\tthis._length--;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The number of items in the timeline.\n\t *  @type {Number}\n\t *  @memberOf Tone.IntervalTimeline#\n\t *  @name length\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.IntervalTimeline.prototype, \"length\", {\n\t\tget : function(){\n\t\t\treturn this._length;\n\t\t}\n\t});\n\n\t/**\n\t *  Remove events whose time time is after the given time\n\t *  @param  {Number}  time  The time to query.\n\t *  @returns {Tone.IntervalTimeline} this\n\t */\n\tTone.IntervalTimeline.prototype.cancel = function(after){\n\t\tthis.forEachFrom(after, function(event){\n\t\t\tthis.remove(event);\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Set the root node as the given node\n\t *  @param {IntervalNode} node\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._setRoot = function(node){\n\t\tthis._root = node;\n\t\tif (this._root !== null){\n\t\t\tthis._root.parent = null;\n\t\t}\n\t};\n\n\t/**\n\t *  Replace the references to the node in the node's parent\n\t *  with the replacement node.\n\t *  @param  {IntervalNode}  node\n\t *  @param  {IntervalNode}  replacement\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._replaceNodeInParent = function(node, replacement){\n\t\tif (node.parent !== null){\n\t\t\tif (node.isLeftChild()){\n\t\t\t\tnode.parent.left = replacement;\n\t\t\t} else {\n\t\t\t\tnode.parent.right = replacement;\n\t\t\t}\n\t\t\tthis._rebalance(node.parent);\n\t\t} else {\n\t\t\tthis._setRoot(replacement);\n\t\t}\n\t};\n\n\t/**\n\t *  Remove the node from the tree and replace it with\n\t *  a successor which follows the schema.\n\t *  @param  {IntervalNode}  node\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._removeNode = function(node){\n\t\tif (node.left === null && node.right === null){\n\t\t\tthis._replaceNodeInParent(node, null);\n\t\t} else if (node.right === null){\n\t\t\tthis._replaceNodeInParent(node, node.left);\n\t\t} else if (node.left === null){\n\t\t\tthis._replaceNodeInParent(node, node.right);\n\t\t} else {\n\t\t\tvar balance = node.getBalance();\n\t\t\tvar replacement, temp;\n\t\t\tif (balance > 0){\n\t\t\t\tif (node.left.right === null){\n\t\t\t\t\treplacement = node.left;\n\t\t\t\t\treplacement.right = node.right;\n\t\t\t\t\ttemp = replacement;\n\t\t\t\t} else {\n\t\t\t\t\treplacement = node.left.right;\n\t\t\t\t\twhile (replacement.right !== null){\n\t\t\t\t\t\treplacement = replacement.right;\n\t\t\t\t\t}\n\t\t\t\t\treplacement.parent.right = replacement.left;\n\t\t\t\t\ttemp = replacement.parent;\n\t\t\t\t\treplacement.left = node.left;\n\t\t\t\t\treplacement.right = node.right;\n\t\t\t\t}\n\t\t\t} else if (node.right.left === null){\n\t\t\t\treplacement = node.right;\n\t\t\t\treplacement.left = node.left;\n\t\t\t\ttemp = replacement;\n\t\t\t} else {\n\t\t\t\treplacement = node.right.left;\n\t\t\t\twhile (replacement.left !== null){\n\t\t\t\t\treplacement = replacement.left;\n\t\t\t\t}\n\t\t\t\treplacement.parent = replacement.parent;\n\t\t\t\treplacement.parent.left = replacement.right;\n\t\t\t\ttemp = replacement.parent;\n\t\t\t\treplacement.left = node.left;\n\t\t\t\treplacement.right = node.right;\n\t\t\t}\n\t\t\tif (node.parent !== null){\n\t\t\t\tif (node.isLeftChild()){\n\t\t\t\t\tnode.parent.left = replacement;\n\t\t\t\t} else {\n\t\t\t\t\tnode.parent.right = replacement;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis._setRoot(replacement);\n\t\t\t}\n\t\t\t// this._replaceNodeInParent(node, replacement);\n\t\t\tthis._rebalance(temp);\n\t\t}\n\t\tnode.dispose();\n\t};\n\n\t/**\n\t *  Rotate the tree to the left\n\t *  @param  {IntervalNode}  node\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._rotateLeft = function(node){\n\t\tvar parent = node.parent;\n\t\tvar isLeftChild = node.isLeftChild();\n\n\t\t// Make node.right the new root of this sub tree (instead of node)\n\t\tvar pivotNode = node.right;\n\t\tnode.right = pivotNode.left;\n\t\tpivotNode.left = node;\n\n\t\tif (parent !== null){\n\t\t\tif (isLeftChild){\n\t\t\t\tparent.left = pivotNode;\n\t\t\t} else {\n\t\t\t\tparent.right = pivotNode;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._setRoot(pivotNode);\n\t\t}\n\t};\n\n\t/**\n\t *  Rotate the tree to the right\n\t *  @param  {IntervalNode}  node\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._rotateRight = function(node){\n\t\tvar parent = node.parent;\n\t\tvar isLeftChild = node.isLeftChild();\n\n\t\t// Make node.left the new root of this sub tree (instead of node)\n\t\tvar pivotNode = node.left;\n\t\tnode.left = pivotNode.right;\n\t\tpivotNode.right = node;\n\n\t\tif (parent !== null){\n\t\t\tif (isLeftChild){\n\t\t\t\tparent.left = pivotNode;\n\t\t\t} else {\n\t\t\t\tparent.right = pivotNode;\n\t\t\t}\n\t\t} else {\n\t\t\tthis._setRoot(pivotNode);\n\t\t}\n\t};\n\n\t/**\n\t *  Balance the BST\n\t *  @param  {IntervalNode}  node\n\t *  @private\n\t */\n\tTone.IntervalTimeline.prototype._rebalance = function(node){\n\t\tvar balance = node.getBalance();\n\t\tif (balance > 1){\n\t\t\tif (node.left.getBalance() < 0){\n\t\t\t\tthis._rotateLeft(node.left);\n\t\t\t} else {\n\t\t\t\tthis._rotateRight(node);\n\t\t\t}\n\t\t} else if (balance < -1){\n\t\t\tif (node.right.getBalance() > 0){\n\t\t\t\tthis._rotateRight(node.right);\n\t\t\t} else {\n\t\t\t\tthis._rotateLeft(node);\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t *  Get an event whose time and duration span the give time. Will\n\t *  return the match whose \"time\" value is closest to the given time.\n\t *  @param  {Object}  event  The event to add to the timeline\n\t *  @return  {Object}  The event which spans the desired time\n\t */\n\tTone.IntervalTimeline.prototype.get = function(time){\n\t\tif (this._root !== null){\n\t\t\tvar results = [];\n\t\t\tthis._root.search(time, results);\n\t\t\tif (results.length > 0){\n\t\t\t\tvar max = results[0];\n\t\t\t\tfor (var i = 1; i < results.length; i++){\n\t\t\t\t\tif (results[i].low > max.low){\n\t\t\t\t\t\tmax = results[i];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn max.event;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t};\n\n\t/**\n\t *  Iterate over everything in the timeline.\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.IntervalTimeline} this\n\t */\n\tTone.IntervalTimeline.prototype.forEach = function(callback){\n\t\tif (this._root !== null){\n\t\t\tvar allNodes = [];\n\t\t\tthis._root.traverse(function(node){\n\t\t\t\tallNodes.push(node);\n\t\t\t});\n\t\t\tfor (var i = 0; i < allNodes.length; i++){\n\t\t\t\tvar ev = allNodes[i].event;\n\t\t\t\tif (ev){\n\t\t\t\t\tcallback(ev);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array in which the given time\n\t *  overlaps with the time and duration time of the event.\n\t *  @param  {Number}  time The time to check if items are overlapping\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.IntervalTimeline} this\n\t */\n\tTone.IntervalTimeline.prototype.forEachAtTime = function(time, callback){\n\t\tif (this._root !== null){\n\t\t\tvar results = [];\n\t\t\tthis._root.search(time, results);\n\t\t\tfor (var i = results.length - 1; i >= 0; i--){\n\t\t\t\tvar ev = results[i].event;\n\t\t\t\tif (ev){\n\t\t\t\t\tcallback(ev);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array in which the time is greater\n\t *  than or equal to the given time.\n\t *  @param  {Number}  time The time to check if items are before\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.IntervalTimeline} this\n\t */\n\tTone.IntervalTimeline.prototype.forEachFrom = function(time, callback){\n\t\tif (this._root !== null){\n\t\t\tvar results = [];\n\t\t\tthis._root.searchAfter(time, results);\n\t\t\tfor (var i = results.length - 1; i >= 0; i--){\n\t\t\t\tvar ev = results[i].event;\n\t\t\t\tcallback(ev);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.IntervalTimeline}  this\n\t */\n\tTone.IntervalTimeline.prototype.dispose = function(){\n\t\tvar allNodes = [];\n\t\tif (this._root !== null){\n\t\t\tthis._root.traverse(function(node){\n\t\t\t\tallNodes.push(node);\n\t\t\t});\n\t\t}\n\t\tfor (var i = 0; i < allNodes.length; i++){\n\t\t\tallNodes[i].dispose();\n\t\t}\n\t\tallNodes = null;\n\t\tthis._root = null;\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tINTERVAL NODE HELPER\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Represents a node in the binary search tree, with the addition\n\t *  of a \"high\" value which keeps track of the highest value of\n\t *  its children.\n\t *  References:\n\t *  https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/\n\t *  http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf\n\t *  @param {Number} low\n\t *  @param {Number} high\n\t *  @private\n\t */\n\tvar IntervalNode = function(low, high, event){\n\t\t//the event container\n\t\tthis.event = event;\n\t\t//the low value\n\t\tthis.low = low;\n\t\t//the high value\n\t\tthis.high = high;\n\t\t//the high value for this and all child nodes\n\t\tthis.max = this.high;\n\t\t//the nodes to the left\n\t\tthis._left = null;\n\t\t//the nodes to the right\n\t\tthis._right = null;\n\t\t//the parent node\n\t\tthis.parent = null;\n\t\t//the number of child nodes\n\t\tthis.height = 0;\n\t};\n\n\t/**\n\t *  Insert a node into the correct spot in the tree\n\t *  @param  {IntervalNode}  node\n\t */\n\tIntervalNode.prototype.insert = function(node){\n\t\tif (node.low <= this.low){\n\t\t\tif (this.left === null){\n\t\t\t\tthis.left = node;\n\t\t\t} else {\n\t\t\t\tthis.left.insert(node);\n\t\t\t}\n\t\t} else if (this.right === null){\n\t\t\tthis.right = node;\n\t\t} else {\n\t\t\tthis.right.insert(node);\n\t\t}\n\t};\n\n\t/**\n\t *  Search the tree for nodes which overlap\n\t *  with the given point\n\t *  @param  {Number}  point  The point to query\n\t *  @param  {Array}  results  The array to put the results\n\t */\n\tIntervalNode.prototype.search = function(point, results){\n\t\t// If p is to the right of the rightmost point of any interval\n\t\t// in this node and all children, there won't be any matches.\n\t\tif (point > this.max){\n\t\t\treturn;\n\t\t}\n\t\t// Search left children\n\t\tif (this.left !== null){\n\t\t\tthis.left.search(point, results);\n\t\t}\n\t\t// Check this node\n\t\tif (this.low <= point && this.high > point){\n\t\t\tresults.push(this);\n\t\t}\n\t\t// If p is to the left of the time of this interval,\n\t\t// then it can't be in any child to the right.\n\t\tif (this.low > point){\n\t\t\treturn;\n\t\t}\n\t\t// Search right children\n\t\tif (this.right !== null){\n\t\t\tthis.right.search(point, results);\n\t\t}\n\t};\n\n\t/**\n\t *  Search the tree for nodes which are less\n\t *  than the given point\n\t *  @param  {Number}  point  The point to query\n\t *  @param  {Array}  results  The array to put the results\n\t */\n\tIntervalNode.prototype.searchAfter = function(point, results){\n\t\t// Check this node\n\t\tif (this.low >= point){\n\t\t\tresults.push(this);\n\t\t\tif (this.left !== null){\n\t\t\t\tthis.left.searchAfter(point, results);\n\t\t\t}\n\t\t}\n\t\t// search the right side\n\t\tif (this.right !== null){\n\t\t\tthis.right.searchAfter(point, results);\n\t\t}\n\t};\n\n\t/**\n\t *  Invoke the callback on this element and both it's branches\n\t *  @param  {Function}  callback\n\t */\n\tIntervalNode.prototype.traverse = function(callback){\n\t\tcallback(this);\n\t\tif (this.left !== null){\n\t\t\tthis.left.traverse(callback);\n\t\t}\n\t\tif (this.right !== null){\n\t\t\tthis.right.traverse(callback);\n\t\t}\n\t};\n\n\t/**\n\t *  Update the height of the node\n\t */\n\tIntervalNode.prototype.updateHeight = function(){\n\t\tif (this.left !== null && this.right !== null){\n\t\t\tthis.height = Math.max(this.left.height, this.right.height) + 1;\n\t\t} else if (this.right !== null){\n\t\t\tthis.height = this.right.height + 1;\n\t\t} else if (this.left !== null){\n\t\t\tthis.height = this.left.height + 1;\n\t\t} else {\n\t\t\tthis.height = 0;\n\t\t}\n\t};\n\n\t/**\n\t *  Update the height of the node\n\t */\n\tIntervalNode.prototype.updateMax = function(){\n\t\tthis.max = this.high;\n\t\tif (this.left !== null){\n\t\t\tthis.max = Math.max(this.max, this.left.max);\n\t\t}\n\t\tif (this.right !== null){\n\t\t\tthis.max = Math.max(this.max, this.right.max);\n\t\t}\n\t};\n\n\t/**\n\t *  The balance is how the leafs are distributed on the node\n\t *  @return  {Number}  Negative numbers are balanced to the right\n\t */\n\tIntervalNode.prototype.getBalance = function(){\n\t\tvar balance = 0;\n\t\tif (this.left !== null && this.right !== null){\n\t\t\tbalance = this.left.height - this.right.height;\n\t\t} else if (this.left !== null){\n\t\t\tbalance = this.left.height + 1;\n\t\t} else if (this.right !== null){\n\t\t\tbalance = -(this.right.height + 1);\n\t\t}\n\t\treturn balance;\n\t};\n\n\t/**\n\t *  @returns {Boolean} true if this node is the left child\n\t *  of its parent\n\t */\n\tIntervalNode.prototype.isLeftChild = function(){\n\t\treturn this.parent !== null && this.parent.left === this;\n\t};\n\n\t/**\n\t *  get/set the left node\n\t *  @type {IntervalNode}\n\t */\n\tObject.defineProperty(IntervalNode.prototype, \"left\", {\n\t\tget : function(){\n\t\t\treturn this._left;\n\t\t},\n\t\tset : function(node){\n\t\t\tthis._left = node;\n\t\t\tif (node !== null){\n\t\t\t\tnode.parent = this;\n\t\t\t}\n\t\t\tthis.updateHeight();\n\t\t\tthis.updateMax();\n\t\t}\n\t});\n\n\t/**\n\t *  get/set the right node\n\t *  @type {IntervalNode}\n\t */\n\tObject.defineProperty(IntervalNode.prototype, \"right\", {\n\t\tget : function(){\n\t\t\treturn this._right;\n\t\t},\n\t\tset : function(node){\n\t\t\tthis._right = node;\n\t\t\tif (node !== null){\n\t\t\t\tnode.parent = this;\n\t\t\t}\n\t\t\tthis.updateHeight();\n\t\t\tthis.updateMax();\n\t\t}\n\t});\n\n\t/**\n\t *  null out references.\n\t */\n\tIntervalNode.prototype.dispose = function(){\n\t\tthis.parent = null;\n\t\tthis._left = null;\n\t\tthis._right = null;\n\t\tthis.event = null;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tEND INTERVAL NODE HELPER\n\t///////////////////////////////////////////////////////////////////////////\n\n\treturn Tone.IntervalTimeline;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/IntervalTimeline.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Listener.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/core/Listener.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\"), __webpack_require__(/*! ../signal/Zero */ \"./node_modules/tone/Tone/signal/Zero.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Both Tone.Panner3D and Tone.Listener have a position in 3D space\n\t *          using a right-handed cartesian coordinate system.\n\t *          The units used in the coordinate system are not defined;\n\t *          these coordinates are independent/invariant of any particular\n\t *          units such as meters or feet. Tone.Panner3D objects have an forward\n\t *          vector representing the direction the sound is projecting. Additionally,\n\t *          they have a sound cone representing how directional the sound is.\n\t *          For example, the sound could be omnidirectional, in which case it would\n\t *          be heard anywhere regardless of its forward, or it can be more directional\n\t *          and heard only if it is facing the listener. Tone.Listener objects\n\t *          (representing a person's ears) have an forward and up vector\n\t *          representing in which direction the person is facing. Because both the\n\t *          source stream and the listener can be moving, they both have a velocity\n\t *          vector representing both the speed and direction of movement. Taken together,\n\t *          these two velocities can be used to generate a doppler shift effect which changes the pitch.\n\t *          <br><br>\n\t *          Note: the position of the Listener will have no effect on nodes not connected to a Tone.Panner3D\n\t *\n\t *  @constructor\n\t *  @extends {Tone}\n\t *  @singleton\n\t */\n\tTone.Listener = function(){\n\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  Holds the current forward orientation\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._orientation = [0, 0, 0, 0, 0, 0];\n\n\t\t/**\n\t\t *  Holds the current position\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._position = [0, 0, 0];\n\n\t\tTone.getContext(function(){\n\t\t\t// set the default position/forward\n\t\t\tthis.set(ListenerConstructor.defaults);\n\n\t\t\t//listener is a singleton so it adds itself to the context\n\t\t\tthis.context.listener = this;\n\t\t}.bind(this));\n\n\t};\n\n\tTone.extend(Tone.Listener);\n\n\t/**\n\t *  Defaults according to the specification\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Listener.defaults = {\n\t\t\"positionX\" : 0,\n\t\t\"positionY\" : 0,\n\t\t\"positionZ\" : 0,\n\t\t\"forwardX\" : 0,\n\t\t\"forwardY\" : 0,\n\t\t\"forwardZ\" : 1,\n\t\t\"upX\" : 0,\n\t\t\"upY\" : 1,\n\t\t\"upZ\" : 0\n\t};\n\n\t/**\n\t * Is an instanceof Tone.Listener\n\t * @type {Boolean}\n\t */\n\tTone.Listener.prototype.isListener = true;\n\n\t/**\n\t * The ramp time which is applied to the setTargetAtTime\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.Listener.prototype._rampTimeConstant = 0.01;\n\n\t/**\n\t *  Sets the position of the listener in 3d space.\n\t *  @param  {Number}  x\n\t *  @param  {Number}  y\n\t *  @param  {Number}  z\n\t *  @return {Tone.Listener} this\n\t */\n\tTone.Listener.prototype.setPosition = function(x, y, z){\n\t\tif (this.context.rawContext.listener.positionX){\n\t\t\tvar now = this.now();\n\t\t\tthis.context.rawContext.listener.positionX.setTargetAtTime(x, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.positionY.setTargetAtTime(y, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.positionZ.setTargetAtTime(z, now, this._rampTimeConstant);\n\t\t} else {\n\t\t\tthis.context.rawContext.listener.setPosition(x, y, z);\n\t\t}\n\t\tthis._position = Array.prototype.slice.call(arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sets the orientation of the listener using two vectors, the forward\n\t *  vector (which direction the listener is facing) and the up vector\n\t *  (which the up direction of the listener). An up vector\n\t *  of 0, 0, 1 is equivalent to the listener standing up in the Z direction.\n\t *  @param  {Number}  x\n\t *  @param  {Number}  y\n\t *  @param  {Number}  z\n\t *  @param  {Number}  upX\n\t *  @param  {Number}  upY\n\t *  @param  {Number}  upZ\n\t *  @return {Tone.Listener} this\n\t */\n\tTone.Listener.prototype.setOrientation = function(x, y, z, upX, upY, upZ){\n\t\tif (this.context.rawContext.listener.forwardX){\n\t\t\tvar now = this.now();\n\t\t\tthis.context.rawContext.listener.forwardX.setTargetAtTime(x, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.forwardY.setTargetAtTime(y, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.forwardZ.setTargetAtTime(z, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.upX.setTargetAtTime(upX, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.upY.setTargetAtTime(upY, now, this._rampTimeConstant);\n\t\t\tthis.context.rawContext.listener.upZ.setTargetAtTime(upZ, now, this._rampTimeConstant);\n\t\t} else {\n\t\t\tthis.context.rawContext.listener.setOrientation(x, y, z, upX, upY, upZ);\n\t\t}\n\t\tthis._orientation = Array.prototype.slice.call(arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The x position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name positionX\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"positionX\", {\n\t\tset : function(pos){\n\t\t\tthis._position[0] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[0];\n\t\t}\n\t});\n\n\t/**\n\t *  The y position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name positionY\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"positionY\", {\n\t\tset : function(pos){\n\t\t\tthis._position[1] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[1];\n\t\t}\n\t});\n\n\t/**\n\t *  The z position of the panner object.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name positionZ\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"positionZ\", {\n\t\tset : function(pos){\n\t\t\tthis._position[2] = pos;\n\t\t\tthis.setPosition.apply(this, this._position);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._position[2];\n\t\t}\n\t});\n\n\t/**\n\t *  The x coordinate of the listeners front direction. i.e.\n\t *  which way they are facing.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name forwardX\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"forwardX\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[0] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[0];\n\t\t}\n\t});\n\n\t/**\n\t *  The y coordinate of the listeners front direction. i.e.\n\t *  which way they are facing.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name forwardY\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"forwardY\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[1] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[1];\n\t\t}\n\t});\n\n\t/**\n\t *  The z coordinate of the listeners front direction. i.e.\n\t *  which way they are facing.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name forwardZ\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"forwardZ\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[2] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[2];\n\t\t}\n\t});\n\n\t/**\n\t *  The x coordinate of the listener's up direction. i.e.\n\t *  the direction the listener is standing in.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name upX\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"upX\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[3] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[3];\n\t\t}\n\t});\n\n\t/**\n\t *  The y coordinate of the listener's up direction. i.e.\n\t *  the direction the listener is standing in.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name upY\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"upY\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[4] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[4];\n\t\t}\n\t});\n\n\t/**\n\t *  The z coordinate of the listener's up direction. i.e.\n\t *  the direction the listener is standing in.\n\t *  @type {Number}\n\t *  @memberOf Tone.Listener#\n\t *  @name upZ\n\t */\n\tObject.defineProperty(Tone.Listener.prototype, \"upZ\", {\n\t\tset : function(pos){\n\t\t\tthis._orientation[5] = pos;\n\t\t\tthis.setOrientation.apply(this, this._orientation);\n\t\t},\n\t\tget : function(){\n\t\t\treturn this._orientation[5];\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Listener} this\n\t */\n\tTone.Listener.prototype.dispose = function(){\n\t\tthis._orientation = null;\n\t\tthis._position = null;\n\t\treturn this;\n\t};\n\n\t//SINGLETON SETUP\n\tvar ListenerConstructor = Tone.Listener;\n\tTone.Listener = new ListenerConstructor();\n\n\tTone.Context.on(\"init\", function(context){\n\t\tif (context.listener && context.listener.isListener){\n\t\t\t//a single listener object\n\t\t\tTone.Listener = context.listener;\n\t\t} else {\n\t\t\t//make new Listener insides\n\t\t\tTone.Listener = new ListenerConstructor();\n\t\t}\n\t});\n\t//END SINGLETON SETUP\n\n\treturn Tone.Listener;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Listener.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Master.js":
/*!***********************************************!*\
  !*** ./node_modules/tone/Tone/core/Master.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Volume */ \"./node_modules/tone/Tone/component/Volume.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  A single master output which is connected to the\n\t *          AudioDestinationNode (aka your speakers).\n\t *          It provides useful conveniences such as the ability\n\t *          to set the volume and mute the entire application.\n\t *          It also gives you the ability to apply master effects to your application.\n\t *          <br><br>\n\t *          Like Tone.Transport, A single Tone.Master is created\n\t *          on initialization and you do not need to explicitly construct one.\n\t *\n\t *  @constructor\n\t *  @extends {Tone}\n\t *  @singleton\n\t *  @example\n\t * //the audio will go from the oscillator to the speakers\n\t * oscillator.connect(Tone.Master);\n\t * //a convenience for connecting to the master output is also provided:\n\t * oscillator.toMaster();\n\t * //the above two examples are equivalent.\n\t */\n\tTone.Master = function(){\n\n\t\tTone.AudioNode.call(this);\n\t\tTone.getContext(function(){\n\t\t\tthis.createInsOuts(1, 0);\n\n\t\t\t/**\n\t\t\t *  The private volume node\n\t\t\t *  @type  {Tone.Volume}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._volume = this.output = new Tone.Volume();\n\n\t\t\t/**\n\t\t\t * The volume of the master output.\n\t\t\t * @type {Decibels}\n\t\t\t * @signal\n\t\t\t */\n\t\t\tthis.volume = this._volume.volume;\n\n\t\t\tthis._readOnly(\"volume\");\n\t\t\t//connections\n\t\t\tthis.input.chain(this.output, this.context.destination);\n\n\t\t\t//master is a singleton so it adds itself to the context\n\t\t\tthis.context.master = this;\n\t\t}.bind(this));\n\t};\n\n\tTone.extend(Tone.Master, Tone.AudioNode);\n\n\t/**\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.Master.defaults = {\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t * Is an instanceof Tone.Master\n\t * @type {Boolean}\n\t */\n\tTone.Master.prototype.isMaster = true;\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.Master#\n\t * @type {boolean}\n\t * @name mute\n\t * @example\n\t * //mute the output\n\t * Tone.Master.mute = true;\n\t */\n\tObject.defineProperty(Tone.Master.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._volume.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._volume.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t *  Add a master effects chain. NOTE: this will disconnect any nodes which were previously\n\t *  chained in the master effects chain.\n\t *  @param {AudioNode|Tone} args... All arguments will be connected in a row\n\t *                                  and the Master will be routed through it.\n\t *  @return  {Tone.Master}  this\n\t *  @example\n\t * //some overall compression to keep the levels in check\n\t * var masterCompressor = new Tone.Compressor({\n\t * \t\"threshold\" : -6,\n\t * \t\"ratio\" : 3,\n\t * \t\"attack\" : 0.5,\n\t * \t\"release\" : 0.1\n\t * });\n\t * //give a little boost to the lows\n\t * var lowBump = new Tone.Filter(200, \"lowshelf\");\n\t * //route everything through the filter\n\t * //and compressor before going to the speakers\n\t * Tone.Master.chain(lowBump, masterCompressor);\n\t */\n\tTone.Master.prototype.chain = function(){\n\t\tthis.input.disconnect();\n\t\tthis.input.chain.apply(this.input, arguments);\n\t\targuments[arguments.length - 1].connect(this.output);\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Master}  this\n\t */\n\tTone.Master.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._writable(\"volume\");\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis.volume = null;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tAUGMENT TONE's PROTOTYPE\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Connect 'this' to the master output. Shorthand for this.connect(Tone.Master)\n\t *  @returns {Tone.AudioNode} this\n\t *  @example\n\t * //connect an oscillator to the master output\n\t * var osc = new Tone.Oscillator().toMaster();\n\t */\n\tTone.AudioNode.prototype.toMaster = function(){\n\t\tthis.connect(this.context.master);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  initialize the module and listen for new audio contexts\n\t */\n\tvar MasterConstructor = Tone.Master;\n\tTone.Master = new MasterConstructor();\n\n\tTone.Context.on(\"init\", function(context){\n\t\t// if it already exists, just restore it\n\t\tif (context.master && context.master.isMaster){\n\t\t\tTone.Master = context.master;\n\t\t} else {\n\t\t\tTone.Master = new MasterConstructor();\n\t\t}\n\t});\n\n\tTone.Context.on(\"close\", function(context){\n\t\tif (context.master && context.master.isMaster){\n\t\t\tcontext.master.dispose();\n\t\t}\n\t});\n\n\treturn Tone.Master;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Master.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Offline.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/core/Offline.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../core/OfflineContext */ \"./node_modules/tone/Tone/core/OfflineContext.js\"), __webpack_require__(/*! ../core/Master */ \"./node_modules/tone/Tone/core/Master.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.\n\t *  The OfflineAudioContext is capable of rendering much faster than real time in many cases.\n\t *  The callback function also passes in an offline instance of Tone.Transport which can be used\n\t *  to schedule events along the Transport. **NOTE** OfflineAudioContext has the same restrictions\n\t *  as the AudioContext in that on certain platforms (like iOS) it must be invoked by an explicit\n\t *  user action like a click or tap. \n\t *  @param  {Function}  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.\n\t *  @param  {Time}  duration     the amount of time to record for.\n\t *  @return  {Promise}  The promise which is invoked with the Tone.Buffer of the recorded output.\n\t *  @example\n\t * //render 2 seconds of the oscillator\n\t * Tone.Offline(function(){\n\t * \t//only nodes created in this callback will be recorded\n\t * \tvar oscillator = new Tone.Oscillator().toMaster().start(0)\n\t * \t//schedule their events\n\t * }, 2).then(function(buffer){\n\t * \t//do something with the output buffer\n\t * })\n\t * @example\n\t * //can also schedule events along the Transport\n\t * //using the passed in Offline Transport\n\t * Tone.Offline(function(Transport){\n\t * \tvar osc = new Tone.Oscillator().toMaster()\n\t * \tTransport.schedule(function(time){\n\t * \t\tosc.start(time).stop(time + 0.1)\n\t * \t}, 1)\n\t * \tTransport.start(0.2)\n\t * }, 4).then(function(buffer){\n\t * \t//do something with the output buffer\n\t * })\n\t */\n\tTone.Offline = function(callback, duration){\n\t\t//set the OfflineAudioContext\n\t\tvar sampleRate = Tone.context.sampleRate;\n\t\tvar originalContext = Tone.context;\n\n\t\tvar context = new Tone.OfflineContext(2, duration, sampleRate);\n\t\tTone.context = context;\n\n\t\t//invoke the callback/scheduling\n\t\tvar response = callback(Tone.Transport);\n\n\t\t//the return value\n\t\tvar ret = null;\n\n\t\tif (response && Tone.isFunction(response.then)){\n\t\t\t//wait for the promise to resolve\n\t\t\tret = response.then(function(){\n\t\t\t\t//then render the audio\n\t\t\t\treturn context.render();\n\t\t\t});\n\t\t} else {\n\t\t\t//process the audio\n\t\t\tret = context.render();\n\t\t}\n\n\t\t//return the original AudioContext\n\t\tTone.context = originalContext;\n\n\t\t//return the audio\n\t\treturn ret.then(function(buffer){\n\t\t\t//wrap it in a Tone.Buffer\n\t\t\treturn new Tone.Buffer(buffer);\n\t\t});\n\t};\n\n\treturn Tone.Offline;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Offline.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/OfflineContext.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/core/OfflineContext.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\"), __webpack_require__(/*! ../shim/OfflineAudioContext */ \"./node_modules/tone/Tone/shim/OfflineAudioContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Wrapper around the OfflineAudioContext\n\t *  @extends {Tone.Context}\n\t *  @param  {Number}  channels  The number of channels to render\n\t *  @param  {Number}  duration  The duration to render in samples\n\t *  @param {Number} sampleRate the sample rate to render at\n\t */\n\tTone.OfflineContext = function(channels, duration, sampleRate){\n\n\t\t/**\n\t\t *  The offline context\n\t\t *  @private\n\t\t *  @type  {OfflineAudioContext}\n\t\t */\n\t\tvar offlineContext = new OfflineAudioContext(channels, duration * sampleRate, sampleRate);\n\n\t\t//wrap the methods/members\n\t\tTone.Context.call(this, {\n\t\t\t\"context\" : offlineContext,\n\t\t\t\"clockSource\" : \"offline\",\n\t\t\t\"lookAhead\" : 0,\n\t\t\t\"updateInterval\" : 128 / sampleRate\n\t\t});\n\n\t\t/**\n\t\t *  A private reference to the duration\n\t\t *  @private\n\t\t *  @type  {Number}\n\t\t */\n\t\tthis._duration = duration;\n\n\t\t/**\n\t\t *  An artificial clock source\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._currentTime = 0;\n\t};\n\n\tTone.extend(Tone.OfflineContext, Tone.Context);\n\n\t/**\n\t *  Override the now method to point to the internal clock time\n\t *  @return  {Number}\n\t */\n\tTone.OfflineContext.prototype.now = function(){\n\t\treturn this._currentTime;\n\t};\n\n\t/**\n\t *  Overwrite resume, should not do anything in the OfflineAudioContext.\n\t *  @return {Promise}\n\t */\n\tTone.OfflineContext.prototype.resume = function(){\n\t\treturn Promise.resolve();\n\t};\n\n\t/**\n\t *  Render the output of the OfflineContext\n\t *  @return  {Promise}\n\t */\n\tTone.OfflineContext.prototype.render = function(){\n\t\twhile (this._duration - this._currentTime >= 0){\n\t\t\t//invoke all the callbacks on that time\n\t\t\tthis.emit(\"tick\");\n\t\t\t//increment the clock\n\t\t\tthis._currentTime += this.blockTime;\n\t\t}\n\n\t\treturn this._context.startRendering();\n\t};\n\n\t/**\n\t *  Close the context\n\t *  @return  {Promise}\n\t */\n\tTone.OfflineContext.prototype.close = function(){\n\t\tthis._context = null;\n\t\treturn Promise.resolve();\n\t};\n\n\treturn Tone.OfflineContext;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/OfflineContext.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Param.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/core/Param.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\"), __webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Param wraps the native Web Audio's AudioParam to provide\n\t *         additional unit conversion functionality. It also\n\t *         serves as a base-class for classes which have a single,\n\t *         automatable parameter.\n\t *  @extends {Tone.AudioNode}\n\t *  @param  {AudioParam}  param  The parameter to wrap.\n\t *  @param  {Tone.Type} units The units of the audio param.\n\t *  @param  {Boolean} convert If the param should be converted.\n\t */\n\tTone.Param = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"param\", \"units\", \"convert\"], Tone.Param);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The native parameter to control\n\t\t *  @type  {AudioParam}\n\t\t *  @private\n\t\t */\n\t\tthis._param = this.input = options.param;\n\n\t\t/**\n\t\t *  The units of the parameter\n\t\t *  @type {Tone.Type}\n\t\t */\n\t\tthis.units = options.units;\n\n\t\t/**\n\t\t *  If the value should be converted or not\n\t\t *  @type {Boolean}\n\t\t */\n\t\tthis.convert = options.convert;\n\n\t\t/**\n\t\t *  True if the signal value is being overridden by\n\t\t *  a connected signal.\n\t\t *  @readOnly\n\t\t *  @type  {boolean}\n\t\t *  @private\n\t\t */\n\t\tthis.overridden = false;\n\n\t\t/**\n\t\t * The timeline which tracks all of the automations.\n\t\t * @type {Tone.Timeline}\n\t\t * @private\n\t\t */\n\t\tthis._events = new Tone.Timeline(1000);\n\n\t\tif (Tone.isDefined(options.value) && this._param){\n\t\t\tthis.setValueAtTime(options.value, 0);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Param, Tone.AudioNode);\n\n\t/**\n\t *  Defaults\n\t *  @type  {Object}\n\t *  @const\n\t */\n\tTone.Param.defaults = {\n\t\t\"units\" : Tone.Type.Default,\n\t\t\"convert\" : true,\n\t\t\"param\" : undefined\n\t};\n\n\t/**\n\t * The current value of the parameter.\n\t * @memberOf Tone.Param#\n\t * @type {Number}\n\t * @name value\n\t */\n\tObject.defineProperty(Tone.Param.prototype, \"value\", {\n\t\tget : function(){\n\t\t\tvar now = this.now();\n\t\t\treturn this._toUnits(this.getValueAtTime(now));\n\t\t},\n\t\tset : function(value){\n\t\t\tthis._initialValue = this._fromUnits(value);\n\t\t\tthis.cancelScheduledValues(this.now());\n\t\t\tthis.setValueAtTime(value, this.now());\n\t\t}\n\t});\n\n\t/**\n\t * The minimum output value of the parameter\n\t * @memberOf Tone.Param#\n\t * @type {Number}\n\t * @name value\n\t */\n\tObject.defineProperty(Tone.Param.prototype, \"minValue\", {\n\t\tget : function(){\n\t\t\tif (this.units === Tone.Type.Time || this.units === Tone.Type.Frequency ||\n\t\t\t\tthis.units === Tone.Type.NormalRange || this.units === Tone.Type.Positive ||\n\t\t\t\tthis.units === Tone.Type.BPM){\n\t\t\t\treturn 0;\n\t\t\t} else if (this.units === Tone.Type.AudioRange){\n\t\t\t\treturn -1;\n\t\t\t} else if (this.units === Tone.Type.Decibels){\n\t\t\t\treturn -Infinity;\n\t\t\t} else {\n\t\t\t\treturn this._param.minValue;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The maximum output value of the parameter\n\t * @memberOf Tone.Param#\n\t * @type {Number}\n\t * @name value\n\t */\n\tObject.defineProperty(Tone.Param.prototype, \"maxValue\", {\n\t\tget : function(){\n\t\t\tif (this.units === Tone.Type.NormalRange ||\n\t\t\t\tthis.units === Tone.Type.AudioRange){\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\treturn this._param.maxValue;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Convert the given value from the type specified by Tone.Param.units\n\t *  into the destination value (such as Gain or Frequency).\n\t *  @private\n\t *  @param  {*} val the value to convert\n\t *  @return {number}     the number which the value should be set to\n\t */\n\tTone.Param.prototype._fromUnits = function(val){\n\t\tif ((this.convert || Tone.isUndef(this.convert)) && !this.overridden){\n\t\t\tswitch (this.units){\n\t\t\t\tcase Tone.Type.Time:\n\t\t\t\t\treturn this.toSeconds(val);\n\t\t\t\tcase Tone.Type.Frequency:\n\t\t\t\t\treturn this.toFrequency(val);\n\t\t\t\tcase Tone.Type.Decibels:\n\t\t\t\t\treturn Tone.dbToGain(val);\n\t\t\t\tcase Tone.Type.NormalRange:\n\t\t\t\t\treturn Math.min(Math.max(val, 0), 1);\n\t\t\t\tcase Tone.Type.AudioRange:\n\t\t\t\t\treturn Math.min(Math.max(val, -1), 1);\n\t\t\t\tcase Tone.Type.Positive:\n\t\t\t\t\treturn Math.max(val, 0);\n\t\t\t\tdefault:\n\t\t\t\t\treturn val;\n\t\t\t}\n\t\t} else {\n\t\t\treturn val;\n\t\t}\n\t};\n\n\t/**\n\t * Convert the parameters value into the units specified by Tone.Param.units.\n\t * @private\n\t * @param  {number} val the value to convert\n\t * @return {number}\n\t */\n\tTone.Param.prototype._toUnits = function(val){\n\t\tif (this.convert || Tone.isUndef(this.convert)){\n\t\t\tswitch (this.units){\n\t\t\t\tcase Tone.Type.Decibels:\n\t\t\t\t\treturn Tone.gainToDb(val);\n\t\t\t\tdefault:\n\t\t\t\t\treturn val;\n\t\t\t}\n\t\t} else {\n\t\t\treturn val;\n\t\t}\n\t};\n\n\t/**\n\t *  the minimum output value\n\t *  @type {Number}\n\t *  @private\n\t */\n\tTone.Param.prototype._minOutput = 1e-5;\n\n\t/**\n\t *  The event types\n\t *  @enum {String}\n\t *  @private\n\t */\n\tTone.Param.AutomationType = {\n\t\tLinear : \"linearRampToValueAtTime\",\n\t\tExponential : \"exponentialRampToValueAtTime\",\n\t\tTarget : \"setTargetAtTime\",\n\t\tSetValue : \"setValueAtTime\",\n\t\tCancel : \"cancelScheduledValues\"\n\t};\n\n\t/**\n\t *  Schedules a parameter value change at the given time.\n\t *  @param {*}\tvalue The value to set the signal.\n\t *  @param {Time}  time The time when the change should occur.\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //set the frequency to \"G4\" in exactly 1 second from now.\n\t * freq.setValueAtTime(\"G4\", \"+1\");\n\t */\n\tTone.Param.prototype.setValueAtTime = function(value, time){\n\t\ttime = this.toSeconds(time);\n\t\tvalue = this._fromUnits(value);\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.SetValue,\n\t\t\t\"value\" : value,\n\t\t\t\"time\" : time,\n\t\t});\n\t\tthis.log(Tone.Param.AutomationType.SetValue, value, time);\n\t\tthis._param.setValueAtTime(value, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the signals value at the given time. Subsequent scheduling\n\t *  may invalidate the returned value.\n\t *  @param {Time} time When to get the value\n\t *  @returns {Number} The value at the given time\n\t */\n\tTone.Param.prototype.getValueAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tvar after = this._events.getAfter(time);\n\t\tvar before = this._events.get(time);\n\t\tvar initialValue = Tone.defaultArg(this._initialValue, this._param.defaultValue);\n\t\tvar value = initialValue;\n\t\t//if it was set by\n\t\tif (before === null){\n\t\t\tvalue = initialValue;\n\t\t} else if (before.type === Tone.Param.AutomationType.Target){\n\t\t\tvar previous = this._events.getBefore(before.time);\n\t\t\tvar previousVal;\n\t\t\tif (previous === null){\n\t\t\t\tpreviousVal = initialValue;\n\t\t\t} else {\n\t\t\t\tpreviousVal = previous.value;\n\t\t\t}\n\t\t\tvalue = this._exponentialApproach(before.time, previousVal, before.value, before.constant, time);\n\t\t} else if (after === null){\n\t\t\tvalue = before.value;\n\t\t} else if (after.type === Tone.Param.AutomationType.Linear){\n\t\t\tvalue = this._linearInterpolate(before.time, before.value, after.time, after.value, time);\n\t\t} else if (after.type === Tone.Param.AutomationType.Exponential){\n\t\t\tvalue = this._exponentialInterpolate(before.time, before.value, after.time, after.value, time);\n\t\t} else {\n\t\t\tvalue = before.value;\n\t\t}\n\t\treturn value;\n\t};\n\n\t/**\n\t *  Creates a schedule point with the current value at the current time.\n\t *  This is useful for creating an automation anchor point in order to\n\t *  schedule changes from the current value.\n\t *\n\t *  @param {number=} now (Optionally) pass the now value in.\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.setRampPoint = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tvar currentVal = this.getValueAtTime(time);\n\t\tthis.cancelAndHoldAtTime(time);\n\t\tif (currentVal === 0){\n\t\t\tcurrentVal = this._minOutput;\n\t\t}\n\t\tthis.setValueAtTime(this._toUnits(currentVal), time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Schedules a linear continuous change in parameter value from the\n\t *  previous scheduled parameter value to the given value.\n\t *\n\t *  @param  {number} value\n\t *  @param  {Time} endTime\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.linearRampToValueAtTime = function(value, endTime){\n\t\tvalue = this._fromUnits(value);\n\t\tendTime = this.toSeconds(endTime);\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.Linear,\n\t\t\t\"value\" : value,\n\t\t\t\"time\" : endTime,\n\t\t});\n\t\tthis.log(Tone.Param.AutomationType.Linear, value, endTime);\n\t\tthis._param.linearRampToValueAtTime(value, endTime);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Schedules an exponential continuous change in parameter value from\n\t *  the previous scheduled parameter value to the given value.\n\t *\n\t *  @param  {number} value\n\t *  @param  {Time} endTime\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.exponentialRampToValueAtTime = function(value, endTime){\n\t\tvalue = this._fromUnits(value);\n\t\tvalue = Math.max(this._minOutput, value);\n\t\tendTime = this.toSeconds(endTime);\n\t\t//store the event\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.Exponential,\n\t\t\t\"time\" : endTime,\n\t\t\t\"value\" : value\n\t\t});\n\t\tthis.log(Tone.Param.AutomationType.Exponential, value, endTime);\n\t\tthis._param.exponentialRampToValueAtTime(value, endTime);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Schedules an exponential continuous change in parameter value from\n\t *  the current time and current value to the given value over the\n\t *  duration of the rampTime.\n\t *\n\t *  @param  {number} value   The value to ramp to.\n\t *  @param  {Time} rampTime the time that it takes the\n\t *                               value to ramp from it's current value\n\t *  @param {Time}\t[startTime=now] \tWhen the ramp should start.\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //exponentially ramp to the value 2 over 4 seconds.\n\t * signal.exponentialRampTo(2, 4);\n\t */\n\tTone.Param.prototype.exponentialRampTo = function(value, rampTime, startTime){\n\t\tstartTime = this.toSeconds(startTime);\n\t\tthis.setRampPoint(startTime);\n\t\tthis.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Schedules an linear continuous change in parameter value from\n\t *  the current time and current value to the given value over the\n\t *  duration of the rampTime.\n\t *\n\t *  @param  {number} value   The value to ramp to.\n\t *  @param  {Time} rampTime the time that it takes the\n\t *                               value to ramp from it's current value\n\t *  @param {Time}\t[startTime=now] \tWhen the ramp should start.\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //linearly ramp to the value 4 over 3 seconds.\n\t * signal.linearRampTo(4, 3);\n\t */\n\tTone.Param.prototype.linearRampTo = function(value, rampTime, startTime){\n\t\tstartTime = this.toSeconds(startTime);\n\t\tthis.setRampPoint(startTime);\n\t\tthis.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Start exponentially approaching the target value at the given time. Since it\n\t *  is an exponential approach it will continue approaching after the ramp duration. The\n\t *  rampTime is the time that it takes to reach over 99% of the way towards the value.\n\t *  @param  {number} value   The value to ramp to.\n\t *  @param  {Time} rampTime the time that it takes the\n\t *                               value to ramp from it's current value\n\t *  @param {Time}\t[startTime=now] \tWhen the ramp should start.\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //exponentially ramp to the value 2 over 4 seconds.\n\t * signal.exponentialRampTo(2, 4);\n\t */\n\tTone.Param.prototype.targetRampTo = function(value, rampTime, startTime){\n\t\tstartTime = this.toSeconds(startTime);\n\t\tthis.setRampPoint(startTime);\n\t\tthis.exponentialApproachValueAtTime(value, startTime, rampTime);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Start exponentially approaching the target value at the given time. Since it\n\t *  is an exponential approach it will continue approaching after the ramp duration. The\n\t *  rampTime is the time that it takes to reach over 99% of the way towards the value. This methods\n\t *  is similar to setTargetAtTime except the third argument is a time instead of a 'timeConstant'\n\t *  @param  {number} value   The value to ramp to.\n\t *  @param {Time}\ttime \tWhen the ramp should start.\n\t *  @param  {Time} rampTime the time that it takes the\n\t *                               value to ramp from it's current value\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //exponentially ramp to the value 2 over 4 seconds.\n\t * signal.exponentialRampTo(2, 4);\n\t */\n\tTone.Param.prototype.exponentialApproachValueAtTime = function(value, time, rampTime){\n\t\tvar timeConstant = Math.log(this.toSeconds(rampTime)+1)/Math.log(200);\n\t\ttime = this.toSeconds(time);\n\t\treturn this.setTargetAtTime(value, time, timeConstant);\n\t};\n\n\t/**\n\t *  Start exponentially approaching the target value at the given time with\n\t *  a rate having the given time constant.\n\t *  @param {number} value\n\t *  @param {Time} startTime\n\t *  @param {number} timeConstant\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.setTargetAtTime = function(value, startTime, timeConstant){\n\t\tvalue = this._fromUnits(value);\n\t\t// The value will never be able to approach without timeConstant > 0.\n\t\tif (timeConstant <= 0){\n\t\t\tthrow new Error(\"timeConstant must be greater than 0\");\n\t\t}\n\t\tstartTime = this.toSeconds(startTime);\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.Target,\n\t\t\t\"value\" : value,\n\t\t\t\"time\" : startTime,\n\t\t\t\"constant\" : timeConstant\n\t\t});\n\t\tthis.log(Tone.Param.AutomationType.Target, value, startTime, timeConstant);\n\t\tthis._param.setTargetAtTime(value, startTime, timeConstant);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sets an array of arbitrary parameter values starting at the given time\n\t *  for the given duration.\n\t *\n\t *  @param {Array} values\n\t *  @param {Time} startTime\n\t *  @param {Time} duration\n\t *  @param {NormalRange} [scaling=1] If the values in the curve should be scaled by some value\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.setValueCurveAtTime = function(values, startTime, duration, scaling){\n\t\tscaling = Tone.defaultArg(scaling, 1);\n\t\tduration = this.toSeconds(duration);\n\t\tstartTime = this.toSeconds(startTime);\n\t\tthis.setValueAtTime(values[0] * scaling, startTime);\n\t\tvar segTime = duration / (values.length - 1);\n\t\tfor (var i = 1; i < values.length; i++){\n\t\t\tthis.linearRampToValueAtTime(values[i] * scaling, startTime + i * segTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancels all scheduled parameter changes with times greater than or\n\t *  equal to startTime.\n\t *\n\t *  @param  {Time} time\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.cancelScheduledValues = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._events.cancel(time);\n\t\tthis._param.cancelScheduledValues(time);\n\t\tthis.log(Tone.Param.AutomationType.Cancel, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  This is similar to [cancelScheduledValues](#cancelScheduledValues) except\n\t *  it holds the automated value at time until the next automated event.\n\t *  @param  {Time} time\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.cancelAndHoldAtTime = function(time){\n\t\tvar valueAtTime = this.getValueAtTime(time);\n\t\tthis.log(\"cancelAndHoldAtTime\", time, \"value=\"+valueAtTime);\n\n\t\t//remove the schedule events\n\t\tthis._param.cancelScheduledValues(time);\n\n\t\t//if there is an event at the given time\n\t\t//and that even is not a \"set\"\n\t\tvar before = this._events.get(time);\n\t\tvar after = this._events.getAfter(time);\n\t\tif (before && before.time === time){\n\t\t\t//remove everything after\n\t\t\tif (after){\n\t\t\t\tthis._events.cancel(after.time);\n\t\t\t} else {\n\t\t\t\tthis._events.cancel(time + this.sampleTime);\n\t\t\t}\n\t\t} else if (after){\n\t\t\t//cancel the next event(s)\n\t\t\tthis._events.cancel(after.time);\n\t\t\tif (after.type === Tone.Param.AutomationType.Linear){\n\t\t\t\tthis.linearRampToValueAtTime(valueAtTime, time);\n\t\t\t} else if (after.type === Tone.Param.AutomationType.Exponential){\n\t\t\t\tthis.exponentialRampToValueAtTime(valueAtTime, time);\n\t\t\t}\n\t\t}\n\n\t\t//set the value at the given time\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.SetValue,\n\t\t\t\"value\" : valueAtTime,\n\t\t\t\"time\" : time\n\t\t});\n\t\tthis._param.setValueAtTime(valueAtTime, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Ramps to the given value over the duration of the rampTime.\n\t *  Automatically selects the best ramp type (exponential or linear)\n\t *  depending on the `units` of the signal\n\t *\n\t *  @param  {number} value\n\t *  @param  {Time} rampTime \tThe time that it takes the\n\t *                              value to ramp from it's current value\n\t *  @param {Time}\t[startTime=now] \tWhen the ramp should start.\n\t *  @returns {Tone.Param} this\n\t *  @example\n\t * //ramp to the value either linearly or exponentially\n\t * //depending on the \"units\" value of the signal\n\t * signal.rampTo(0, 10);\n\t *  @example\n\t * //schedule it to ramp starting at a specific time\n\t * signal.rampTo(0, 10, 5)\n\t */\n\tTone.Param.prototype.rampTo = function(value, rampTime, startTime){\n\t\trampTime = Tone.defaultArg(rampTime, 0.1);\n\t\tif (this.units === Tone.Type.Frequency || this.units === Tone.Type.BPM || this.units === Tone.Type.Decibels){\n\t\t\tthis.exponentialRampTo(value, rampTime, startTime);\n\t\t} else {\n\t\t\tthis.linearRampTo(value, rampTime, startTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tAUTOMATION CURVE CALCULATIONS\n\t//\tMIT License, copyright (c) 2014 Jordan Santell\n\t///////////////////////////////////////////////////////////////////////////\n\n\t// Calculates the the value along the curve produced by setTargetAtTime\n\tTone.Param.prototype._exponentialApproach = function(t0, v0, v1, timeConstant, t){\n\t\treturn v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);\n\t};\n\n\t// Calculates the the value along the curve produced by linearRampToValueAtTime\n\tTone.Param.prototype._linearInterpolate = function(t0, v0, t1, v1, t){\n\t\treturn v0 + (v1 - v0) * ((t - t0) / (t1 - t0));\n\t};\n\n\t// Calculates the the value along the curve produced by exponentialRampToValueAtTime\n\tTone.Param.prototype._exponentialInterpolate = function(t0, v0, t1, v1, t){\n\t\treturn v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.Param.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._param = null;\n\t\tthis._events = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Param;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Param.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Timeline.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/core/Timeline.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class A Timeline class for scheduling and maintaining state\n\t *         along a timeline. All events must have a \"time\" property.\n\t *         Internally, events are stored in time order for fast\n\t *         retrieval.\n\t *  @extends {Tone}\n\t *  @param {Positive} [memory=Infinity] The number of previous events that are retained.\n\t */\n\tTone.Timeline = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"memory\"], Tone.Timeline);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The array of scheduled timeline events\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._timeline = [];\n\n\t\t/**\n\t\t *  The memory of the timeline, i.e.\n\t\t *  how many events in the past it will retain\n\t\t *  @type {Positive}\n\t\t */\n\t\tthis.memory = options.memory;\n\t};\n\n\tTone.extend(Tone.Timeline);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t */\n\tTone.Timeline.defaults = {\n\t\t\"memory\" : Infinity\n\t};\n\n\t/**\n\t *  The number of items in the timeline.\n\t *  @type {Number}\n\t *  @memberOf Tone.Timeline#\n\t *  @name length\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Timeline.prototype, \"length\", {\n\t\tget : function(){\n\t\t\treturn this._timeline.length;\n\t\t}\n\t});\n\n\t/**\n\t *  Insert an event object onto the timeline. Events must have a \"time\" attribute.\n\t *  @param  {Object}  event  The event object to insert into the\n\t *                           timeline.\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.add = function(event){\n\t\t//the event needs to have a time attribute\n\t\tif (Tone.isUndef(event.time)){\n\t\t\tthrow new Error(\"Tone.Timeline: events must have a time attribute\");\n\t\t}\n\t\tevent.time = event.time.valueOf();\n\t\tvar index = this._search(event.time);\n\t\tthis._timeline.splice(index + 1, 0, event);\n\t\t//if the length is more than the memory, remove the previous ones\n\t\tif (this.length > this.memory){\n\t\t\tvar diff = this.length - this.memory;\n\t\t\tthis._timeline.splice(0, diff);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Remove an event from the timeline.\n\t *  @param  {Object}  event  The event object to remove from the list.\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.remove = function(event){\n\t\tvar index = this._timeline.indexOf(event);\n\t\tif (index !== -1){\n\t\t\tthis._timeline.splice(index, 1);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the nearest event whose time is less than or equal to the given time.\n\t *  @param  {Number}  time  The time to query.\n\t *  @param  {String}  comparator Which value in the object to compare\n\t *  @returns {Object} The event object set after that time.\n\t */\n\tTone.Timeline.prototype.get = function(time, comparator){\n\t\tcomparator = Tone.defaultArg(comparator, \"time\");\n\t\tvar index = this._search(time, comparator);\n\t\tif (index !== -1){\n\t\t\treturn this._timeline[index];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\t/**\n\t *  Return the first event in the timeline without removing it\n\t *  @returns {Object} The first event object\n\t */\n\tTone.Timeline.prototype.peek = function(){\n\t\treturn this._timeline[0];\n\t};\n\n\t/**\n\t *  Return the first event in the timeline and remove it\n\t *  @returns {Object} The first event object\n\t */\n\tTone.Timeline.prototype.shift = function(){\n\t\treturn this._timeline.shift();\n\t};\n\n\t/**\n\t *  Get the event which is scheduled after the given time.\n\t *  @param  {Number}  time  The time to query.\n\t *  @param  {String}  comparator Which value in the object to compare\n\t *  @returns {Object} The event object after the given time\n\t */\n\tTone.Timeline.prototype.getAfter = function(time, comparator){\n\t\tcomparator = Tone.defaultArg(comparator, \"time\");\n\t\tvar index = this._search(time, comparator);\n\t\tif (index + 1 < this._timeline.length){\n\t\t\treturn this._timeline[index + 1];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\t/**\n\t *  Get the event before the event at the given time.\n\t *  @param  {Number}  time  The time to query.\n\t *  @param  {String}  comparator Which value in the object to compare\n\t *  @returns {Object} The event object before the given time\n\t */\n\tTone.Timeline.prototype.getBefore = function(time, comparator){\n\t\tcomparator = Tone.defaultArg(comparator, \"time\");\n\t\tvar len = this._timeline.length;\n\t\t//if it's after the last item, return the last item\n\t\tif (len > 0 && this._timeline[len - 1][comparator] < time){\n\t\t\treturn this._timeline[len - 1];\n\t\t}\n\t\tvar index = this._search(time, comparator);\n\t\tif (index - 1 >= 0){\n\t\t\treturn this._timeline[index - 1];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\t/**\n\t *  Cancel events after the given time\n\t *  @param  {Number}  time  The time to query.\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.cancel = function(after){\n\t\tif (this._timeline.length > 1){\n\t\t\tvar index = this._search(after);\n\t\t\tif (index >= 0){\n\t\t\t\tif (this._timeline[index].time === after){\n\t\t\t\t\t//get the first item with that time\n\t\t\t\t\tfor (var i = index; i >= 0; i--){\n\t\t\t\t\t\tif (this._timeline[i].time === after){\n\t\t\t\t\t\t\tindex = i;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tthis._timeline = this._timeline.slice(0, index);\n\t\t\t\t} else {\n\t\t\t\t\tthis._timeline = this._timeline.slice(0, index + 1);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis._timeline = [];\n\t\t\t}\n\t\t} else if (this._timeline.length === 1){\n\t\t\t//the first item's time\n\t\t\tif (this._timeline[0].time >= after){\n\t\t\t\tthis._timeline = [];\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel events before or equal to the given time.\n\t *  @param  {Number}  time  The time to cancel before.\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.cancelBefore = function(time){\n\t\tvar index = this._search(time);\n\t\tif (index >= 0){\n\t\t\tthis._timeline = this._timeline.slice(index + 1);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Returns the previous event if there is one. null otherwise\n\t * @param  {Object} event The event to find the previous one of\n\t * @return {Object}       The event right before the given event\n\t */\n\tTone.Timeline.prototype.previousEvent = function(event){\n\t\tvar index = this._timeline.indexOf(event);\n\t\tif (index > 0){\n\t\t\treturn this._timeline[index-1];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\t/**\n\t *  Does a binary search on the timeline array and returns the\n\t *  nearest event index whose time is after or equal to the given time.\n\t *  If a time is searched before the first index in the timeline, -1 is returned.\n\t *  If the time is after the end, the index of the last item is returned.\n\t *  @param  {Number}  time\n\t *  @param  {String}  comparator Which value in the object to compare\n\t *  @return  {Number} the index in the timeline array\n\t *  @private\n\t */\n\tTone.Timeline.prototype._search = function(time, comparator){\n\t\tif (this._timeline.length === 0){\n\t\t\treturn -1;\n\t\t}\n\t\tcomparator = Tone.defaultArg(comparator, \"time\");\n\t\tvar beginning = 0;\n\t\tvar len = this._timeline.length;\n\t\tvar end = len;\n\t\tif (len > 0 && this._timeline[len - 1][comparator] <= time){\n\t\t\treturn len - 1;\n\t\t}\n\t\twhile (beginning < end){\n\t\t\t// calculate the midpoint for roughly equal partition\n\t\t\tvar midPoint = Math.floor(beginning + (end - beginning) / 2);\n\t\t\tvar event = this._timeline[midPoint];\n\t\t\tvar nextEvent = this._timeline[midPoint + 1];\n\t\t\tif (event[comparator] === time){\n\t\t\t\t//choose the last one that has the same time\n\t\t\t\tfor (var i = midPoint; i < this._timeline.length; i++){\n\t\t\t\t\tvar testEvent = this._timeline[i];\n\t\t\t\t\tif (testEvent[comparator] === time){\n\t\t\t\t\t\tmidPoint = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn midPoint;\n\t\t\t} else if (event[comparator] < time && nextEvent[comparator] > time){\n\t\t\t\treturn midPoint;\n\t\t\t} else if (event[comparator] > time){\n\t\t\t\t//search lower\n\t\t\t\tend = midPoint;\n\t\t\t} else {\n\t\t\t\t//search upper\n\t\t\t\tbeginning = midPoint + 1;\n\t\t\t}\n\t\t}\n\t\treturn -1;\n\t};\n\n\t/**\n\t *  Internal iterator. Applies extra safety checks for\n\t *  removing items from the array.\n\t *  @param  {Function}  callback\n\t *  @param  {Number=}    lowerBound\n\t *  @param  {Number=}    upperBound\n\t *  @private\n\t */\n\tTone.Timeline.prototype._iterate = function(callback, lowerBound, upperBound){\n\t\tlowerBound = Tone.defaultArg(lowerBound, 0);\n\t\tupperBound = Tone.defaultArg(upperBound, this._timeline.length-1);\n\t\tthis._timeline.slice(lowerBound, upperBound+1).forEach(function(event){\n\t\t\tcallback.call(this, event);\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Iterate over everything in the array\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEach = function(callback){\n\t\tthis._iterate(callback);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array at or before the given time.\n\t *  @param  {Number}  time The time to check if items are before\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEachBefore = function(time, callback){\n\t\t//iterate over the items in reverse so that removing an item doesn't break things\n\t\tvar upperBound = this._search(time);\n\t\tif (upperBound !== -1){\n\t\t\tthis._iterate(callback, 0, upperBound);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array after the given time.\n\t *  @param  {Number}  time The time to check if items are before\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEachAfter = function(time, callback){\n\t\t//iterate over the items in reverse so that removing an item doesn't break things\n\t\tvar lowerBound = this._search(time);\n\t\tthis._iterate(callback, lowerBound + 1);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array between the startTime and endTime. \n\t *  The timerange is inclusive of the startTime, but exclusive of the endTime. \n\t *  range = [startTime, endTime). \n\t *  @param  {Number}  startTime The time to check if items are before\n\t *  @param  {Number}  endTime The end of the test interval. \n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEachBetween = function(startTime, endTime, callback){\n\t\tvar lowerBound = this._search(startTime);\n\t\tvar upperBound = this._search(endTime);\n\t\tif (lowerBound !== -1 && upperBound !== -1){\n\t\t\tif (this._timeline[lowerBound].time !== startTime){\n\t\t\t\tlowerBound += 1;\n\t\t\t}\n\t\t\t//exclusive of the end time\n\t\t\tif (this._timeline[upperBound].time === endTime){\n\t\t\t\tupperBound -= 1;\n\t\t\t}\n\t\t\tthis._iterate(callback, lowerBound, upperBound);\n\t\t} else if (lowerBound === -1){\n\t\t\tthis._iterate(callback, 0, upperBound);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array at or after the given time. Similar to\n\t *  forEachAfter, but includes the item(s) at the given time.\n\t *  @param  {Number}  time The time to check if items are before\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEachFrom = function(time, callback){\n\t\t//iterate over the items in reverse so that removing an item doesn't break things\n\t\tvar lowerBound = this._search(time);\n\t\t//work backwards until the event time is less than time\n\t\twhile (lowerBound >= 0 && this._timeline[lowerBound].time >= time){\n\t\t\tlowerBound--;\n\t\t}\n\t\tthis._iterate(callback, lowerBound + 1);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over everything in the array at the given time\n\t *  @param  {Number}  time The time to check if items are before\n\t *  @param  {Function}  callback The callback to invoke with every item\n\t *  @returns {Tone.Timeline} this\n\t */\n\tTone.Timeline.prototype.forEachAtTime = function(time, callback){\n\t\t//iterate over the items in reverse so that removing an item doesn't break things\n\t\tvar upperBound = this._search(time);\n\t\tif (upperBound !== -1){\n\t\t\tthis._iterate(function(event){\n\t\t\t\tif (event.time === time){\n\t\t\t\t\tcallback.call(this, event);\n\t\t\t\t}\n\t\t\t}, 0, upperBound);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Timeline}  this\n\t */\n\tTone.Timeline.prototype.dispose = function(){\n\t\tTone.prototype.dispose.call(this);\n\t\tthis._timeline = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Timeline;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Timeline.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/TimelineState.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/core/TimelineState.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  A Timeline State. Provides the methods: <code>setStateAtTime(\"state\", time)</code>\n\t *          and <code>getValueAtTime(time)</code>.\n\t *\n\t *  @extends {Tone.Timeline}\n\t *  @param {String} initial The initial state of the TimelineState. \n\t *                          Defaults to <code>undefined</code>\n\t */\n\tTone.TimelineState = function(initial){\n\n\t\tTone.Timeline.call(this);\n\n\t\t/**\n\t\t *  The initial state\n\t\t *  @private\n\t\t *  @type {String}\n\t\t */\n\t\tthis._initial = initial;\n\t};\n\n\tTone.extend(Tone.TimelineState, Tone.Timeline);\n\n\t/**\n\t *  Returns the scheduled state scheduled before or at\n\t *  the given time.\n\t *  @param  {Number}  time  The time to query.\n\t *  @return  {String}  The name of the state input in setStateAtTime.\n\t */\n\tTone.TimelineState.prototype.getValueAtTime = function(time){\n\t\tvar event = this.get(time);\n\t\tif (event !== null){\n\t\t\treturn event.state;\n\t\t} else {\n\t\t\treturn this._initial;\n\t\t}\n\t};\n\n\t/**\n\t *  Add a state to the timeline.\n\t *  @param  {String}  state The name of the state to set.\n\t *  @param  {Number}  time  The time to query.\n\t *  @returns {Tone.TimelineState} this\n\t */\n\tTone.TimelineState.prototype.setStateAtTime = function(state, time){\n\t\t//all state changes need to be >= the previous state time\n\t\t//TODO throw error if time < the previous event time\n\t\tthis.add({\n\t\t\t\"state\" : state,\n\t\t\t\"time\" : time\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Return the event before the time with the given state\n\t *  @param {Tone.State} state The state to look for\n\t *  @param  {Time}  time  When to check before\t\t\t\n\t *  @return  {Object}  The event with the given state before the time\n\t */\n\tTone.TimelineState.prototype.getLastState = function(state, time){\n\t\ttime = this.toSeconds(time);\n\t\tvar index = this._search(time);\n\t\tfor (var i = index; i >= 0; i--){\n\t\t\tvar event = this._timeline[i];\n\t\t\tif (event.state === state){\n\t\t\t\treturn event;\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t *  Return the event after the time with the given state\n\t *  @param {Tone.State} state The state to look for\n\t *  @param  {Time}  time  When to check from\n\t *  @return  {Object}  The event with the given state after the time\n\t */\n\tTone.TimelineState.prototype.getNextState = function(state, time){\n\t\ttime = this.toSeconds(time);\n\t\tvar index = this._search(time);\n\t\tif (index !== -1){\n\t\t\tfor (var i = index; i < this._timeline.length; i++){\n\t\t\t\tvar event = this._timeline[i];\n\t\t\t\tif (event.state === state){\n\t\t\t\t\treturn event;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\treturn Tone.TimelineState;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/TimelineState.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Tone.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/core/Tone.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/**\n *  Tone.js\n *  @author Yotam Mann\n *  @license http://opensource.org/licenses/MIT MIT License\n *  @copyright 2014-2019 Yotam Mann\n */\n!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../version */ \"./node_modules/tone/Tone/version.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(version){\n\n\t\"use strict\";\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tTONE\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  @class  Tone is the base class of all other classes.\n\t *  @constructor\n\t */\n\tvar Tone = function(){\n\t\tif (!(this instanceof Tone)){\n\t\t\tthrow new Error(\"constructor needs to be called with the 'new' keyword\");\n\t\t}\n\t};\n\n\t/**\n\t *  @memberOf Tone#\n\t *  @returns {String} returns the name of the class as a string\n\t */\n\tTone.prototype.toString = function(){\n\t\tfor (var className in Tone){\n\t\t\tvar isLetter = className[0].match(/^[A-Z]$/);\n\t\t\tvar sameConstructor = Tone[className] === this.constructor;\n\t\t\tif (Tone.isFunction(Tone[className]) && isLetter && sameConstructor){\n\t\t\t\treturn className;\n\t\t\t}\n\t\t}\n\t\treturn \"Tone\";\n\t};\n\n\t/**\n\t *  @memberOf Tone#\n\t *  disconnect and dispose\n\t *  @returns {Tone} this\n\t */\n\tTone.prototype.dispose = function(){\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tGET/SET\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Set the parameters at once. Either pass in an\n\t *  object mapping parameters to values, or to set a\n\t *  single parameter, by passing in a string and value.\n\t *  The last argument is an optional ramp time which\n\t *  will ramp any signal values to their destination value\n\t *  over the duration of the rampTime.\n\t *  @param {Object|String} params\n\t *  @param {Number=} value\n\t *  @param {Time=} rampTime\n\t *  @returns {Tone} this\n\t *  @memberOf Tone#\n\t *  @example\n\t * //set values using an object\n\t * filter.set({\n\t * \t\"frequency\" : 300,\n\t * \t\"type\" : highpass\n\t * });\n\t *  @example\n\t * filter.set(\"type\", \"highpass\");\n\t *  @example\n\t * //ramp to the value 220 over 3 seconds.\n\t * oscillator.set({\n\t * \t\"frequency\" : 220\n\t * }, 3);\n\t */\n\tTone.prototype.set = function(params, value, rampTime){\n\t\tif (Tone.isObject(params)){\n\t\t\trampTime = value;\n\t\t} else if (Tone.isString(params)){\n\t\t\tvar tmpObj = {};\n\t\t\ttmpObj[params] = value;\n\t\t\tparams = tmpObj;\n\t\t}\n\n\t\tparamLoop:\n\t\tfor (var attr in params){\n\t\t\tvalue = params[attr];\n\t\t\tvar parent = this;\n\t\t\tif (attr.indexOf(\".\") !== -1){\n\t\t\t\tvar attrSplit = attr.split(\".\");\n\t\t\t\tfor (var i = 0; i < attrSplit.length - 1; i++){\n\t\t\t\t\tparent = parent[attrSplit[i]];\n\t\t\t\t\tif (parent instanceof Tone){\n\t\t\t\t\t\tattrSplit.splice(0, i+1);\n\t\t\t\t\t\tvar innerParam = attrSplit.join(\".\");\n\t\t\t\t\t\tparent.set(innerParam, value);\n\t\t\t\t\t\tcontinue paramLoop;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tattr = attrSplit[attrSplit.length - 1];\n\t\t\t}\n\t\t\tvar param = parent[attr];\n\t\t\tif (Tone.isUndef(param)){\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif ((Tone.Signal && param instanceof Tone.Signal) ||\n\t\t\t\t\t(Tone.Param && param instanceof Tone.Param)){\n\t\t\t\tif (param.value !== value){\n\t\t\t\t\tif (Tone.isUndef(rampTime)){\n\t\t\t\t\t\tparam.value = value;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tparam.rampTo(value, rampTime);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (param instanceof AudioParam){\n\t\t\t\tif (param.value !== value){\n\t\t\t\t\tparam.value = value;\n\t\t\t\t}\n\t\t\t} else if (Tone.TimeBase && param instanceof Tone.TimeBase){\n\t\t\t\tparent[attr] = value;\n\t\t\t} else if (param instanceof Tone){\n\t\t\t\tparam.set(value);\n\t\t\t} else if (param !== value){\n\t\t\t\tparent[attr] = value;\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the object's attributes. Given no arguments get\n\t *  will return all available object properties and their corresponding\n\t *  values. Pass in a single attribute to retrieve or an array\n\t *  of attributes. The attribute strings can also include a \".\"\n\t *  to access deeper properties.\n\t *  @memberOf Tone#\n\t *  @example\n\t * osc.get();\n\t * //returns {\"type\" : \"sine\", \"frequency\" : 440, ...etc}\n\t *  @example\n\t * osc.get(\"type\");\n\t * //returns { \"type\" : \"sine\"}\n\t * @example\n\t * //use dot notation to access deep properties\n\t * synth.get([\"envelope.attack\", \"envelope.release\"]);\n\t * //returns {\"envelope\" : {\"attack\" : 0.2, \"release\" : 0.4}}\n\t *  @param {Array=|string|undefined} params the parameters to get, otherwise will return\n\t *  \t\t\t\t\t                  all available.\n\t *  @returns {Object}\n\t */\n\tTone.prototype.get = function(params){\n\t\tif (Tone.isUndef(params)){\n\t\t\tparams = this._collectDefaults(this.constructor);\n\t\t} else if (Tone.isString(params)){\n\t\t\tparams = [params];\n\t\t}\n\t\tvar ret = {};\n\t\tfor (var i = 0; i < params.length; i++){\n\t\t\tvar attr = params[i];\n\t\t\tvar parent = this;\n\t\t\tvar subRet = ret;\n\t\t\tif (attr.indexOf(\".\") !== -1){\n\t\t\t\tvar attrSplit = attr.split(\".\");\n\t\t\t\tfor (var j = 0; j < attrSplit.length - 1; j++){\n\t\t\t\t\tvar subAttr = attrSplit[j];\n\t\t\t\t\tsubRet[subAttr] = subRet[subAttr] || {};\n\t\t\t\t\tsubRet = subRet[subAttr];\n\t\t\t\t\tparent = parent[subAttr];\n\t\t\t\t}\n\t\t\t\tattr = attrSplit[attrSplit.length - 1];\n\t\t\t}\n\t\t\tvar param = parent[attr];\n\t\t\tif (Tone.isObject(params[attr])){\n\t\t\t\tsubRet[attr] = param.get();\n\t\t\t} else if (Tone.Signal && param instanceof Tone.Signal){\n\t\t\t\tsubRet[attr] = param.value;\n\t\t\t} else if (Tone.Param && param instanceof Tone.Param){\n\t\t\t\tsubRet[attr] = param.value;\n\t\t\t} else if (param instanceof AudioParam){\n\t\t\t\tsubRet[attr] = param.value;\n\t\t\t} else if (param instanceof Tone){\n\t\t\t\tsubRet[attr] = param.get();\n\t\t\t} else if (!Tone.isFunction(param) && Tone.isDefined(param)){\n\t\t\t\tsubRet[attr] = param;\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t};\n\n\t/**\n\t *  collect all of the default attributes in one\n\t *  @private\n\t *  @param {Function} constr the constructor to find the defaults from\n\t *  @return {Array} all of the attributes which belong to the class\n\t */\n\tTone.prototype._collectDefaults = function(constr){\n\t\tvar ret = [];\n\t\tif (Tone.isDefined(constr.defaults)){\n\t\t\tret = Object.keys(constr.defaults);\n\t\t}\n\t\tif (Tone.isDefined(constr._super)){\n\t\t\tvar superDefs = this._collectDefaults(constr._super);\n\t\t\t//filter out repeats\n\t\t\tfor (var i = 0; i < superDefs.length; i++){\n\t\t\t\tif (ret.indexOf(superDefs[i]) === -1){\n\t\t\t\t\tret.push(superDefs[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tDEFAULTS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  @memberOf Tone\n\t *  @param  {Array}  values  The arguments array\n\t *  @param  {Array}  keys    The names of the arguments\n\t *  @param {Function|Object} constr The class constructor\n\t *  @return  {Object}  An object composed of the  defaults between the class' defaults\n\t *                        and the passed in arguments.\n\t */\n\tTone.defaults = function(values, keys, constr){\n\t\tvar options = {};\n\t\tif (values.length === 1 && Tone.isObject(values[0])){\n\t\t\toptions = values[0];\n\t\t} else {\n\t\t\tfor (var i = 0; i < keys.length; i++){\n\t\t\t\toptions[keys[i]] = values[i];\n\t\t\t}\n\t\t}\n\t\tif (Tone.isDefined(constr.defaults)){\n\t\t\treturn Tone.defaultArg(options, constr.defaults);\n\t\t} else if (Tone.isObject(constr)){\n\t\t\treturn Tone.defaultArg(options, constr);\n\t\t} else {\n\t\t\treturn options;\n\t\t}\n\t};\n\n\t/**\n\t *  If the `given` parameter is undefined, use the `fallback`.\n\t *  If both `given` and `fallback` are object literals, it will\n\t *  return a deep copy which includes all of the parameters from both\n\t *  objects. If a parameter is undefined in given, it will return\n\t *  the fallback property.\n\t *  <br><br>\n\t *  WARNING: if object is self referential, it will go into an an\n\t *  infinite recursive loop.\n\t *  @memberOf Tone\n\t *  @param  {*} given\n\t *  @param  {*} fallback\n\t *  @return {*}\n\t */\n\tTone.defaultArg = function(given, fallback){\n\t\tif (Tone.isObject(given) && Tone.isObject(fallback)){\n\t\t\tvar ret = {};\n\t\t\t//make a deep copy of the given object\n\t\t\tfor (var givenProp in given){\n\t\t\t\tret[givenProp] = Tone.defaultArg(fallback[givenProp], given[givenProp]);\n\t\t\t}\n\t\t\tfor (var fallbackProp in fallback){\n\t\t\t\tret[fallbackProp] = Tone.defaultArg(given[fallbackProp], fallback[fallbackProp]);\n\t\t\t}\n\t\t\treturn ret;\n\t\t} else {\n\t\t\treturn Tone.isUndef(given) ? fallback : given;\n\t\t}\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tDEBUGGING\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Print the outputs to the console log for debugging purposes. \n\t *  Prints the contents only if either the object has a property\n\t *  called `debug` set to true, or a variable called TONE_DEBUG_CLASS\n\t *  is set to the name of the class. \n\t *  @example\n\t * //prints all logs originating from Tone.OscillatorNode\n\t * Tone.global.TONE_DEBUG_CLASS = \"OscillatorNode\"\n\t *  @param {*} args Any arguments to print to the console.\n\t *  @private\n\t */\n\tTone.prototype.log = function(){\n\t\t//if the object is either set to debug = true\n\t\t//or if there is a string on the Tone.global.with the class name\n\t\tif (this.debug || this.toString() === Tone.global.TONE_DEBUG_CLASS){\n\t\t\tvar args = Array.from(arguments);\n\t\t\targs.unshift(this.toString()+\":\");\n\t\t\t// eslint-disable-next-line no-console\n\t\t\tconsole.log.apply(undefined, args);\n\t\t}\n\t};\n\n\t/**\n\t *  Assert that the statement is true, otherwise invoke the error. \n\t *  @param {Boolean} statement\n\t *  @param {String} error The message which is passed into an Error\n\t *  @private\n\t */\n\tTone.prototype.assert = function(statement, error){\n\t\tif (!statement){\n\t\t\tthrow new Error(error);\n\t\t}\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tCONNECTIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  connect together all of the arguments in series\n\t *  @param {...AudioParam|Tone|AudioNode} nodes\n\t *  @returns {Tone}\n\t *  @memberOf Tone\n\t *  @static\n\t */\n\tTone.connectSeries = function(){\n\t\tvar currentUnit = arguments[0];\n\t\tfor (var i = 1; i < arguments.length; i++){\n\t\t\tvar toUnit = arguments[i];\n\t\t\tcurrentUnit.connect(toUnit);\n\t\t\tcurrentUnit = toUnit;\n\t\t}\n\t\treturn Tone;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// TYPE CHECKING\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Test if the arg is undefined\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is undefined\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isUndef = function(val){\n\t\treturn typeof val === \"undefined\";\n\t};\n\n\t/**\n\t *  Test if the arg is not undefined\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is undefined\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isDefined = function(val){\n\t\treturn !Tone.isUndef(val);\n\t};\n\n\t/**\n\t *  Test if the arg is a function\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is a function\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isFunction = function(val){\n\t\treturn typeof val === \"function\";\n\t};\n\n\t/**\n\t *  Test if the argument is a number.\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is a number\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isNumber = function(arg){\n\t\treturn (typeof arg === \"number\");\n\t};\n\n\t/**\n\t *  Test if the given argument is an object literal (i.e. `{}`);\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is an object literal.\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isObject = function(arg){\n\t\treturn (Object.prototype.toString.call(arg) === \"[object Object]\" && arg.constructor === Object);\n\t};\n\n\t/**\n\t *  Test if the argument is a boolean.\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is a boolean\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isBoolean = function(arg){\n\t\treturn (typeof arg === \"boolean\");\n\t};\n\n\t/**\n\t *  Test if the argument is an Array\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is an array\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isArray = function(arg){\n\t\treturn (Array.isArray(arg));\n\t};\n\n\t/**\n\t *  Test if the argument is a string.\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is a string\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isString = function(arg){\n\t\treturn (typeof arg === \"string\");\n\t};\n\n\t/**\n\t *  Test if the argument is in the form of a note in scientific pitch notation.\n\t *  e.g. \"C4\"\n\t *  @param {*} arg the argument to test\n\t *  @returns {Boolean} true if the arg is a string\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.isNote = function(arg){\n\t\treturn Tone.isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);\n\t};\n\n\t/**\n\t *  An empty function.\n\t *  @static\n\t */\n\tTone.noOp = function(){};\n\n\t/**\n\t *  Make the property not writable. Internal use only.\n\t *  @private\n\t *  @param  {String}  property  the property to make not writable\n\t */\n\tTone.prototype._readOnly = function(property){\n\t\tif (Array.isArray(property)){\n\t\t\tfor (var i = 0; i < property.length; i++){\n\t\t\t\tthis._readOnly(property[i]);\n\t\t\t}\n\t\t} else {\n\t\t\tObject.defineProperty(this, property, {\n\t\t\t\t\"writable\" : false,\n\t\t\t\t\"enumerable\" : true,\n\t\t\t});\n\t\t}\n\t};\n\n\t/**\n\t *  Make an attribute writeable. Interal use only.\n\t *  @private\n\t *  @param  {String}  property  the property to make writable\n\t */\n\tTone.prototype._writable = function(property){\n\t\tif (Array.isArray(property)){\n\t\t\tfor (var i = 0; i < property.length; i++){\n\t\t\t\tthis._writable(property[i]);\n\t\t\t}\n\t\t} else {\n\t\t\tObject.defineProperty(this, property, {\n\t\t\t\t\"writable\" : true,\n\t\t\t});\n\t\t}\n\t};\n\n\t/**\n\t * Possible play states.\n\t * @enum {String}\n\t */\n\tTone.State = {\n\t\t\"Started\" : \"started\",\n\t\t\"Stopped\" : \"stopped\",\n\t\t\"Paused\" : \"paused\",\n\t};\n\n\t/**\n\t * A reference to the global context, `global` or `Tone.global.\n\t */\n\tTone.global = Tone.isUndef(global) ? window : global;\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// CONVERSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Equal power gain scale. Good for cross-fading.\n\t *  @param  {NormalRange} percent (0-1)\n\t *  @return {Number}         output gain (0-1)\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.equalPowerScale = function(percent){\n\t\tvar piFactor = 0.5 * Math.PI;\n\t\treturn Math.sin(percent * piFactor);\n\t};\n\n\t/**\n\t *  Convert decibels into gain.\n\t *  @param  {Decibels} db\n\t *  @return {Number}\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.dbToGain = function(db){\n\t\treturn Math.pow(10, db / 20);\n\t};\n\n\t/**\n\t *  Convert gain to decibels.\n\t *  @param  {Number} gain (0-1)\n\t *  @return {Decibels}\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.gainToDb = function(gain){\n\t\treturn 20 * (Math.log(gain) / Math.LN10);\n\t};\n\n\t/**\n\t *  Convert an interval (in semitones) to a frequency ratio.\n\t *  @param  {Interval} interval the number of semitones above the base note\n\t *  @return {Number}          the frequency ratio\n\t *  @static\n\t *  @memberOf Tone\n\t *  @example\n\t * tone.intervalToFrequencyRatio(0); // 1\n\t * tone.intervalToFrequencyRatio(12); // 2\n\t * tone.intervalToFrequencyRatio(-12); // 0.5\n\t */\n\tTone.intervalToFrequencyRatio = function(interval){\n\t\treturn Math.pow(2, (interval/12));\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tTIMING\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Return the current time of the AudioContext clock plus\n\t *  the lookAhead.\n\t *  @return {Number} the currentTime from the AudioContext\n\t *  @memberOf Tone#\n\t */\n\tTone.prototype.now = function(){\n\t\treturn Tone.context.now();\n\t};\n\n\t/**\n\t *  Return the current time of the AudioContext clock plus\n\t *  the lookAhead.\n\t *  @return {Number} the currentTime from the AudioContext\n\t *  @static\n\t *  @memberOf Tone\n\t */\n\tTone.now = function(){\n\t\treturn Tone.context.now();\n\t};\n\n\t/**\n\t *  Return the current time of the AudioContext clock without\n\t *  any lookAhead.\n\t *  @return {Number} the currentTime from the AudioContext\n\t *  @memberOf Tone#\n\t */\n\tTone.prototype.immediate = function(){\n\t\treturn Tone.context.currentTime;\n\t};\n\n\t/**\n\t *  Return the current time of the AudioContext clock without\n\t *  any lookAhead.\n\t *  @return {Number} the currentTime from the AudioContext\n\t *  @memberOf Tone\n\t */\n\tTone.immediate = function(){\n\t\treturn Tone.context.currentTime;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tINHERITANCE\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  have a child inherit all of Tone's (or a parent's) prototype\n\t *  to inherit the parent's properties, make sure to call\n\t *  Parent.call(this) in the child's constructor\n\t *\n\t *  based on closure library's inherit function\n\t *\n\t *  @memberOf Tone\n\t *  @static\n\t *  @param  {Function} \tchild\n\t *  @param  {Function=} parent (optional) parent to inherit from\n\t *                             if no parent is supplied, the child\n\t *                             will inherit from Tone\n\t */\n\tTone.extend = function(child, parent){\n\t\tif (Tone.isUndef(parent)){\n\t\t\tparent = Tone;\n\t\t}\n\t\tfunction TempConstructor(){}\n\t\tTempConstructor.prototype = parent.prototype;\n\t\tchild.prototype = new TempConstructor();\n\t\t/** @override */\n\t\tchild.prototype.constructor = child;\n\t\tchild._super = parent;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tCONTEXT\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t * The shared AudioContext\n\t * @type {Tone.Context}\n\t * @private\n\t */\n\tTone._audioContext = null;\n\n\t/**\n\t * \tMost browsers will not play _any_ audio until a user \n\t * \tclicks something (like a play button). Invoke this method\n\t * \ton a click or keypress event handler to start the audio context. \n\t * \tMore about the Autoplay policy [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)\n\t *  @memberOf Tone\n\t *  @static\n\t *  @return {Promise} This promise is resolved when the audio context is started. \n\t *  @example\n\t * document.querySelector('#playbutton').addEventListener('click', () => Tone.start())\n\t */\n\tTone.start = function(){\n\t\treturn Tone.context.resume();\n\t};\n\n\t/**\n\t *  A static pointer to the audio context accessible as Tone.context.\n\t *  @type {Tone.Context}\n\t *  @name context\n\t *  @memberOf Tone\n\t */\n\tObject.defineProperty(Tone, \"context\", {\n\t\t\"get\" : function(){\n\t\t\treturn Tone._audioContext;\n\t\t},\n\t\t\"set\" : function(context){\n\t\t\tif (context.isContext){\n\t\t\t\tTone._audioContext = context;\n\t\t\t} else {\n\t\t\t\tTone._audioContext = new Tone.Context(context);\n\t\t\t}\n\t\t\t//initialize the new audio context\n\t\t\tTone.Context.emit(\"init\", Tone._audioContext);\n\t\t}\n\t});\n\n\t/**\n\t *  The AudioContext\n\t *  @type {Tone.Context}\n\t *  @name context\n\t *  @memberOf Tone#\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.prototype, \"context\", {\n\t\t\"get\" : function(){\n\t\t\treturn Tone.context;\n\t\t}\n\t});\n\n\t/**\n\t *  Tone automatically creates a context on init, but if you are working\n\t *  with other libraries which also create an AudioContext, it can be\n\t *  useful to set your own. If you are going to set your own context,\n\t *  be sure to do it at the start of your code, before creating any objects.\n\t *  @static\n\t *  @param {AudioContext} ctx The new audio context to set\n\t */\n\tTone.setContext = function(ctx){\n\t\tTone.context = ctx;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tATTRIBUTES\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  The number of seconds of 1 processing block (128 samples)\n\t *  @type {Number}\n\t *  @name blockTime\n\t *  @memberOf Tone\n\t *  @static\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.prototype, \"blockTime\", {\n\t\t\"get\" : function(){\n\t\t\treturn 128 / this.context.sampleRate;\n\t\t}\n\t});\n\n\t/**\n\t *  The duration in seconds of one sample.\n\t *  @type {Number}\n\t *  @name sampleTime\n\t *  @memberOf Tone\n\t *  @static\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.prototype, \"sampleTime\", {\n\t\t\"get\" : function(){\n\t\t\treturn 1 / this.context.sampleRate;\n\t\t}\n\t});\n\n\t/**\n\t *  Whether or not all the technologies that Tone.js relies on are supported by the current browser.\n\t *  @type {Boolean}\n\t *  @name supported\n\t *  @memberOf Tone\n\t *  @readOnly\n\t *  @static\n\t */\n\tObject.defineProperty(Tone, \"supported\", {\n\t\t\"get\" : function(){\n\t\t\tvar hasAudioContext = Tone.global.hasOwnProperty(\"AudioContext\") || Tone.global.hasOwnProperty(\"webkitAudioContext\");\n\t\t\tvar hasPromises = Tone.global.hasOwnProperty(\"Promise\");\n\t\t\treturn hasAudioContext && hasPromises;\n\t\t}\n\t});\n\n\t/**\n\t *  Boolean value if the audio context has been initialized.\n\t *  @type {Boolean}\n\t *  @memberOf Tone\n\t *  @static\n\t *  @name initialized\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone, \"initialized\", {\n\t\t\"get\" : function(){\n\t\t\treturn Boolean(Tone.context);\n\t\t}\n\t});\n\n\t/**\n\t *  Get the context when it becomes available\n\t *  @param  {Function}  resolve  Callback when the context is initialized\n\t *  @return  {Tone}\n\t */\n\tTone.getContext = function(resolve){\n\t\tif (Tone.initialized){\n\t\t\tresolve(Tone.context);\n\t\t} else {\n\t\t\tvar resCallback = function(){\n\t\t\t\tresolve(Tone.context);\n\t\t\t\tTone.Context.off(\"init\", resCallback);\n\t\t\t};\n\t\t\tTone.Context.on(\"init\", resCallback);\n\t\t}\n\t\treturn Tone;\n\t};\n\n\t/**\n\t * The version number\n\t * @type {String}\n\t * @static\n\t */\n\tTone.version = version;\n\n\treturn Tone;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Tone.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/Transport.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/core/Transport.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Clock */ \"./node_modules/tone/Tone/core/Clock.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\"),\n\t__webpack_require__(/*! ../core/Emitter */ \"./node_modules/tone/Tone/core/Emitter.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../core/IntervalTimeline */ \"./node_modules/tone/Tone/core/IntervalTimeline.js\"),\n\t__webpack_require__(/*! ../core/TransportRepeatEvent */ \"./node_modules/tone/Tone/core/TransportRepeatEvent.js\"), __webpack_require__(/*! ../core/TransportEvent */ \"./node_modules/tone/Tone/core/TransportEvent.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Transport for timing musical events.\n\t *          Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n\t *          Tone.Transport timing events pass in the exact time of the scheduled event\n\t *          in the argument of the callback function. Pass that time value to the object\n\t *          you're scheduling. <br><br>\n\t *          A single transport is created for you when the library is initialized.\n\t *          <br><br>\n\t *          The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n\t *          called with the time of that event as the argument.\n\t *\n\t *  @extends {Tone.Emitter}\n\t *  @singleton\n\t *  @example\n\t * //repeated event every 8th note\n\t * Tone.Transport.scheduleRepeat(function(time){\n\t * \t//do something with the time\n\t * }, \"8n\");\n\t *  @example\n\t * //schedule an event on the 16th measure\n\t * Tone.Transport.schedule(function(time){\n\t * \t//do something with the time\n\t * }, \"16:0:0\");\n\t */\n\tTone.Transport = function(){\n\n\t\tTone.Emitter.call(this);\n\n\t\tTone.getContext(function(){\n\n\t\t\t///////////////////////////////////////////////////////////////////////\n\t\t\t//\tLOOPING\n\t\t\t//////////////////////////////////////////////////////////////////////\n\n\t\t\t/**\n\t\t\t * \tIf the transport loops or not.\n\t\t\t *  @type {boolean}\n\t\t\t */\n\t\t\tthis.loop = false;\n\n\t\t\t/**\n\t\t\t * \tThe loop start position in ticks\n\t\t\t *  @type {Ticks}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._loopStart = 0;\n\n\t\t\t/**\n\t\t\t * \tThe loop end position in ticks\n\t\t\t *  @type {Ticks}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._loopEnd = 0;\n\n\t\t\t///////////////////////////////////////////////////////////////////////\n\t\t\t//\tCLOCK/TEMPO\n\t\t\t//////////////////////////////////////////////////////////////////////\n\n\t\t\t/**\n\t\t\t *  Pulses per quarter is the number of ticks per quarter note.\n\t\t\t *  @private\n\t\t\t *  @type  {Number}\n\t\t\t */\n\t\t\tthis._ppq = TransportConstructor.defaults.PPQ;\n\n\t\t\t/**\n\t\t\t *  watches the main oscillator for timing ticks\n\t\t\t *  initially starts at 120bpm\n\t\t\t *  @private\n\t\t\t *  @type {Tone.Clock}\n\t\t\t */\n\t\t\tthis._clock = new Tone.Clock({\n\t\t\t\t\"callback\" : this._processTick.bind(this),\n\t\t\t\t\"frequency\" : 0,\n\t\t\t});\n\n\t\t\tthis._bindClockEvents();\n\n\t\t\t/**\n\t\t\t *  The Beats Per Minute of the Transport.\n\t\t\t *  @type {BPM}\n\t\t\t *  @signal\n\t\t\t *  @example\n\t\t\t * Tone.Transport.bpm.value = 80;\n\t\t\t * //ramp the bpm to 120 over 10 seconds\n\t\t\t * Tone.Transport.bpm.rampTo(120, 10);\n\t\t\t */\n\t\t\tthis.bpm = this._clock.frequency;\n\t\t\tthis.bpm._toUnits = this._toUnits.bind(this);\n\t\t\tthis.bpm._fromUnits = this._fromUnits.bind(this);\n\t\t\tthis.bpm.units = Tone.Type.BPM;\n\t\t\tthis.bpm.value = TransportConstructor.defaults.bpm;\n\t\t\tthis._readOnly(\"bpm\");\n\n\t\t\t/**\n\t\t\t *  The time signature, or more accurately the numerator\n\t\t\t *  of the time signature over a denominator of 4.\n\t\t\t *  @type {Number}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._timeSignature = TransportConstructor.defaults.timeSignature;\n\n\t\t\t///////////////////////////////////////////////////////////////////////\n\t\t\t//\tTIMELINE EVENTS\n\t\t\t//////////////////////////////////////////////////////////////////////\n\n\t\t\t/**\n\t\t\t *  All the events in an object to keep track by ID\n\t\t\t *  @type {Object}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._scheduledEvents = {};\n\n\t\t\t/**\n\t\t\t * \tThe scheduled events.\n\t\t\t *  @type {Tone.Timeline}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._timeline = new Tone.Timeline();\n\n\t\t\t/**\n\t\t\t *  Repeated events\n\t\t\t *  @type {Array}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._repeatedEvents = new Tone.IntervalTimeline();\n\n\t\t\t/**\n\t\t\t *  All of the synced Signals\n\t\t\t *  @private\n\t\t\t *  @type {Array}\n\t\t\t */\n\t\t\tthis._syncedSignals = [];\n\n\t\t\t///////////////////////////////////////////////////////////////////////\n\t\t\t//\tSWING\n\t\t\t//////////////////////////////////////////////////////////////////////\n\n\t\t\t/**\n\t\t\t *  The subdivision of the swing\n\t\t\t *  @type  {Ticks}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._swingTicks = TransportConstructor.defaults.PPQ / 2; //8n\n\n\t\t\t/**\n\t\t\t *  The swing amount\n\t\t\t *  @type {NormalRange}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._swingAmount = 0;\n\n\t\t\t//transport is a singleton so it adds itself to the context\n\t\t\tthis.context.transport = this;\n\n\t\t}.bind(this));\n\t};\n\n\tTone.extend(Tone.Transport, Tone.Emitter);\n\n\t/**\n\t *  the defaults\n\t *  @type {Object}\n\t *  @const\n\t *  @static\n\t */\n\tTone.Transport.defaults = {\n\t\t\"bpm\" : 120,\n\t\t\"swing\" : 0,\n\t\t\"swingSubdivision\" : \"8n\",\n\t\t\"timeSignature\" : 4,\n\t\t\"loopStart\" : 0,\n\t\t\"loopEnd\" : \"4m\",\n\t\t\"PPQ\" : 192\n\t};\n\n\t/**\n\t * Is an instanceof Tone.Transport\n\t * @type {Boolean}\n\t */\n\tTone.Transport.prototype.isTransport = true;\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tTICKS\n\t///////////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  called on every tick\n\t *  @param   {number} tickTime clock relative tick time\n\t *  @private\n\t */\n\tTone.Transport.prototype._processTick = function(tickTime, ticks){\n\t\t//handle swing\n\t\tif (this._swingAmount > 0 &&\n\t\t\tticks % this._ppq !== 0 && //not on a downbeat\n\t\t\tticks % (this._swingTicks * 2) !== 0){\n\t\t\t//add some swing\n\t\t\tvar progress = (ticks % (this._swingTicks * 2)) / (this._swingTicks * 2);\n\t\t\tvar amount = Math.sin((progress) * Math.PI) * this._swingAmount;\n\t\t\ttickTime += Tone.Ticks(this._swingTicks * 2/3).toSeconds() * amount;\n\t\t}\n\t\t//do the loop test\n\t\tif (this.loop){\n\t\t\tif (ticks >= this._loopEnd){\n\t\t\t\tthis.emit(\"loopEnd\", tickTime);\n\t\t\t\tthis._clock.setTicksAtTime(this._loopStart, tickTime);\n\t\t\t\tticks = this._loopStart;\n\t\t\t\tthis.emit(\"loopStart\", tickTime, this._clock.getSecondsAtTime(tickTime));\n\t\t\t\tthis.emit(\"loop\", tickTime);\n\t\t\t}\n\t\t}\n\t\t//invoke the timeline events scheduled on this tick\n\t\tthis._timeline.forEachAtTime(ticks, function(event){\n\t\t\tevent.invoke(tickTime);\n\t\t});\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tSCHEDULABLE EVENTS\n\t///////////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Schedule an event along the timeline.\n\t *  @param {Function} callback The callback to be invoked at the time.\n\t *  @param {TransportTime}  time The time to invoke the callback at.\n\t *  @return {Number} The id of the event which can be used for canceling the event.\n\t *  @example\n\t * //trigger the callback when the Transport reaches the desired time\n\t * Tone.Transport.schedule(function(time){\n\t * \tenvelope.triggerAttack(time);\n\t * }, \"128i\");\n\t */\n\tTone.Transport.prototype.schedule = function(callback, time){\n\t\tvar event = new Tone.TransportEvent(this, {\n\t\t\t\"time\" : Tone.TransportTime(time),\n\t\t\t\"callback\" : callback\n\t\t});\n\t\treturn this._addEvent(event, this._timeline);\n\t};\n\n\t/**\n\t *  Schedule a repeated event along the timeline. The event will fire\n\t *  at the `interval` starting at the `startTime` and for the specified\n\t *  `duration`.\n\t *  @param  {Function}  callback   The callback to invoke.\n\t *  @param  {Time}    interval   The duration between successive\n\t *                               callbacks. Must be a positive number.\n\t *  @param  {TransportTime=}    startTime  When along the timeline the events should\n\t *                               start being invoked.\n\t *  @param {Time} [duration=Infinity] How long the event should repeat.\n\t *  @return  {Number}    The ID of the scheduled event. Use this to cancel\n\t *                           the event.\n\t *  @example\n\t * //a callback invoked every eighth note after the first measure\n\t * Tone.Transport.scheduleRepeat(callback, \"8n\", \"1m\");\n\t */\n\tTone.Transport.prototype.scheduleRepeat = function(callback, interval, startTime, duration){\n\t\tvar event = new Tone.TransportRepeatEvent(this, {\n\t\t\t\"callback\" : callback,\n\t\t\t\"interval\" : Tone.Time(interval),\n\t\t\t\"time\" : Tone.TransportTime(startTime),\n\t\t\t\"duration\" : Tone.Time(Tone.defaultArg(duration, Infinity)),\n\t\t});\n\t\t//kick it off if the Transport is started\n\t\treturn this._addEvent(event, this._repeatedEvents);\n\t};\n\n\t/**\n\t *  Schedule an event that will be removed after it is invoked.\n\t *  Note that if the given time is less than the current transport time,\n\t *  the event will be invoked immediately.\n\t *  @param {Function} callback The callback to invoke once.\n\t *  @param {TransportTime} time The time the callback should be invoked.\n\t *  @returns {Number} The ID of the scheduled event.\n\t */\n\tTone.Transport.prototype.scheduleOnce = function(callback, time){\n\t\tvar event = new Tone.TransportEvent(this, {\n\t\t\t\"time\" : Tone.TransportTime(time),\n\t\t\t\"callback\" : callback,\n\t\t\t\"once\" : true\n\t\t});\n\t\treturn this._addEvent(event, this._timeline);\n\t};\n\n\t/**\n\t *  Clear the passed in event id from the timeline\n\t *  @param {Number} eventId The id of the event.\n\t *  @returns {Tone.Transport} this\n\t */\n\tTone.Transport.prototype.clear = function(eventId){\n\t\tif (this._scheduledEvents.hasOwnProperty(eventId)){\n\t\t\tvar item = this._scheduledEvents[eventId.toString()];\n\t\t\titem.timeline.remove(item.event);\n\t\t\titem.event.dispose();\n\t\t\tdelete this._scheduledEvents[eventId.toString()];\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Add an event to the correct timeline. Keep track of the\n\t * timeline it was added to.\n\t * @param {Tone.TransportEvent}\tevent\n\t * @param {Tone.Timeline} timeline\n\t * @returns {Number} the event id which was just added\n\t * @private\n\t */\n\tTone.Transport.prototype._addEvent = function(event, timeline){\n\t\tthis._scheduledEvents[event.id.toString()] = {\n\t\t\t\"event\" : event,\n\t\t\t\"timeline\" : timeline\n\t\t};\n\t\ttimeline.add(event);\n\t\treturn event.id;\n\t};\n\n\t/**\n\t *  Remove scheduled events from the timeline after\n\t *  the given time. Repeated events will be removed\n\t *  if their startTime is after the given time\n\t *  @param {TransportTime} [after=0] Clear all events after\n\t *                          this time.\n\t *  @returns {Tone.Transport} this\n\t */\n\tTone.Transport.prototype.cancel = function(after){\n\t\tafter = Tone.defaultArg(after, 0);\n\t\tafter = this.toTicks(after);\n\t\tthis._timeline.forEachFrom(after, function(event){\n\t\t\tthis.clear(event.id);\n\t\t}.bind(this));\n\t\tthis._repeatedEvents.forEachFrom(after, function(event){\n\t\t\tthis.clear(event.id);\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tSTART/STOP/PAUSE\n\t///////////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Bind start/stop/pause events from the clock and emit them.\n\t *  @private\n\t */\n\tTone.Transport.prototype._bindClockEvents = function(){\n\t\tthis._clock.on(\"start\", function(time, offset){\n\t\t\toffset = Tone.Ticks(offset).toSeconds();\n\t\t\tthis.emit(\"start\", time, offset);\n\t\t}.bind(this));\n\n\t\tthis._clock.on(\"stop\", function(time){\n\t\t\tthis.emit(\"stop\", time);\n\t\t}.bind(this));\n\n\t\tthis._clock.on(\"pause\", function(time){\n\t\t\tthis.emit(\"pause\", time);\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\", \"stopped\", or \"paused\"\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.Transport#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._clock.getStateAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Start the transport and all sources synced to the transport.\n\t *  @param  {Time} [time=now] The time when the transport should start.\n\t *  @param  {TransportTime=} offset The timeline offset to start the transport.\n\t *  @returns {Tone.Transport} this\n\t *  @example\n\t * //start the transport in one second starting at beginning of the 5th measure.\n\t * Tone.Transport.start(\"+1\", \"4:0:0\");\n\t */\n\tTone.Transport.prototype.start = function(time, offset){\n\t\t//start the clock\n\t\tif (Tone.isDefined(offset)){\n\t\t\toffset = this.toTicks(offset);\n\t\t}\n\t\tthis._clock.start(time, offset);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the transport and all sources synced to the transport.\n\t *  @param  {Time} [time=now] The time when the transport should stop.\n\t *  @returns {Tone.Transport} this\n\t *  @example\n\t * Tone.Transport.stop();\n\t */\n\tTone.Transport.prototype.stop = function(time){\n\t\tthis._clock.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Pause the transport and all sources synced to the transport.\n\t *  @param  {Time} [time=now]\n\t *  @returns {Tone.Transport} this\n\t */\n\tTone.Transport.prototype.pause = function(time){\n\t\tthis._clock.pause(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Toggle the current state of the transport. If it is\n\t * started, it will stop it, otherwise it will start the Transport.\n\t * @param  {Time=} time The time of the event\n\t * @return {Tone.Transport}      this\n\t */\n\tTone.Transport.prototype.toggle = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._clock.getStateAtTime(time) !== Tone.State.Started){\n\t\t\tthis.start(time);\n\t\t} else {\n\t\t\tthis.stop(time);\n\t\t}\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tSETTERS/GETTERS\n\t///////////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  The time signature as just the numerator over 4.\n\t *  For example 4/4 would be just 4 and 6/8 would be 3.\n\t *  @memberOf Tone.Transport#\n\t *  @type {Number|Array}\n\t *  @name timeSignature\n\t *  @example\n\t * //common time\n\t * Tone.Transport.timeSignature = 4;\n\t * // 7/8\n\t * Tone.Transport.timeSignature = [7, 8];\n\t * //this will be reduced to a single number\n\t * Tone.Transport.timeSignature; //returns 3.5\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"timeSignature\", {\n\t\tget : function(){\n\t\t\treturn this._timeSignature;\n\t\t},\n\t\tset : function(timeSig){\n\t\t\tif (Tone.isArray(timeSig)){\n\t\t\t\ttimeSig = (timeSig[0] / timeSig[1]) * 4;\n\t\t\t}\n\t\t\tthis._timeSignature = timeSig;\n\t\t}\n\t});\n\n\t/**\n\t * When the Tone.Transport.loop = true, this is the starting position of the loop.\n\t * @memberOf Tone.Transport#\n\t * @type {Time}\n\t * @name loopStart\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopStart).toSeconds();\n\t\t},\n\t\tset : function(startPosition){\n\t\t\tthis._loopStart = this.toTicks(startPosition);\n\t\t}\n\t});\n\n\t/**\n\t * When the Tone.Transport.loop = true, this is the ending position of the loop.\n\t * @memberOf Tone.Transport#\n\t * @type {Time}\n\t * @name loopEnd\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopEnd).toSeconds();\n\t\t},\n\t\tset : function(endPosition){\n\t\t\tthis._loopEnd = this.toTicks(endPosition);\n\t\t}\n\t});\n\n\t/**\n\t *  Set the loop start and stop at the same time.\n\t *  @param {TransportTime} startPosition\n\t *  @param {TransportTime} endPosition\n\t *  @returns {Tone.Transport} this\n\t *  @example\n\t * //loop over the first measure\n\t * Tone.Transport.setLoopPoints(0, \"1m\");\n\t * Tone.Transport.loop = true;\n\t */\n\tTone.Transport.prototype.setLoopPoints = function(startPosition, endPosition){\n\t\tthis.loopStart = startPosition;\n\t\tthis.loopEnd = endPosition;\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The swing value. Between 0-1 where 1 equal to\n\t *  the note + half the subdivision.\n\t *  @memberOf Tone.Transport#\n\t *  @type {NormalRange}\n\t *  @name swing\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"swing\", {\n\t\tget : function(){\n\t\t\treturn this._swingAmount;\n\t\t},\n\t\tset : function(amount){\n\t\t\t//scale the values to a normal range\n\t\t\tthis._swingAmount = amount;\n\t\t}\n\t});\n\n\t/**\n\t *  Set the subdivision which the swing will be applied to.\n\t *  The default value is an 8th note. Value must be less\n\t *  than a quarter note.\n\t *\n\t *  @memberOf Tone.Transport#\n\t *  @type {Time}\n\t *  @name swingSubdivision\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"swingSubdivision\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._swingTicks).toNotation();\n\t\t},\n\t\tset : function(subdivision){\n\t\t\tthis._swingTicks = this.toTicks(subdivision);\n\t\t}\n\t});\n\n\t/**\n\t *  The Transport's position in Bars:Beats:Sixteenths.\n\t *  Setting the value will jump to that position right away.\n\t *  @memberOf Tone.Transport#\n\t *  @type {BarsBeatsSixteenths}\n\t *  @name position\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"position\", {\n\t\tget : function(){\n\t\t\tvar now = this.now();\n\t\t\tvar ticks = this._clock.getTicksAtTime(now);\n\t\t\treturn Tone.Ticks(ticks).toBarsBeatsSixteenths();\n\t\t},\n\t\tset : function(progress){\n\t\t\tvar ticks = this.toTicks(progress);\n\t\t\tthis.ticks = ticks;\n\t\t}\n\t});\n\n\t/**\n\t *  The Transport's position in seconds\n\t *  Setting the value will jump to that position right away.\n\t *  @memberOf Tone.Transport#\n\t *  @type {Seconds}\n\t *  @name seconds\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"seconds\", {\n\t\tget : function(){\n\t\t\treturn this._clock.seconds;\n\t\t},\n\t\tset : function(s){\n\t\t\tvar now = this.now();\n\t\t\tvar ticks = this.bpm.timeToTicks(s, now);\n\t\t\tthis.ticks = ticks;\n\t\t}\n\t});\n\n\t/**\n\t *  The Transport's loop position as a normalized value. Always\n\t *  returns 0 if the transport if loop is not true.\n\t *  @memberOf Tone.Transport#\n\t *  @name progress\n\t *  @type {NormalRange}\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"progress\", {\n\t\tget : function(){\n\t\t\tif (this.loop){\n\t\t\t\tvar now = this.now();\n\t\t\t\tvar ticks = this._clock.getTicksAtTime(now);\n\t\t\t\treturn (ticks - this._loopStart) / (this._loopEnd - this._loopStart);\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The transports current tick position.\n\t *\n\t *  @memberOf Tone.Transport#\n\t *  @type {Ticks}\n\t *  @name ticks\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"ticks\", {\n\t\tget : function(){\n\t\t\treturn this._clock.ticks;\n\t\t},\n\t\tset : function(t){\n\t\t\tif (this._clock.ticks !== t){\n\t\t\t\tvar now = this.now();\n\t\t\t\t//stop everything synced to the transport\n\t\t\t\tif (this.state === Tone.State.Started){\n\t\t\t\t\tthis.emit(\"stop\", now);\n\t\t\t\t\tthis._clock.setTicksAtTime(t, now);\n\t\t\t\t\t//restart it with the new time\n\t\t\t\t\tthis.emit(\"start\", now, this.seconds);\n\t\t\t\t} else {\n\t\t\t\t\tthis._clock.setTicksAtTime(t, now);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * Get the clock's ticks at the given time.\n\t * @param  {Time} time  When to get the tick value\n\t * @return {Ticks}       The tick value at the given time.\n\t */\n\tTone.Transport.prototype.getTicksAtTime = function(time){\n\t\treturn Math.round(this._clock.getTicksAtTime(time));\n\t};\n\n\t/**\n\t *  Return the elapsed seconds at the given time.\n\t *  @param  {Time}  time  When to get the elapsed seconds\n\t *  @return  {Seconds}  The number of elapsed seconds\n\t */\n\tTone.Transport.prototype.getSecondsAtTime = function(time){\n\t\treturn this._clock.getSecondsAtTime(time);\n\t};\n\n\t/**\n\t *  Pulses Per Quarter note. This is the smallest resolution\n\t *  the Transport timing supports. This should be set once\n\t *  on initialization and not set again. Changing this value\n\t *  after other objects have been created can cause problems.\n\t *\n\t *  @memberOf Tone.Transport#\n\t *  @type {Number}\n\t *  @name PPQ\n\t */\n\tObject.defineProperty(Tone.Transport.prototype, \"PPQ\", {\n\t\tget : function(){\n\t\t\treturn this._ppq;\n\t\t},\n\t\tset : function(ppq){\n\t\t\tvar bpm = this.bpm.value;\n\t\t\tthis._ppq = ppq;\n\t\t\tthis.bpm.value = bpm;\n\t\t}\n\t});\n\n\t/**\n\t *  Convert from BPM to frequency (factoring in PPQ)\n\t *  @param  {BPM}  bpm The BPM value to convert to frequency\n\t *  @return  {Frequency}  The BPM as a frequency with PPQ factored in.\n\t *  @private\n\t */\n\tTone.Transport.prototype._fromUnits = function(bpm){\n\t\treturn 1 / (60 / bpm / this.PPQ);\n\t};\n\n\t/**\n\t *  Convert from frequency (with PPQ) into BPM\n\t *  @param  {Frequency}  freq The clocks frequency to convert to BPM\n\t *  @return  {BPM}  The frequency value as BPM.\n\t *  @private\n\t */\n\tTone.Transport.prototype._toUnits = function(freq){\n\t\treturn (freq / this.PPQ) * 60;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tSYNCING\n\t///////////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Returns the time aligned to the next subdivision\n\t *  of the Transport. If the Transport is not started,\n\t *  it will return 0.\n\t *  Note: this will not work precisely during tempo ramps.\n\t *  @param  {Time}  subdivision  The subdivision to quantize to\n\t *  @return  {Number}  The context time of the next subdivision.\n\t *  @example\n\t * Tone.Transport.start(); //the transport must be started\n\t * Tone.Transport.nextSubdivision(\"4n\");\n\t */\n\tTone.Transport.prototype.nextSubdivision = function(subdivision){\n\t\tsubdivision = this.toTicks(subdivision);\n\t\tif (this.state !== Tone.State.Started){\n\t\t\t//if the transport's not started, return 0\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tvar now = this.now();\n\t\t\t//the remainder of the current ticks and the subdivision\n\t\t\tvar transportPos = this.getTicksAtTime(now);\n\t\t\tvar remainingTicks = subdivision - transportPos % subdivision;\n\t\t\treturn this._clock.nextTickTime(remainingTicks, now);\n\t\t}\n\t};\n\n\t/**\n\t *  Attaches the signal to the tempo control signal so that\n\t *  any changes in the tempo will change the signal in the same\n\t *  ratio.\n\t *\n\t *  @param  {Tone.Signal} signal\n\t *  @param {number=} ratio Optionally pass in the ratio between\n\t *                         the two signals. Otherwise it will be computed\n\t *                         based on their current values.\n\t *  @returns {Tone.Transport} this\n\t */\n\tTone.Transport.prototype.syncSignal = function(signal, ratio){\n\t\tif (!ratio){\n\t\t\t//get the sync ratio\n\t\t\tvar now = this.now();\n\t\t\tif (signal.getValueAtTime(now) !== 0){\n\t\t\t\tratio = signal.getValueAtTime(now) / this.bpm.getValueAtTime(now);\n\t\t\t} else {\n\t\t\t\tratio = 0;\n\t\t\t}\n\t\t}\n\t\tvar ratioSignal = new Tone.Gain(ratio);\n\t\tthis.bpm.chain(ratioSignal, signal._param);\n\t\tthis._syncedSignals.push({\n\t\t\t\"ratio\" : ratioSignal,\n\t\t\t\"signal\" : signal,\n\t\t\t\"initial\" : signal.value\n\t\t});\n\t\tsignal.value = 0;\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Unsyncs a previously synced signal from the transport's control.\n\t *  See Tone.Transport.syncSignal.\n\t *  @param  {Tone.Signal} signal\n\t *  @returns {Tone.Transport} this\n\t */\n\tTone.Transport.prototype.unsyncSignal = function(signal){\n\t\tfor (var i = this._syncedSignals.length - 1; i >= 0; i--){\n\t\t\tvar syncedSignal = this._syncedSignals[i];\n\t\t\tif (syncedSignal.signal === signal){\n\t\t\t\tsyncedSignal.ratio.dispose();\n\t\t\t\tsyncedSignal.signal.value = syncedSignal.initial;\n\t\t\t\tthis._syncedSignals.splice(i, 1);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Transport} this\n\t *  @private\n\t */\n\tTone.Transport.prototype.dispose = function(){\n\t\tTone.Emitter.prototype.dispose.call(this);\n\t\tthis._clock.dispose();\n\t\tthis._clock = null;\n\t\tthis._writable(\"bpm\");\n\t\tthis.bpm = null;\n\t\tthis._timeline.dispose();\n\t\tthis._timeline = null;\n\t\tthis._repeatedEvents.dispose();\n\t\tthis._repeatedEvents = null;\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////////\n\t//\tINITIALIZATION\n\t///////////////////////////////////////////////////////////////////////////////\n\n\tvar TransportConstructor = Tone.Transport;\n\tTone.Transport = new TransportConstructor();\n\n\tTone.Context.on(\"init\", function(context){\n\t\tif (context.transport && context.transport.isTransport){\n\t\t\tTone.Transport = context.transport;\n\t\t} else {\n\t\t\tTone.Transport = new TransportConstructor();\n\t\t}\n\t});\n\n\tTone.Context.on(\"close\", function(context){\n\t\tif (context.transport && context.transport.isTransport){\n\t\t\tcontext.transport.dispose();\n\t\t}\n\t});\n\n\treturn Tone.Transport;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/Transport.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/TransportEvent.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/core/TransportEvent.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/Tone/type/Ticks.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.TransportEvent is an internal class used by (Tone.Transport)[Transport]\n\t *         to schedule events. Do no invoke this class directly, it is\n\t *         handled from within Tone.Transport.\n\t *  @extends {Tone}\n\t *  @param {Object} options\n\t */\n\tTone.TransportEvent = function(Transport, options){\n\n\t\toptions = Tone.defaultArg(options, Tone.TransportEvent.defaults);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t * Reference to the Transport that created it\n\t\t * @type {Tone.Transport}\n\t\t */\n\t\tthis.Transport = Transport;\n\n\t\t/**\n\t\t * The unique id of the event\n\t\t * @type {Number}\n\t\t */\n\t\tthis.id = Tone.TransportEvent._eventId++;\n\n\t\t/**\n\t\t * The time the event starts\n\t\t * @type {Ticks}\n\t\t */\n\t\tthis.time = Tone.Ticks(options.time);\n\n\t\t/**\n\t\t * The callback to invoke\n\t\t * @type {Function}\n\t\t */\n\t\tthis.callback = options.callback;\n\n\t\t/**\n\t\t * If the event should be removed after being created.\n\t\t * @type {Boolean}\n\t\t * @private\n\t\t */\n\t\tthis._once = options.once;\n\t};\n\n\tTone.extend(Tone.TransportEvent);\n\n\t/**\n\t * The defaults\n\t * @static\n\t * @type {Object}\n\t */\n\tTone.TransportEvent.defaults = {\n\t\t\"once\" : false,\n\t\t\"callback\" : Tone.noOp,\n\t};\n\n\t/**\n\t * Current ID counter\n\t * @private\n\t * @static\n\t * @type {Number}\n\t */\n\tTone.TransportEvent._eventId = 0;\n\n\t/**\n\t * Invoke the event callback.\n\t * @param  {Time} time  The AudioContext time in seconds of the event\n\t */\n\tTone.TransportEvent.prototype.invoke = function(time){\n\t\tif (this.callback){\n\t\t\tthis.callback(time);\n\t\t\tif (this._once && this.Transport){\n\t\t\t\tthis.Transport.clear(this.id);\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t * Clean up\n\t * @return {Tone.TransportEvent} this\n\t */\n\tTone.TransportEvent.prototype.dispose = function(){\n\t\tTone.prototype.dispose.call(this);\n\t\tthis.Transport = null;\n\t\tthis.callback = null;\n\t\tthis.time = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.TransportEvent;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/TransportEvent.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/core/TransportRepeatEvent.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/Tone/core/TransportRepeatEvent.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/TransportEvent */ \"./node_modules/tone/Tone/core/TransportEvent.js\"), __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/Tone/type/Ticks.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.TransportRepeatEvent is an internal class used by Tone.Transport\n\t *         to schedule repeat events. This class should not be instantiated directly.\n\t *  @extends {Tone.TransportEvent}\n\t *  @param {Object} options\n\t */\n\tTone.TransportRepeatEvent = function(Transport, options){\n\n\t\tTone.TransportEvent.call(this, Transport, options);\n\t\toptions = Tone.defaultArg(options, Tone.TransportRepeatEvent.defaults);\n\n\t\t/**\n\t\t * When the event should stop repeating\n\t\t * @type {Ticks}\n\t\t * @private\n\t\t */\n\t\tthis.duration = Tone.Ticks(options.duration);\n\n\t\t/**\n\t\t * The interval of the repeated event\n\t\t * @type {Ticks}\n\t\t * @private\n\t\t */\n\t\tthis._interval = Tone.Ticks(options.interval);\n\n\t\t/**\n\t\t * The ID of the current timeline event\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._currentId = -1;\n\n\t\t/**\n\t\t * The ID of the next timeline event\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._nextId = -1;\n\n\t\t/**\n\t\t  * The time of the next event\n\t\t  * @type {Ticks}\n\t\t  * @private\n\t\t  */\n\t\tthis._nextTick = this.time;\n\n\t\t/**\n\t\t * a reference to the bound start method\n\t\t * @type {Function}\n\t\t * @private\n\t\t */\n\t\tthis._boundRestart = this._restart.bind(this);\n\t\tthis.Transport.on(\"start loopStart\", this._boundRestart);\n\t\tthis._restart();\n\t};\n\n\tTone.extend(Tone.TransportRepeatEvent, Tone.TransportEvent);\n\n\t/**\n\t * The defaults\n\t * @static\n\t * @type {Object}\n\t */\n\tTone.TransportRepeatEvent.defaults = {\n\t\t\"duration\" : Infinity,\n\t\t\"interval\" : 1\n\t};\n\n\t/**\n\t * Invoke the callback. Returns the tick time which\n\t * the next event should be scheduled at.\n\t * @param  {Number} time  The AudioContext time in seconds of the event\n\t */\n\tTone.TransportRepeatEvent.prototype.invoke = function(time){\n\t\t//create more events if necessary\n\t\tthis._createEvents(time);\n\t\t//call the super class\n\t\tTone.TransportEvent.prototype.invoke.call(this, time);\n\t};\n\n\t/**\n\t * Push more events onto the timeline to keep up with the position of the timeline\n\t * @private\n\t */\n\tTone.TransportRepeatEvent.prototype._createEvents = function(time){\n\t\t// schedule the next event\n\t\tvar ticks = this.Transport.getTicksAtTime(time);\n\t\tif (ticks >= this.time && ticks >= this._nextTick &&\n\t\tthis._nextTick + this._interval < this.time + this.duration){\n\t\t\tthis._nextTick += this._interval;\n\t\t\tthis._currentId = this._nextId;\n\t\t\tthis._nextId = this.Transport.scheduleOnce(this.invoke.bind(this), Tone.Ticks(this._nextTick));\n\t\t}\n\t};\n\n\t/**\n\t * Push more events onto the timeline to keep up with the position of the timeline\n\t * @private\n\t */\n\tTone.TransportRepeatEvent.prototype._restart = function(time){\n\t\tthis.Transport.clear(this._currentId);\n\t\tthis.Transport.clear(this._nextId);\n\t\tthis._nextTick = this.time;\n\t\tvar ticks = this.Transport.getTicksAtTime(time);\n\t\tif (ticks > this.time){\n\t\t\tthis._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;\n\t\t}\n\t\tthis._currentId = this.Transport.scheduleOnce(this.invoke.bind(this), Tone.Ticks(this._nextTick));\n\t\tthis._nextTick += this._interval;\n\t\tthis._nextId = this.Transport.scheduleOnce(this.invoke.bind(this), Tone.Ticks(this._nextTick));\n\t};\n\n\t/**\n\t * Clean up\n\t * @return {Tone.TransportRepeatEvent} this\n\t */\n\tTone.TransportRepeatEvent.prototype.dispose = function(){\n\t\tthis.Transport.clear(this._currentId);\n\t\tthis.Transport.clear(this._nextId);\n\t\tthis.Transport.off(\"start loopStart\", this._boundRestart);\n\t\tthis._boundCreateEvents = null;\n\t\tTone.TransportEvent.prototype.dispose.call(this);\n\t\tthis.duration = null;\n\t\tthis._interval = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.TransportRepeatEvent;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/core/TransportRepeatEvent.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/AutoFilter.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/AutoFilter.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n\t *         Setting the LFO rate and depth allows for control over the filter modulation rate \n\t *         and depth.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {Time|Object} [frequency] The rate of the LFO.\n\t *  @param {Frequency=} baseFrequency The lower value of the LFOs oscillation\n \t *  @param {Frequency=} octaves The number of octaves above the baseFrequency\n\t *  @example\n\t * //create an autofilter and start it's LFO\n\t * var autoFilter = new Tone.AutoFilter(\"4n\").toMaster().start();\n\t * //route an oscillator through the filter and start it\n\t * var oscillator = new Tone.Oscillator().connect(autoFilter).start();\n\t */\n\tTone.AutoFilter = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"baseFrequency\", \"octaves\"], Tone.AutoFilter);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  the lfo which drives the filter cutoff\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfo = new Tone.LFO({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"amplitude\" : options.depth,\n\t\t});\n\n\t\t/**\n\t\t * The range of the filter modulating between the min and max frequency. \n\t\t * 0 = no modulation. 1 = full modulation.\n\t\t * @type {NormalRange}\n\t\t * @signal\n\t\t */\n\t\tthis.depth = this._lfo.amplitude;\n\n\t\t/**\n\t\t * How fast the filter modulates between min and max. \n\t\t * @type {Frequency}\n\t\t * @signal\n\t\t */\n\t\tthis.frequency = this._lfo.frequency;\n\n\t\t/**\n\t\t *  The filter node\n\t\t *  @type {Tone.Filter}\n\t\t */\n\t\tthis.filter = new Tone.Filter(options.filter);\n\n\t\t/**\n\t\t *  The octaves placeholder\n\t\t *  @type {Positive}\n\t\t *  @private\n\t\t */\n\t\tthis._octaves = 0;\n\n\t\t//connections\n\t\tthis.connectEffect(this.filter);\n\t\tthis._lfo.connect(this.filter.frequency);\n\t\tthis.type = options.type;\n\t\tthis._readOnly([\"frequency\", \"depth\"]);\n\t\tthis.octaves = options.octaves;\n\t\tthis.baseFrequency = options.baseFrequency;\n\t};\n\n\t//extend Effect\n\tTone.extend(Tone.AutoFilter, Tone.Effect);\n\n\t/**\n\t *  defaults\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.AutoFilter.defaults = {\n\t\t\"frequency\" : 1,\n\t\t\"type\" : \"sine\",\n\t\t\"depth\" : 1,\n\t\t\"baseFrequency\" : 200,\n\t\t\"octaves\" : 2.6,\n\t\t\"filter\" : {\n\t\t\t\"type\" : \"lowpass\",\n\t\t\t\"rolloff\" : -12,\n\t\t\t\"Q\" : 1,\n\t\t}\n\t};\n\t\n\t/**\n\t * Start the effect.\n\t * @param {Time} [time=now] When the LFO will start. \n\t * @returns {Tone.AutoFilter} this\n\t */\n\tTone.AutoFilter.prototype.start = function(time){\n\t\tthis._lfo.start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Stop the effect.\n\t * @param {Time} [time=now] When the LFO will stop. \n\t * @returns {Tone.AutoFilter} this\n\t */\n\tTone.AutoFilter.prototype.stop = function(time){\n\t\tthis._lfo.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the filter to the transport.\n\t * @param {Time} [delay=0] Delay time before starting the effect after the\n\t *                               Transport has started. \n\t * @returns {Tone.AutoFilter} this\n\t */\n\tTone.AutoFilter.prototype.sync = function(delay){\n\t\tthis._lfo.sync(delay);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Unsync the filter from the transport.\n\t * @returns {Tone.AutoFilter} this\n\t */\n\tTone.AutoFilter.prototype.unsync = function(){\n\t\tthis._lfo.unsync();\n\t\treturn this;\n\t};\n\n\t/**\n\t * Type of oscillator attached to the AutoFilter. \n\t * Possible values: \"sine\", \"square\", \"triangle\", \"sawtooth\".\n\t * @memberOf Tone.AutoFilter#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.AutoFilter.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._lfo.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._lfo.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The minimum value of the filter's cutoff frequency.\n\t * @memberOf Tone.AutoFilter#\n\t * @type {Frequency}\n\t * @name baseFrequency\n\t */\n\tObject.defineProperty(Tone.AutoFilter.prototype, \"baseFrequency\", {\n\t\tget : function(){\n\t\t\treturn this._lfo.min;\n\t\t},\n\t\tset : function(freq){\n\t\t\tthis._lfo.min = this.toFrequency(freq);\n\t\t\t//and set the max\n\t\t\tthis.octaves = this._octaves;\n\t\t}\n\t});\n\n\t/**\n\t * The maximum value of the filter's cutoff frequency. \n\t * @memberOf Tone.AutoFilter#\n\t * @type {Positive}\n\t * @name octaves\n\t */\n\tObject.defineProperty(Tone.AutoFilter.prototype, \"octaves\", {\n\t\tget : function(){\n\t\t\treturn this._octaves;\n\t\t},\n\t\tset : function(oct){\n\t\t\tthis._octaves = oct;\n\t\t\tthis._lfo.max = this.baseFrequency * Math.pow(2, oct);\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up. \n\t *  @returns {Tone.AutoFilter} this\n\t */\n\tTone.AutoFilter.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._lfo.dispose();\n\t\tthis._lfo = null;\n\t\tthis.filter.dispose();\n\t\tthis.filter = null;\n\t\tthis._writable([\"frequency\", \"depth\"]);\n\t\tthis.frequency = null;\n\t\tthis.depth = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AutoFilter;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/AutoFilter.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/AutoPanner.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/AutoPanner.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../component/Panner */ \"./node_modules/tone/Tone/component/Panner.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.AutoPanner is a Tone.Panner with an LFO connected to the pan amount. \n\t *         More on using autopanners [here](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {Frequency|Object} [frequency] Rate of left-right oscillation. \n\t *  @example\n\t * //create an autopanner and start it's LFO\n\t * var autoPanner = new Tone.AutoPanner(\"4n\").toMaster().start();\n\t * //route an oscillator through the panner and start it\n\t * var oscillator = new Tone.Oscillator().connect(autoPanner).start();\n\t */\n\tTone.AutoPanner = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\"], Tone.AutoPanner);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  the lfo which drives the panning\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfo = new Tone.LFO({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"amplitude\" : options.depth,\n\t\t\t\"min\" : -1,\n\t\t\t\"max\" : 1,\n\t\t});\n\n\t\t/**\n\t\t * The amount of panning between left and right. \n\t\t * 0 = always center. 1 = full range between left and right. \n\t\t * @type {NormalRange}\n\t\t * @signal\n\t\t */\n\t\tthis.depth = this._lfo.amplitude;\n\n\t\t/**\n\t\t *  the panner node which does the panning\n\t\t *  @type {Tone.Panner}\n\t\t *  @private\n\t\t */\n\t\tthis._panner = new Tone.Panner();\n\n\t\t/**\n\t\t * How fast the panner modulates between left and right. \n\t\t * @type {Frequency}\n\t\t * @signal\n\t\t */\n\t\tthis.frequency = this._lfo.frequency;\n\n\t\t//connections\n\t\tthis.connectEffect(this._panner);\n\t\tthis._lfo.connect(this._panner.pan);\n\t\tthis.type = options.type;\n\t\tthis._readOnly([\"depth\", \"frequency\"]);\n\t};\n\n\t//extend Effect\n\tTone.extend(Tone.AutoPanner, Tone.Effect);\n\n\t/**\n\t *  defaults\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.AutoPanner.defaults = {\n\t\t\"frequency\" : 1,\n\t\t\"type\" : \"sine\",\n\t\t\"depth\" : 1\n\t};\n\t\n\t/**\n\t * Start the effect.\n\t * @param {Time} [time=now] When the LFO will start. \n\t * @returns {Tone.AutoPanner} this\n\t */\n\tTone.AutoPanner.prototype.start = function(time){\n\t\tthis._lfo.start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Stop the effect.\n\t * @param {Time} [time=now] When the LFO will stop. \n\t * @returns {Tone.AutoPanner} this\n\t */\n\tTone.AutoPanner.prototype.stop = function(time){\n\t\tthis._lfo.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the panner to the transport.\n\t * @param {Time} [delay=0] Delay time before starting the effect after the\n\t *                               Transport has started. \n\t * @returns {Tone.AutoPanner} this\n\t */\n\tTone.AutoPanner.prototype.sync = function(delay){\n\t\tthis._lfo.sync(delay);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Unsync the panner from the transport\n\t * @returns {Tone.AutoPanner} this\n\t */\n\tTone.AutoPanner.prototype.unsync = function(){\n\t\tthis._lfo.unsync();\n\t\treturn this;\n\t};\n\n\t/**\n\t * Type of oscillator attached to the AutoFilter. \n\t * Possible values: \"sine\", \"square\", \"triangle\", \"sawtooth\".\n\t * @memberOf Tone.AutoFilter#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.AutoPanner.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._lfo.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._lfo.type = type;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.AutoPanner} this\n\t */\n\tTone.AutoPanner.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._lfo.dispose();\n\t\tthis._lfo = null;\n\t\tthis._panner.dispose();\n\t\tthis._panner = null;\n\t\tthis._writable([\"depth\", \"frequency\"]);\n\t\tthis.frequency = null;\n\t\tthis.depth = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AutoPanner;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/AutoPanner.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/AutoWah.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/effect/AutoWah.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Follower */ \"./node_modules/tone/Tone/component/Follower.js\"), __webpack_require__(/*! ../signal/ScaleExp */ \"./node_modules/tone/Tone/signal/ScaleExp.js\"),\n\t__webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.AutoWah connects a Tone.Follower to a bandpass filter (Tone.Filter).\n\t *          The frequency of the filter is adjusted proportionally to the\n\t *          incoming signal's amplitude. Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {Frequency|Object} [baseFrequency] The frequency the filter is set\n\t *                                            to at the low point of the wah\n\t *  @param {Positive} [octaves] The number of octaves above the baseFrequency\n\t *                                the filter will sweep to when fully open\n\t *  @param {Decibels} [sensitivity] The decibel threshold sensitivity for\n\t *                                   the incoming signal. Normal range of -40 to 0.\n\t *  @example\n\t * var autoWah = new Tone.AutoWah(50, 6, -30).toMaster();\n\t * //initialize the synth and connect to autowah\n\t * var synth = new Synth.connect(autoWah);\n\t * //Q value influences the effect of the wah - default is 2\n\t * autoWah.Q.value = 6;\n\t * //more audible on higher notes\n\t * synth.triggerAttackRelease(\"C4\", \"8n\")\n\t */\n\tTone.AutoWah = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"], Tone.AutoWah);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  The envelope follower. Set the attack/release\n\t\t *  timing to adjust how the envelope is followed.\n\t\t *  @type {Tone.Follower}\n\t\t *  @private\n\t\t */\n\t\tthis.follower = new Tone.Follower(options.follower);\n\n\t\t/**\n\t\t *  scales the follower value to the frequency domain\n\t\t *  @type {Tone}\n\t\t *  @private\n\t\t */\n\t\tthis._sweepRange = new Tone.ScaleExp(0, 1, 0.5);\n\n\t\t/**\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._baseFrequency = options.baseFrequency;\n\n\t\t/**\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._octaves = options.octaves;\n\n\t\t/**\n\t\t *  the input gain to adjust the sensitivity\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._inputBoost = new Tone.Gain();\n\n\t\t/**\n\t\t *  @type {BiquadFilterNode}\n\t\t *  @private\n\t\t */\n\t\tthis._bandpass = new Tone.Filter({\n\t\t\t\"rolloff\" : -48,\n\t\t\t\"frequency\" : 0,\n\t\t\t\"Q\" : options.Q,\n\t\t});\n\n\t\t/**\n\t\t *  @type {Tone.Filter}\n\t\t *  @private\n\t\t */\n\t\tthis._peaking = new Tone.Filter(0, \"peaking\");\n\t\tthis._peaking.gain.value = options.gain;\n\n\t\t/**\n\t\t * The gain of the filter.\n\t\t * @type {Number}\n\t\t * @signal\n\t\t */\n\t\tthis.gain = this._peaking.gain;\n\n\t\t/**\n\t\t * The quality of the filter.\n\t\t * @type {Positive}\n\t\t * @signal\n\t\t */\n\t\tthis.Q = this._bandpass.Q;\n\n\t\t//the control signal path\n\t\tthis.effectSend.chain(this._inputBoost, this.follower, this._sweepRange);\n\t\tthis._sweepRange.connect(this._bandpass.frequency);\n\t\tthis._sweepRange.connect(this._peaking.frequency);\n\t\t//the filtered path\n\t\tthis.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);\n\t\t//set the initial value\n\t\tthis._setSweepRange();\n\t\tthis.sensitivity = options.sensitivity;\n\n\t\tthis._readOnly([\"gain\", \"Q\"]);\n\t};\n\n\tTone.extend(Tone.AutoWah, Tone.Effect);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.AutoWah.defaults = {\n\t\t\"baseFrequency\" : 100,\n\t\t\"octaves\" : 6,\n\t\t\"sensitivity\" : 0,\n\t\t\"Q\" : 2,\n\t\t\"gain\" : 2,\n\t\t\"follower\" : {\n\t\t\t\"attack\" : 0.3,\n\t\t\t\"release\" : 0.5\n\t\t}\n\t};\n\n\t/**\n\t * The number of octaves that the filter will sweep above the\n\t * baseFrequency.\n\t * @memberOf Tone.AutoWah#\n\t * @type {Number}\n\t * @name octaves\n\t */\n\tObject.defineProperty(Tone.AutoWah.prototype, \"octaves\", {\n\t\tget : function(){\n\t\t\treturn this._octaves;\n\t\t},\n\t\tset : function(octaves){\n\t\t\tthis._octaves = octaves;\n\t\t\tthis._setSweepRange();\n\t\t}\n\t});\n\n\t/**\n\t * The base frequency from which the sweep will start from.\n\t * @memberOf Tone.AutoWah#\n\t * @type {Frequency}\n\t * @name baseFrequency\n\t */\n\tObject.defineProperty(Tone.AutoWah.prototype, \"baseFrequency\", {\n\t\tget : function(){\n\t\t\treturn this._baseFrequency;\n\t\t},\n\t\tset : function(baseFreq){\n\t\t\tthis._baseFrequency = baseFreq;\n\t\t\tthis._setSweepRange();\n\t\t}\n\t});\n\n\t/**\n\t * The sensitivity to control how responsive to the input signal the filter is.\n\t * @memberOf Tone.AutoWah#\n\t * @type {Decibels}\n\t * @name sensitivity\n\t */\n\tObject.defineProperty(Tone.AutoWah.prototype, \"sensitivity\", {\n\t\tget : function(){\n\t\t\treturn Tone.gainToDb(1 / this._inputBoost.gain.value);\n\t\t},\n\t\tset : function(sensitivy){\n\t\t\tthis._inputBoost.gain.value = 1 / Tone.dbToGain(sensitivy);\n\t\t}\n\t});\n\n\t/**\n\t *  sets the sweep range of the scaler\n\t *  @private\n\t */\n\tTone.AutoWah.prototype._setSweepRange = function(){\n\t\tthis._sweepRange.min = this._baseFrequency;\n\t\tthis._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.AutoWah} this\n\t */\n\tTone.AutoWah.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis.follower.dispose();\n\t\tthis.follower = null;\n\t\tthis._sweepRange.dispose();\n\t\tthis._sweepRange = null;\n\t\tthis._bandpass.dispose();\n\t\tthis._bandpass = null;\n\t\tthis._peaking.dispose();\n\t\tthis._peaking = null;\n\t\tthis._inputBoost.dispose();\n\t\tthis._inputBoost = null;\n\t\tthis._writable([\"gain\", \"Q\"]);\n\t\tthis.gain = null;\n\t\tthis.Q = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AutoWah;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/AutoWah.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/BitCrusher.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/BitCrusher.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"), __webpack_require__(/*! ../signal/Modulo */ \"./node_modules/tone/Tone/signal/Modulo.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Bitcrusher downsamples the incoming signal to a different bitdepth.\n\t *         Lowering the bitdepth of the signal creates distortion. Read more about Bitcrushing\n\t *         on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {Number} bits The number of bits to downsample the signal. Nominal range\n\t *                       of 1 to 8.\n\t *  @example\n\t * //initialize crusher and route a synth through it\n\t * var crusher = new Tone.BitCrusher(4).toMaster();\n\t * var synth = new Tone.MonoSynth().connect(crusher);\n\t */\n\tTone.BitCrusher = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"bits\"], Tone.BitCrusher);\n\t\tTone.Effect.call(this, options);\n\n\t\tvar invStepSize = 1 / Math.pow(2, options.bits - 1);\n\n\t\t/**\n\t\t *  Subtract the input signal and the modulus of the input signal\n\t\t *  @type {Tone.Subtract}\n\t\t *  @private\n\t\t */\n\t\tthis._subtract = new Tone.Subtract();\n\n\t\t/**\n\t\t *  The mod function\n\t\t *  @type  {Tone.Modulo}\n\t\t *  @private\n\t\t */\n\t\tthis._modulo = new Tone.Modulo(invStepSize);\n\n\t\t/**\n\t\t *  keeps track of the bits\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._bits = options.bits;\n\n\t\t//connect it up\n\t\tthis.effectSend.fan(this._subtract, this._modulo);\n\t\tthis._modulo.connect(this._subtract, 0, 1);\n\t\tthis._subtract.connect(this.effectReturn);\n\t};\n\n\tTone.extend(Tone.BitCrusher, Tone.Effect);\n\n\t/**\n\t *  the default values\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.BitCrusher.defaults = {\n\t\t\"bits\" : 4\n\t};\n\n\t/**\n\t * The bit depth of the effect. Nominal range of 1-8.\n\t * @memberOf Tone.BitCrusher#\n\t * @type {number}\n\t * @name bits\n\t */\n\tObject.defineProperty(Tone.BitCrusher.prototype, \"bits\", {\n\t\tget : function(){\n\t\t\treturn this._bits;\n\t\t},\n\t\tset : function(bits){\n\t\t\tthis._bits = bits;\n\t\t\tvar invStepSize = 1 / Math.pow(2, bits - 1);\n\t\t\tthis._modulo.value = invStepSize;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.BitCrusher} this\n\t */\n\tTone.BitCrusher.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._subtract.dispose();\n\t\tthis._subtract = null;\n\t\tthis._modulo.dispose();\n\t\tthis._modulo = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.BitCrusher;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/BitCrusher.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Chebyshev.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Chebyshev.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.ChebyShev is a Chebyshev waveshaper, an effect which is good \n\t *         for making different types of distortion sounds.\n\t *         Note that odd orders sound very different from even ones, \n\t *         and order = 1 is no change. \n\t *         Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).\n\t *\n\t *  @extends {Tone.Effect}\n\t *  @constructor\n\t *  @param {Positive|Object} [order] The order of the chebyshev polynomial. Normal range between 1-100. \n\t *  @example\n\t * //create a new cheby\n\t * var cheby = new Tone.Chebyshev(50);\n\t * //create a monosynth connected to our cheby\n\t * synth = new Tone.MonoSynth().connect(cheby);\n\t */\n\tTone.Chebyshev = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"order\"], Tone.Chebyshev);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  @type {WaveShaperNode}\n\t\t *  @private\n\t\t */\n\t\tthis._shaper = new Tone.WaveShaper(4096);\n\n\t\t/**\n\t\t * holds onto the order of the filter\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._order = options.order;\n\n\t\tthis.connectEffect(this._shaper);\n\t\tthis.order = options.order;\n\t\tthis.oversample = options.oversample;\n\t};\n\n\tTone.extend(Tone.Chebyshev, Tone.Effect);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Chebyshev.defaults = {\n\t\t\"order\" : 1,\n\t\t\"oversample\" : \"none\"\n\t};\n\n\t/**\n\t *  get the coefficient for that degree\n\t *  @param {number} x the x value\n\t *  @param   {number} degree \n\t *  @param {Object} memo memoize the computed value. \n\t *                       this speeds up computation greatly. \n\t *  @return  {number}       the coefficient \n\t *  @private\n\t */\n\tTone.Chebyshev.prototype._getCoefficient = function(x, degree, memo){\n\t\tif (memo.hasOwnProperty(degree)){\n\t\t\treturn memo[degree];\n\t\t} else if (degree === 0){\n\t\t\tmemo[degree] = 0;\n\t\t} else if (degree === 1){\n\t\t\tmemo[degree] = x;\n\t\t} else {\n\t\t\tmemo[degree] = 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo);\n\t\t}\n\t\treturn memo[degree];\n\t};\n\n\t/**\n\t * The order of the Chebyshev polynomial which creates\n\t * the equation which is applied to the incoming \n\t * signal through a Tone.WaveShaper. The equations\n\t * are in the form:<br>\n\t * order 2: 2x^2 + 1<br>\n\t * order 3: 4x^3 + 3x <br>\n\t * @memberOf Tone.Chebyshev#\n\t * @type {Positive}\n\t * @name order\n\t */\n\tObject.defineProperty(Tone.Chebyshev.prototype, \"order\", {\n\t\tget : function(){\n\t\t\treturn this._order;\n\t\t},\n\t\tset : function(order){\n\t\t\tthis._order = order;\n\t\t\tvar curve = new Array(4096);\n\t\t\tvar len = curve.length;\n\t\t\tfor (var i = 0; i < len; ++i){\n\t\t\t\tvar x = i * 2 / len - 1;\n\t\t\t\tif (x === 0){\n\t\t\t\t\t//should output 0 when input is 0\n\t\t\t\t\tcurve[i] = 0;\n\t\t\t\t} else {\n\t\t\t\t\tcurve[i] = this._getCoefficient(x, order, {});\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._shaper.curve = curve;\n\t\t} \n\t});\n\n\t/**\n\t * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n\t * @memberOf Tone.Chebyshev#\n\t * @type {string}\n\t * @name oversample\n\t */\n\tObject.defineProperty(Tone.Chebyshev.prototype, \"oversample\", {\n\t\tget : function(){\n\t\t\treturn this._shaper.oversample;\n\t\t},\n\t\tset : function(oversampling){\n\t\t\tthis._shaper.oversample = oversampling;\n\t\t} \n\t});\n\n\t/**\n\t *  Clean up. \n\t *  @returns {Tone.Chebyshev} this\n\t */\n\tTone.Chebyshev.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._shaper.dispose();\n\t\tthis._shaper = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Chebyshev;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Chebyshev.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Chorus.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Chorus.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Chorus is a stereo chorus effect composed of\n\t *         a left and right delay with a Tone.LFO applied to the delayTime of each channel.\n\t *         Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n\t *         Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).\n\t *\n\t *\t@constructor\n\t *\t@extends {Tone.StereoEffect}\n\t *\t@param {Frequency|Object} [frequency] The frequency of the LFO.\n\t *\t@param {Milliseconds} [delayTime] The delay of the chorus effect in ms.\n\t *\t@param {NormalRange} [depth] The depth of the chorus.\n\t *\t@example\n\t * var chorus = new Tone.Chorus(4, 2.5, 0.5);\n\t * var synth = new Tone.PolySynth(4, Tone.MonoSynth).connect(chorus);\n\t * synth.triggerAttackRelease([\"C3\",\"E3\",\"G3\"], \"8n\");\n\t */\n\tTone.Chorus = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"delayTime\", \"depth\"], Tone.Chorus);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  the depth of the chorus\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._depth = options.depth;\n\n\t\t/**\n\t\t *  the delayTime\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._delayTime = options.delayTime / 1000;\n\n\t\t/**\n\t\t *  the lfo which controls the delayTime\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoL = new Tone.LFO({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : 1,\n\t\t});\n\n\t\t/**\n\t\t *  another LFO for the right side with a 180 degree phase diff\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoR = new Tone.LFO({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : 1,\n\t\t\t\"phase\" : 180\n\t\t});\n\n\t\t/**\n\t\t *  delay for left\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._delayNodeL = new Tone.Delay();\n\n\t\t/**\n\t\t *  delay for right\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._delayNodeR = new Tone.Delay();\n\n\t\t/**\n\t\t * The frequency of the LFO which modulates the delayTime.\n\t\t * @type {Frequency}\n\t\t * @signal\n\t\t */\n\t\tthis.frequency = this._lfoL.frequency;\n\n\t\t//connections\n\t\tthis.effectSendL.chain(this._delayNodeL, this.effectReturnL);\n\t\tthis.effectSendR.chain(this._delayNodeR, this.effectReturnR);\n\t\t//and pass through to make the detune apparent\n\t\tthis.effectSendL.connect(this.effectReturnL);\n\t\tthis.effectSendR.connect(this.effectReturnR);\n\t\t//lfo setup\n\t\tthis._lfoL.connect(this._delayNodeL.delayTime);\n\t\tthis._lfoR.connect(this._delayNodeR.delayTime);\n\t\t//start the lfo\n\t\tthis._lfoL.start();\n\t\tthis._lfoR.start();\n\t\t//have one LFO frequency control the other\n\t\tthis._lfoL.frequency.connect(this._lfoR.frequency);\n\t\t//set the initial values\n\t\tthis.depth = this._depth;\n\t\tthis.frequency.value = options.frequency;\n\t\tthis.type = options.type;\n\t\tthis._readOnly([\"frequency\"]);\n\t\tthis.spread = options.spread;\n\t};\n\n\tTone.extend(Tone.Chorus, Tone.StereoEffect);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Chorus.defaults = {\n\t\t\"frequency\" : 1.5,\n\t\t\"delayTime\" : 3.5,\n\t\t\"depth\" : 0.7,\n\t\t\"type\" : \"sine\",\n\t\t\"spread\" : 180\n\t};\n\n\t/**\n\t * The depth of the effect. A depth of 1 makes the delayTime\n\t * modulate between 0 and 2*delayTime (centered around the delayTime).\n\t * @memberOf Tone.Chorus#\n\t * @type {NormalRange}\n\t * @name depth\n\t */\n\tObject.defineProperty(Tone.Chorus.prototype, \"depth\", {\n\t\tget : function(){\n\t\t\treturn this._depth;\n\t\t},\n\t\tset : function(depth){\n\t\t\tthis._depth = depth;\n\t\t\tvar deviation = this._delayTime * depth;\n\t\t\tthis._lfoL.min = Math.max(this._delayTime - deviation, 0);\n\t\t\tthis._lfoL.max = this._delayTime + deviation;\n\t\t\tthis._lfoR.min = Math.max(this._delayTime - deviation, 0);\n\t\t\tthis._lfoR.max = this._delayTime + deviation;\n\t\t}\n\t});\n\n\t/**\n\t * The delayTime in milliseconds of the chorus. A larger delayTime\n\t * will give a more pronounced effect. Nominal range a delayTime\n\t * is between 2 and 20ms.\n\t * @memberOf Tone.Chorus#\n\t * @type {Milliseconds}\n\t * @name delayTime\n\t */\n\tObject.defineProperty(Tone.Chorus.prototype, \"delayTime\", {\n\t\tget : function(){\n\t\t\treturn this._delayTime * 1000;\n\t\t},\n\t\tset : function(delayTime){\n\t\t\tthis._delayTime = delayTime / 1000;\n\t\t\tthis.depth = this._depth;\n\t\t}\n\t});\n\n\t/**\n\t * The oscillator type of the LFO.\n\t * @memberOf Tone.Chorus#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.Chorus.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._lfoL.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._lfoL.type = type;\n\t\t\tthis._lfoR.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n\t * When set to 180, LFO's will be panned hard left and right respectively.\n\t * @memberOf Tone.Chorus#\n\t * @type {Degrees}\n\t * @name spread\n\t */\n\tObject.defineProperty(Tone.Chorus.prototype, \"spread\", {\n\t\tget : function(){\n\t\t\treturn this._lfoR.phase - this._lfoL.phase;\n\t\t},\n\t\tset : function(spread){\n\t\t\tthis._lfoL.phase = 90 - (spread/2);\n\t\t\tthis._lfoR.phase = (spread/2) + 90;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Chorus} this\n\t */\n\tTone.Chorus.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tthis._lfoL.dispose();\n\t\tthis._lfoL = null;\n\t\tthis._lfoR.dispose();\n\t\tthis._lfoR = null;\n\t\tthis._delayNodeL.dispose();\n\t\tthis._delayNodeL = null;\n\t\tthis._delayNodeR.dispose();\n\t\tthis._delayNodeR = null;\n\t\tthis._writable(\"frequency\");\n\t\tthis.frequency = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Chorus;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Chorus.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Convolver.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Convolver.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Convolver is a wrapper around the Native Web Audio\n\t *          [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n\t *          Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n\t *          [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {string|Tone.Buffer|Object} [url] The URL of the impulse response or the Tone.Buffer\n\t *                                           contianing the impulse response.\n\t *  @param {Function=} onload The callback to invoke when the url is loaded.\n\t *  @example\n\t * //initializing the convolver with an impulse response\n\t * var convolver = new Tone.Convolver(\"./path/to/ir.wav\").toMaster();\n\t */\n\tTone.Convolver = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"url\", \"onload\"], Tone.Convolver);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  convolver node\n\t\t *  @type {ConvolverNode}\n\t\t *  @private\n\t\t */\n\t\tthis._convolver = this.context.createConvolver();\n\n\t\t/**\n\t\t *  the convolution buffer\n\t\t *  @type {Tone.Buffer}\n\t\t *  @private\n\t\t */\n\t\tthis._buffer = new Tone.Buffer(options.url, function(buffer){\n\t\t\tthis.buffer = buffer.get();\n\t\t\toptions.onload();\n\t\t}.bind(this));\n\n\t\t//set if it's already loaded\n\t\tif (this._buffer.loaded){\n\t\t\tthis.buffer = this._buffer;\n\t\t}\n\n\t\t//initially set normalization\n\t\tthis.normalize = options.normalize;\n\n\t\tthis.connectEffect(this._convolver);\n\t};\n\n\tTone.extend(Tone.Convolver, Tone.Effect);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Convolver.defaults = {\n\t\t\"onload\" : Tone.noOp,\n\t\t\"normalize\" : true\n\t};\n\n\t/**\n\t *  The convolver's buffer\n\t *  @memberOf Tone.Convolver#\n\t *  @type {AudioBuffer}\n\t *  @name buffer\n\t */\n\tObject.defineProperty(Tone.Convolver.prototype, \"buffer\", {\n\t\t\"get\" : function(){\n\t\t\tif (this._buffer.length){\n\t\t\t\treturn this._buffer;\n\t\t\t} else {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t},\n\t\t\"set\" : function(buffer){\n\t\t\tthis._buffer.set(buffer);\n\t\t\t//if it's already got a buffer, create a new one\n\t\t\tif (this._convolver.buffer){\n\t\t\t\t//disconnect the old one\n\t\t\t\tthis.effectSend.disconnect();\n\t\t\t\tthis._convolver.disconnect();\n\t\t\t\t//create and connect a new one\n\t\t\t\tthis._convolver = this.context.createConvolver();\n\t\t\t\tthis.connectEffect(this._convolver);\n\t\t\t}\n\t\t\tthis._convolver.buffer = this._buffer.get();\n\t\t}\n\t});\n\n\t/**\n\t *  The normalize property of the ConvolverNode interface is a boolean that controls whether the impulse response from the buffer will be scaled by an equal-power normalization when the buffer attribute is set, or not.\n\t *  @memberOf Tone.Convolver#\n\t *  @type {Boolean}\n\t *  @name normalize\n\t */\n\tObject.defineProperty(Tone.Convolver.prototype, \"normalize\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._convolver.normalize;\n\t\t},\n\t\t\"set\" : function(norm){\n\t\t\tthis._convolver.normalize = norm;\n\t\t}\n\t});\n\n\t/**\n\t *  Load an impulse response url as an audio buffer.\n\t *  Decodes the audio asynchronously and invokes\n\t *  the callback once the audio buffer loads.\n\t *  @param {string} url The url of the buffer to load.\n\t *                      filetype support depends on the\n\t *                      browser.\n\t *  @param  {function=} callback\n\t *  @returns {Promise}\n\t */\n\tTone.Convolver.prototype.load = function(url, callback){\n\t\treturn this._buffer.load(url, function(buff){\n\t\t\tthis.buffer = buff;\n\t\t\tif (callback){\n\t\t\t\tcallback();\n\t\t\t}\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Convolver} this\n\t */\n\tTone.Convolver.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._buffer.dispose();\n\t\tthis._buffer = null;\n\t\tthis._convolver.disconnect();\n\t\tthis._convolver = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Convolver;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Convolver.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Distortion.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Distortion.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Distortion is a simple distortion effect using Tone.WaveShaper.\n\t *         Algorithm from [a stackoverflow answer](http://stackoverflow.com/a/22313408).\n\t *\n\t *  @extends {Tone.Effect}\n\t *  @constructor\n\t *  @param {Number|Object} [distortion] The amount of distortion (nominal range of 0-1)\n\t *  @example\n\t * var dist = new Tone.Distortion(0.8).toMaster();\n\t * var fm = new Tone.SimpleFM().connect(dist);\n\t * //this sounds good on bass notes\n\t * fm.triggerAttackRelease(\"A1\", \"8n\");\n\t */\n\tTone.Distortion = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"distortion\"], Tone.Distortion);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  @type {Tone.WaveShaper}\n\t\t *  @private\n\t\t */\n\t\tthis._shaper = new Tone.WaveShaper(4096);\n\n\t\t/**\n\t\t * holds the distortion amount\n\t\t * @type {number}\n\t\t * @private\n\t\t */\n\t\tthis._distortion = options.distortion;\n\n\t\tthis.connectEffect(this._shaper);\n\t\tthis.distortion = options.distortion;\n\t\tthis.oversample = options.oversample;\n\t};\n\n\tTone.extend(Tone.Distortion, Tone.Effect);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Distortion.defaults = {\n\t\t\"distortion\" : 0.4,\n\t\t\"oversample\" : \"none\"\n\t};\n\n\t/**\n\t * The amount of distortion.\n\t * @memberOf Tone.Distortion#\n\t * @type {NormalRange}\n\t * @name distortion\n\t */\n\tObject.defineProperty(Tone.Distortion.prototype, \"distortion\", {\n\t\tget : function(){\n\t\t\treturn this._distortion;\n\t\t},\n\t\tset : function(amount){\n\t\t\tthis._distortion = amount;\n\t\t\tvar k = amount * 100;\n\t\t\tvar deg = Math.PI / 180;\n\t\t\tthis._shaper.setMap(function(x){\n\t\t\t\tif (Math.abs(x) < 0.001){\n\t\t\t\t\t//should output 0 when input is 0\n\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\treturn (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));\n\t\t\t\t}\n\t\t\t});\n\t\t} \n\t});\n\n\t/**\n\t * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n\t * @memberOf Tone.Distortion#\n\t * @type {string}\n\t * @name oversample\n\t */\n\tObject.defineProperty(Tone.Distortion.prototype, \"oversample\", {\n\t\tget : function(){\n\t\t\treturn this._shaper.oversample;\n\t\t},\n\t\tset : function(oversampling){\n\t\t\tthis._shaper.oversample = oversampling;\n\t\t} \n\t});\n\n\t/**\n\t *  Clean up. \n\t *  @returns {Tone.Distortion} this\n\t */\n\tTone.Distortion.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._shaper.dispose();\n\t\tthis._shaper = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Distortion;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Distortion.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Effect.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Effect.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t * \t@class  Tone.Effect is the base class for effects. Connect the effect between\n\t * \t        the effectSend and effectReturn GainNodes, then control the amount of\n\t * \t        effect which goes to the output using the wet control.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {NormalRange|Object} [wet] The starting wet value.\n\t */\n\tTone.Effect = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"wet\"], Tone.Effect);\n\t\tTone.AudioNode.call(this);\n\t\tthis.createInsOuts(1, 1);\n\n\t\t/**\n\t\t *  the drywet knob to control the amount of effect\n\t\t *  @type {Tone.CrossFade}\n\t\t *  @private\n\t\t */\n\t\tthis._dryWet = new Tone.CrossFade(options.wet);\n\n\t\t/**\n\t\t *  The wet control is how much of the effected\n\t\t *  will pass through to the output. 1 = 100% effected\n\t\t *  signal, 0 = 100% dry signal.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.wet = this._dryWet.fade;\n\n\t\t/**\n\t\t *  connect the effectSend to the input of hte effect\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis.effectSend = new Tone.Gain();\n\n\t\t/**\n\t\t *  connect the output of the effect to the effectReturn\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis.effectReturn = new Tone.Gain();\n\n\t\t//connections\n\t\tthis.input.connect(this._dryWet.a);\n\t\tthis.input.connect(this.effectSend);\n\t\tthis.effectReturn.connect(this._dryWet.b);\n\t\tthis._dryWet.connect(this.output);\n\t\tthis._readOnly([\"wet\"]);\n\t};\n\n\tTone.extend(Tone.Effect, Tone.AudioNode);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Effect.defaults = {\n\t\t\"wet\" : 1\n\t};\n\n\t/**\n\t *  chains the effect in between the effectSend and effectReturn\n\t *  @param  {Tone} effect\n\t *  @private\n\t *  @returns {Tone.Effect} this\n\t */\n\tTone.Effect.prototype.connectEffect = function(effect){\n\t\tthis.effectSend.chain(effect, this.effectReturn);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Effect} this\n\t */\n\tTone.Effect.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._dryWet.dispose();\n\t\tthis._dryWet = null;\n\t\tthis.effectSend.dispose();\n\t\tthis.effectSend = null;\n\t\tthis.effectReturn.dispose();\n\t\tthis.effectReturn = null;\n\t\tthis._writable([\"wet\"]);\n\t\tthis.wet = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Effect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Effect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/FeedbackDelay.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/effect/FeedbackDelay.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/FeedbackEffect */ \"./node_modules/tone/Tone/effect/FeedbackEffect.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.FeedbackDelay is a DelayNode in which part of output\n\t *          signal is fed back into the delay.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.FeedbackEffect}\n\t *  @param {Time|Object} [delayTime] The delay applied to the incoming signal.\n\t *  @param {NormalRange=} feedback The amount of the effected signal which\n\t *                            is fed back through the delay.\n\t *  @example\n\t * var feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toMaster();\n\t * var tom = new Tone.DrumSynth({\n\t * \t\"octaves\" : 4,\n\t * \t\"pitchDecay\" : 0.1\n\t * }).connect(feedbackDelay);\n\t * tom.triggerAttackRelease(\"A2\",\"32n\");\n\t */\n\tTone.FeedbackDelay = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"delayTime\", \"feedback\"], Tone.FeedbackDelay);\n\t\tTone.FeedbackEffect.call(this, options);\n\n\t\t/**\n\t\t *  the delay node\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._delayNode = new Tone.Delay(options.delayTime, options.maxDelay);\n\n\t\t/**\n\t\t *  The delayTime of the DelayNode.\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = this._delayNode.delayTime;\n\n\t\t// connect it up\n\t\tthis.connectEffect(this._delayNode);\n\t\tthis._readOnly([\"delayTime\"]);\n\t};\n\n\tTone.extend(Tone.FeedbackDelay, Tone.FeedbackEffect);\n\n\t/**\n\t *  The default values.\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.FeedbackDelay.defaults = {\n\t\t\"delayTime\" : 0.25,\n\t\t\"maxDelay\" : 1\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.FeedbackDelay} this\n\t */\n\tTone.FeedbackDelay.prototype.dispose = function(){\n\t\tTone.FeedbackEffect.prototype.dispose.call(this);\n\t\tthis._delayNode.dispose();\n\t\tthis._delayNode = null;\n\t\tthis._writable([\"delayTime\"]);\n\t\tthis.delayTime = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FeedbackDelay;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/FeedbackDelay.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/FeedbackEffect.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/effect/FeedbackEffect.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), \n\t__webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\t\n\t/**\n\t * \t@class  Tone.FeedbackEffect provides a loop between an \n\t * \t        audio source and its own output. This is a base-class\n\t * \t        for feedback effects. \n\t *\n\t *  @constructor\n\t *  @extends {Tone.Effect}\n\t *  @param {NormalRange|Object} [feedback] The initial feedback value.\n\t */\n\tTone.FeedbackEffect = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"feedback\"], Tone.FeedbackEffect);\n\t\tTone.Effect.call(this, options);\n\t\t\n\t\t/**\n\t\t *  the gain which controls the feedback\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackGain = new Tone.Gain(options.feedback, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  The amount of signal which is fed back into the effect input. \n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.feedback = this._feedbackGain.gain;\n\n\t\t//the feedback loop\n\t\tthis.effectReturn.chain(this._feedbackGain, this.effectSend);\n\t\tthis._readOnly([\"feedback\"]);\n\t};\n\n\tTone.extend(Tone.FeedbackEffect, Tone.Effect);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.FeedbackEffect.defaults = {\n\t\t\"feedback\" : 0.125\n\t};\n\n\t/**\n\t *  Clean up. \n\t *  @returns {Tone.FeedbackEffect} this\n\t */\n\tTone.FeedbackEffect.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._writable([\"feedback\"]);\n\t\tthis._feedbackGain.dispose();\n\t\tthis._feedbackGain = null;\n\t\tthis.feedback = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FeedbackEffect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/FeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Freeverb.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Freeverb.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/LowpassCombFilter */ \"./node_modules/tone/Tone/component/LowpassCombFilter.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../signal/ScaleExp */ \"./node_modules/tone/Tone/signal/ScaleExp.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  an array of comb filter delay values from Freeverb implementation\n\t *  @static\n\t *  @private\n\t *  @type {Array}\n\t */\n\tvar combFilterTunings = [1557 / 44100, 1617 / 44100, 1491 / 44100, 1422 / 44100, 1277 / 44100, 1356 / 44100, 1188 / 44100, 1116 / 44100];\n\n\t/**\n\t *  an array of allpass filter frequency values from Freeverb implementation\n\t *  @private\n\t *  @static\n\t *  @type {Array}\n\t */\n\tvar allpassFilterFrequencies = [225, 556, 441, 341];\n\n\t/**\n\t *  @class Tone.Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n\t *         Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).\n\t *\n\t *  @extends {Tone.Effect}\n\t *  @constructor\n\t *  @param {NormalRange|Object} [roomSize] Correlated to the decay time.\n\t *  @param {Frequency} [dampening] The cutoff frequency of a lowpass filter as part\n\t *                                 of the reverb.\n\t *  @example\n\t * var freeverb = new Tone.Freeverb().toMaster();\n\t * freeverb.dampening.value = 1000;\n\t * //routing synth through the reverb\n\t * var synth = new Tone.AMSynth().connect(freeverb);\n\t */\n\tTone.Freeverb = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"roomSize\", \"dampening\"], Tone.Freeverb);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  The roomSize value between. A larger roomSize\n\t\t *  will result in a longer decay.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.roomSize = new Tone.Signal(options.roomSize, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  The amount of dampening of the reverberant signal.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.dampening = new Tone.Signal(options.dampening, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  the comb filters\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._combFilters = [];\n\n\t\t/**\n\t\t *  the allpass filters on the left\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._allpassFiltersL = [];\n\n\t\t/**\n\t\t *  the allpass filters on the right\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._allpassFiltersR = [];\n\n\t\t//make the allpass filters on the right\n\t\tfor (var l = 0; l < allpassFilterFrequencies.length; l++){\n\t\t\tvar allpassL = this.context.createBiquadFilter();\n\t\t\tallpassL.type = \"allpass\";\n\t\t\tallpassL.frequency.value = allpassFilterFrequencies[l];\n\t\t\tthis._allpassFiltersL.push(allpassL);\n\t\t}\n\n\t\t//make the allpass filters on the left\n\t\tfor (var r = 0; r < allpassFilterFrequencies.length; r++){\n\t\t\tvar allpassR = this.context.createBiquadFilter();\n\t\t\tallpassR.type = \"allpass\";\n\t\t\tallpassR.frequency.value = allpassFilterFrequencies[r];\n\t\t\tthis._allpassFiltersR.push(allpassR);\n\t\t}\n\n\t\t//make the comb filters\n\t\tfor (var c = 0; c < combFilterTunings.length; c++){\n\t\t\tvar lfpf = new Tone.LowpassCombFilter(combFilterTunings[c]);\n\t\t\tif (c < combFilterTunings.length / 2){\n\t\t\t\tthis.effectSendL.chain(lfpf, this._allpassFiltersL[0]);\n\t\t\t} else {\n\t\t\t\tthis.effectSendR.chain(lfpf, this._allpassFiltersR[0]);\n\t\t\t}\n\t\t\tthis.roomSize.connect(lfpf.resonance);\n\t\t\tthis.dampening.connect(lfpf.dampening);\n\t\t\tthis._combFilters.push(lfpf);\n\t\t}\n\n\t\t//chain the allpass filters togetehr\n\t\tTone.connectSeries.apply(Tone, this._allpassFiltersL);\n\t\tTone.connectSeries.apply(Tone, this._allpassFiltersR);\n\t\tthis._allpassFiltersL[this._allpassFiltersL.length - 1].connect(this.effectReturnL);\n\t\tthis._allpassFiltersR[this._allpassFiltersR.length - 1].connect(this.effectReturnR);\n\t\tthis._readOnly([\"roomSize\", \"dampening\"]);\n\t};\n\n\tTone.extend(Tone.Freeverb, Tone.StereoEffect);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Freeverb.defaults = {\n\t\t\"roomSize\" : 0.7,\n\t\t\"dampening\" : 3000\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Freeverb} this\n\t */\n\tTone.Freeverb.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tfor (var al = 0; al < this._allpassFiltersL.length; al++){\n\t\t\tthis._allpassFiltersL[al].disconnect();\n\t\t\tthis._allpassFiltersL[al] = null;\n\t\t}\n\t\tthis._allpassFiltersL = null;\n\t\tfor (var ar = 0; ar < this._allpassFiltersR.length; ar++){\n\t\t\tthis._allpassFiltersR[ar].disconnect();\n\t\t\tthis._allpassFiltersR[ar] = null;\n\t\t}\n\t\tthis._allpassFiltersR = null;\n\t\tfor (var cf = 0; cf < this._combFilters.length; cf++){\n\t\t\tthis._combFilters[cf].dispose();\n\t\t\tthis._combFilters[cf] = null;\n\t\t}\n\t\tthis._combFilters = null;\n\t\tthis._writable([\"roomSize\", \"dampening\"]);\n\t\tthis.roomSize.dispose();\n\t\tthis.roomSize = null;\n\t\tthis.dampening.dispose();\n\t\tthis.dampening = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Freeverb;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Freeverb.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/JCReverb.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/effect/JCReverb.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/FeedbackCombFilter */ \"./node_modules/tone/Tone/component/FeedbackCombFilter.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\"), __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/Tone/signal/Scale.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  an array of the comb filter delay time values\n\t *  @private\n\t *  @static\n\t *  @type {Array}\n\t */\n\tvar combFilterDelayTimes = [1687 / 25000, 1601 / 25000, 2053 / 25000, 2251 / 25000];\n\n\t/**\n\t *  the resonances of each of the comb filters\n\t *  @private\n\t *  @static\n\t *  @type {Array}\n\t */\n\tvar combFilterResonances = [0.773, 0.802, 0.753, 0.733];\n\n\t/**\n\t *  the allpass filter frequencies\n\t *  @private\n\t *  @static\n\t *  @type {Array}\n\t */\n\tvar allpassFilterFreqs = [347, 113, 37];\n\n\t/**\n\t *  @class Tone.JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n\t *         tuned by John Chowning in 1970.\n\t *         It is made up of three allpass filters and four Tone.FeedbackCombFilter.\n\t *\n\t *\n\t *  @extends {Tone.Effect}\n\t *  @constructor\n\t *  @param {NormalRange|Object} [roomSize] Coorelates to the decay time.\n\t *  @example\n\t * var reverb = new Tone.JCReverb(0.4).connect(Tone.Master);\n\t * var delay = new Tone.FeedbackDelay(0.5);\n\t * //connecting the synth to reverb through delay\n\t * var synth = new Tone.DuoSynth().chain(delay, reverb);\n\t * synth.triggerAttackRelease(\"A4\",\"8n\");\n\t */\n\tTone.JCReverb = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"roomSize\"], Tone.JCReverb);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  room size control values between [0,1]\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.roomSize = new Tone.Signal(options.roomSize, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  scale the room size\n\t\t *  @type {Tone.Scale}\n\t\t *  @private\n\t\t */\n\t\tthis._scaleRoomSize = new Tone.Scale(-0.733, 0.197);\n\n\t\t/**\n\t\t *  a series of allpass filters\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._allpassFilters = [];\n\n\t\t/**\n\t\t *  parallel feedback comb filters\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackCombFilters = [];\n\n\t\t//make the allpass filters\n\t\tfor (var af = 0; af < allpassFilterFreqs.length; af++){\n\t\t\tvar allpass = this.context.createBiquadFilter();\n\t\t\tallpass.type = \"allpass\";\n\t\t\tallpass.frequency.value = allpassFilterFreqs[af];\n\t\t\tthis._allpassFilters.push(allpass);\n\t\t}\n\n\t\t//and the comb filters\n\t\tfor (var cf = 0; cf < combFilterDelayTimes.length; cf++){\n\t\t\tvar fbcf = new Tone.FeedbackCombFilter(combFilterDelayTimes[cf], 0.1);\n\t\t\tthis._scaleRoomSize.connect(fbcf.resonance);\n\t\t\tfbcf.resonance.value = combFilterResonances[cf];\n\t\t\tthis._allpassFilters[this._allpassFilters.length - 1].connect(fbcf);\n\t\t\tif (cf < combFilterDelayTimes.length / 2){\n\t\t\t\tfbcf.connect(this.effectReturnL);\n\t\t\t} else {\n\t\t\t\tfbcf.connect(this.effectReturnR);\n\t\t\t}\n\t\t\tthis._feedbackCombFilters.push(fbcf);\n\t\t}\n\n\t\t//chain the allpass filters together\n\t\tthis.roomSize.connect(this._scaleRoomSize);\n\t\tTone.connectSeries.apply(Tone, this._allpassFilters);\n\t\tthis.effectSendL.connect(this._allpassFilters[0]);\n\t\tthis.effectSendR.connect(this._allpassFilters[0]);\n\t\tthis._readOnly([\"roomSize\"]);\n\t};\n\n\tTone.extend(Tone.JCReverb, Tone.StereoEffect);\n\n\t/**\n\t *  the default values\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.JCReverb.defaults = {\n\t\t\"roomSize\" : 0.5\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.JCReverb} this\n\t */\n\tTone.JCReverb.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tfor (var apf = 0; apf < this._allpassFilters.length; apf++){\n\t\t\tthis._allpassFilters[apf].disconnect();\n\t\t\tthis._allpassFilters[apf] = null;\n\t\t}\n\t\tthis._allpassFilters = null;\n\t\tfor (var fbcf = 0; fbcf < this._feedbackCombFilters.length; fbcf++){\n\t\t\tthis._feedbackCombFilters[fbcf].dispose();\n\t\t\tthis._feedbackCombFilters[fbcf] = null;\n\t\t}\n\t\tthis._feedbackCombFilters = null;\n\t\tthis._writable([\"roomSize\"]);\n\t\tthis.roomSize.dispose();\n\t\tthis.roomSize = null;\n\t\tthis._scaleRoomSize.dispose();\n\t\tthis._scaleRoomSize = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.JCReverb;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/JCReverb.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/MidSideEffect.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/effect/MidSideEffect.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../component/MidSideSplit */ \"./node_modules/tone/Tone/component/MidSideSplit.js\"), __webpack_require__(/*! ../component/MidSideMerge */ \"./node_modules/tone/Tone/component/MidSideMerge.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Mid/Side processing separates the the 'mid' signal\n\t *         (which comes out of both the left and the right channel)\n\t *         and the 'side' (which only comes out of the the side channels)\n\t *         and effects them separately before being recombined.\n\t *         Applies a Mid/Side seperation and recombination.\n\t *         Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n\t *         <br><br>\n\t *         This is a base-class for Mid/Side Effects.\n\t *\n\t *  @extends {Tone.Effect}\n\t *  @constructor\n\t */\n\tTone.MidSideEffect = function(){\n\n\t\tTone.Effect.apply(this, arguments);\n\n\t\t/**\n\t\t *  The mid/side split\n\t\t *  @type  {Tone.MidSideSplit}\n\t\t *  @private\n\t\t */\n\t\tthis._midSideSplit = new Tone.MidSideSplit();\n\n\t\t/**\n\t\t *  The mid/side merge\n\t\t *  @type  {Tone.MidSideMerge}\n\t\t *  @private\n\t\t */\n\t\tthis._midSideMerge = new Tone.MidSideMerge();\n\n\t\t/**\n\t\t *  The mid send. Connect to mid processing\n\t\t *  @type {Tone}\n\t\t *  @private\n\t\t */\n\t\tthis.midSend = this._midSideSplit.mid;\n\n\t\t/**\n\t\t *  The side send. Connect to side processing\n\t\t *  @type {Tone}\n\t\t *  @private\n\t\t */\n\t\tthis.sideSend = this._midSideSplit.side;\n\n\t\t/**\n\t\t *  The mid return connection\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.midReturn = this._midSideMerge.mid;\n\n\t\t/**\n\t\t *  The side return connection\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.sideReturn = this._midSideMerge.side;\n\n\t\t//the connections\n\t\tthis.effectSend.connect(this._midSideSplit);\n\t\tthis._midSideMerge.connect(this.effectReturn);\n\t};\n\n\tTone.extend(Tone.MidSideEffect, Tone.Effect);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.MidSideEffect} this\n\t */\n\tTone.MidSideEffect.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._midSideSplit.dispose();\n\t\tthis._midSideSplit = null;\n\t\tthis._midSideMerge.dispose();\n\t\tthis._midSideMerge = null;\n\t\tthis.midSend = null;\n\t\tthis.sideSend = null;\n\t\tthis.midReturn = null;\n\t\tthis.sideReturn = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MidSideEffect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/MidSideEffect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Phaser.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Phaser.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Phaser is a phaser effect. Phasers work by changing the phase\n\t *         of different frequency components of an incoming signal. Read more on\n\t *         [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).\n\t *         Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).\n\t *\n\t *\t@extends {Tone.StereoEffect}\n\t *\t@constructor\n\t *\t@param {Frequency|Object} [frequency] The speed of the phasing.\n\t *\t@param {number} [octaves] The octaves of the effect.\n\t *\t@param {Frequency} [baseFrequency] The base frequency of the filters.\n\t *\t@example\n\t * var phaser = new Tone.Phaser({\n\t * \t\"frequency\" : 15,\n\t * \t\"octaves\" : 5,\n\t * \t\"baseFrequency\" : 1000\n\t * }).toMaster();\n\t * var synth = new Tone.FMSynth().connect(phaser);\n\t * synth.triggerAttackRelease(\"E3\", \"2n\");\n\t */\n\tTone.Phaser = function(){\n\n\t\t//set the defaults\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"octaves\", \"baseFrequency\"], Tone.Phaser);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  the lfo which controls the frequency on the left side\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoL = new Tone.LFO(options.frequency, 0, 1);\n\n\t\t/**\n\t\t *  the lfo which controls the frequency on the right side\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoR = new Tone.LFO(options.frequency, 0, 1);\n\t\tthis._lfoR.phase = 180;\n\n\t\t/**\n\t\t *  the base modulation frequency\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._baseFrequency = options.baseFrequency;\n\n\t\t/**\n\t\t *  the octaves of the phasing\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._octaves = options.octaves;\n\n\t\t/**\n\t\t *  The quality factor of the filters\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t */\n\t\tthis.Q = new Tone.Signal(options.Q, Tone.Type.Positive);\n\n\t\t/**\n\t\t *  the array of filters for the left side\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._filtersL = this._makeFilters(options.stages, this._lfoL, this.Q);\n\n\t\t/**\n\t\t *  the array of filters for the left side\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._filtersR = this._makeFilters(options.stages, this._lfoR, this.Q);\n\n\t\t/**\n\t\t * the frequency of the effect\n\t\t * @type {Tone.Signal}\n\t\t */\n\t\tthis.frequency = this._lfoL.frequency;\n\t\tthis.frequency.value = options.frequency;\n\n\t\t//connect them up\n\t\tthis.effectSendL.connect(this._filtersL[0]);\n\t\tthis.effectSendR.connect(this._filtersR[0]);\n\t\tthis._filtersL[options.stages - 1].connect(this.effectReturnL);\n\t\tthis._filtersR[options.stages - 1].connect(this.effectReturnR);\n\t\t//control the frequency with one LFO\n\t\tthis._lfoL.frequency.connect(this._lfoR.frequency);\n\t\t//set the options\n\t\tthis.baseFrequency = options.baseFrequency;\n\t\tthis.octaves = options.octaves;\n\t\t//start the lfo\n\t\tthis._lfoL.start();\n\t\tthis._lfoR.start();\n\t\tthis._readOnly([\"frequency\", \"Q\"]);\n\t};\n\n\tTone.extend(Tone.Phaser, Tone.StereoEffect);\n\n\t/**\n\t *  defaults\n\t *  @static\n\t *  @type {object}\n\t */\n\tTone.Phaser.defaults = {\n\t\t\"frequency\" : 0.5,\n\t\t\"octaves\" : 3,\n\t\t\"stages\" : 10,\n\t\t\"Q\" : 10,\n\t\t\"baseFrequency\" : 350,\n\t};\n\n\t/**\n\t *  @param {number} stages\n\t *  @returns {Array} the number of filters all connected together\n\t *  @private\n\t */\n\tTone.Phaser.prototype._makeFilters = function(stages, connectToFreq, Q){\n\t\tvar filters = new Array(stages);\n\t\t//make all the filters\n\t\tfor (var i = 0; i < stages; i++){\n\t\t\tvar filter = this.context.createBiquadFilter();\n\t\t\tfilter.type = \"allpass\";\n\t\t\tQ.connect(filter.Q);\n\t\t\tconnectToFreq.connect(filter.frequency);\n\t\t\tfilters[i] = filter;\n\t\t}\n\t\tTone.connectSeries.apply(Tone, filters);\n\t\treturn filters;\n\t};\n\n\t/**\n\t * The number of octaves the phase goes above\n\t * the baseFrequency\n\t * @memberOf Tone.Phaser#\n\t * @type {Positive}\n\t * @name octaves\n\t */\n\tObject.defineProperty(Tone.Phaser.prototype, \"octaves\", {\n\t\tget : function(){\n\t\t\treturn this._octaves;\n\t\t},\n\t\tset : function(octaves){\n\t\t\tthis._octaves = octaves;\n\t\t\tvar max = this._baseFrequency * Math.pow(2, octaves);\n\t\t\tthis._lfoL.max = max;\n\t\t\tthis._lfoR.max = max;\n\t\t}\n\t});\n\n\t/**\n\t * The the base frequency of the filters.\n\t * @memberOf Tone.Phaser#\n\t * @type {number}\n\t * @name baseFrequency\n\t */\n\tObject.defineProperty(Tone.Phaser.prototype, \"baseFrequency\", {\n\t\tget : function(){\n\t\t\treturn this._baseFrequency;\n\t\t},\n\t\tset : function(freq){\n\t\t\tthis._baseFrequency = freq;\n\t\t\tthis._lfoL.min = freq;\n\t\t\tthis._lfoR.min = freq;\n\t\t\tthis.octaves = this._octaves;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Phaser} this\n\t */\n\tTone.Phaser.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"Q\"]);\n\t\tthis.Q.dispose();\n\t\tthis.Q = null;\n\t\tthis._lfoL.dispose();\n\t\tthis._lfoL = null;\n\t\tthis._lfoR.dispose();\n\t\tthis._lfoR = null;\n\t\tfor (var i = 0; i < this._filtersL.length; i++){\n\t\t\tthis._filtersL[i].disconnect();\n\t\t\tthis._filtersL[i] = null;\n\t\t}\n\t\tthis._filtersL = null;\n\t\tfor (var j = 0; j < this._filtersR.length; j++){\n\t\t\tthis._filtersR[j].disconnect();\n\t\t\tthis._filtersR[j] = null;\n\t\t}\n\t\tthis._filtersR = null;\n\t\tthis.frequency = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Phaser;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Phaser.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/PingPongDelay.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/effect/PingPongDelay.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/StereoXFeedbackEffect */ \"./node_modules/tone/Tone/effect/StereoXFeedbackEffect.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.PingPongDelay is a feedback delay effect where the echo is heard\n\t *          first in one channel and next in the opposite channel. In a stereo\n\t *          system these are the right and left channels.\n\t *          PingPongDelay in more simplified terms is two Tone.FeedbackDelays\n\t *          with independent delay values. Each delay is routed to one channel\n\t *          (left or right), and the channel triggered second will always\n\t *          trigger at the same interval after the first.\n\t *\n\t * \t@constructor\n\t * \t@extends {Tone.StereoXFeedbackEffect}\n\t *  @param {Time|Object} [delayTime] The delayTime between consecutive echos.\n\t *  @param {NormalRange=} feedback The amount of the effected signal which\n\t *                                 is fed back through the delay.\n\t *  @example\n\t * var pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toMaster();\n\t * var drum = new Tone.DrumSynth().connect(pingPong);\n\t * drum.triggerAttackRelease(\"C4\", \"32n\");\n\t */\n\tTone.PingPongDelay = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"delayTime\", \"feedback\"], Tone.PingPongDelay);\n\t\tTone.StereoXFeedbackEffect.call(this, options);\n\n\t\t/**\n\t\t *  the delay node on the left side\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._leftDelay = new Tone.Delay(0, options.maxDelayTime);\n\n\t\t/**\n\t\t *  the delay node on the right side\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._rightDelay = new Tone.Delay(0, options.maxDelayTime);\n\n\t\t/**\n\t\t *  the predelay on the right side\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._rightPreDelay = new Tone.Delay(0, options.maxDelayTime);\n\n\t\t/**\n\t\t *  the delay time signal\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = new Tone.Signal(options.delayTime, Tone.Type.Time);\n\n\t\t//connect it up\n\t\tthis.effectSendL.chain(this._leftDelay, this.effectReturnL);\n\t\tthis.effectSendR.chain(this._rightPreDelay, this._rightDelay, this.effectReturnR);\n\t\tthis.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);\n\t\t//rearranged the feedback to be after the rightPreDelay\n\t\tthis._feedbackLR.disconnect();\n\t\tthis._feedbackLR.connect(this._rightDelay);\n\t\tthis._readOnly([\"delayTime\"]);\n\t};\n\n\tTone.extend(Tone.PingPongDelay, Tone.StereoXFeedbackEffect);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.PingPongDelay.defaults = {\n\t\t\"delayTime\" : 0.25,\n\t\t\"maxDelayTime\" : 1\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.PingPongDelay} this\n\t */\n\tTone.PingPongDelay.prototype.dispose = function(){\n\t\tTone.StereoXFeedbackEffect.prototype.dispose.call(this);\n\t\tthis._leftDelay.dispose();\n\t\tthis._leftDelay = null;\n\t\tthis._rightDelay.dispose();\n\t\tthis._rightDelay = null;\n\t\tthis._rightPreDelay.dispose();\n\t\tthis._rightPreDelay = null;\n\t\tthis._writable([\"delayTime\"]);\n\t\tthis.delayTime.dispose();\n\t\tthis.delayTime = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PingPongDelay;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/PingPongDelay.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/PitchShift.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/effect/PitchShift.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../effect/FeedbackEffect */ \"./node_modules/tone/Tone/effect/FeedbackEffect.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.PitchShift does near-realtime pitch shifting to the incoming signal.\n\t *         The effect is achieved by speeding up or slowing down the delayTime\n\t *         of a DelayNode using a sawtooth wave.\n\t *         Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n\t *         Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).\n\t *\n\t *  @extends {Tone.FeedbackEffect}\n\t *  @param {Interval=} pitch The interval to transpose the incoming signal by.\n\t */\n\tTone.PitchShift = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"pitch\"], Tone.PitchShift);\n\t\tTone.FeedbackEffect.call(this, options);\n\n\t\t/**\n\t\t *  The pitch signal\n\t\t *  @type  {Tone.Signal}\n\t\t *  @private\n\t\t */\n\t\tthis._frequency = new Tone.Signal(0);\n\n\t\t/**\n\t\t *  Uses two DelayNodes to cover up the jump in\n\t\t *  the sawtooth wave.\n\t\t *  @type  {DelayNode}\n\t\t *  @private\n\t\t */\n\t\tthis._delayA = new Tone.Delay(0, 1);\n\n\t\t/**\n\t\t *  The first LFO.\n\t\t *  @type  {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoA = new Tone.LFO({\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : 0.1,\n\t\t\t\"type\" : \"sawtooth\"\n\t\t}).connect(this._delayA.delayTime);\n\n\t\t/**\n\t\t *  The second DelayNode\n\t\t *  @type  {DelayNode}\n\t\t *  @private\n\t\t */\n\t\tthis._delayB = new Tone.Delay(0, 1);\n\n\t\t/**\n\t\t *  The first LFO.\n\t\t *  @type  {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoB = new Tone.LFO({\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : 0.1,\n\t\t\t\"type\" : \"sawtooth\",\n\t\t\t\"phase\" : 180\n\t\t}).connect(this._delayB.delayTime);\n\n\t\t/**\n\t\t *  Crossfade quickly between the two delay lines\n\t\t *  to cover up the jump in the sawtooth wave\n\t\t *  @type  {Tone.CrossFade}\n\t\t *  @private\n\t\t */\n\t\tthis._crossFade = new Tone.CrossFade();\n\n\t\t/**\n\t\t *  LFO which alternates between the two\n\t\t *  delay lines to cover up the disparity in the\n\t\t *  sawtooth wave.\n\t\t *  @type  {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._crossFadeLFO = new Tone.LFO({\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : 1,\n\t\t\t\"type\" : \"triangle\",\n\t\t\t\"phase\" : 90\n\t\t}).connect(this._crossFade.fade);\n\n\t\t/**\n\t\t *  The delay node\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackDelay = new Tone.Delay(options.delayTime);\n\n\t\t/**\n\t\t *  The amount of delay on the input signal\n\t\t *  @type {Time}\n\t\t *  @signal\n\t\t */\n\t\tthis.delayTime = this._feedbackDelay.delayTime;\n\t\tthis._readOnly(\"delayTime\");\n\n\t\t/**\n\t\t *  Hold the current pitch\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._pitch = options.pitch;\n\n\t\t/**\n\t\t *  Hold the current windowSize\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._windowSize = options.windowSize;\n\n\t\t//connect the two delay lines up\n\t\tthis._delayA.connect(this._crossFade.a);\n\t\tthis._delayB.connect(this._crossFade.b);\n\t\t//connect the frequency\n\t\tthis._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);\n\t\t//route the input\n\t\tthis.effectSend.fan(this._delayA, this._delayB);\n\t\tthis._crossFade.chain(this._feedbackDelay, this.effectReturn);\n\t\t//start the LFOs at the same time\n\t\tvar now = this.now();\n\t\tthis._lfoA.start(now);\n\t\tthis._lfoB.start(now);\n\t\tthis._crossFadeLFO.start(now);\n\t\t//set the initial value\n\t\tthis.windowSize = this._windowSize;\n\t};\n\n\tTone.extend(Tone.PitchShift, Tone.FeedbackEffect);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.PitchShift.defaults = {\n\t\t\"pitch\" : 0,\n\t\t\"windowSize\" : 0.1,\n\t\t\"delayTime\" : 0,\n\t\t\"feedback\" : 0\n\t};\n\n\t/**\n\t * Repitch the incoming signal by some interval (measured\n\t * in semi-tones).\n\t * @memberOf Tone.PitchShift#\n\t * @type {Interval}\n\t * @name pitch\n\t * @example\n\t * pitchShift.pitch = -12; //down one octave\n\t * pitchShift.pitch = 7; //up a fifth\n\t */\n\tObject.defineProperty(Tone.PitchShift.prototype, \"pitch\", {\n\t\tget : function(){\n\t\t\treturn this._pitch;\n\t\t},\n\t\tset : function(interval){\n\t\t\tthis._pitch = interval;\n\t\t\tvar factor = 0;\n\t\t\tif (interval < 0){\n\t\t\t\tthis._lfoA.min = 0;\n\t\t\t\tthis._lfoA.max = this._windowSize;\n\t\t\t\tthis._lfoB.min = 0;\n\t\t\t\tthis._lfoB.max = this._windowSize;\n\t\t\t\tfactor = Tone.intervalToFrequencyRatio(interval - 1) + 1;\n\t\t\t} else {\n\t\t\t\tthis._lfoA.min = this._windowSize;\n\t\t\t\tthis._lfoA.max = 0;\n\t\t\t\tthis._lfoB.min = this._windowSize;\n\t\t\t\tthis._lfoB.max = 0;\n\t\t\t\tfactor = Tone.intervalToFrequencyRatio(interval) - 1;\n\t\t\t}\n\t\t\tthis._frequency.value = factor * (1.2 / this._windowSize);\n\t\t}\n\t});\n\n\t/**\n\t * The window size corresponds roughly to the sample length in a looping sampler.\n\t * Smaller values are desirable for a less noticeable delay time of the pitch shifted\n\t * signal, but larger values will result in smoother pitch shifting for larger intervals.\n\t * A nominal range of 0.03 to 0.1 is recommended.\n\t * @memberOf Tone.PitchShift#\n\t * @type {Time}\n\t * @name windowSize\n\t * @example\n\t * pitchShift.windowSize = 0.1;\n\t */\n\tObject.defineProperty(Tone.PitchShift.prototype, \"windowSize\", {\n\t\tget : function(){\n\t\t\treturn this._windowSize;\n\t\t},\n\t\tset : function(size){\n\t\t\tthis._windowSize = this.toSeconds(size);\n\t\t\tthis.pitch = this._pitch;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.PitchShift}  this\n\t */\n\tTone.PitchShift.prototype.dispose = function(){\n\t\tTone.FeedbackEffect.prototype.dispose.call(this);\n\t\tthis._frequency.dispose();\n\t\tthis._frequency = null;\n\t\tthis._delayA.disconnect();\n\t\tthis._delayA = null;\n\t\tthis._delayB.disconnect();\n\t\tthis._delayB = null;\n\t\tthis._lfoA.dispose();\n\t\tthis._lfoA = null;\n\t\tthis._lfoB.dispose();\n\t\tthis._lfoB = null;\n\t\tthis._crossFade.dispose();\n\t\tthis._crossFade = null;\n\t\tthis._crossFadeLFO.dispose();\n\t\tthis._crossFadeLFO = null;\n\t\tthis._writable(\"delayTime\");\n\t\tthis._feedbackDelay.dispose();\n\t\tthis._feedbackDelay = null;\n\t\tthis.delayTime = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PitchShift;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/PitchShift.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Reverb.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Reverb.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Offline */ \"./node_modules/tone/Tone/core/Offline.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"),\n\t__webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/Tone/source/Noise.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../effect/Convolver */ \"./node_modules/tone/Tone/effect/Convolver.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Simple convolution created with decaying noise.\n\t *  \t\tGenerates an Impulse Response Buffer\n\t * \t\t\twith Tone.Offline then feeds the IR into ConvolverNode.\n\t * \t\t\tNote: the Reverb will not make any sound until [generate](#generate)\n\t * \t\t\thas been invoked and resolved.\n\t *\n\t * \t\t\tInspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).\n\t * \t\t\tCopyright (c) 2014 Alan deLespinasse Apache 2.0 License.\n\t *\n\t *  @extends {Tone.Convolver}\n\t *  @param {Time=} decay The amount of time it will reverberate for.\n\t */\n\tTone.Reverb = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"decay\"], Tone.Reverb);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  Convolver node\n\t\t *  @type {ConvolverNode}\n\t\t *  @private\n\t\t */\n\t\tthis._convolver = this.context.createConvolver();\n\n\t\t/**\n\t\t * The duration of the reverb\n\t\t * @type {Time}\n\t\t */\n\t\tthis.decay = options.decay;\n\n\t\t/**\n\t\t * The amount of time before the reverb is fully\n\t\t * ramped in.\n\t\t * @type {Time}\n\t\t */\n\t\tthis.preDelay = options.preDelay;\n\n\t\tthis.connectEffect(this._convolver);\n\t};\n\n\tTone.extend(Tone.Reverb, Tone.Effect);\n\n\t/**\n\t * The defaults\n\t * @type {Object}\n\t * @static\n\t */\n\tTone.Reverb.defaults = {\n\t\t\"decay\" : 1.5,\n\t\t\"preDelay\" : 0.01,\n\t};\n\n\t/**\n\t * Generate the Impulse Response. Returns a promise while the IR is being\n\t * generated.\n\t * @return {Promise<Tone.Reverb>} Promise which returns this object.\n\t */\n\tTone.Reverb.prototype.generate = function(){\n\t\treturn Tone.Offline(function(){\n\t\t\t//create a noise burst which decays over the duration\n\t\t\tvar noiseL = new Tone.Noise();\n\t\t\tvar noiseR = new Tone.Noise();\n\t\t\tvar merge = new Tone.Merge();\n\t\t\tnoiseL.connect(merge.left);\n\t\t\tnoiseR.connect(merge.right);\n\t\t\tvar gainNode = new Tone.Gain().toMaster();\n\t\t\tmerge.connect(gainNode);\n\t\t\tnoiseL.start(0);\n\t\t\tnoiseR.start(0);\n\t\t\t//short fade in\n\t\t\tgainNode.gain.setValueAtTime(0, 0);\n\t\t\tgainNode.gain.linearRampToValueAtTime(1, this.preDelay);\n\t\t\t//decay\n\t\t\tgainNode.gain.exponentialApproachValueAtTime(0, this.preDelay, this.decay - this.preDelay);\n\t\t}.bind(this), this.decay).then(function(buffer){\n\t\t\tthis._convolver.buffer = buffer.get();\n\t\t\treturn this;\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.Reverb}  this\n\t */\n\tTone.Reverb.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._convolver.disconnect();\n\t\tthis._convolver = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Reverb;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Reverb.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/StereoEffect.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/effect/StereoEffect.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"),\n\t__webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../component/CrossFade */ \"./node_modules/tone/Tone/component/CrossFade.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Base class for Stereo effects. Provides effectSendL/R and effectReturnL/R.\n\t *\n\t *\t@constructor\n\t *\t@extends {Tone.Effect}\n\t */\n\tTone.StereoEffect = function(){\n\n\t\t//get the defaults\n\t\tTone.AudioNode.call(this);\n\t\tvar options = Tone.defaults(arguments, [\"wet\"], Tone.Effect);\n\t\tthis.createInsOuts(1, 1);\n\n\t\t/**\n\t\t *  the drywet knob to control the amount of effect\n\t\t *  @type {Tone.CrossFade}\n\t\t *  @private\n\t\t */\n\t\tthis._dryWet = new Tone.CrossFade(options.wet);\n\n\t\t/**\n\t\t *  The wet control, i.e. how much of the effected\n\t\t *  will pass through to the output.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.wet = this._dryWet.fade;\n\n\t\t/**\n\t\t *  then split it\n\t\t *  @type {Tone.Split}\n\t\t *  @private\n\t\t */\n\t\tthis._split = new Tone.Split();\n\n\t\t/**\n\t\t *  the effects send LEFT\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.effectSendL = this._split.left;\n\n\t\t/**\n\t\t *  the effects send RIGHT\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.effectSendR = this._split.right;\n\n\t\t/**\n\t\t *  the stereo effect merger\n\t\t *  @type {Tone.Merge}\n\t\t *  @private\n\t\t */\n\t\tthis._merge = new Tone.Merge();\n\n\t\t/**\n\t\t *  the effect return LEFT\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.effectReturnL = this._merge.left;\n\n\t\t/**\n\t\t *  the effect return RIGHT\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis.effectReturnR = this._merge.right;\n\n\t\t//connections\n\t\tthis.input.connect(this._split);\n\t\t//dry wet connections\n\t\tthis.input.connect(this._dryWet, 0, 0);\n\t\tthis._merge.connect(this._dryWet, 0, 1);\n\t\tthis._dryWet.connect(this.output);\n\t\tthis._readOnly([\"wet\"]);\n\t};\n\n\tTone.extend(Tone.StereoEffect, Tone.Effect);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.StereoEffect} this\n\t */\n\tTone.StereoEffect.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._dryWet.dispose();\n\t\tthis._dryWet = null;\n\t\tthis._split.dispose();\n\t\tthis._split = null;\n\t\tthis._merge.dispose();\n\t\tthis._merge = null;\n\t\tthis.effectSendL = null;\n\t\tthis.effectSendR = null;\n\t\tthis.effectReturnL = null;\n\t\tthis.effectReturnR = null;\n\t\tthis._writable([\"wet\"]);\n\t\tthis.wet = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.StereoEffect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/StereoEffect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/StereoFeedbackEffect.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/Tone/effect/StereoFeedbackEffect.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\"), __webpack_require__(/*! ../effect/FeedbackEffect */ \"./node_modules/tone/Tone/effect/FeedbackEffect.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Base class for stereo feedback effects where the effectReturn\n\t *         is fed back into the same channel.\n\t *\n\t *\t@constructor\n\t *\t@extends {Tone.StereoEffect}\n\t */\n\tTone.StereoFeedbackEffect = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"feedback\"], Tone.FeedbackEffect);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  controls the amount of feedback\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.feedback = new Tone.Signal(options.feedback, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  the left side feeback\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackL = new Tone.Gain();\n\n\t\t/**\n\t\t *  the right side feeback\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackR = new Tone.Gain();\n\n\t\t//connect it up\n\t\tthis.effectReturnL.chain(this._feedbackL, this.effectSendL);\n\t\tthis.effectReturnR.chain(this._feedbackR, this.effectSendR);\n\t\tthis.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);\n\t\tthis._readOnly([\"feedback\"]);\n\t};\n\n\tTone.extend(Tone.StereoFeedbackEffect, Tone.StereoEffect);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.StereoFeedbackEffect} this\n\t */\n\tTone.StereoFeedbackEffect.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tthis._writable([\"feedback\"]);\n\t\tthis.feedback.dispose();\n\t\tthis.feedback = null;\n\t\tthis._feedbackL.dispose();\n\t\tthis._feedbackL = null;\n\t\tthis._feedbackR.dispose();\n\t\tthis._feedbackR = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.StereoFeedbackEffect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/StereoFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/StereoWidener.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/effect/StereoWidener.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/MidSideEffect */ \"./node_modules/tone/Tone/effect/MidSideEffect.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"),\n\t__webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Applies a width factor to the mid/side seperation.\n\t *         0 is all mid and 1 is all side.\n\t *         Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n\t *         <br><br>\n\t *         <code>\n\t *         Mid *= 2*(1-width)<br>\n\t *         Side *= 2*width\n\t *         </code>\n\t *\n\t *  @extends {Tone.MidSideEffect}\n\t *  @constructor\n\t *  @param {NormalRange|Object} [width] The stereo width. A width of 0 is mono and 1 is stereo. 0.5 is no change.\n\t */\n\tTone.StereoWidener = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"width\"], Tone.StereoWidener);\n\t\tTone.MidSideEffect.call(this, options);\n\n\t\t/**\n\t\t *  The width control. 0 = 100% mid. 1 = 100% side. 0.5 = no change.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.width = new Tone.Signal(options.width, Tone.Type.NormalRange);\n\t\tthis._readOnly([\"width\"]);\n\n\t\t/**\n\t\t * Two times the (1-width) for the mid channel\n\t\t * @type {Tone.Multiply}\n\t\t * @private\n\t\t */\n\t\tthis._twoTimesWidthMid = new Tone.Multiply(2);\n\n\t\t/**\n\t\t * Two times the width for the side channel\n\t\t * @type {Tone.Multiply}\n\t\t * @private\n\t\t */\n\t\tthis._twoTimesWidthSide = new Tone.Multiply(2);\n\n\t\t/**\n\t\t *  Mid multiplier\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._midMult = new Tone.Multiply();\n\t\tthis._twoTimesWidthMid.connect(this._midMult, 0, 1);\n\t\tthis.midSend.chain(this._midMult, this.midReturn);\n\n\t\t/**\n\t\t * 1 - width\n\t\t * @type {Tone.Subtract}\n\t\t * @private\n\t\t */\n\t\tthis._oneMinusWidth = new Tone.Subtract();\n\t\tthis._oneMinusWidth.connect(this._twoTimesWidthMid);\n\t\tthis.context.getConstant(1).connect(this._oneMinusWidth, 0, 0);\n\t\tthis.width.connect(this._oneMinusWidth, 0, 1);\n\n\t\t/**\n\t\t *  Side multiplier\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._sideMult = new Tone.Multiply();\n\t\tthis.width.connect(this._twoTimesWidthSide);\n\t\tthis._twoTimesWidthSide.connect(this._sideMult, 0, 1);\n\t\tthis.sideSend.chain(this._sideMult, this.sideReturn);\n\t};\n\n\tTone.extend(Tone.StereoWidener, Tone.MidSideEffect);\n\n\t/**\n\t *  the default values\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.StereoWidener.defaults = {\n\t\t\"width\" : 0.5\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.StereoWidener} this\n\t */\n\tTone.StereoWidener.prototype.dispose = function(){\n\t\tTone.MidSideEffect.prototype.dispose.call(this);\n\t\tthis._writable([\"width\"]);\n\t\tthis.width.dispose();\n\t\tthis.width = null;\n\t\tthis._midMult.dispose();\n\t\tthis._midMult = null;\n\t\tthis._sideMult.dispose();\n\t\tthis._sideMult = null;\n\t\tthis._twoTimesWidthMid.dispose();\n\t\tthis._twoTimesWidthMid = null;\n\t\tthis._twoTimesWidthSide.dispose();\n\t\tthis._twoTimesWidthSide = null;\n\t\tthis._oneMinusWidth.dispose();\n\t\tthis._oneMinusWidth = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.StereoWidener;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/StereoWidener.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/StereoXFeedbackEffect.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/Tone/effect/StereoXFeedbackEffect.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\"), __webpack_require__(/*! ../effect/FeedbackEffect */ \"./node_modules/tone/Tone/effect/FeedbackEffect.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Just like a stereo feedback effect, but the feedback is routed from left to right\n\t *         and right to left instead of on the same channel.\n\t *\n\t *\t@constructor\n\t *\t@extends {Tone.StereoEffect}\n\t */\n\tTone.StereoXFeedbackEffect = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"feedback\"], Tone.FeedbackEffect);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  The amount of feedback from the output\n\t\t *  back into the input of the effect (routed\n\t\t *  across left and right channels).\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.feedback = new Tone.Signal(options.feedback, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  the left side feeback\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackLR = new Tone.Gain();\n\n\t\t/**\n\t\t *  the right side feeback\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._feedbackRL = new Tone.Gain();\n\n\t\t//connect it up\n\t\tthis.effectReturnL.chain(this._feedbackLR, this.effectSendR);\n\t\tthis.effectReturnR.chain(this._feedbackRL, this.effectSendL);\n\t\tthis.feedback.fan(this._feedbackLR.gain, this._feedbackRL.gain);\n\t\tthis._readOnly([\"feedback\"]);\n\t};\n\n\tTone.extend(Tone.StereoXFeedbackEffect, Tone.StereoEffect);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.StereoXFeedbackEffect} this\n\t */\n\tTone.StereoXFeedbackEffect.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tthis._writable([\"feedback\"]);\n\t\tthis.feedback.dispose();\n\t\tthis.feedback = null;\n\t\tthis._feedbackLR.dispose();\n\t\tthis._feedbackLR = null;\n\t\tthis._feedbackRL.dispose();\n\t\tthis._feedbackRL = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.StereoXFeedbackEffect;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/StereoXFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Tremolo.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Tremolo.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../effect/StereoEffect */ \"./node_modules/tone/Tone/effect/StereoEffect.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Tremolo modulates the amplitude of an incoming signal using a Tone.LFO.\n\t *         The type, frequency, and depth of the LFO is controllable.\n\t *\n\t *  @extends {Tone.StereoEffect}\n\t *  @constructor\n\t *  @param {Frequency} [frequency] The rate of the effect.\n\t *  @param {NormalRange} [depth] The depth of the effect.\n\t *  @example\n\t * //create a tremolo and start it's LFO\n\t * var tremolo = new Tone.Tremolo(9, 0.75).toMaster().start();\n\t * //route an oscillator through the tremolo and start it\n\t * var oscillator = new Tone.Oscillator().connect(tremolo).start();\n\t */\n\tTone.Tremolo = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"depth\"], Tone.Tremolo);\n\t\tTone.StereoEffect.call(this, options);\n\n\t\t/**\n\t\t *  The tremelo LFO in the left channel\n\t\t *  @type  {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoL = new Tone.LFO({\n\t\t\t\"phase\" : options.spread,\n\t\t\t\"min\" : 1,\n\t\t\t\"max\" : 0,\n\t\t});\n\n\t\t/**\n\t\t *  The tremelo LFO in the left channel\n\t\t *  @type  {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfoR = new Tone.LFO({\n\t\t\t\"phase\" : options.spread,\n\t\t\t\"min\" : 1,\n\t\t\t\"max\" : 0,\n\t\t});\n\n\t\t/**\n\t\t *  Where the gain is multiplied\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._amplitudeL = new Tone.Gain();\n\n\t\t/**\n\t\t *  Where the gain is multiplied\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._amplitudeR = new Tone.Gain();\n\n\t\t/**\n\t\t *  The frequency of the tremolo.\n\t\t *  @type  {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The depth of the effect. A depth of 0, has no effect\n\t\t *  on the amplitude, and a depth of 1 makes the amplitude\n\t\t *  modulate fully between 0 and 1.\n\t\t *  @type  {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.depth = new Tone.Signal(options.depth, Tone.Type.NormalRange);\n\n\t\tthis._readOnly([\"frequency\", \"depth\"]);\n\t\tthis.effectSendL.chain(this._amplitudeL, this.effectReturnL);\n\t\tthis.effectSendR.chain(this._amplitudeR, this.effectReturnR);\n\t\tthis._lfoL.connect(this._amplitudeL.gain);\n\t\tthis._lfoR.connect(this._amplitudeR.gain);\n\t\tthis.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);\n\t\tthis.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);\n\t\tthis.type = options.type;\n\t\tthis.spread = options.spread;\n\t};\n\n\tTone.extend(Tone.Tremolo, Tone.StereoEffect);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Tremolo.defaults = {\n\t\t\"frequency\" : 10,\n\t\t\"type\" : \"sine\",\n\t\t\"depth\" : 0.5,\n\t\t\"spread\" : 180,\n\t};\n\n\t/**\n\t * Start the tremolo.\n\t * @param {Time} [time=now] When the tremolo begins.\n\t * @returns {Tone.Tremolo} this\n\t */\n\tTone.Tremolo.prototype.start = function(time){\n\t\tthis._lfoL.start(time);\n\t\tthis._lfoR.start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Stop the tremolo.\n\t * @param {Time} [time=now] When the tremolo stops.\n\t * @returns {Tone.Tremolo} this\n\t */\n\tTone.Tremolo.prototype.stop = function(time){\n\t\tthis._lfoL.stop(time);\n\t\tthis._lfoR.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the effect to the transport.\n\t * @param {Time} [delay=0] Delay time before starting the effect after the\n\t *                              Transport has started.\n\t * @returns {Tone.AutoFilter} this\n\t */\n\tTone.Tremolo.prototype.sync = function(delay){\n\t\tthis._lfoL.sync(delay);\n\t\tthis._lfoR.sync(delay);\n\t\tTone.Transport.syncSignal(this.frequency);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Unsync the filter from the transport\n\t * @returns {Tone.Tremolo} this\n\t */\n\tTone.Tremolo.prototype.unsync = function(){\n\t\tthis._lfoL.unsync();\n\t\tthis._lfoR.unsync();\n\t\tTone.Transport.unsyncSignal(this.frequency);\n\t\treturn this;\n\t};\n\n\t/**\n\t * The Tremolo's oscillator type.\n\t * @memberOf Tone.Tremolo#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.Tremolo.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._lfoL.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._lfoL.type = type;\n\t\t\tthis._lfoR.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n\t * When set to 180, LFO's will be panned hard left and right respectively.\n\t * @memberOf Tone.Tremolo#\n\t * @type {Degrees}\n\t * @name spread\n\t */\n\tObject.defineProperty(Tone.Tremolo.prototype, \"spread\", {\n\t\tget : function(){\n\t\t\treturn this._lfoR.phase - this._lfoL.phase; //180\n\t\t},\n\t\tset : function(spread){\n\t\t\tthis._lfoL.phase = 90 - (spread/2);\n\t\t\tthis._lfoR.phase = (spread/2) + 90;\n\t\t}\n\t});\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Tremolo} this\n\t */\n\tTone.Tremolo.prototype.dispose = function(){\n\t\tTone.StereoEffect.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"depth\"]);\n\t\tthis._lfoL.dispose();\n\t\tthis._lfoL = null;\n\t\tthis._lfoR.dispose();\n\t\tthis._lfoR = null;\n\t\tthis._amplitudeL.dispose();\n\t\tthis._amplitudeL = null;\n\t\tthis._amplitudeR.dispose();\n\t\tthis._amplitudeR = null;\n\t\tthis.frequency = null;\n\t\tthis.depth = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Tremolo;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Tremolo.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/effect/Vibrato.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/effect/Vibrato.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/Tone/effect/Effect.js\"), __webpack_require__(/*! ../core/Delay */ \"./node_modules/tone/Tone/core/Delay.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n\t *         modulates the delayTime of the delay, causing the pitch to rise\n\t *         and fall. \n\t *  @extends {Tone.Effect}\n\t *  @param {Frequency} frequency The frequency of the vibrato.\n\t *  @param {NormalRange} depth The amount the pitch is modulated.\n\t */\n\tTone.Vibrato = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"depth\"], Tone.Vibrato);\n\t\tTone.Effect.call(this, options);\n\n\t\t/**\n\t\t *  The delay node used for the vibrato effect\n\t\t *  @type {Tone.Delay}\n\t\t *  @private\n\t\t */\n\t\tthis._delayNode = new Tone.Delay(0, options.maxDelay);\n\n\t\t/**\n\t\t *  The LFO used to control the vibrato\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._lfo = new Tone.LFO({\n\t\t\t\"type\" : options.type,\n\t\t\t\"min\" : 0,\n\t\t\t\"max\" : options.maxDelay, \n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"phase\" : -90 //offse the phase so the resting position is in the center\n\t\t}).start().connect(this._delayNode.delayTime);\n\n\t\t/**\n\t\t *  The frequency of the vibrato\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._lfo.frequency;\n\n\t\t/**\n\t\t *  The depth of the vibrato. \n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.depth = this._lfo.amplitude;\n\n\t\tthis.depth.value = options.depth;\n\t\tthis._readOnly([\"frequency\", \"depth\"]);\n\t\tthis.effectSend.chain(this._delayNode, this.effectReturn);\n\t};\n\n\tTone.extend(Tone.Vibrato, Tone.Effect);\n\n\t/**\n\t *  The defaults\n\t *  @type  {Object}\n\t *  @const\n\t */\n\tTone.Vibrato.defaults = {\n\t\t\"maxDelay\" : 0.005,\n\t\t\"frequency\" : 5,\n\t\t\"depth\" : 0.1,\n\t\t\"type\" : \"sine\"\n\t};\n\n\t/**\n\t * Type of oscillator attached to the Vibrato.\n\t * @memberOf Tone.Vibrato#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.Vibrato.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._lfo.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._lfo.type = type;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Vibrato} this\n\t */\n\tTone.Vibrato.prototype.dispose = function(){\n\t\tTone.Effect.prototype.dispose.call(this);\n\t\tthis._delayNode.dispose();\n\t\tthis._delayNode = null;\n\t\tthis._lfo.dispose();\n\t\tthis._lfo = null;\n\t\tthis._writable([\"frequency\", \"depth\"]);\n\t\tthis.frequency = null;\n\t\tthis.depth = null;\n\t};\n\n\treturn Tone.Vibrato;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/effect/Vibrato.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/event/Event.js":
/*!***********************************************!*\
  !*** ./node_modules/tone/Tone/event/Event.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/TimelineState */ \"./node_modules/tone/Tone/core/TimelineState.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Event abstracts away Tone.Transport.schedule and provides a schedulable\n\t *          callback for a single or repeatable events along the timeline.\n\t *\n\t *  @extends {Tone}\n\t *  @param {function} callback The callback to invoke at the time.\n\t *  @param {*} value The value or values which should be passed to\n\t *                      the callback function on invocation.\n\t *  @example\n\t * var chord = new Tone.Event(function(time, chord){\n\t * \t//the chord as well as the exact time of the event\n\t * \t//are passed in as arguments to the callback function\n\t * }, [\"D4\", \"E4\", \"F4\"]);\n\t * //start the chord at the beginning of the transport timeline\n\t * chord.start();\n\t * //loop it every measure for 8 measures\n\t * chord.loop = 8;\n\t * chord.loopEnd = \"1m\";\n\t */\n\tTone.Event = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"value\"], Tone.Event);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  Loop value\n\t\t *  @type  {Boolean|Positive}\n\t\t *  @private\n\t\t */\n\t\tthis._loop = options.loop;\n\n\t\t/**\n\t\t *  The callback to invoke.\n\t\t *  @type  {Function}\n\t\t */\n\t\tthis.callback = options.callback;\n\n\t\t/**\n\t\t *  The value which is passed to the\n\t\t *  callback function.\n\t\t *  @type  {*}\n\t\t *  @private\n\t\t */\n\t\tthis.value = options.value;\n\n\t\t/**\n\t\t *  When the note is scheduled to start.\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._loopStart = this.toTicks(options.loopStart);\n\n\t\t/**\n\t\t *  When the note is scheduled to start.\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._loopEnd = this.toTicks(options.loopEnd);\n\n\t\t/**\n\t\t *  Tracks the scheduled events\n\t\t *  @type {Tone.TimelineState}\n\t\t *  @private\n\t\t */\n\t\tthis._state = new Tone.TimelineState(Tone.State.Stopped);\n\n\t\t/**\n\t\t *  The playback speed of the note. A speed of 1\n\t\t *  is no change.\n\t\t *  @private\n\t\t *  @type {Positive}\n\t\t */\n\t\tthis._playbackRate = 1;\n\n\t\t/**\n\t\t *  A delay time from when the event is scheduled to start\n\t\t *  @type {Ticks}\n\t\t *  @private\n\t\t */\n\t\tthis._startOffset = 0;\n\n\t\t/**\n\t\t *  private holder of probability value\n\t\t *  @type {NormalRange}\n\t\t *  @private\n\t\t */\n\t\tthis._probability = options.probability;\n\n\t\t/**\n\t\t *  the amount of variation from the\n\t\t *  given time.\n\t\t *  @type {Boolean|Time}\n\t\t *  @private\n\t\t */\n\t\tthis._humanize = options.humanize;\n\n\t\t/**\n\t\t *  If mute is true, the callback won't be\n\t\t *  invoked.\n\t\t *  @type {Boolean}\n\t\t */\n\t\tthis.mute = options.mute;\n\n\t\t//set the initial values\n\t\tthis.playbackRate = options.playbackRate;\n\t};\n\n\tTone.extend(Tone.Event);\n\n\t/**\n\t *  The default values\n\t *  @type  {Object}\n\t *  @const\n\t */\n\tTone.Event.defaults = {\n\t\t\"callback\" : Tone.noOp,\n\t\t\"loop\" : false,\n\t\t\"loopEnd\" : \"1m\",\n\t\t\"loopStart\" : 0,\n\t\t\"playbackRate\" : 1,\n\t\t\"value\" : null,\n\t\t\"probability\" : 1,\n\t\t\"mute\" : false,\n\t\t\"humanize\" : false,\n\t};\n\n\t/**\n\t *  Reschedule all of the events along the timeline\n\t *  with the updated values.\n\t *  @param {Time} after Only reschedules events after the given time.\n\t *  @return  {Tone.Event}  this\n\t *  @private\n\t */\n\tTone.Event.prototype._rescheduleEvents = function(after){\n\t\t//if no argument is given, schedules all of the events\n\t\tafter = Tone.defaultArg(after, -1);\n\t\tthis._state.forEachFrom(after, function(event){\n\t\t\tvar duration;\n\t\t\tif (event.state === Tone.State.Started){\n\t\t\t\tif (Tone.isDefined(event.id)){\n\t\t\t\t\tTone.Transport.clear(event.id);\n\t\t\t\t}\n\t\t\t\tvar startTick = event.time + Math.round(this.startOffset / this._playbackRate);\n\t\t\t\tif (this._loop){\n\t\t\t\t\tduration = Infinity;\n\t\t\t\t\tif (Tone.isNumber(this._loop)){\n\t\t\t\t\t\tduration = (this._loop) * this._getLoopDuration();\n\t\t\t\t\t}\n\t\t\t\t\tvar nextEvent = this._state.getAfter(startTick);\n\t\t\t\t\tif (nextEvent !== null){\n\t\t\t\t\t\tduration = Math.min(duration, nextEvent.time - startTick);\n\t\t\t\t\t}\n\t\t\t\t\tif (duration !== Infinity){\n\t\t\t\t\t\t//schedule a stop since it's finite duration\n\t\t\t\t\t\tthis._state.setStateAtTime(Tone.State.Stopped, startTick + duration + 1);\n\t\t\t\t\t\tduration = Tone.Ticks(duration);\n\t\t\t\t\t}\n\t\t\t\t\tvar interval = Tone.Ticks(this._getLoopDuration());\n\t\t\t\t\tevent.id = Tone.Transport.scheduleRepeat(this._tick.bind(this), interval, Tone.Ticks(startTick), duration);\n\t\t\t\t} else {\n\t\t\t\t\tevent.id = Tone.Transport.schedule(this._tick.bind(this), Tone.Ticks(startTick));\n\t\t\t\t}\n\t\t\t}\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Returns the playback state of the note, either \"started\" or \"stopped\".\n\t *  @type {String}\n\t *  @readOnly\n\t *  @memberOf Tone.Event#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._state.getValueAtTime(Tone.Transport.ticks);\n\t\t}\n\t});\n\n\t/**\n\t *  The start from the scheduled start time\n\t *  @type {Ticks}\n\t *  @memberOf Tone.Event#\n\t *  @name startOffset\n\t *  @private\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"startOffset\", {\n\t\tget : function(){\n\t\t\treturn this._startOffset;\n\t\t},\n\t\tset : function(offset){\n\t\t\tthis._startOffset = offset;\n\t\t}\n\t});\n\n\t/**\n\t *  The probability of the notes being triggered.\n\t *  @memberOf Tone.Event#\n\t *  @type {NormalRange}\n\t *  @name probability\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"probability\", {\n\t\tget : function(){\n\t\t\treturn this._probability;\n\t\t},\n\t\tset : function(prob){\n\t\t\tthis._probability = prob;\n\t\t}\n\t});\n\n\t/**\n\t *  If set to true, will apply small random variation\n\t *  to the callback time. If the value is given as a time, it will randomize\n\t *  by that amount.\n\t *  @example\n\t * event.humanize = true;\n\t *  @type {Boolean|Time}\n\t *  @name humanize\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"humanize\", {\n\t\tget : function(){\n\t\t\treturn this._humanize;\n\t\t},\n\t\tset : function(variation){\n\t\t\tthis._humanize = variation;\n\t\t}\n\t});\n\n\t/**\n\t *  Start the note at the given time.\n\t *  @param  {TimelinePosition}  time  When the note should start.\n\t *  @return  {Tone.Event}  this\n\t */\n\tTone.Event.prototype.start = function(time){\n\t\ttime = this.toTicks(time);\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Stopped){\n\t\t\tthis._state.add({\n\t\t\t\t\"state\" : Tone.State.Started,\n\t\t\t\t\"time\" : time,\n\t\t\t\t\"id\" : undefined,\n\t\t\t});\n\t\t\tthis._rescheduleEvents(time);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the Event at the given time.\n\t *  @param  {TimelinePosition}  time  When the note should stop.\n\t *  @return  {Tone.Event}  this\n\t */\n\tTone.Event.prototype.stop = function(time){\n\t\tthis.cancel(time);\n\t\ttime = this.toTicks(time);\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Started){\n\t\t\tthis._state.setStateAtTime(Tone.State.Stopped, time);\n\t\t\tvar previousEvent = this._state.getBefore(time);\n\t\t\tvar reschedulTime = time;\n\t\t\tif (previousEvent !== null){\n\t\t\t\treschedulTime = previousEvent.time;\n\t\t\t}\n\t\t\tthis._rescheduleEvents(reschedulTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel all scheduled events greater than or equal to the given time\n\t *  @param  {TimelinePosition}  [time=0]  The time after which events will be cancel.\n\t *  @return  {Tone.Event}  this\n\t */\n\tTone.Event.prototype.cancel = function(time){\n\t\ttime = Tone.defaultArg(time, -Infinity);\n\t\ttime = this.toTicks(time);\n\t\tthis._state.forEachFrom(time, function(event){\n\t\t\tTone.Transport.clear(event.id);\n\t\t});\n\t\tthis._state.cancel(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The callback function invoker. Also\n\t *  checks if the Event is done playing\n\t *  @param  {Number}  time  The time of the event in seconds\n\t *  @private\n\t */\n\tTone.Event.prototype._tick = function(time){\n\t\tvar ticks = Tone.Transport.getTicksAtTime(time);\n\t\tif (!this.mute && this._state.getValueAtTime(ticks) === Tone.State.Started){\n\t\t\tif (this.probability < 1 && Math.random() > this.probability){\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (this.humanize){\n\t\t\t\tvar variation = 0.02;\n\t\t\t\tif (!Tone.isBoolean(this.humanize)){\n\t\t\t\t\tvariation = this.toSeconds(this.humanize);\n\t\t\t\t}\n\t\t\t\ttime += (Math.random() * 2 - 1) * variation;\n\t\t\t}\n\t\t\tthis.callback(time, this.value);\n\t\t}\n\t};\n\n\t/**\n\t *  Get the duration of the loop.\n\t *  @return  {Ticks}\n\t *  @private\n\t */\n\tTone.Event.prototype._getLoopDuration = function(){\n\t\treturn Math.round((this._loopEnd - this._loopStart) / this._playbackRate);\n\t};\n\n\t/**\n\t *  If the note should loop or not\n\t *  between Tone.Event.loopStart and\n\t *  Tone.Event.loopEnd. An integer\n\t *  value corresponds to the number of\n\t *  loops the Event does after it starts.\n\t *  @memberOf Tone.Event#\n\t *  @type {Boolean|Positive}\n\t *  @name loop\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"loop\", {\n\t\tget : function(){\n\t\t\treturn this._loop;\n\t\t},\n\t\tset : function(loop){\n\t\t\tthis._loop = loop;\n\t\t\tthis._rescheduleEvents();\n\t\t}\n\t});\n\n\t/**\n\t * \tThe playback rate of the note. Defaults to 1.\n\t *  @memberOf Tone.Event#\n\t *  @type {Positive}\n\t *  @name playbackRate\n\t *  @example\n\t * note.loop = true;\n\t * //repeat the note twice as fast\n\t * note.playbackRate = 2;\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._playbackRate = rate;\n\t\t\tthis._rescheduleEvents();\n\t\t}\n\t});\n\n\t/**\n\t *  The loopEnd point is the time the event will loop\n\t *  if Tone.Event.loop is true.\n\t *  @memberOf Tone.Event#\n\t *  @type {Time}\n\t *  @name loopEnd\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopEnd).toSeconds();\n\t\t},\n\t\tset : function(loopEnd){\n\t\t\tthis._loopEnd = this.toTicks(loopEnd);\n\t\t\tif (this._loop){\n\t\t\t\tthis._rescheduleEvents();\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The time when the loop should start.\n\t *  @memberOf Tone.Event#\n\t *  @type {Time}\n\t *  @name loopStart\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopStart).toSeconds();\n\t\t},\n\t\tset : function(loopStart){\n\t\t\tthis._loopStart = this.toTicks(loopStart);\n\t\t\tif (this._loop){\n\t\t\t\tthis._rescheduleEvents();\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The current progress of the loop interval.\n\t *  Returns 0 if the event is not started yet or\n\t *  it is not set to loop.\n\t *  @memberOf Tone.Event#\n\t *  @type {NormalRange}\n\t *  @name progress\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Event.prototype, \"progress\", {\n\t\tget : function(){\n\t\t\tif (this._loop){\n\t\t\t\tvar ticks = Tone.Transport.ticks;\n\t\t\t\tvar lastEvent = this._state.get(ticks);\n\t\t\t\tif (lastEvent !== null && lastEvent.state === Tone.State.Started){\n\t\t\t\t\tvar loopDuration = this._getLoopDuration();\n\t\t\t\t\tvar progress = (ticks - lastEvent.time) % loopDuration;\n\t\t\t\t\treturn progress / loopDuration;\n\t\t\t\t} else {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Event}  this\n\t */\n\tTone.Event.prototype.dispose = function(){\n\t\tthis.cancel();\n\t\tthis._state.dispose();\n\t\tthis._state = null;\n\t\tthis.callback = null;\n\t\tthis.value = null;\n\t};\n\n\treturn Tone.Event;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/event/Event.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/event/Loop.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/event/Loop.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../event/Event */ \"./node_modules/tone/Tone/event/Event.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Loop creates a looped callback at the \n\t *         specified interval. The callback can be \n\t *         started, stopped and scheduled along\n\t *         the Transport's timeline. \n\t *  @example\n\t * var loop = new Tone.Loop(function(time){\n\t * \t//triggered every eighth note. \n\t * \tconsole.log(time);\n\t * }, \"8n\").start(0);\n\t * Tone.Transport.start();\n\t *  @extends {Tone}\n\t *  @param {Function} callback The callback to invoke with the event.\n\t *  @param {Time} interval The time between successive callback calls. \n\t */\n\tTone.Loop = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"interval\"], Tone.Loop);\n\t\tTone.call(this);\n\n\t\t/**\n\t\t *  The event which produces the callbacks\n\t\t */\n\t\tthis._event = new Tone.Event({\n\t\t\t\"callback\" : this._tick.bind(this),\n\t\t\t\"loop\" : true,\n\t\t\t\"loopEnd\" : options.interval,\n\t\t\t\"playbackRate\" : options.playbackRate,\n\t\t\t\"probability\" : options.probability\n\t\t});\n\n\t\t/**\n\t\t *  The callback to invoke with the next event in the pattern\n\t\t *  @type {Function}\n\t\t */\n\t\tthis.callback = options.callback;\n\n\t\t//set the iterations\n\t\tthis.iterations = options.iterations;\n\t};\n\n\tTone.extend(Tone.Loop);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Loop.defaults = {\n\t\t\"interval\" : \"4n\",\n\t\t\"callback\" : Tone.noOp,\n\t\t\"playbackRate\" : 1,\n\t\t\"iterations\" : Infinity,\n\t\t\"probability\" : true,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t *  Start the loop at the specified time along the Transport's\n\t *  timeline.\n\t *  @param  {TimelinePosition=}  time  When to start the Loop.\n\t *  @return  {Tone.Loop}  this\n\t */\n\tTone.Loop.prototype.start = function(time){\n\t\tthis._event.start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the loop at the given time.\n\t *  @param  {TimelinePosition=}  time  When to stop the Loop.\n\t *  @return  {Tone.Loop}  this\n\t */\n\tTone.Loop.prototype.stop = function(time){\n\t\tthis._event.stop(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel all scheduled events greater than or equal to the given time\n\t *  @param  {TimelinePosition}  [time=0]  The time after which events will be cancel.\n\t *  @return  {Tone.Loop}  this\n\t */\n\tTone.Loop.prototype.cancel = function(time){\n\t\tthis._event.cancel(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Internal function called when the notes should be called\n\t *  @param  {Number}  time  The time the event occurs\n\t *  @private\n\t */\n\tTone.Loop.prototype._tick = function(time){\n\t\tthis.callback(time);\n\t};\n\n\t/**\n\t *  The state of the Loop, either started or stopped.\n\t *  @memberOf Tone.Loop#\n\t *  @type {String}\n\t *  @name state\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._event.state;\n\t\t}\n\t});\n\n\t/**\n\t *  The progress of the loop as a value between 0-1. 0, when\n\t *  the loop is stopped or done iterating. \n\t *  @memberOf Tone.Loop#\n\t *  @type {NormalRange}\n\t *  @name progress\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"progress\", {\n\t\tget : function(){\n\t\t\treturn this._event.progress;\n\t\t}\n\t});\n\n\t/**\n\t *  The time between successive callbacks. \n\t *  @example\n\t * loop.interval = \"8n\"; //loop every 8n\n\t *  @memberOf Tone.Loop#\n\t *  @type {Time}\n\t *  @name interval\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"interval\", {\n\t\tget : function(){\n\t\t\treturn this._event.loopEnd;\n\t\t},\n\t\tset : function(interval){\n\t\t\tthis._event.loopEnd = interval;\n\t\t}\n\t});\n\n\t/**\n\t *  The playback rate of the loop. The normal playback rate is 1 (no change). \n\t *  A `playbackRate` of 2 would be twice as fast. \n\t *  @memberOf Tone.Loop#\n\t *  @type {Time}\n\t *  @name playbackRate\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._event.playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._event.playbackRate = rate;\n\t\t}\n\t});\n\n\t/**\n\t *  Random variation +/-0.01s to the scheduled time. \n\t *  Or give it a time value which it will randomize by.\n\t *  @type {Boolean|Time}\n\t *  @memberOf Tone.Loop#\n\t *  @name humanize\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"humanize\", {\n\t\tget : function(){\n\t\t\treturn this._event.humanize;\n\t\t},\n\t\tset : function(variation){\n\t\t\tthis._event.humanize = variation;\n\t\t}\n\t});\n\n\t/**\n\t *  The probably of the callback being invoked.\n\t *  @memberOf Tone.Loop#\n\t *  @type {NormalRange}\n\t *  @name probability\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"probability\", {\n\t\tget : function(){\n\t\t\treturn this._event.probability;\n\t\t},\n\t\tset : function(prob){\n\t\t\tthis._event.probability = prob;\n\t\t}\n\t});\n\n\t/**\n\t *  Muting the Loop means that no callbacks are invoked.\n\t *  @memberOf Tone.Loop#\n\t *  @type {Boolean}\n\t *  @name mute\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._event.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._event.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t *  The number of iterations of the loop. The default\n\t *  value is Infinity (loop forever).\n\t *  @memberOf Tone.Loop#\n\t *  @type {Positive}\n\t *  @name iterations\n\t */\n\tObject.defineProperty(Tone.Loop.prototype, \"iterations\", {\n\t\tget : function(){\n\t\t\tif (this._event.loop === true){\n\t\t\t\treturn Infinity;\n\t\t\t} else {\n\t\t\t\treturn this._event.loop;\n\t\t\t}\n\t\t},\n\t\tset : function(iters){\n\t\t\tif (iters === Infinity){\n\t\t\t\tthis._event.loop = true;\n\t\t\t} else {\n\t\t\t\tthis._event.loop = iters;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Loop}  this\n\t */\n\tTone.Loop.prototype.dispose = function(){\n\t\tthis._event.dispose();\n\t\tthis._event = null;\n\t\tthis.callback = null;\n\t};\n\n\treturn Tone.Loop;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/event/Loop.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/event/Part.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/event/Part.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../event/Event */ \"./node_modules/tone/Tone/event/Event.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Part is a collection Tone.Events which can be\n\t *         started/stopped and looped as a single unit.\n\t *\n\t *  @extends {Tone.Event}\n\t *  @param {Function} callback The callback to invoke on each event\n\t *  @param {Array} events the array of events\n\t *  @example\n\t * var part = new Tone.Part(function(time, note){\n\t * \t//the notes given as the second element in the array\n\t * \t//will be passed in as the second argument\n\t * \tsynth.triggerAttackRelease(note, \"8n\", time);\n\t * }, [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]);\n\t *  @example\n\t * //use an array of objects as long as the object has a \"time\" attribute\n\t * var part = new Tone.Part(function(time, value){\n\t * \t//the value is an object which contains both the note and the velocity\n\t * \tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n\t * }, [{\"time\" : 0, \"note\" : \"C3\", \"velocity\": 0.9},\n\t * \t   {\"time\" : \"0:2\", \"note\" : \"C4\", \"velocity\": 0.5}\n\t * ]).start(0);\n\t */\n\tTone.Part = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"events\"], Tone.Part);\n\t\tTone.Event.call(this, options);\n\n\t\t/**\n\t\t *  An array of Objects.\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._events = [];\n\n\t\t//add the events\n\t\tfor (var i = 0; i < options.events.length; i++){\n\t\t\tif (Array.isArray(options.events[i])){\n\t\t\t\tthis.add(options.events[i][0], options.events[i][1]);\n\t\t\t} else {\n\t\t\t\tthis.add(options.events[i]);\n\t\t\t}\n\t\t}\n\t};\n\n\tTone.extend(Tone.Part, Tone.Event);\n\n\t/**\n\t *  The default values\n\t *  @type  {Object}\n\t *  @const\n\t */\n\tTone.Part.defaults = {\n\t\t\"callback\" : Tone.noOp,\n\t\t\"loop\" : false,\n\t\t\"loopEnd\" : \"1m\",\n\t\t\"loopStart\" : 0,\n\t\t\"playbackRate\" : 1,\n\t\t\"probability\" : 1,\n\t\t\"humanize\" : false,\n\t\t\"mute\" : false,\n\t\t\"events\" : []\n\t};\n\n\t/**\n\t *  Start the part at the given time.\n\t *  @param  {TransportTime}  time    When to start the part.\n\t *  @param  {Time=}  offset  The offset from the start of the part\n\t *                           to begin playing at.\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.start = function(time, offset){\n\t\tvar ticks = this.toTicks(time);\n\t\tif (this._state.getValueAtTime(ticks) !== Tone.State.Started){\n\t\t\tif (this._loop){\n\t\t\t\toffset = Tone.defaultArg(offset, this._loopStart);\n\t\t\t} else {\n\t\t\t\toffset = Tone.defaultArg(offset, 0);\n\t\t\t}\n\t\t\toffset = this.toTicks(offset);\n\t\t\tthis._state.add({\n\t\t\t\t\"state\" : Tone.State.Started,\n\t\t\t\t\"time\" : ticks,\n\t\t\t\t\"offset\" : offset\n\t\t\t});\n\t\t\tthis._forEach(function(event){\n\t\t\t\tthis._startNote(event, ticks, offset);\n\t\t\t});\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Start the event in the given event at the correct time given\n\t *  the ticks and offset and looping.\n\t *  @param  {Tone.Event}  event\n\t *  @param  {Ticks}  ticks\n\t *  @param  {Ticks}  offset\n\t *  @private\n\t */\n\tTone.Part.prototype._startNote = function(event, ticks, offset){\n\t\tticks -= offset;\n\t\tif (this._loop){\n\t\t\tif (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd){\n\t\t\t\tif (event.startOffset < offset){\n\t\t\t\t\t//start it on the next loop\n\t\t\t\t\tticks += this._getLoopDuration();\n\t\t\t\t}\n\t\t\t\tevent.start(Tone.Ticks(ticks));\n\t\t\t} else if (event.startOffset < this._loopStart && event.startOffset >= offset){\n\t\t\t\tevent.loop = false;\n\t\t\t\tevent.start(Tone.Ticks(ticks));\n\t\t\t}\n\t\t} else if (event.startOffset >= offset){\n\t\t\tevent.start(Tone.Ticks(ticks));\n\t\t}\n\t};\n\n\t/**\n\t *  The start from the scheduled start time\n\t *  @type {Ticks}\n\t *  @memberOf Tone.Part#\n\t *  @name startOffset\n\t *  @private\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"startOffset\", {\n\t\tget : function(){\n\t\t\treturn this._startOffset;\n\t\t},\n\t\tset : function(offset){\n\t\t\tthis._startOffset = offset;\n\t\t\tthis._forEach(function(event){\n\t\t\t\tevent.startOffset += this._startOffset;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t *  Stop the part at the given time.\n\t *  @param  {TimelinePosition}  time  When to stop the part.\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.stop = function(time){\n\t\tvar ticks = this.toTicks(time);\n\t\tthis._state.cancel(ticks);\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, ticks);\n\t\tthis._forEach(function(event){\n\t\t\tevent.stop(time);\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get/Set an Event's value at the given time.\n\t *  If a value is passed in and no event exists at\n\t *  the given time, one will be created with that value.\n\t *  If two events are at the same time, the first one will\n\t *  be returned.\n\t *  @example\n\t * part.at(\"1m\"); //returns the part at the first measure\n\t *\n\t * part.at(\"2m\", \"C2\"); //set the value at \"2m\" to C2.\n\t * //if an event didn't exist at that time, it will be created.\n\t *  @param {TransportTime} time The time of the event to get or set.\n\t *  @param {*=} value If a value is passed in, the value of the\n\t *                    event at the given time will be set to it.\n\t *  @return {Tone.Event} the event at the time\n\t */\n\tTone.Part.prototype.at = function(time, value){\n\t\ttime = Tone.TransportTime(time);\n\t\tvar tickTime = Tone.Ticks(1).toSeconds();\n\t\tfor (var i = 0; i < this._events.length; i++){\n\t\t\tvar event = this._events[i];\n\t\t\tif (Math.abs(time.toTicks() - event.startOffset) < tickTime){\n\t\t\t\tif (Tone.isDefined(value)){\n\t\t\t\t\tevent.value = value;\n\t\t\t\t}\n\t\t\t\treturn event;\n\t\t\t}\n\t\t}\n\t\t//if there was no event at that time, create one\n\t\tif (Tone.isDefined(value)){\n\t\t\tthis.add(time, value);\n\t\t\t//return the new event\n\t\t\treturn this._events[this._events.length - 1];\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t};\n\n\t/**\n\t *  Add a an event to the part.\n\t *  @param {Time} time The time the note should start.\n\t *                            If an object is passed in, it should\n\t *                            have a 'time' attribute and the rest\n\t *                            of the object will be used as the 'value'.\n\t *  @param  {Tone.Event|*}  value\n\t *  @returns {Tone.Part} this\n\t *  @example\n\t * part.add(\"1m\", \"C#+11\");\n\t */\n\tTone.Part.prototype.add = function(time, value){\n\t\t//extract the parameters\n\t\tif (time.hasOwnProperty(\"time\")){\n\t\t\tvalue = time;\n\t\t\ttime = value.time;\n\t\t}\n\t\ttime = this.toTicks(time);\n\t\tvar event;\n\t\tif (value instanceof Tone.Event){\n\t\t\tevent = value;\n\t\t\tevent.callback = this._tick.bind(this);\n\t\t} else {\n\t\t\tevent = new Tone.Event({\n\t\t\t\t\"callback\" : this._tick.bind(this),\n\t\t\t\t\"value\" : value,\n\t\t\t});\n\t\t}\n\t\t//the start offset\n\t\tevent.startOffset = time;\n\n\t\t//initialize the values\n\t\tevent.set({\n\t\t\t\"loopEnd\" : this.loopEnd,\n\t\t\t\"loopStart\" : this.loopStart,\n\t\t\t\"loop\" : this.loop,\n\t\t\t\"humanize\" : this.humanize,\n\t\t\t\"playbackRate\" : this.playbackRate,\n\t\t\t\"probability\" : this.probability\n\t\t});\n\n\t\tthis._events.push(event);\n\n\t\t//start the note if it should be played right now\n\t\tthis._restartEvent(event);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Restart the given event\n\t *  @param  {Tone.Event}  event\n\t *  @private\n\t */\n\tTone.Part.prototype._restartEvent = function(event){\n\t\tthis._state.forEach(function(stateEvent){\n\t\t\tif (stateEvent.state === Tone.State.Started){\n\t\t\t\tthis._startNote(event, stateEvent.time, stateEvent.offset);\n\t\t\t} else {\n\t\t\t\t//stop the note\n\t\t\t\tevent.stop(Tone.Ticks(stateEvent.time));\n\t\t\t}\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Remove an event from the part. If the event at that time is a Tone.Part,\n\t *  it will remove the entire part.\n\t *  @param {Time} time The time of the event\n\t *  @param {*} value Optionally select only a specific event value\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.remove = function(time, value){\n\t\t//extract the parameters\n\t\tif (time.hasOwnProperty(\"time\")){\n\t\t\tvalue = time;\n\t\t\ttime = value.time;\n\t\t}\n\t\ttime = this.toTicks(time);\n\t\tfor (var i = this._events.length - 1; i >= 0; i--){\n\t\t\tvar event = this._events[i];\n\t\t\tif (event.startOffset === time){\n\t\t\t\tif (Tone.isUndef(value) || (Tone.isDefined(value) && event.value === value)){\n\t\t\t\t\tthis._events.splice(i, 1);\n\t\t\t\t\tevent.dispose();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Remove all of the notes from the group.\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.removeAll = function(){\n\t\tthis._forEach(function(event){\n\t\t\tevent.dispose();\n\t\t});\n\t\tthis._events = [];\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel scheduled state change events: i.e. \"start\" and \"stop\".\n\t *  @param {TimelinePosition} after The time after which to cancel the scheduled events.\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.cancel = function(after){\n\t\tthis._forEach(function(event){\n\t\t\tevent.cancel(after);\n\t\t});\n\t\tthis._state.cancel(this.toTicks(after));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Iterate over all of the events\n\t *  @param {Function} callback\n\t *  @param {Object} ctx The context\n\t *  @private\n\t */\n\tTone.Part.prototype._forEach = function(callback, ctx){\n\t\tif (this._events){\n\t\t\tctx = Tone.defaultArg(ctx, this);\n\t\t\tfor (var i = this._events.length - 1; i >= 0; i--){\n\t\t\t\tvar e = this._events[i];\n\t\t\t\tif (e instanceof Tone.Part){\n\t\t\t\t\te._forEach(callback, ctx);\n\t\t\t\t} else {\n\t\t\t\t\tcallback.call(ctx, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Set the attribute of all of the events\n\t *  @param  {String}  attr  the attribute to set\n\t *  @param  {*}  value      The value to set it to\n\t *  @private\n\t */\n\tTone.Part.prototype._setAll = function(attr, value){\n\t\tthis._forEach(function(event){\n\t\t\tevent[attr] = value;\n\t\t});\n\t};\n\n\t/**\n\t *  Internal tick method\n\t *  @param  {Number}  time  The time of the event in seconds\n\t *  @private\n\t */\n\tTone.Part.prototype._tick = function(time, value){\n\t\tif (!this.mute){\n\t\t\tthis.callback(time, value);\n\t\t}\n\t};\n\n\t/**\n\t *  Determine if the event should be currently looping\n\t *  given the loop boundries of this Part.\n\t *  @param  {Tone.Event}  event  The event to test\n\t *  @private\n\t */\n\tTone.Part.prototype._testLoopBoundries = function(event){\n\t\tif (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd){\n\t\t\tevent.cancel(0);\n\t\t} else if (event.state === Tone.State.Stopped){\n\t\t\t//reschedule it if it's stopped\n\t\t\tthis._restartEvent(event);\n\t\t}\n\t};\n\n\t/**\n\t *  The probability of the notes being triggered.\n\t *  @memberOf Tone.Part#\n\t *  @type {NormalRange}\n\t *  @name probability\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"probability\", {\n\t\tget : function(){\n\t\t\treturn this._probability;\n\t\t},\n\t\tset : function(prob){\n\t\t\tthis._probability = prob;\n\t\t\tthis._setAll(\"probability\", prob);\n\t\t}\n\t});\n\n\t/**\n\t *  If set to true, will apply small random variation\n\t *  to the callback time. If the value is given as a time, it will randomize\n\t *  by that amount.\n\t *  @example\n\t * event.humanize = true;\n\t *  @type {Boolean|Time}\n\t *  @name humanize\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"humanize\", {\n\t\tget : function(){\n\t\t\treturn this._humanize;\n\t\t},\n\t\tset : function(variation){\n\t\t\tthis._humanize = variation;\n\t\t\tthis._setAll(\"humanize\", variation);\n\t\t}\n\t});\n\n\t/**\n\t *  If the part should loop or not\n\t *  between Tone.Part.loopStart and\n\t *  Tone.Part.loopEnd. An integer\n\t *  value corresponds to the number of\n\t *  loops the Part does after it starts.\n\t *  @memberOf Tone.Part#\n\t *  @type {Boolean|Positive}\n\t *  @name loop\n\t *  @example\n\t * //loop the part 8 times\n\t * part.loop = 8;\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"loop\", {\n\t\tget : function(){\n\t\t\treturn this._loop;\n\t\t},\n\t\tset : function(loop){\n\t\t\tthis._loop = loop;\n\t\t\tthis._forEach(function(event){\n\t\t\t\tevent._loopStart = this._loopStart;\n\t\t\t\tevent._loopEnd = this._loopEnd;\n\t\t\t\tevent.loop = loop;\n\t\t\t\tthis._testLoopBoundries(event);\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t *  The loopEnd point determines when it will\n\t *  loop if Tone.Part.loop is true.\n\t *  @memberOf Tone.Part#\n\t *  @type {Time}\n\t *  @name loopEnd\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopEnd).toSeconds();\n\t\t},\n\t\tset : function(loopEnd){\n\t\t\tthis._loopEnd = this.toTicks(loopEnd);\n\t\t\tif (this._loop){\n\t\t\t\tthis._forEach(function(event){\n\t\t\t\t\tevent.loopEnd = loopEnd;\n\t\t\t\t\tthis._testLoopBoundries(event);\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The loopStart point determines when it will\n\t *  loop if Tone.Part.loop is true.\n\t *  @memberOf Tone.Part#\n\t *  @type {Time}\n\t *  @name loopStart\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._loopStart).toSeconds();\n\t\t},\n\t\tset : function(loopStart){\n\t\t\tthis._loopStart = this.toTicks(loopStart);\n\t\t\tif (this._loop){\n\t\t\t\tthis._forEach(function(event){\n\t\t\t\t\tevent.loopStart = this.loopStart;\n\t\t\t\t\tthis._testLoopBoundries(event);\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * \tThe playback rate of the part\n\t *  @memberOf Tone.Part#\n\t *  @type {Positive}\n\t *  @name playbackRate\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._playbackRate = rate;\n\t\t\tthis._setAll(\"playbackRate\", rate);\n\t\t}\n\t});\n\n\t/**\n\t * \tThe number of scheduled notes in the part.\n\t *  @memberOf Tone.Part#\n\t *  @type {Positive}\n\t *  @name length\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Part.prototype, \"length\", {\n\t\tget : function(){\n\t\t\treturn this._events.length;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Part}  this\n\t */\n\tTone.Part.prototype.dispose = function(){\n\t\tTone.Event.prototype.dispose.call(this);\n\t\tthis.removeAll();\n\t\tthis.callback = null;\n\t\tthis._events = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Part;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/event/Part.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/event/Pattern.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/event/Pattern.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../event/Loop */ \"./node_modules/tone/Tone/event/Loop.js\"), __webpack_require__(/*! ../control/CtrlPattern */ \"./node_modules/tone/Tone/control/CtrlPattern.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Pattern arpeggiates between the given notes\n\t *         in a number of patterns. See Tone.CtrlPattern for\n\t *         a full list of patterns.\n\t *  @example\n\t * var pattern = new Tone.Pattern(function(time, note){\n\t *   //the order of the notes passed in depends on the pattern\n\t * }, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n\t *  @extends {Tone.Loop}\n\t *  @param {Function} callback The callback to invoke with the\n\t *                             event.\n\t *  @param {Array} values The values to arpeggiate over.\n\t */\n\tTone.Pattern = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"values\", \"pattern\"], Tone.Pattern);\n\t\tTone.Loop.call(this, options);\n\n\t\t/**\n\t\t *  The pattern manager\n\t\t *  @type {Tone.CtrlPattern}\n\t\t *  @private\n\t\t */\n\t\tthis._pattern = new Tone.CtrlPattern({\n\t\t\t\"values\" : options.values, \n\t\t\t\"type\" : options.pattern,\n\t\t\t\"index\" : options.index\n\t\t});\n\t};\n\n\tTone.extend(Tone.Pattern, Tone.Loop);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.Pattern.defaults = {\n\t\t\"pattern\" : Tone.CtrlPattern.Type.Up,\n\t\t\"callback\" : Tone.noOp,\n\t\t\"values\" : [],\n\t};\n\n\t/**\n\t *  Internal function called when the notes should be called\n\t *  @param  {Number}  time  The time the event occurs\n\t *  @private\n\t */\n\tTone.Pattern.prototype._tick = function(time){\n\t\tthis.callback(time, this._pattern.value);\n\t\tthis._pattern.next();\n\t};\n\n\t/**\n\t *  The current index in the values array.\n\t *  @memberOf Tone.Pattern#\n\t *  @type {Positive}\n\t *  @name index\n\t */\n\tObject.defineProperty(Tone.Pattern.prototype, \"index\", {\n\t\tget : function(){\n\t\t\treturn this._pattern.index;\n\t\t},\n\t\tset : function(i){\n\t\t\tthis._pattern.index = i;\n\t\t}\n\t});\n\n\t/**\n\t *  The array of events.\n\t *  @memberOf Tone.Pattern#\n\t *  @type {Array}\n\t *  @name values\n\t */\n\tObject.defineProperty(Tone.Pattern.prototype, \"values\", {\n\t\tget : function(){\n\t\t\treturn this._pattern.values;\n\t\t},\n\t\tset : function(vals){\n\t\t\tthis._pattern.values = vals;\n\t\t}\n\t});\n\n\t/**\n\t *  The current value of the pattern.\n\t *  @memberOf Tone.Pattern#\n\t *  @type {*}\n\t *  @name value\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Pattern.prototype, \"value\", {\n\t\tget : function(){\n\t\t\treturn this._pattern.value;\n\t\t}\n\t});\n\n\t/**\n\t *  The pattern type. See Tone.CtrlPattern for the full list of patterns.\n\t *  @memberOf Tone.Pattern#\n\t *  @type {String}\n\t *  @name pattern\n\t */\n\tObject.defineProperty(Tone.Pattern.prototype, \"pattern\", {\n\t\tget : function(){\n\t\t\treturn this._pattern.type;\n\t\t},\n\t\tset : function(pattern){\n\t\t\tthis._pattern.type = pattern;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up\n\t *  @return  {Tone.Pattern}  this\n\t */\n\tTone.Pattern.prototype.dispose = function(){\n\t\tTone.Loop.prototype.dispose.call(this);\n\t\tthis._pattern.dispose();\n\t\tthis._pattern = null;\n\t};\n\n\treturn Tone.Pattern;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/event/Pattern.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/event/Sequence.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/event/Sequence.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../event/Part */ \"./node_modules/tone/Tone/event/Part.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class A sequence is an alternate notation of a part. Instead\n\t *         of passing in an array of [time, event] pairs, pass\n\t *         in an array of events which will be spaced at the\n\t *         given subdivision. Sub-arrays will subdivide that beat\n\t *         by the number of items are in the array.\n\t *         Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)\n\t *  @param  {Function}  callback  The callback to invoke with every note\n\t *  @param  {Array}    events  The sequence\n\t *  @param  {Time} subdivision  The subdivision between which events are placed.\n\t *  @extends {Tone.Part}\n\t *  @example\n\t * var seq = new Tone.Sequence(function(time, note){\n\t * \tconsole.log(note);\n\t * //straight quater notes\n\t * }, [\"C4\", \"E4\", \"G4\", \"A4\"], \"4n\");\n\t *  @example\n\t * var seq = new Tone.Sequence(function(time, note){\n\t * \tconsole.log(note);\n\t * //subdivisions are given as subarrays\n\t * }, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]);\n\t */\n\tTone.Sequence = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"callback\", \"events\", \"subdivision\"], Tone.Sequence);\n\n\t\t//remove the events\n\t\tvar events = options.events;\n\t\tdelete options.events;\n\n\t\tTone.Part.call(this, options);\n\n\t\t/**\n\t\t *  The subdivison of each note\n\t\t *  @type  {Ticks}\n\t\t *  @private\n\t\t */\n\t\tthis._subdivision = this.toTicks(options.subdivision);\n\n\t\t//if no time was passed in, the loop end is the end of the cycle\n\t\tif (Tone.isUndef(options.loopEnd) && Tone.isDefined(events)){\n\t\t\tthis._loopEnd = (events.length * this._subdivision);\n\t\t}\n\t\t//defaults to looping\n\t\tthis._loop = true;\n\n\t\t//add all of the events\n\t\tif (Tone.isDefined(events)){\n\t\t\tfor (var i = 0; i < events.length; i++){\n\t\t\t\tthis.add(i, events[i]);\n\t\t\t}\n\t\t}\n\t};\n\n\tTone.extend(Tone.Sequence, Tone.Part);\n\n\t/**\n\t *  The default values.\n\t *  @type  {Object}\n\t */\n\tTone.Sequence.defaults = {\n\t\t\"subdivision\" : \"4n\",\n\t};\n\n\t/**\n\t *  The subdivision of the sequence. This can only be\n\t *  set in the constructor. The subdivision is the\n\t *  interval between successive steps.\n\t *  @type {Time}\n\t *  @memberOf Tone.Sequence#\n\t *  @name subdivision\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.Sequence.prototype, \"subdivision\", {\n\t\tget : function(){\n\t\t\treturn Tone.Ticks(this._subdivision).toSeconds();\n\t\t}\n\t});\n\n\t/**\n\t *  Get/Set an index of the sequence. If the index contains a subarray,\n\t *  a Tone.Sequence representing that sub-array will be returned.\n\t *  @example\n\t * var sequence = new Tone.Sequence(playNote, [\"E4\", \"C4\", \"F#4\", [\"A4\", \"Bb3\"]])\n\t * sequence.at(0)// => returns \"E4\"\n\t * //set a value\n\t * sequence.at(0, \"G3\");\n\t * //get a nested sequence\n\t * sequence.at(3).at(1)// => returns \"Bb3\"\n\t * @param {Positive} index The index to get or set\n\t * @param {*} value Optionally pass in the value to set at the given index.\n\t */\n\tTone.Sequence.prototype.at = function(index, value){\n\t\t//if the value is an array,\n\t\tif (Tone.isArray(value)){\n\t\t\t//remove the current event at that index\n\t\t\tthis.remove(index);\n\t\t}\n\t\t//call the parent's method\n\t\treturn Tone.Part.prototype.at.call(this, this._indexTime(index), value);\n\t};\n\n\t/**\n\t *  Add an event at an index, if there's already something\n\t *  at that index, overwrite it. If `value` is an array,\n\t *  it will be parsed as a subsequence.\n\t *  @param {Number} index The index to add the event to\n\t *  @param {*} value The value to add at that index\n\t *  @returns {Tone.Sequence} this\n\t */\n\tTone.Sequence.prototype.add = function(index, value){\n\t\tif (value === null){\n\t\t\treturn this;\n\t\t}\n\t\tif (Tone.isArray(value)){\n\t\t\t//make a subsequence and add that to the sequence\n\t\t\tvar subSubdivision = Math.round(this._subdivision / value.length);\n\t\t\tvalue = new Tone.Sequence(this._tick.bind(this), value, Tone.Ticks(subSubdivision));\n\t\t}\n\t\tTone.Part.prototype.add.call(this, this._indexTime(index), value);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Remove a value from the sequence by index\n\t *  @param {Number} index The index of the event to remove\n\t *  @returns {Tone.Sequence} this\n\t */\n\tTone.Sequence.prototype.remove = function(index, value){\n\t\tTone.Part.prototype.remove.call(this, this._indexTime(index), value);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the time of the index given the Sequence's subdivision\n\t *  @param  {Number}  index\n\t *  @return  {Time}  The time of that index\n\t *  @private\n\t */\n\tTone.Sequence.prototype._indexTime = function(index){\n\t\tif (index instanceof Tone.TransportTime){\n\t\t\treturn index;\n\t\t} else {\n\t\t\treturn Tone.Ticks(index * this._subdivision + this.startOffset).toSeconds();\n\t\t}\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.Sequence} this\n\t */\n\tTone.Sequence.prototype.dispose = function(){\n\t\tTone.Part.prototype.dispose.call(this);\n\t\treturn this;\n\t};\n\n\treturn Tone.Sequence;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/event/Sequence.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/index.js":
/*!*****************************************!*\
  !*** ./node_modules/tone/Tone/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("__webpack_require__(/*! ./component/AmplitudeEnvelope.js */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\");\n__webpack_require__(/*! ./component/Analyser.js */ \"./node_modules/tone/Tone/component/Analyser.js\");\n__webpack_require__(/*! ./component/Channel.js */ \"./node_modules/tone/Tone/component/Channel.js\");\n__webpack_require__(/*! ./component/Compressor.js */ \"./node_modules/tone/Tone/component/Compressor.js\");\n__webpack_require__(/*! ./component/CrossFade.js */ \"./node_modules/tone/Tone/component/CrossFade.js\");\n__webpack_require__(/*! ./component/Envelope.js */ \"./node_modules/tone/Tone/component/Envelope.js\");\n__webpack_require__(/*! ./component/EQ3.js */ \"./node_modules/tone/Tone/component/EQ3.js\");\n__webpack_require__(/*! ./component/FeedbackCombFilter.js */ \"./node_modules/tone/Tone/component/FeedbackCombFilter.js\");\n__webpack_require__(/*! ./component/FFT.js */ \"./node_modules/tone/Tone/component/FFT.js\");\n__webpack_require__(/*! ./component/Filter.js */ \"./node_modules/tone/Tone/component/Filter.js\");\n__webpack_require__(/*! ./component/Follower.js */ \"./node_modules/tone/Tone/component/Follower.js\");\n__webpack_require__(/*! ./component/FrequencyEnvelope.js */ \"./node_modules/tone/Tone/component/FrequencyEnvelope.js\");\n__webpack_require__(/*! ./component/Gate.js */ \"./node_modules/tone/Tone/component/Gate.js\");\n__webpack_require__(/*! ./component/LFO.js */ \"./node_modules/tone/Tone/component/LFO.js\");\n__webpack_require__(/*! ./component/Limiter.js */ \"./node_modules/tone/Tone/component/Limiter.js\");\n__webpack_require__(/*! ./component/LowpassCombFilter.js */ \"./node_modules/tone/Tone/component/LowpassCombFilter.js\");\n__webpack_require__(/*! ./component/Merge.js */ \"./node_modules/tone/Tone/component/Merge.js\");\n__webpack_require__(/*! ./component/Meter.js */ \"./node_modules/tone/Tone/component/Meter.js\");\n__webpack_require__(/*! ./component/MidSideCompressor.js */ \"./node_modules/tone/Tone/component/MidSideCompressor.js\");\n__webpack_require__(/*! ./component/MidSideMerge.js */ \"./node_modules/tone/Tone/component/MidSideMerge.js\");\n__webpack_require__(/*! ./component/MidSideSplit.js */ \"./node_modules/tone/Tone/component/MidSideSplit.js\");\n__webpack_require__(/*! ./component/Mono.js */ \"./node_modules/tone/Tone/component/Mono.js\");\n__webpack_require__(/*! ./component/MultibandCompressor.js */ \"./node_modules/tone/Tone/component/MultibandCompressor.js\");\n__webpack_require__(/*! ./component/MultibandSplit.js */ \"./node_modules/tone/Tone/component/MultibandSplit.js\");\n__webpack_require__(/*! ./component/Panner.js */ \"./node_modules/tone/Tone/component/Panner.js\");\n__webpack_require__(/*! ./component/Panner3D.js */ \"./node_modules/tone/Tone/component/Panner3D.js\");\n__webpack_require__(/*! ./component/PanVol.js */ \"./node_modules/tone/Tone/component/PanVol.js\");\n__webpack_require__(/*! ./component/ScaledEnvelope.js */ \"./node_modules/tone/Tone/component/ScaledEnvelope.js\");\n__webpack_require__(/*! ./component/Solo.js */ \"./node_modules/tone/Tone/component/Solo.js\");\n__webpack_require__(/*! ./component/Split.js */ \"./node_modules/tone/Tone/component/Split.js\");\n__webpack_require__(/*! ./component/Volume.js */ \"./node_modules/tone/Tone/component/Volume.js\");\n__webpack_require__(/*! ./component/Waveform.js */ \"./node_modules/tone/Tone/component/Waveform.js\");\n__webpack_require__(/*! ./control/CtrlInterpolate.js */ \"./node_modules/tone/Tone/control/CtrlInterpolate.js\");\n__webpack_require__(/*! ./control/CtrlMarkov.js */ \"./node_modules/tone/Tone/control/CtrlMarkov.js\");\n__webpack_require__(/*! ./control/CtrlPattern.js */ \"./node_modules/tone/Tone/control/CtrlPattern.js\");\n__webpack_require__(/*! ./control/CtrlRandom.js */ \"./node_modules/tone/Tone/control/CtrlRandom.js\");\n__webpack_require__(/*! ./core/AudioNode.js */ \"./node_modules/tone/Tone/core/AudioNode.js\");\n__webpack_require__(/*! ./core/Buffer.js */ \"./node_modules/tone/Tone/core/Buffer.js\");\n__webpack_require__(/*! ./core/Buffers.js */ \"./node_modules/tone/Tone/core/Buffers.js\");\n__webpack_require__(/*! ./core/Bus.js */ \"./node_modules/tone/Tone/core/Bus.js\");\n__webpack_require__(/*! ./core/Clock.js */ \"./node_modules/tone/Tone/core/Clock.js\");\n__webpack_require__(/*! ./core/Context.js */ \"./node_modules/tone/Tone/core/Context.js\");\n__webpack_require__(/*! ./core/Delay.js */ \"./node_modules/tone/Tone/core/Delay.js\");\n__webpack_require__(/*! ./core/Draw.js */ \"./node_modules/tone/Tone/core/Draw.js\");\n__webpack_require__(/*! ./core/Emitter.js */ \"./node_modules/tone/Tone/core/Emitter.js\");\n__webpack_require__(/*! ./core/Gain.js */ \"./node_modules/tone/Tone/core/Gain.js\");\n__webpack_require__(/*! ./core/IntervalTimeline.js */ \"./node_modules/tone/Tone/core/IntervalTimeline.js\");\n__webpack_require__(/*! ./core/Listener.js */ \"./node_modules/tone/Tone/core/Listener.js\");\n__webpack_require__(/*! ./core/Master.js */ \"./node_modules/tone/Tone/core/Master.js\");\n__webpack_require__(/*! ./core/Offline.js */ \"./node_modules/tone/Tone/core/Offline.js\");\n__webpack_require__(/*! ./core/OfflineContext.js */ \"./node_modules/tone/Tone/core/OfflineContext.js\");\n__webpack_require__(/*! ./core/Param.js */ \"./node_modules/tone/Tone/core/Param.js\");\n__webpack_require__(/*! ./core/Timeline.js */ \"./node_modules/tone/Tone/core/Timeline.js\");\n__webpack_require__(/*! ./core/TimelineState.js */ \"./node_modules/tone/Tone/core/TimelineState.js\");\n__webpack_require__(/*! ./core/Transport.js */ \"./node_modules/tone/Tone/core/Transport.js\");\n__webpack_require__(/*! ./core/TransportEvent.js */ \"./node_modules/tone/Tone/core/TransportEvent.js\");\n__webpack_require__(/*! ./core/TransportRepeatEvent.js */ \"./node_modules/tone/Tone/core/TransportRepeatEvent.js\");\n__webpack_require__(/*! ./effect/AutoFilter.js */ \"./node_modules/tone/Tone/effect/AutoFilter.js\");\n__webpack_require__(/*! ./effect/AutoPanner.js */ \"./node_modules/tone/Tone/effect/AutoPanner.js\");\n__webpack_require__(/*! ./effect/AutoWah.js */ \"./node_modules/tone/Tone/effect/AutoWah.js\");\n__webpack_require__(/*! ./effect/BitCrusher.js */ \"./node_modules/tone/Tone/effect/BitCrusher.js\");\n__webpack_require__(/*! ./effect/Chebyshev.js */ \"./node_modules/tone/Tone/effect/Chebyshev.js\");\n__webpack_require__(/*! ./effect/Chorus.js */ \"./node_modules/tone/Tone/effect/Chorus.js\");\n__webpack_require__(/*! ./effect/Convolver.js */ \"./node_modules/tone/Tone/effect/Convolver.js\");\n__webpack_require__(/*! ./effect/Distortion.js */ \"./node_modules/tone/Tone/effect/Distortion.js\");\n__webpack_require__(/*! ./effect/Effect.js */ \"./node_modules/tone/Tone/effect/Effect.js\");\n__webpack_require__(/*! ./effect/FeedbackDelay.js */ \"./node_modules/tone/Tone/effect/FeedbackDelay.js\");\n__webpack_require__(/*! ./effect/FeedbackEffect.js */ \"./node_modules/tone/Tone/effect/FeedbackEffect.js\");\n__webpack_require__(/*! ./effect/Freeverb.js */ \"./node_modules/tone/Tone/effect/Freeverb.js\");\n__webpack_require__(/*! ./effect/JCReverb.js */ \"./node_modules/tone/Tone/effect/JCReverb.js\");\n__webpack_require__(/*! ./effect/MidSideEffect.js */ \"./node_modules/tone/Tone/effect/MidSideEffect.js\");\n__webpack_require__(/*! ./effect/Phaser.js */ \"./node_modules/tone/Tone/effect/Phaser.js\");\n__webpack_require__(/*! ./effect/PingPongDelay.js */ \"./node_modules/tone/Tone/effect/PingPongDelay.js\");\n__webpack_require__(/*! ./effect/PitchShift.js */ \"./node_modules/tone/Tone/effect/PitchShift.js\");\n__webpack_require__(/*! ./effect/Reverb.js */ \"./node_modules/tone/Tone/effect/Reverb.js\");\n__webpack_require__(/*! ./effect/StereoEffect.js */ \"./node_modules/tone/Tone/effect/StereoEffect.js\");\n__webpack_require__(/*! ./effect/StereoFeedbackEffect.js */ \"./node_modules/tone/Tone/effect/StereoFeedbackEffect.js\");\n__webpack_require__(/*! ./effect/StereoWidener.js */ \"./node_modules/tone/Tone/effect/StereoWidener.js\");\n__webpack_require__(/*! ./effect/StereoXFeedbackEffect.js */ \"./node_modules/tone/Tone/effect/StereoXFeedbackEffect.js\");\n__webpack_require__(/*! ./effect/Tremolo.js */ \"./node_modules/tone/Tone/effect/Tremolo.js\");\n__webpack_require__(/*! ./effect/Vibrato.js */ \"./node_modules/tone/Tone/effect/Vibrato.js\");\n__webpack_require__(/*! ./event/Event.js */ \"./node_modules/tone/Tone/event/Event.js\");\n__webpack_require__(/*! ./event/Loop.js */ \"./node_modules/tone/Tone/event/Loop.js\");\n__webpack_require__(/*! ./event/Part.js */ \"./node_modules/tone/Tone/event/Part.js\");\n__webpack_require__(/*! ./event/Pattern.js */ \"./node_modules/tone/Tone/event/Pattern.js\");\n__webpack_require__(/*! ./event/Sequence.js */ \"./node_modules/tone/Tone/event/Sequence.js\");\n__webpack_require__(/*! ./instrument/AMSynth.js */ \"./node_modules/tone/Tone/instrument/AMSynth.js\");\n__webpack_require__(/*! ./instrument/DuoSynth.js */ \"./node_modules/tone/Tone/instrument/DuoSynth.js\");\n__webpack_require__(/*! ./instrument/FMSynth.js */ \"./node_modules/tone/Tone/instrument/FMSynth.js\");\n__webpack_require__(/*! ./instrument/Instrument.js */ \"./node_modules/tone/Tone/instrument/Instrument.js\");\n__webpack_require__(/*! ./instrument/MembraneSynth.js */ \"./node_modules/tone/Tone/instrument/MembraneSynth.js\");\n__webpack_require__(/*! ./instrument/MetalSynth.js */ \"./node_modules/tone/Tone/instrument/MetalSynth.js\");\n__webpack_require__(/*! ./instrument/Monophonic.js */ \"./node_modules/tone/Tone/instrument/Monophonic.js\");\n__webpack_require__(/*! ./instrument/MonoSynth.js */ \"./node_modules/tone/Tone/instrument/MonoSynth.js\");\n__webpack_require__(/*! ./instrument/NoiseSynth.js */ \"./node_modules/tone/Tone/instrument/NoiseSynth.js\");\n__webpack_require__(/*! ./instrument/PluckSynth.js */ \"./node_modules/tone/Tone/instrument/PluckSynth.js\");\n__webpack_require__(/*! ./instrument/PolySynth.js */ \"./node_modules/tone/Tone/instrument/PolySynth.js\");\n__webpack_require__(/*! ./instrument/Sampler.js */ \"./node_modules/tone/Tone/instrument/Sampler.js\");\n__webpack_require__(/*! ./instrument/Synth.js */ \"./node_modules/tone/Tone/instrument/Synth.js\");\n__webpack_require__(/*! ./shim/AnalyserNode.js */ \"./node_modules/tone/Tone/shim/AnalyserNode.js\");\n__webpack_require__(/*! ./shim/AudioBuffer.js */ \"./node_modules/tone/Tone/shim/AudioBuffer.js\");\n__webpack_require__(/*! ./shim/AudioContext.js */ \"./node_modules/tone/Tone/shim/AudioContext.js\");\n__webpack_require__(/*! ./shim/BufferSourceNode.js */ \"./node_modules/tone/Tone/shim/BufferSourceNode.js\");\n__webpack_require__(/*! ./shim/ConstantSourceNode.js */ \"./node_modules/tone/Tone/shim/ConstantSourceNode.js\");\n__webpack_require__(/*! ./shim/OfflineAudioContext.js */ \"./node_modules/tone/Tone/shim/OfflineAudioContext.js\");\n__webpack_require__(/*! ./shim/OscillatorNode.js */ \"./node_modules/tone/Tone/shim/OscillatorNode.js\");\n__webpack_require__(/*! ./shim/StereoPannerNode.js */ \"./node_modules/tone/Tone/shim/StereoPannerNode.js\");\n__webpack_require__(/*! ./shim/WaveShaperNode.js */ \"./node_modules/tone/Tone/shim/WaveShaperNode.js\");\n__webpack_require__(/*! ./signal/Abs.js */ \"./node_modules/tone/Tone/signal/Abs.js\");\n__webpack_require__(/*! ./signal/Add.js */ \"./node_modules/tone/Tone/signal/Add.js\");\n__webpack_require__(/*! ./signal/AudioToGain.js */ \"./node_modules/tone/Tone/signal/AudioToGain.js\");\n__webpack_require__(/*! ./signal/EqualPowerGain.js */ \"./node_modules/tone/Tone/signal/EqualPowerGain.js\");\n__webpack_require__(/*! ./signal/GainToAudio.js */ \"./node_modules/tone/Tone/signal/GainToAudio.js\");\n__webpack_require__(/*! ./signal/GreaterThan.js */ \"./node_modules/tone/Tone/signal/GreaterThan.js\");\n__webpack_require__(/*! ./signal/GreaterThanZero.js */ \"./node_modules/tone/Tone/signal/GreaterThanZero.js\");\n__webpack_require__(/*! ./signal/Modulo.js */ \"./node_modules/tone/Tone/signal/Modulo.js\");\n__webpack_require__(/*! ./signal/Multiply.js */ \"./node_modules/tone/Tone/signal/Multiply.js\");\n__webpack_require__(/*! ./signal/Negate.js */ \"./node_modules/tone/Tone/signal/Negate.js\");\n__webpack_require__(/*! ./signal/Normalize.js */ \"./node_modules/tone/Tone/signal/Normalize.js\");\n__webpack_require__(/*! ./signal/Pow.js */ \"./node_modules/tone/Tone/signal/Pow.js\");\n__webpack_require__(/*! ./signal/Scale.js */ \"./node_modules/tone/Tone/signal/Scale.js\");\n__webpack_require__(/*! ./signal/ScaleExp.js */ \"./node_modules/tone/Tone/signal/ScaleExp.js\");\n__webpack_require__(/*! ./signal/Signal.js */ \"./node_modules/tone/Tone/signal/Signal.js\");\n__webpack_require__(/*! ./signal/SignalBase.js */ \"./node_modules/tone/Tone/signal/SignalBase.js\");\n__webpack_require__(/*! ./signal/Subtract.js */ \"./node_modules/tone/Tone/signal/Subtract.js\");\n__webpack_require__(/*! ./signal/TickSignal.js */ \"./node_modules/tone/Tone/signal/TickSignal.js\");\n__webpack_require__(/*! ./signal/TransportTimelineSignal.js */ \"./node_modules/tone/Tone/signal/TransportTimelineSignal.js\");\n__webpack_require__(/*! ./signal/WaveShaper.js */ \"./node_modules/tone/Tone/signal/WaveShaper.js\");\n__webpack_require__(/*! ./signal/Zero.js */ \"./node_modules/tone/Tone/signal/Zero.js\");\n__webpack_require__(/*! ./source/AMOscillator.js */ \"./node_modules/tone/Tone/source/AMOscillator.js\");\n__webpack_require__(/*! ./source/BufferSource.js */ \"./node_modules/tone/Tone/source/BufferSource.js\");\n__webpack_require__(/*! ./source/FatOscillator.js */ \"./node_modules/tone/Tone/source/FatOscillator.js\");\n__webpack_require__(/*! ./source/FMOscillator.js */ \"./node_modules/tone/Tone/source/FMOscillator.js\");\n__webpack_require__(/*! ./source/GrainPlayer.js */ \"./node_modules/tone/Tone/source/GrainPlayer.js\");\n__webpack_require__(/*! ./source/Noise.js */ \"./node_modules/tone/Tone/source/Noise.js\");\n__webpack_require__(/*! ./source/OmniOscillator.js */ \"./node_modules/tone/Tone/source/OmniOscillator.js\");\n__webpack_require__(/*! ./source/Oscillator.js */ \"./node_modules/tone/Tone/source/Oscillator.js\");\n__webpack_require__(/*! ./source/OscillatorNode.js */ \"./node_modules/tone/Tone/source/OscillatorNode.js\");\n__webpack_require__(/*! ./source/Player.js */ \"./node_modules/tone/Tone/source/Player.js\");\n__webpack_require__(/*! ./source/Players.js */ \"./node_modules/tone/Tone/source/Players.js\");\n__webpack_require__(/*! ./source/PulseOscillator.js */ \"./node_modules/tone/Tone/source/PulseOscillator.js\");\n__webpack_require__(/*! ./source/PWMOscillator.js */ \"./node_modules/tone/Tone/source/PWMOscillator.js\");\n__webpack_require__(/*! ./source/Source.js */ \"./node_modules/tone/Tone/source/Source.js\");\n__webpack_require__(/*! ./source/TickSource.js */ \"./node_modules/tone/Tone/source/TickSource.js\");\n__webpack_require__(/*! ./source/UserMedia.js */ \"./node_modules/tone/Tone/source/UserMedia.js\");\n__webpack_require__(/*! ./type/Frequency.js */ \"./node_modules/tone/Tone/type/Frequency.js\");\n__webpack_require__(/*! ./type/Midi.js */ \"./node_modules/tone/Tone/type/Midi.js\");\n__webpack_require__(/*! ./type/Ticks.js */ \"./node_modules/tone/Tone/type/Ticks.js\");\n__webpack_require__(/*! ./type/Time.js */ \"./node_modules/tone/Tone/type/Time.js\");\n__webpack_require__(/*! ./type/TimeBase.js */ \"./node_modules/tone/Tone/type/TimeBase.js\");\n__webpack_require__(/*! ./type/TransportTime.js */ \"./node_modules/tone/Tone/type/TransportTime.js\");\n__webpack_require__(/*! ./type/Type.js */ \"./node_modules/tone/Tone/type/Type.js\");\nmodule.exports = __webpack_require__(/*! ./core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\");\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/index.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/AMSynth.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/AMSynth.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Synth */ \"./node_modules/tone/Tone/instrument/Synth.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"),\n\t__webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/Tone/instrument/Monophonic.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  AMSynth uses the output of one Tone.Synth to modulate the\n\t *          amplitude of another Tone.Synth. The harmonicity (the ratio between\n\t *          the two signals) affects the timbre of the output signal greatly.\n\t *          Read more about Amplitude Modulation Synthesis on\n\t *          [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n\t *          <img src=\"https://docs.google.com/drawings/d/1TQu8Ed4iFr1YTLKpB3U1_hur-UwBrh5gdBXc8BxfGKw/pub?w=1009&h=457\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Monophonic}\n\t *  @param {Object} [options] the options available for the synth\n\t *                            see defaults below\n\t *  @example\n\t * var synth = new Tone.AMSynth().toMaster();\n\t * synth.triggerAttackRelease(\"C4\", \"4n\");\n\t */\n\tTone.AMSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.AMSynth.defaults);\n\t\tTone.Monophonic.call(this, options);\n\n\t\t/**\n\t\t *  The carrier voice.\n\t\t *  @type {Tone.Synth}\n\t\t *  @private\n\t\t */\n\t\tthis._carrier = new Tone.Synth();\n\t\tthis._carrier.volume.value = -10;\n\n\t\t/**\n\t\t *  The carrier's oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.oscillator = this._carrier.oscillator.set(options.oscillator);\n\n\t\t/**\n\t\t *  The carrier's envelope\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.envelope = this._carrier.envelope.set(options.envelope);\n\n\t\t/**\n\t\t *  The modulator voice.\n\t\t *  @type {Tone.Synth}\n\t\t *  @private\n\t\t */\n\t\tthis._modulator = new Tone.Synth();\n\t\tthis._modulator.volume.value = -10;\n\n\t\t/**\n\t\t *  The modulator's oscillator which is applied\n\t\t *  to the amplitude of the oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.modulation = this._modulator.oscillator.set(options.modulation);\n\n\t\t/**\n\t\t *  The modulator's envelope\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.modulationEnvelope = this._modulator.envelope.set(options.modulationEnvelope);\n\n\t\t/**\n\t\t *  The frequency.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(440, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune in cents\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  Harmonicity is the ratio between the two voices. A harmonicity of\n\t\t *  1 is no change. Harmonicity = 2 means a change of an octave.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t *  @example\n\t\t * //pitch voice1 an octave below voice0\n\t\t * synth.harmonicity.value = 0.5;\n\t\t */\n\t\tthis.harmonicity = new Tone.Multiply(options.harmonicity);\n\t\tthis.harmonicity.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  convert the -1,1 output to 0,1\n\t\t *  @type {Tone.AudioToGain}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationScale = new Tone.AudioToGain();\n\n\t\t/**\n\t\t *  the node where the modulation happens\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationNode = new Tone.Gain();\n\n\t\t//control the two voices frequency\n\t\tthis.frequency.connect(this._carrier.frequency);\n\t\tthis.frequency.chain(this.harmonicity, this._modulator.frequency);\n\t\tthis.detune.fan(this._carrier.detune, this._modulator.detune);\n\t\tthis._modulator.chain(this._modulationScale, this._modulationNode.gain);\n\t\tthis._carrier.chain(this._modulationNode, this.output);\n\t\tthis._readOnly([\"frequency\", \"harmonicity\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.AMSynth, Tone.Monophonic);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.AMSynth.defaults = {\n\t\t\"harmonicity\" : 3,\n\t\t\"detune\" : 0,\n\t\t\"oscillator\" : {\n\t\t\t\"type\" : \"sine\"\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.01,\n\t\t\t\"decay\" : 0.01,\n\t\t\t\"sustain\" : 1,\n\t\t\t\"release\" : 0.5\n\t\t},\n\t\t\"modulation\" : {\n\t\t\t\"type\" : \"square\"\n\t\t},\n\t\t\"modulationEnvelope\" : {\n\t\t\t\"attack\" : 0.5,\n\t\t\t\"decay\" : 0.0,\n\t\t\t\"sustain\" : 1,\n\t\t\t\"release\" : 0.5\n\t\t}\n\t};\n\n\t/**\n\t *  trigger the attack portion of the note\n\t *\n\t *  @param  {Time} [time=now] the time the note will occur\n\t *  @param {NormalRange} [velocity=1] the velocity of the note\n\t *  @private\n\t *  @returns {Tone.AMSynth} this\n\t */\n\tTone.AMSynth.prototype._triggerEnvelopeAttack = function(time, velocity){\n\t\t//the port glide\n\t\ttime = this.toSeconds(time);\n\t\t//the envelopes\n\t\tthis._carrier._triggerEnvelopeAttack(time, velocity);\n\t\tthis._modulator._triggerEnvelopeAttack(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  trigger the release portion of the note\n\t *\n\t *  @param  {Time} [time=now] the time the note will release\n\t *  @private\n\t *  @returns {Tone.AMSynth} this\n\t */\n\tTone.AMSynth.prototype._triggerEnvelopeRelease = function(time){\n\t\tthis._carrier._triggerEnvelopeRelease(time);\n\t\tthis._modulator._triggerEnvelopeRelease(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.AMSynth} this\n\t */\n\tTone.AMSynth.prototype.dispose = function(){\n\t\tTone.Monophonic.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"harmonicity\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n\t\tthis._carrier.dispose();\n\t\tthis._carrier = null;\n\t\tthis._modulator.dispose();\n\t\tthis._modulator = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis.harmonicity.dispose();\n\t\tthis.harmonicity = null;\n\t\tthis._modulationScale.dispose();\n\t\tthis._modulationScale = null;\n\t\tthis._modulationNode.dispose();\n\t\tthis._modulationNode = null;\n\t\tthis.oscillator = null;\n\t\tthis.envelope = null;\n\t\tthis.modulationEnvelope = null;\n\t\tthis.modulation = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AMSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/AMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/DuoSynth.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/DuoSynth.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/MonoSynth */ \"./node_modules/tone/Tone/instrument/MonoSynth.js\"), __webpack_require__(/*! ../component/LFO */ \"./node_modules/tone/Tone/component/LFO.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"),\n\t__webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/Tone/instrument/Monophonic.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.DuoSynth is a monophonic synth composed of two\n\t *          MonoSynths run in parallel with control over the\n\t *          frequency ratio between the two voices and vibrato effect.\n\t *          <img src=\"https://docs.google.com/drawings/d/1bL4GXvfRMMlqS7XyBm9CjL9KJPSUKbcdBNpqOlkFLxk/pub?w=1012&h=448\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Monophonic}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t *  @example\n\t * var duoSynth = new Tone.DuoSynth().toMaster();\n\t * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n\t */\n\tTone.DuoSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.DuoSynth.defaults);\n\t\tTone.Monophonic.call(this, options);\n\n\t\t/**\n\t\t *  the first voice\n\t\t *  @type {Tone.MonoSynth}\n\t\t */\n\t\tthis.voice0 = new Tone.MonoSynth(options.voice0);\n\t\tthis.voice0.volume.value = -10;\n\n\t\t/**\n\t\t *  the second voice\n\t\t *  @type {Tone.MonoSynth}\n\t\t */\n\t\tthis.voice1 = new Tone.MonoSynth(options.voice1);\n\t\tthis.voice1.volume.value = -10;\n\n\t\t/**\n\t\t *  The vibrato LFO.\n\t\t *  @type {Tone.LFO}\n\t\t *  @private\n\t\t */\n\t\tthis._vibrato = new Tone.LFO(options.vibratoRate, -50, 50);\n\t\tthis._vibrato.start();\n\n\t\t/**\n\t\t * the vibrato frequency\n\t\t * @type {Frequency}\n\t\t * @signal\n\t\t */\n\t\tthis.vibratoRate = this._vibrato.frequency;\n\n\t\t/**\n\t\t *  the vibrato gain\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._vibratoGain = new Tone.Gain(options.vibratoAmount, Tone.Type.Positive);\n\n\t\t/**\n\t\t * The amount of vibrato\n\t\t * @type {Positive}\n\t\t * @signal\n\t\t */\n\t\tthis.vibratoAmount = this._vibratoGain.gain;\n\n\t\t/**\n\t\t *  the frequency control\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(440, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  Harmonicity is the ratio between the two voices. A harmonicity of\n\t\t *  1 is no change. Harmonicity = 2 means a change of an octave.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t *  @example\n\t\t * //pitch voice1 an octave below voice0\n\t\t * duoSynth.harmonicity.value = 0.5;\n\t\t */\n\t\tthis.harmonicity = new Tone.Multiply(options.harmonicity);\n\t\tthis.harmonicity.units = Tone.Type.Positive;\n\n\t\t//control the two voices frequency\n\t\tthis.frequency.connect(this.voice0.frequency);\n\t\tthis.frequency.chain(this.harmonicity, this.voice1.frequency);\n\t\tthis._vibrato.connect(this._vibratoGain);\n\t\tthis._vibratoGain.fan(this.voice0.detune, this.voice1.detune);\n\t\tthis.voice0.connect(this.output);\n\t\tthis.voice1.connect(this.output);\n\t\tthis._readOnly([\"voice0\", \"voice1\", \"frequency\", \"vibratoAmount\", \"vibratoRate\"]);\n\t};\n\n\tTone.extend(Tone.DuoSynth, Tone.Monophonic);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.DuoSynth.defaults = {\n\t\t\"vibratoAmount\" : 0.5,\n\t\t\"vibratoRate\" : 5,\n\t\t\"harmonicity\" : 1.5,\n\t\t\"voice0\" : {\n\t\t\t\"volume\" : -10,\n\t\t\t\"portamento\" : 0,\n\t\t\t\"oscillator\" : {\n\t\t\t\t\"type\" : \"sine\"\n\t\t\t},\n\t\t\t\"filterEnvelope\" : {\n\t\t\t\t\"attack\" : 0.01,\n\t\t\t\t\"decay\" : 0.0,\n\t\t\t\t\"sustain\" : 1,\n\t\t\t\t\"release\" : 0.5\n\t\t\t},\n\t\t\t\"envelope\" : {\n\t\t\t\t\"attack\" : 0.01,\n\t\t\t\t\"decay\" : 0.0,\n\t\t\t\t\"sustain\" : 1,\n\t\t\t\t\"release\" : 0.5\n\t\t\t}\n\t\t},\n\t\t\"voice1\" : {\n\t\t\t\"volume\" : -10,\n\t\t\t\"portamento\" : 0,\n\t\t\t\"oscillator\" : {\n\t\t\t\t\"type\" : \"sine\"\n\t\t\t},\n\t\t\t\"filterEnvelope\" : {\n\t\t\t\t\"attack\" : 0.01,\n\t\t\t\t\"decay\" : 0.0,\n\t\t\t\t\"sustain\" : 1,\n\t\t\t\t\"release\" : 0.5\n\t\t\t},\n\t\t\t\"envelope\" : {\n\t\t\t\t\"attack\" : 0.01,\n\t\t\t\t\"decay\" : 0.0,\n\t\t\t\t\"sustain\" : 1,\n\t\t\t\t\"release\" : 0.5\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t *  start the attack portion of the envelopes\n\t *\n\t *  @param {Time} [time=now] the time the attack should start\n\t *  @param {NormalRange} [velocity=1] the velocity of the note (0-1)\n\t *  @returns {Tone.DuoSynth} this\n\t *  @private\n\t */\n\tTone.DuoSynth.prototype._triggerEnvelopeAttack = function(time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tthis.voice0._triggerEnvelopeAttack(time, velocity);\n\t\tthis.voice1._triggerEnvelopeAttack(time, velocity);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  start the release portion of the envelopes\n\t *\n\t *  @param {Time} [time=now] the time the release should start\n\t *  @returns {Tone.DuoSynth} this\n\t *  @private\n\t */\n\tTone.DuoSynth.prototype._triggerEnvelopeRelease = function(time){\n\t\tthis.voice0._triggerEnvelopeRelease(time);\n\t\tthis.voice1._triggerEnvelopeRelease(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the level of the output at the given time. Measures\n\t *  the envelope(s) value at the time. \n\t *  @param {Time} time The time to query the envelope value\n\t *  @return {NormalRange} The output level between 0-1\n\t */\n\tTone.DuoSynth.prototype.getLevelAtTime = function(time){\n\t\treturn (this.voice0.getLevelAtTime(time) + this.voice1.getLevelAtTime(time))/2;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.DuoSynth} this\n\t */\n\tTone.DuoSynth.prototype.dispose = function(){\n\t\tTone.Monophonic.prototype.dispose.call(this);\n\t\tthis._writable([\"voice0\", \"voice1\", \"frequency\", \"vibratoAmount\", \"vibratoRate\"]);\n\t\tthis.voice0.dispose();\n\t\tthis.voice0 = null;\n\t\tthis.voice1.dispose();\n\t\tthis.voice1 = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis._vibratoGain.dispose();\n\t\tthis._vibratoGain = null;\n\t\tthis._vibrato = null;\n\t\tthis.harmonicity.dispose();\n\t\tthis.harmonicity = null;\n\t\tthis.vibratoAmount.dispose();\n\t\tthis.vibratoAmount = null;\n\t\tthis.vibratoRate = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.DuoSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/DuoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/FMSynth.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/FMSynth.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Synth */ \"./node_modules/tone/Tone/instrument/Synth.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"),\n\t__webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/Tone/instrument/Monophonic.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n\t *          the frequency of a second Tone.Synth. A lot of spectral content\n\t *          can be explored using the modulationIndex parameter. Read more about\n\t *          frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n\t *          <img src=\"https://docs.google.com/drawings/d/1h0PUDZXPgi4Ikx6bVT6oncrYPLluFKy7lj53puxj-DM/pub?w=902&h=462\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Monophonic}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t *  @example\n\t * var fmSynth = new Tone.FMSynth().toMaster();\n\t * fmSynth.triggerAttackRelease(\"C5\", \"4n\");\n\t */\n\tTone.FMSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.FMSynth.defaults);\n\t\tTone.Monophonic.call(this, options);\n\n\t\t/**\n\t\t *  The carrier voice.\n\t\t *  @type {Tone.Synth}\n\t\t *  @private\n\t\t */\n\t\tthis._carrier = new Tone.Synth(options.carrier);\n\t\tthis._carrier.volume.value = -10;\n\n\t\t/**\n\t\t *  The carrier's oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.oscillator = this._carrier.oscillator;\n\n\t\t/**\n\t\t *  The carrier's envelope\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.envelope = this._carrier.envelope.set(options.envelope);\n\n\t\t/**\n\t\t *  The modulator voice.\n\t\t *  @type {Tone.Synth}\n\t\t *  @private\n\t\t */\n\t\tthis._modulator = new Tone.Synth(options.modulator);\n\t\tthis._modulator.volume.value = -10;\n\n\t\t/**\n\t\t *  The modulator's oscillator which is applied\n\t\t *  to the amplitude of the oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.modulation = this._modulator.oscillator.set(options.modulation);\n\n\t\t/**\n\t\t *  The modulator's envelope\n\t\t *  @type {Tone.Oscillator}\n\t\t */\n\t\tthis.modulationEnvelope = this._modulator.envelope.set(options.modulationEnvelope);\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(440, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune in cents\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  Harmonicity is the ratio between the two voices. A harmonicity of\n\t\t *  1 is no change. Harmonicity = 2 means a change of an octave.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t *  @example\n\t\t * //pitch voice1 an octave below voice0\n\t\t * synth.harmonicity.value = 0.5;\n\t\t */\n\t\tthis.harmonicity = new Tone.Multiply(options.harmonicity);\n\t\tthis.harmonicity.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  The modulation index which essentially the depth or amount of the modulation. It is the\n\t\t *  ratio of the frequency of the modulating signal (mf) to the amplitude of the\n\t\t *  modulating signal (ma) -- as in ma/mf.\n\t\t *\t@type {Positive}\n\t\t *\t@signal\n\t\t */\n\t\tthis.modulationIndex = new Tone.Multiply(options.modulationIndex);\n\t\tthis.modulationIndex.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  the node where the modulation happens\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationNode = new Tone.Gain(0);\n\n\t\t//control the two voices frequency\n\t\tthis.frequency.connect(this._carrier.frequency);\n\t\tthis.frequency.chain(this.harmonicity, this._modulator.frequency);\n\t\tthis.frequency.chain(this.modulationIndex, this._modulationNode);\n\t\tthis.detune.fan(this._carrier.detune, this._modulator.detune);\n\t\tthis._modulator.connect(this._modulationNode.gain);\n\t\tthis._modulationNode.connect(this._carrier.frequency);\n\t\tthis._carrier.connect(this.output);\n\t\tthis._readOnly([\"frequency\", \"harmonicity\", \"modulationIndex\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.FMSynth, Tone.Monophonic);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.FMSynth.defaults = {\n\t\t\"harmonicity\" : 3,\n\t\t\"modulationIndex\" : 10,\n\t\t\"detune\" : 0,\n\t\t\"oscillator\" : {\n\t\t\t\"type\" : \"sine\"\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.01,\n\t\t\t\"decay\" : 0.01,\n\t\t\t\"sustain\" : 1,\n\t\t\t\"release\" : 0.5\n\t\t},\n\t\t\"modulation\" : {\n\t\t\t\"type\" : \"square\"\n\t\t},\n\t\t\"modulationEnvelope\" : {\n\t\t\t\"attack\" : 0.5,\n\t\t\t\"decay\" : 0.0,\n\t\t\t\"sustain\" : 1,\n\t\t\t\"release\" : 0.5\n\t\t}\n\t};\n\n\t/**\n\t * \ttrigger the attack portion of the note\n\t *\n\t *  @param  {Time} [time=now] the time the note will occur\n\t *  @param {number} [velocity=1] the velocity of the note\n\t *  @returns {Tone.FMSynth} this\n\t *  @private\n\t */\n\tTone.FMSynth.prototype._triggerEnvelopeAttack = function(time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\t//the envelopes\n\t\tthis._carrier._triggerEnvelopeAttack(time, velocity);\n\t\tthis._modulator._triggerEnvelopeAttack(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  trigger the release portion of the note\n\t *\n\t *  @param  {Time} [time=now] the time the note will release\n\t *  @returns {Tone.FMSynth} this\n\t *  @private\n\t */\n\tTone.FMSynth.prototype._triggerEnvelopeRelease = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._carrier._triggerEnvelopeRelease(time);\n\t\tthis._modulator._triggerEnvelopeRelease(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.FMSynth} this\n\t */\n\tTone.FMSynth.prototype.dispose = function(){\n\t\tTone.Monophonic.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"harmonicity\", \"modulationIndex\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n\t\tthis._carrier.dispose();\n\t\tthis._carrier = null;\n\t\tthis._modulator.dispose();\n\t\tthis._modulator = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis.modulationIndex.dispose();\n\t\tthis.modulationIndex = null;\n\t\tthis.harmonicity.dispose();\n\t\tthis.harmonicity = null;\n\t\tthis._modulationNode.dispose();\n\t\tthis._modulationNode = null;\n\t\tthis.oscillator = null;\n\t\tthis.envelope = null;\n\t\tthis.modulationEnvelope = null;\n\t\tthis.modulation = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FMSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/FMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/Instrument.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/Instrument.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/Master */ \"./node_modules/tone/Tone/core/Master.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Base-class for all instruments\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t */\n\tTone.Instrument = function(options){\n\n\t\t//get the defaults\n\t\toptions = Tone.defaultArg(options, Tone.Instrument.defaults);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The output and volume triming node\n\t\t *  @type  {Tone.Volume}\n\t\t *  @private\n\t\t */\n\t\tthis._volume = this.output = new Tone.Volume(options.volume);\n\n\t\t/**\n\t\t * The volume of the output in decibels.\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t * @example\n\t\t * source.volume.value = -6;\n\t\t */\n\t\tthis.volume = this._volume.volume;\n\t\tthis._readOnly(\"volume\");\n\n\t\t/**\n\t\t * Keep track of all events scheduled to the transport\n\t\t * when the instrument is 'synced'\n\t\t * @type {Array<Number>}\n\t\t * @private\n\t\t */\n\t\tthis._scheduledEvents = [];\n\t};\n\n\tTone.extend(Tone.Instrument, Tone.AudioNode);\n\n\t/**\n\t *  the default attributes\n\t *  @type {object}\n\t */\n\tTone.Instrument.defaults = {\n\t\t/** the volume of the output in decibels */\n\t\t\"volume\" : 0\n\t};\n\n\t/**\n\t *  @abstract\n\t *  @param {string|number} note the note to trigger\n\t *  @param {Time} [time=now] the time to trigger the ntoe\n\t *  @param {number} [velocity=1] the velocity to trigger the note\n\t */\n\tTone.Instrument.prototype.triggerAttack = Tone.noOp;\n\n\t/**\n\t *  @abstract\n\t *  @param {Time} [time=now] when to trigger the release\n\t */\n\tTone.Instrument.prototype.triggerRelease = Tone.noOp;\n\n\t/**\n\t * Sync the instrument to the Transport. All subsequent calls of\n\t * [triggerAttack](#triggerattack) and [triggerRelease](#triggerrelease)\n\t * will be scheduled along the transport.\n\t * @example\n\t * instrument.sync()\n\t * //schedule 3 notes when the transport first starts\n\t * instrument.triggerAttackRelease('C4', '8n', 0)\n\t * instrument.triggerAttackRelease('E4', '8n', '8n')\n\t * instrument.triggerAttackRelease('G4', '8n', '4n')\n\t * //start the transport to hear the notes\n\t * Transport.start()\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.Instrument.prototype.sync = function(){\n\t\tthis._syncMethod(\"triggerAttack\", 1);\n\t\tthis._syncMethod(\"triggerRelease\", 0);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Wrap the given method so that it can be synchronized\n\t * @param {String} method Which method to wrap and sync\n\t * @param  {Number} timePosition What position the time argument appears in\n\t * @private\n\t */\n\tTone.Instrument.prototype._syncMethod = function(method, timePosition){\n\t\tvar originalMethod = this[\"_original_\"+method] = this[method];\n\t\tthis[method] = function(){\n\t\t\tvar args = Array.prototype.slice.call(arguments);\n\t\t\tvar time = args[timePosition];\n\t\t\tvar id = Tone.Transport.schedule(function(t){\n\t\t\t\targs[timePosition] = t;\n\t\t\t\toriginalMethod.apply(this, args);\n\t\t\t}.bind(this), time);\n\t\t\tthis._scheduledEvents.push(id);\n\t\t}.bind(this);\n\t};\n\n\t/**\n\t * Unsync the instrument from the Transport\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.Instrument.prototype.unsync = function(){\n\t\tthis._scheduledEvents.forEach(function(id){\n\t\t\tTone.Transport.clear(id);\n\t\t});\n\t\tthis._scheduledEvents = [];\n\t\tif (this._original_triggerAttack){\n\t\t\tthis.triggerAttack = this._original_triggerAttack;\n\t\t\tthis.triggerRelease = this._original_triggerRelease;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the attack and then the release after the duration.\n\t *  @param  {Frequency} note     The note to trigger.\n\t *  @param  {Time} duration How long the note should be held for before\n\t *                          triggering the release. This value must be greater than 0.\n\t *  @param {Time} [time=now]  When the note should be triggered.\n\t *  @param  {NormalRange} [velocity=1] The velocity the note should be triggered at.\n\t *  @returns {Tone.Instrument} this\n\t *  @example\n\t * //trigger \"C4\" for the duration of an 8th note\n\t * synth.triggerAttackRelease(\"C4\", \"8n\");\n\t */\n\tTone.Instrument.prototype.triggerAttackRelease = function(note, duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tduration = this.toSeconds(duration);\n\t\tthis.triggerAttack(note, time, velocity);\n\t\tthis.triggerRelease(time + duration);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Instrument} this\n\t */\n\tTone.Instrument.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis._writable([\"volume\"]);\n\t\tthis.volume = null;\n\t\tthis.unsync();\n\t\tthis._scheduledEvents = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Instrument;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/Instrument.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/MembraneSynth.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/MembraneSynth.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/OmniOscillator */ \"./node_modules/tone/Tone/source/OmniOscillator.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\"),\n\t__webpack_require__(/*! ../component/AmplitudeEnvelope */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.MembraneSynth makes kick and tom sounds using a single oscillator\n\t *          with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n\t *          is routed through a Tone.AmplitudeEnvelope to the output. The drum\n\t *          quality of the sound comes from the frequency envelope applied\n\t *          during Tone.MembraneSynth.triggerAttack(note). The frequency envelope\n\t *          starts at <code>note * .octaves</code> and ramps to <code>note</code>\n\t *          over the duration of <code>.pitchDecay</code>.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Instrument}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t *  @example\n\t * var synth = new Tone.MembraneSynth().toMaster();\n\t * synth.triggerAttackRelease(\"C2\", \"8n\");\n\t */\n\tTone.MembraneSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.MembraneSynth.defaults);\n\t\tTone.Instrument.call(this, options);\n\n\t\t/**\n\t\t *  The oscillator.\n\t\t *  @type {Tone.OmniOscillator}\n\t\t */\n\t\tthis.oscillator = new Tone.OmniOscillator(options.oscillator);\n\n\t\t/**\n\t\t *  The amplitude envelope.\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.envelope = new Tone.AmplitudeEnvelope(options.envelope);\n\n\t\t/**\n\t\t *  The number of octaves the pitch envelope ramps.\n\t\t *  @type {Positive}\n\t\t */\n\t\tthis.octaves = options.octaves;\n\n\t\t/**\n\t\t *  The amount of time the frequency envelope takes.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.pitchDecay = options.pitchDecay;\n\n\t\tthis.oscillator.chain(this.envelope, this.output);\n\t\tthis._readOnly([\"oscillator\", \"envelope\"]);\n\t};\n\n\tTone.extend(Tone.MembraneSynth, Tone.Instrument);\n\n\t/**\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.MembraneSynth.defaults = {\n\t\t\"pitchDecay\" : 0.05,\n\t\t\"octaves\" : 10,\n\t\t\"oscillator\" : {\n\t\t\t\"type\" : \"sine\",\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.001,\n\t\t\t\"decay\" : 0.4,\n\t\t\t\"sustain\" : 0.01,\n\t\t\t\"release\" : 1.4,\n\t\t\t\"attackCurve\" : \"exponential\"\n\t\t}\n\t};\n\n\t/**\n\t *  Trigger the note at the given time with the given velocity.\n\t *\n\t *  @param  {Frequency} note     the note\n\t *  @param  {Time} [time=now]     the time, if not given is now\n\t *  @param  {number} [velocity=1] velocity defaults to 1\n\t *  @returns {Tone.MembraneSynth} this\n\t *  @example\n\t *  kick.triggerAttack(60);\n\t */\n\tTone.MembraneSynth.prototype.triggerAttack = function(note, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tnote = this.toFrequency(note);\n\t\tvar maxNote = note * this.octaves;\n\t\tthis.oscillator.frequency.setValueAtTime(maxNote, time);\n\t\tthis.oscillator.frequency.exponentialRampToValueAtTime(note, time + this.toSeconds(this.pitchDecay));\n\t\tthis.envelope.triggerAttack(time, velocity);\n\t\tthis.oscillator.start(time);\n\t\tif (this.envelope.sustain === 0){\n\t\t\tthis.oscillator.stop(time + this.envelope.attack + this.envelope.decay);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the release portion of the note.\n\t *\n\t *  @param  {Time} [time=now] the time the note will release\n\t *  @returns {Tone.MembraneSynth} this\n\t */\n\tTone.MembraneSynth.prototype.triggerRelease = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis.envelope.triggerRelease(time);\n\t\tthis.oscillator.stop(time + this.envelope.release);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.MembraneSynth} this\n\t */\n\tTone.MembraneSynth.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tthis._writable([\"oscillator\", \"envelope\"]);\n\t\tthis.oscillator.dispose();\n\t\tthis.oscillator = null;\n\t\tthis.envelope.dispose();\n\t\tthis.envelope = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MembraneSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/MembraneSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/MetalSynth.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/MetalSynth.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\"), __webpack_require__(/*! ../source/FMOscillator */ \"./node_modules/tone/Tone/source/FMOscillator.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"),\n\t__webpack_require__(/*! ../component/FrequencyEnvelope */ \"./node_modules/tone/Tone/component/FrequencyEnvelope.js\"), __webpack_require__(/*! ../component/AmplitudeEnvelope */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"),\n\t__webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/Tone/signal/Scale.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  Inharmonic ratio of frequencies based on the Roland TR-808\n\t *  Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model\n\t *  @private\n\t *  @static\n\t *  @type {Array}\n\t */\n\tvar inharmRatios = [1.0, 1.483, 1.932, 2.546, 2.630, 3.897];\n\n\t/**\n\t *  @class  A highly inharmonic and spectrally complex source with a highpass filter\n\t *          and amplitude envelope which is good for making metalophone sounds. Based\n\t *          on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n\t *          Inspiration from [Sound on Sound](https://web.archive.org/web/20160610143924/https://www.soundonsound.com/sos/jul02/articles/synthsecrets0702.asp).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Instrument}\n\t *  @param {Object} [options] The options availble for the synth\n\t *                             see defaults below\n\t */\n\tTone.MetalSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.MetalSynth.defaults);\n\t\tTone.Instrument.call(this, options);\n\n\t\t/**\n\t\t *  The frequency of the cymbal\n\t\t *  @type  {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The array of FMOscillators\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillators = [];\n\n\t\t/**\n\t\t *  The frequency multipliers\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._freqMultipliers = [];\n\n\t\t/**\n\t\t *  The amplitude for the body\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._amplitue = new Tone.Gain(0).connect(this.output);\n\n\t\t/**\n\t\t *  highpass the output\n\t\t *  @type {Tone.Filter}\n\t\t *  @private\n\t\t */\n\t\tthis._highpass = new Tone.Filter({\n\t\t\t\"type\" : \"highpass\",\n\t\t\t\"Q\" : -3.0102999566398125\n\t\t}).connect(this._amplitue);\n\n\t\t/**\n\t\t *  The number of octaves the highpass\n\t\t *  filter frequency ramps\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._octaves = options.octaves;\n\n\t\t/**\n\t\t *  Scale the body envelope\n\t\t *  for the bandpass\n\t\t *  @type {Tone.Scale}\n\t\t *  @private\n\t\t */\n\t\tthis._filterFreqScaler = new Tone.Scale(options.resonance, 7000);\n\n\t\t/**\n\t\t *  The envelope which is connected both to the\n\t\t *  amplitude and highpass filter's cutoff frequency\n\t\t *  @type  {Tone.Envelope}\n\t\t */\n\t\tthis.envelope = new Tone.Envelope({\n\t\t\t\"attack\" : options.envelope.attack,\n\t\t\t\"attackCurve\" : \"linear\",\n\t\t\t\"decay\" : options.envelope.decay,\n\t\t\t\"sustain\" : 0,\n\t\t\t\"release\" : options.envelope.release,\n\t\t}).chain(this._filterFreqScaler, this._highpass.frequency);\n\t\tthis.envelope.connect(this._amplitue.gain);\n\n\t\tfor (var i = 0; i < inharmRatios.length; i++){\n\t\t\tvar osc = new Tone.FMOscillator({\n\t\t\t\t\"type\" : \"square\",\n\t\t\t\t\"modulationType\" : \"square\",\n\t\t\t\t\"harmonicity\" : options.harmonicity,\n\t\t\t\t\"modulationIndex\" : options.modulationIndex\n\t\t\t});\n\t\t\tosc.connect(this._highpass);\n\t\t\tthis._oscillators[i] = osc;\n\n\t\t\tvar mult = new Tone.Multiply(inharmRatios[i]);\n\t\t\tthis._freqMultipliers[i] = mult;\n\t\t\tthis.frequency.chain(mult, osc.frequency);\n\t\t}\n\n\t\t//set the octaves\n\t\tthis.octaves = options.octaves;\n\n\t};\n\n\tTone.extend(Tone.MetalSynth, Tone.Instrument);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.MetalSynth.defaults = {\n\t\t\"frequency\" : 200,\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.001,\n\t\t\t\"decay\" : 1.4,\n\t\t\t\"release\" : 0.2\n\t\t},\n\t\t\"harmonicity\" : 5.1,\n\t\t\"modulationIndex\" : 32,\n\t\t\"resonance\" : 4000,\n\t\t\"octaves\" : 1.5\n\t};\n\n\t/**\n\t *  Trigger the attack.\n\t *  @param  {Time}  time      When the attack should be triggered.\n\t *  @param  {NormalRange}  [velocity=1]  The velocity that the envelope should be triggered at.\n\t *  @return  {Tone.MetalSynth}  this\n\t */\n\tTone.MetalSynth.prototype.triggerAttack = function(time, vel){\n\t\ttime = this.toSeconds(time);\n\t\tvel = Tone.defaultArg(vel, 1);\n\t\tthis.envelope.triggerAttack(time, vel);\n\t\tthis._oscillators.forEach(function(osc){\n\t\t\tosc.start(time);\n\t\t});\n\t\t//if the sustain is 0, stop the oscillator as well\n\t\tif (this.envelope.sustain === 0){\n\t\t\tthis._oscillators.forEach(function(osc){\n\t\t\t\tosc.stop(time + this.envelope.attack + this.envelope.decay);\n\t\t\t}.bind(this));\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the release of the envelope.\n\t *  @param  {Time}  time      When the release should be triggered.\n\t *  @return  {Tone.MetalSynth}  this\n\t */\n\tTone.MetalSynth.prototype.triggerRelease = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis.envelope.triggerRelease(time);\n\t\tthis._oscillators.forEach(function(osc){\n\t\t\tosc.stop(time + this.envelope.release);\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the instrument to the Transport. All subsequent calls of\n\t * [triggerAttack](#triggerattack) and [triggerRelease](#triggerrelease)\n\t * will be scheduled along the transport.\n\t * @example\n\t * synth.sync()\n\t * //schedule 3 notes when the transport first starts\n\t * synth.triggerAttackRelease('8n', 0)\n\t * synth.triggerAttackRelease('8n', '8n')\n\t * synth.triggerAttackRelease('8n', '4n')\n\t * //start the transport to hear the notes\n\t * Transport.start()\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.MetalSynth.prototype.sync = function(){\n\t\tthis._syncMethod(\"triggerAttack\", 0);\n\t\tthis._syncMethod(\"triggerRelease\", 0);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the attack and release of the envelope after the given\n\t *  duration.\n\t *  @param  {Time}  duration  The duration before triggering the release\n\t *  @param  {Time}  time      When the attack should be triggered.\n\t *  @param  {NormalRange}  [velocity=1]  The velocity that the envelope should be triggered at.\n\t *  @return  {Tone.MetalSynth}  this\n\t */\n\tTone.MetalSynth.prototype.triggerAttackRelease = function(duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tduration = this.toSeconds(duration);\n\t\tthis.triggerAttack(time, velocity);\n\t\tthis.triggerRelease(time + duration);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The modulationIndex of the oscillators which make up the source.\n\t *  see Tone.FMOscillator.modulationIndex\n\t *  @memberOf Tone.MetalSynth#\n\t *  @type {Positive}\n\t *  @name  modulationIndex\n\t */\n\tObject.defineProperty(Tone.MetalSynth.prototype, \"modulationIndex\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators[0].modulationIndex.value;\n\t\t},\n\t\tset : function(val){\n\t\t\tfor (var i = 0; i < this._oscillators.length; i++){\n\t\t\t\tthis._oscillators[i].modulationIndex.value = val;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The harmonicity of the oscillators which make up the source.\n\t *  see Tone.FMOscillator.harmonicity\n\t *  @memberOf Tone.MetalSynth#\n\t *  @type {Positive}\n\t *  @name  harmonicity\n\t */\n\tObject.defineProperty(Tone.MetalSynth.prototype, \"harmonicity\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators[0].harmonicity.value;\n\t\t},\n\t\tset : function(val){\n\t\t\tfor (var i = 0; i < this._oscillators.length; i++){\n\t\t\t\tthis._oscillators[i].harmonicity.value = val;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The frequency of the highpass filter attached to the envelope\n\t *  @memberOf Tone.MetalSynth#\n\t *  @type {Frequency}\n\t *  @name  resonance\n\t */\n\tObject.defineProperty(Tone.MetalSynth.prototype, \"resonance\", {\n\t\tget : function(){\n\t\t\treturn this._filterFreqScaler.min;\n\t\t},\n\t\tset : function(val){\n\t\t\tthis._filterFreqScaler.min = val;\n\t\t\tthis.octaves = this._octaves;\n\t\t}\n\t});\n\n\t/**\n\t *  The number of octaves above the \"resonance\" frequency\n\t *  that the filter ramps during the attack/decay envelope\n\t *  @memberOf Tone.MetalSynth#\n\t *  @type {Number}\n\t *  @name  octaves\n\t */\n\tObject.defineProperty(Tone.MetalSynth.prototype, \"octaves\", {\n\t\tget : function(){\n\t\t\treturn this._octaves;\n\t\t},\n\t\tset : function(octs){\n\t\t\tthis._octaves = octs;\n\t\t\tthis._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, octs);\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up\n\t *  @returns {Tone.MetalSynth} this\n\t */\n\tTone.MetalSynth.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tfor (var i = 0; i < this._oscillators.length; i++){\n\t\t\tthis._oscillators[i].dispose();\n\t\t\tthis._freqMultipliers[i].dispose();\n\t\t}\n\t\tthis._oscillators = null;\n\t\tthis._freqMultipliers = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis._filterFreqScaler.dispose();\n\t\tthis._filterFreqScaler = null;\n\t\tthis._amplitue.dispose();\n\t\tthis._amplitue = null;\n\t\tthis.envelope.dispose();\n\t\tthis.envelope = null;\n\t\tthis._highpass.dispose();\n\t\tthis._highpass = null;\n\t};\n\n\treturn Tone.MetalSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/MetalSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/MonoSynth.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/MonoSynth.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/AmplitudeEnvelope */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\"), __webpack_require__(/*! ../component/FrequencyEnvelope */ \"./node_modules/tone/Tone/component/FrequencyEnvelope.js\"), __webpack_require__(/*! ../source/OmniOscillator */ \"./node_modules/tone/Tone/source/OmniOscillator.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/Tone/instrument/Monophonic.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.MonoSynth is composed of one oscillator, one filter, and two envelopes.\n\t *          The amplitude of the Tone.Oscillator and the cutoff frequency of the\n\t *          Tone.Filter are controlled by Tone.Envelopes.\n\t *          <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Monophonic}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t *  @example\n\t * var synth = new Tone.MonoSynth({\n\t * \t\"oscillator\" : {\n\t * \t\t\"type\" : \"square\"\n\t *  },\n\t *  \"envelope\" : {\n\t *  \t\"attack\" : 0.1\n\t *  }\n\t * }).toMaster();\n\t * synth.triggerAttackRelease(\"C4\", \"8n\");\n\t */\n\tTone.MonoSynth = function(options){\n\n\t\t//get the defaults\n\t\toptions = Tone.defaultArg(options, Tone.MonoSynth.defaults);\n\t\tTone.Monophonic.call(this, options);\n\n\t\t/**\n\t\t *  The oscillator.\n\t\t *  @type {Tone.OmniOscillator}\n\t\t */\n\t\tthis.oscillator = new Tone.OmniOscillator(options.oscillator);\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this.oscillator.frequency;\n\n\t\t/**\n\t\t *  The detune control.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this.oscillator.detune;\n\n\t\t/**\n\t\t *  The filter.\n\t\t *  @type {Tone.Filter}\n\t\t */\n\t\tthis.filter = new Tone.Filter(options.filter);\n\t\tthis.filter.frequency.value = 5000;\n\n\t\t/**\n\t\t *  The filter envelope.\n\t\t *  @type {Tone.FrequencyEnvelope}\n\t\t */\n\t\tthis.filterEnvelope = new Tone.FrequencyEnvelope(options.filterEnvelope);\n\n\t\t/**\n\t\t *  The amplitude envelope.\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.envelope = new Tone.AmplitudeEnvelope(options.envelope);\n\n\t\t//connect the oscillators to the output\n\t\tthis.oscillator.chain(this.filter, this.envelope, this.output);\n\t\t//connect the filter envelope\n\t\tthis.filterEnvelope.connect(this.filter.frequency);\n\t\tthis._readOnly([\"oscillator\", \"frequency\", \"detune\", \"filter\", \"filterEnvelope\", \"envelope\"]);\n\t};\n\n\tTone.extend(Tone.MonoSynth, Tone.Monophonic);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.MonoSynth.defaults = {\n\t\t\"frequency\" : \"C4\",\n\t\t\"detune\" : 0,\n\t\t\"oscillator\" : {\n\t\t\t\"type\" : \"square\"\n\t\t},\n\t\t\"filter\" : {\n\t\t\t\"Q\" : 6,\n\t\t\t\"type\" : \"lowpass\",\n\t\t\t\"rolloff\" : -24\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.005,\n\t\t\t\"decay\" : 0.1,\n\t\t\t\"sustain\" : 0.9,\n\t\t\t\"release\" : 1\n\t\t},\n\t\t\"filterEnvelope\" : {\n\t\t\t\"attack\" : 0.06,\n\t\t\t\"decay\" : 0.2,\n\t\t\t\"sustain\" : 0.5,\n\t\t\t\"release\" : 2,\n\t\t\t\"baseFrequency\" : 200,\n\t\t\t\"octaves\" : 7,\n\t\t\t\"exponent\" : 2\n\t\t}\n\t};\n\n\t/**\n\t *  start the attack portion of the envelope\n\t *  @param {Time} [time=now] the time the attack should start\n\t *  @param {NormalRange} [velocity=1] the velocity of the note (0-1)\n\t *  @returns {Tone.MonoSynth} this\n\t *  @private\n\t */\n\tTone.MonoSynth.prototype._triggerEnvelopeAttack = function(time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\t//the envelopes\n\t\tthis.envelope.triggerAttack(time, velocity);\n\t\tthis.filterEnvelope.triggerAttack(time);\n\t\tthis.oscillator.start(time);\n\t\tif (this.envelope.sustain === 0){\n\t\t\tthis.oscillator.stop(time + this.envelope.attack + this.envelope.decay);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  start the release portion of the envelope\n\t *  @param {Time} [time=now] the time the release should start\n\t *  @returns {Tone.MonoSynth} this\n\t *  @private\n\t */\n\tTone.MonoSynth.prototype._triggerEnvelopeRelease = function(time){\n\t\tthis.envelope.triggerRelease(time);\n\t\tthis.filterEnvelope.triggerRelease(time);\n\t\tthis.oscillator.stop(time + this.envelope.release);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.MonoSynth} this\n\t */\n\tTone.MonoSynth.prototype.dispose = function(){\n\t\tTone.Monophonic.prototype.dispose.call(this);\n\t\tthis._writable([\"oscillator\", \"frequency\", \"detune\", \"filter\", \"filterEnvelope\", \"envelope\"]);\n\t\tthis.oscillator.dispose();\n\t\tthis.oscillator = null;\n\t\tthis.envelope.dispose();\n\t\tthis.envelope = null;\n\t\tthis.filterEnvelope.dispose();\n\t\tthis.filterEnvelope = null;\n\t\tthis.filter.dispose();\n\t\tthis.filter = null;\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.MonoSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/MonoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/Monophonic.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/Monophonic.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  This is an abstract base class for other monophonic instruments to \n\t *          extend. IMPORTANT: It does not make any sound on its own and\n\t *          shouldn't be directly instantiated.\n\t *\n\t *  @constructor\n\t *  @abstract\n\t *  @extends {Tone.Instrument}\n\t */\n\tTone.Monophonic = function(options){\n\n\t\t//get the defaults\n\t\toptions = Tone.defaultArg(options, Tone.Monophonic.defaults);\n\t\tTone.Instrument.call(this, options);\n\n\t\t/**\n\t\t *  The glide time between notes. \n\t\t *  @type {Time}\n\t\t */\n\t\tthis.portamento = options.portamento;\n\t};\n\n\tTone.extend(Tone.Monophonic, Tone.Instrument);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Monophonic.defaults = {\n\t\t\"portamento\" : 0\n\t};\n\n\t/**\n\t *  Trigger the attack of the note optionally with a given velocity. \n\t *  \n\t *  \n\t *  @param  {Frequency} note     The note to trigger.\n\t *  @param  {Time} [time=now]     When the note should start.\n\t *  @param  {number} [velocity=1] velocity The velocity scaler \n\t *                                determines how \"loud\" the note \n\t *                                will be triggered.\n\t *  @returns {Tone.Monophonic} this\n\t *  @example\n\t * synth.triggerAttack(\"C4\");\n\t *  @example\n\t * //trigger the note a half second from now at half velocity\n\t * synth.triggerAttack(\"C4\", \"+0.5\", 0.5);\n\t */\n\tTone.Monophonic.prototype.triggerAttack = function(note, time, velocity){\n\t\tthis.log(\"triggerAttack\", note, time, velocity);\n\t\ttime = this.toSeconds(time);\n\t\tthis._triggerEnvelopeAttack(time, velocity);\n\t\tthis.setNote(note, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the release portion of the envelope\n\t *  @param  {Time} [time=now] If no time is given, the release happens immediatly\n\t *  @returns {Tone.Monophonic} this\n\t *  @example\n\t * synth.triggerRelease();\n\t */\n\tTone.Monophonic.prototype.triggerRelease = function(time){\n\t\tthis.log(\"triggerRelease\", time);\n\t\ttime = this.toSeconds(time);\n\t\tthis._triggerEnvelopeRelease(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  override this method with the actual method\n\t *  @abstract\n\t *  @private\n\t */\t\n\tTone.Monophonic.prototype._triggerEnvelopeAttack = function(){};\n\n\t/**\n\t *  override this method with the actual method\n\t *  @abstract\n\t *  @private\n\t */\t\n\tTone.Monophonic.prototype._triggerEnvelopeRelease = function(){};\n\n\t/**\n\t *  Get the level of the output at the given time. Measures\n\t *  the envelope(s) value at the time. \n\t *  @param {Time} time The time to query the envelope value\n\t *  @return {NormalRange} The output level between 0-1\n\t */\n\tTone.Monophonic.prototype.getLevelAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\treturn this.envelope.getValueAtTime(time);\n\t};\n\n\t/**\n\t *  Set the note at the given time. If no time is given, the note\n\t *  will set immediately. \n\t *  @param {Frequency} note The note to change to.\n\t *  @param  {Time} [time=now] The time when the note should be set. \n\t *  @returns {Tone.Monophonic} this\n\t * @example\n\t * //change to F#6 in one quarter note from now.\n\t * synth.setNote(\"F#6\", \"+4n\");\n\t * @example\n\t * //change to Bb4 right now\n\t * synth.setNote(\"Bb4\");\n\t */\n\tTone.Monophonic.prototype.setNote = function(note, time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this.portamento > 0 && this.getLevelAtTime(time) > 0.05){\n\t\t\tvar portTime = this.toSeconds(this.portamento);\n\t\t\tthis.frequency.exponentialRampTo(note, portTime, time);\n\t\t} else {\n\t\t\tthis.frequency.setValueAtTime(note, time);\n\t\t}\n\t\treturn this;\n\t};\n\n\treturn Tone.Monophonic;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/Monophonic.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/NoiseSynth.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/NoiseSynth.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/AmplitudeEnvelope */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\"), __webpack_require__(/*! ../component/FrequencyEnvelope */ \"./node_modules/tone/Tone/component/FrequencyEnvelope.js\"),\n\t__webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/Tone/source/Noise.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../component/Filter */ \"./node_modules/tone/Tone/component/Filter.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.NoiseSynth is composed of a noise generator (Tone.Noise), one filter (Tone.Filter),\n\t *          and two envelopes (Tone.Envelop). One envelope controls the amplitude\n\t *          of the noise and the other is controls the cutoff frequency of the filter.\n\t *          <img src=\"https://docs.google.com/drawings/d/1rqzuX9rBlhT50MRvD2TKml9bnZhcZmzXF1rf_o7vdnE/pub?w=918&h=242\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Instrument}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t * @example\n\t * var noiseSynth = new Tone.NoiseSynth().toMaster();\n\t * noiseSynth.triggerAttackRelease(\"8n\");\n\t */\n\tTone.NoiseSynth = function(options){\n\n\t\t//get the defaults\n\t\toptions = Tone.defaultArg(options, Tone.NoiseSynth.defaults);\n\t\tTone.Instrument.call(this, options);\n\n\t\t/**\n\t\t *  The noise source.\n\t\t *  @type {Tone.Noise}\n\t\t *  @example\n\t\t * noiseSynth.set(\"noise.type\", \"brown\");\n\t\t */\n\t\tthis.noise = new Tone.Noise(options.noise);\n\n\t\t/**\n\t\t *  The amplitude envelope.\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.envelope = new Tone.AmplitudeEnvelope(options.envelope);\n\n\t\t//connect the noise to the output\n\t\tthis.noise.chain(this.envelope, this.output);\n\t\tthis._readOnly([\"noise\", \"envelope\"]);\n\t};\n\n\tTone.extend(Tone.NoiseSynth, Tone.Instrument);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.NoiseSynth.defaults = {\n\t\t\"noise\" : {\n\t\t\t\"type\" : \"white\"\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.005,\n\t\t\t\"decay\" : 0.1,\n\t\t\t\"sustain\" : 0.0,\n\t\t}\n\t};\n\n\t/**\n\t *  Start the attack portion of the envelopes. Unlike other\n\t *  instruments, Tone.NoiseSynth doesn't have a note.\n\t *  @param {Time} [time=now] the time the attack should start\n\t *  @param {number} [velocity=1] the velocity of the note (0-1)\n\t *  @returns {Tone.NoiseSynth} this\n\t *  @example\n\t * noiseSynth.triggerAttack();\n\t */\n\tTone.NoiseSynth.prototype.triggerAttack = function(time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\t//the envelopes\n\t\tthis.envelope.triggerAttack(time, velocity);\n\t\t//start the noise\n\t\tthis.noise.start(time);\n\t\tif (this.envelope.sustain === 0){\n\t\t\tthis.noise.stop(time + this.envelope.attack + this.envelope.decay);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Start the release portion of the envelopes.\n\t *  @param {Time} [time=now] the time the release should start\n\t *  @returns {Tone.NoiseSynth} this\n\t */\n\tTone.NoiseSynth.prototype.triggerRelease = function(time){\n\t\tthis.envelope.triggerRelease(time);\n\t\tthis.noise.stop(time + this.envelope.release);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the instrument to the Transport. All subsequent calls of\n\t * [triggerAttack](#triggerattack) and [triggerRelease](#triggerrelease)\n\t * will be scheduled along the transport.\n\t * @example\n\t * synth.sync()\n\t * //schedule 3 notes when the transport first starts\n\t * synth.triggerAttackRelease('8n', 0)\n\t * synth.triggerAttackRelease('8n', '8n')\n\t * synth.triggerAttackRelease('8n', '4n')\n\t * //start the transport to hear the notes\n\t * Transport.start()\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.NoiseSynth.prototype.sync = function(){\n\t\tthis._syncMethod(\"triggerAttack\", 0);\n\t\tthis._syncMethod(\"triggerRelease\", 0);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the attack and then the release.\n\t *  @param  {Time} duration the duration of the note\n\t *  @param  {Time} [time=now]     the time of the attack\n\t *  @param  {number} [velocity=1] the velocity\n\t *  @returns {Tone.NoiseSynth} this\n\t */\n\tTone.NoiseSynth.prototype.triggerAttackRelease = function(duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tduration = this.toSeconds(duration);\n\t\tthis.triggerAttack(time, velocity);\n\t\tthis.triggerRelease(time + duration);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.NoiseSynth} this\n\t */\n\tTone.NoiseSynth.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tthis._writable([\"noise\", \"envelope\"]);\n\t\tthis.noise.dispose();\n\t\tthis.noise = null;\n\t\tthis.envelope.dispose();\n\t\tthis.envelope = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.NoiseSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/NoiseSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/PluckSynth.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/PluckSynth.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\"), __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/Tone/source/Noise.js\"), __webpack_require__(/*! ../component/LowpassCombFilter */ \"./node_modules/tone/Tone/component/LowpassCombFilter.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Karplus-String string synthesis. Often out of tune.\n\t *         Will change when the AudioWorkerNode is available across\n\t *         browsers.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Instrument}\n\t *  @param {Object} [options] see the defaults\n\t *  @example\n\t * var plucky = new Tone.PluckSynth().toMaster();\n\t * plucky.triggerAttack(\"C4\");\n\t */\n\tTone.PluckSynth = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.PluckSynth.defaults);\n\t\tTone.Instrument.call(this, options);\n\n\t\t/**\n\t\t *  @type {Tone.Noise}\n\t\t *  @private\n\t\t */\n\t\tthis._noise = new Tone.Noise(\"pink\");\n\n\t\t/**\n\t\t *  The amount of noise at the attack.\n\t\t *  Nominal range of [0.1, 20]\n\t\t *  @type {number}\n\t\t */\n\t\tthis.attackNoise = options.attackNoise;\n\n\t\t/**\n\t\t *  the LFCF\n\t\t *  @type {Tone.LowpassCombFilter}\n\t\t *  @private\n\t\t */\n\t\tthis._lfcf = new Tone.LowpassCombFilter({\n\t\t\t\"resonance\" : options.resonance,\n\t\t\t\"dampening\" : options.dampening\n\t\t});\n\n\t\t/**\n\t\t *  The resonance control.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.resonance = this._lfcf.resonance;\n\n\t\t/**\n\t\t *  The dampening control. i.e. the lowpass filter frequency of the comb filter\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.dampening = this._lfcf.dampening;\n\n\t\t//connections\n\t\tthis._noise.connect(this._lfcf);\n\t\tthis._lfcf.connect(this.output);\n\t\tthis._readOnly([\"resonance\", \"dampening\"]);\n\t};\n\n\tTone.extend(Tone.PluckSynth, Tone.Instrument);\n\n\t/**\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.PluckSynth.defaults = {\n\t\t\"attackNoise\" : 1,\n\t\t\"dampening\" : 4000,\n\t\t\"resonance\" : 0.7\n\t};\n\n\t/**\n\t *  Trigger the note.\n\t *  @param {Frequency} note The note to trigger.\n\t *  @param {Time} [time=now] When the note should be triggered.\n\t *  @returns {Tone.PluckSynth} this\n\t */\n\tTone.PluckSynth.prototype.triggerAttack = function(note, time){\n\t\tnote = this.toFrequency(note);\n\t\ttime = this.toSeconds(time);\n\t\tvar delayAmount = 1 / note;\n\t\tthis._lfcf.delayTime.setValueAtTime(delayAmount, time);\n\t\tthis._noise.start(time);\n\t\tthis._noise.stop(time + delayAmount * this.attackNoise);\n\t\treturn this;\n\t};\n\n\t/**\n\t *\tMake this method which belongs to the parent class private since\n\t *\tPluckSynth does not have any 'release' method.\n\t * \t@memberOf Tone.PluckSynth#\n\t *  @function\n\t *  @private\n\t *  @name triggerAttackRelease\n\t */\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.PluckSynth} this\n\t */\n\tTone.PluckSynth.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tthis._noise.dispose();\n\t\tthis._lfcf.dispose();\n\t\tthis._noise = null;\n\t\tthis._lfcf = null;\n\t\tthis._writable([\"resonance\", \"dampening\"]);\n\t\tthis.dampening = null;\n\t\tthis.resonance = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PluckSynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/PluckSynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/PolySynth.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/PolySynth.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Synth */ \"./node_modules/tone/Tone/instrument/Synth.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.PolySynth handles voice creation and allocation for any\n\t *          instruments passed in as the second paramter. PolySynth is\n\t *          not a synthesizer by itself, it merely manages voices of\n\t *          one of the other types of synths, allowing any of the\n\t *          monophonic synthesizers to be polyphonic.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Instrument}\n\t *  @param {number|Object} [polyphony=4] The number of voices to create\n\t *  @param {function} [voice=Tone.Synth] The constructor of the voices\n\t *                                            uses Tone.Synth by default.\n\t *  @example\n\t * //a polysynth composed of 6 Voices of Synth\n\t * var synth = new Tone.PolySynth(6, Tone.Synth).toMaster();\n\t * //set the attributes using the set interface\n\t * synth.set(\"detune\", -1200);\n\t * //play a chord\n\t * synth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], \"4n\");\n\t */\n\tTone.PolySynth = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"polyphony\", \"voice\"], Tone.PolySynth);\n\t\tTone.Instrument.call(this, options);\n\t\toptions = Tone.defaultArg(options, Tone.Instrument.defaults);\n\n\t\t//max polyphony\n\t\toptions.polyphony = Math.min(Tone.PolySynth.MAX_POLYPHONY, options.polyphony);\n\n\t\t/**\n\t\t *  the array of voices\n\t\t *  @type {Array}\n\t\t */\n\t\tthis.voices = new Array(options.polyphony);\n\t\tthis.assert(options.polyphony > 0, \"polyphony must be greater than 0\");\n\n\t\t/**\n\t\t *  The detune in cents\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\t\tthis._readOnly(\"detune\");\n\n\t\t//create the voices\n\t\tfor (var i = 0; i < options.polyphony; i++){\n\t\t\tvar v = new options.voice(arguments[2], arguments[3]);\n\t\t\tif (!(v instanceof Tone.Monophonic)){\n\t\t\t\tthrow new Error(\"Synth constructor must be instance of Tone.Monophonic\");\n\t\t\t}\n\t\t\tthis.voices[i] = v;\n\t\t\tv.index = i;\n\t\t\tv.connect(this.output);\n\t\t\tif (v.hasOwnProperty(\"detune\")){\n\t\t\t\tthis.detune.connect(v.detune);\n\t\t\t}\n\t\t}\n\t};\n\n\tTone.extend(Tone.PolySynth, Tone.Instrument);\n\n\t/**\n\t *  the defaults\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.PolySynth.defaults = {\n\t\t\"polyphony\" : 4,\n\t\t\"volume\" : 0,\n\t\t\"detune\" : 0,\n\t\t\"voice\" : Tone.Synth\n\t};\n\n\t/**\n\t *  Get the closest available voice, that is the\n\t *  one that is either the closest to the note,\n\t *  or has the lowest envelope value.\n\t *  @param {Time} time return the voice that has the lowest energy at this time.\n\t *  @param  {Note}  note  if there is a voice with this note, that should be returned\n\t *  @return  {Tone.Monophonic}  A synth voice.\n\t *  @private\n\t */\n\tTone.PolySynth.prototype._getClosestVoice = function(time, note){\n\t\t//play the note which has the same frequency, if that exists\n\t\tvar sameNote = this.voices.find(function(voice){\n\t\t\t//break if it's within a small epsion of the voice's frequency\n\t\t\tif (Math.abs(voice.frequency.getValueAtTime(time) - Tone.Frequency(note)) < 1e-4 && \n\t\t\t\t//and that note is currently active\n\t\t\t\tvoice.getLevelAtTime(time) > 1e-5){\n\t\t\t\treturn voice;\n\t\t\t} \n\t\t});\n\t\tif (sameNote){\n\t\t\treturn sameNote;\n\t\t}\n\n\t\tvar sortedVoices = this.voices.slice().sort(function(a, b){\n\t\t\t//check that it's not scheduled in the future\n\t\t\tvar aLevel = a.getLevelAtTime(time + this.blockTime);\n\t\t\tvar bLevel = b.getLevelAtTime(time + this.blockTime);\n\n\t\t\tvar silenceThresh = 1e-5;\n\t\t\tif (aLevel < silenceThresh){\n\t\t\t\taLevel = 0;\n\t\t\t}\n\t\t\tif (bLevel < silenceThresh){\n\t\t\t\tbLevel = 0;\n\t\t\t}\n\t\t\treturn aLevel - bLevel;\n\t\t}.bind(this));\n\n\t\treturn sortedVoices[0];\n\t};\n\n\t/**\n\t *  Trigger the attack portion of the note\n\t *  @param  {Frequency|Array} notes The notes to play. Accepts a single\n\t *                                  Frequency or an array of frequencies.\n\t *  @param  {Time} [time=now]  The start time of the note.\n\t *  @param {number} [velocity=1] The velocity of the note.\n\t *  @returns {Tone.PolySynth} this\n\t *  @example\n\t * //trigger a chord immediately with a velocity of 0.2\n\t * poly.triggerAttack([\"Ab3\", \"C4\", \"F5\"], undefined, 0.2);\n\t */\n\tTone.PolySynth.prototype.triggerAttack = function(notes, time, velocity){\n\t\tif (!Array.isArray(notes)){\n\t\t\tnotes = [notes];\n\t\t}\n\t\ttime = this.toSeconds(time);\n\t\tnotes.forEach(function(note){\n\t\t\tvar voice = this._getClosestVoice(time, note);\n\t\t\tvoice.triggerAttack(note, time, velocity);\n\t\t\tthis.log(\"triggerAttack\", voice.index, note);\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the release of the note. Unlike monophonic instruments,\n\t *  a note (or array of notes) needs to be passed in as the first argument.\n\t *  @param  {Frequency|Array} notes The notes to play. Accepts a single\n\t *                                  Frequency or an array of frequencies.\n\t *  @param  {Time} [time=now]  When the release will be triggered.\n\t *  @returns {Tone.PolySynth} this\n\t *  @example\n\t * poly.triggerRelease([\"Ab3\", \"C4\", \"F5\"], \"+2n\");\n\t */\n\tTone.PolySynth.prototype.triggerRelease = function(notes, time){\n\t\tif (!Array.isArray(notes)){\n\t\t\tnotes = [notes];\n\t\t}\n\t\ttime = this.toSeconds(time);\n\t\tnotes.forEach(function(note){\n\t\t\tvar voice = this._getClosestVoice(time, note);\n\t\t\tthis.log(\"triggerRelease\", voice.index, note);\n\t\t\tvoice.triggerRelease(time);\n\t\t}.bind(this));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Trigger the attack and release after the specified duration\n\t *\n\t *  @param  {Frequency|Array} notes The notes to play. Accepts a single\n\t *                                  Frequency or an array of frequencies.\n\t *  @param  {Time} duration the duration of the note\n\t *  @param  {Time} [time=now]     if no time is given, defaults to now\n\t *  @param  {number} [velocity=1] the velocity of the attack (0-1)\n\t *  @returns {Tone.PolySynth} this\n\t *  @example\n\t * //trigger a chord for a duration of a half note\n\t * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"C5\"], \"2n\");\n\t *  @example\n\t * //can pass in an array of durations as well\n\t * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"C5\"], [\"2n\", \"4n\", \"4n\"]);\n\t */\n\tTone.PolySynth.prototype.triggerAttackRelease = function(notes, duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tthis.triggerAttack(notes, time, velocity);\n\t\tif (Tone.isArray(duration) && Tone.isArray(notes)){\n\t\t\tfor (var i = 0; i < notes.length; i++){\n\t\t\t\tvar d = duration[Math.min(i, duration.length - 1)];\n\t\t\t\tthis.triggerRelease(notes[i], time + this.toSeconds(d));\n\t\t\t}\n\t\t} else {\n\t\t\tthis.triggerRelease(notes, time + this.toSeconds(duration));\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the instrument to the Transport. All subsequent calls of\n\t * [triggerAttack](#triggerattack) and [triggerRelease](#triggerrelease)\n\t * will be scheduled along the transport.\n\t * @example\n\t * synth.sync()\n\t * //schedule 3 notes when the transport first starts\n\t * synth.triggerAttackRelease('8n', 0)\n\t * synth.triggerAttackRelease('8n', '8n')\n\t * synth.triggerAttackRelease('8n', '4n')\n\t * //start the transport to hear the notes\n\t * Transport.start()\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.PolySynth.prototype.sync = function(){\n\t\tthis._syncMethod(\"triggerAttack\", 1);\n\t\tthis._syncMethod(\"triggerRelease\", 1);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Set a member/attribute of the voices.\n\t *  @param {Object|string} params\n\t *  @param {number=} value\n\t *  @param {Time=} rampTime\n\t *  @returns {Tone.PolySynth} this\n\t *  @example\n\t * poly.set({\n\t * \t\"filter\" : {\n\t * \t\t\"type\" : \"highpass\"\n\t * \t},\n\t * \t\"envelope\" : {\n\t * \t\t\"attack\" : 0.25\n\t * \t}\n\t * });\n\t */\n\tTone.PolySynth.prototype.set = function(params, value, rampTime){\n\t\tfor (var i = 0; i < this.voices.length; i++){\n\t\t\tthis.voices[i].set(params, value, rampTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the synth's attributes. Given no arguments get\n\t *  will return all available object properties and their corresponding\n\t *  values. Pass in a single attribute to retrieve or an array\n\t *  of attributes. The attribute strings can also include a \".\"\n\t *  to access deeper properties.\n\t *  @param {Array=} params the parameters to get, otherwise will return\n\t *  \t\t\t\t\t   all available.\n\t */\n\tTone.PolySynth.prototype.get = function(params){\n\t\treturn this.voices[0].get(params);\n\t};\n\n\t/**\n\t *  Trigger the release portion of all the currently active voices.\n\t *  @param {Time} [time=now] When the notes should be released.\n\t *  @return {Tone.PolySynth} this\n\t */\n\tTone.PolySynth.prototype.releaseAll = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis.voices.forEach(function(voice){\n\t\t\tvoice.triggerRelease(time);\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.PolySynth} this\n\t */\n\tTone.PolySynth.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tthis.voices.forEach(function(voice){\n\t\t\tvoice.dispose();\n\t\t});\n\t\tthis._writable(\"detune\");\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis.voices = null;\n\t\treturn this;\n\t};\n\n\t/**\n\t *  The maximum number of notes that can be allocated\n\t *  to a polysynth.\n\t *  @type  {Number}\n\t *  @static\n\t */\n\tTone.PolySynth.MAX_POLYPHONY = 20;\n\n\treturn Tone.PolySynth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/PolySynth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/Sampler.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/Sampler.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/Tone/instrument/Instrument.js\"), __webpack_require__(/*! ../core/Buffers */ \"./node_modules/tone/Tone/core/Buffers.js\"), __webpack_require__(/*! ../source/BufferSource */ \"./node_modules/tone/Tone/source/BufferSource.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t * @class Automatically interpolates between a set of pitched samples. Pass in an object which maps the note's pitch or midi value to the url, then you can trigger the attack and release of that note like other instruments. By automatically repitching the samples, it is possible to play pitches which were not explicitly included which can save loading time.\n\t *        For sample or buffer playback where repitching is not necessary, use [Tone.Player](https://tonejs.github.io/docs/Player).\n\t * @param {Object} samples An object of samples mapping either Midi\n\t *                         Note Numbers or Scientific Pitch Notation\n\t *                         to the url of that sample.\n\t * @param {Function=} onload The callback to invoke when all of the samples are loaded.\n\t * @param {String=} baseUrl The root URL of all of the samples, which is prepended to all the URLs.\n\t * @example\n\t * var sampler = new Tone.Sampler({\n\t * \t\"C3\" : \"path/to/C3.mp3\",\n\t * \t\"D#3\" : \"path/to/Dsharp3.mp3\",\n\t * \t\"F#3\" : \"path/to/Fsharp3.mp3\",\n\t * \t\"A3\" : \"path/to/A3.mp3\",\n\t * }, function(){\n\t * \t//sampler will repitch the closest sample\n\t * \tsampler.triggerAttack(\"D3\")\n\t * })\n\t * @extends {Tone.Instrument}\n\t */\n\tTone.Sampler = function(urls){\n\n\t\t// shift arguments over one. Those are the remainder of the options\n\t\tvar args = Array.prototype.slice.call(arguments);\n\t\targs.shift();\n\t\tvar options = Tone.defaults(args, [\"onload\", \"baseUrl\"], Tone.Sampler);\n\t\tTone.Instrument.call(this, options);\n\n\t\tvar urlMap = {};\n\t\tfor (var note in urls){\n\t\t\tif (Tone.isNote(note)){\n\t\t\t\t//convert the note name to MIDI\n\t\t\t\tvar mid = Tone.Frequency(note).toMidi();\n\t\t\t\turlMap[mid] = urls[note];\n\t\t\t} else if (!isNaN(parseFloat(note))){\n\t\t\t\t//otherwise if it's numbers assume it's midi\n\t\t\t\turlMap[note] = urls[note];\n\t\t\t} else {\n\t\t\t\tthrow new Error(\"Tone.Sampler: url keys must be the note's pitch\");\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * The stored and loaded buffers\n\t\t * @type {Tone.Buffers}\n\t\t * @private\n\t\t */\n\t\tthis._buffers = new Tone.Buffers(urlMap, options.onload, options.baseUrl);\n\n\t\t/**\n\t\t * The object of all currently playing BufferSources\n\t\t * @type {Object}\n\t\t * @private\n\t\t */\n\t\tthis._activeSources = {};\n\n\t\t/**\n\t\t * The envelope applied to the beginning of the sample.\n\t\t * @type {Time}\n\t\t */\n\t\tthis.attack = options.attack;\n\n\t\t/**\n\t\t * The envelope applied to the end of the envelope.\n\t\t * @type {Time}\n\t\t */\n\t\tthis.release = options.release;\n\n\t\t/**\n\t\t *  The shape of the attack/release curve.\n\t\t *  Either \"linear\" or \"exponential\"\n\t\t *  @type {String}\n\t\t */\n\t\tthis.curve = options.curve;\n\t};\n\n\tTone.extend(Tone.Sampler, Tone.Instrument);\n\n\t/**\n\t * The defaults\n\t * @const\n\t * @type {Object}\n\t */\n\tTone.Sampler.defaults = {\n\t\t\"attack\" : 0,\n\t\t\"release\" : 0.1,\n\t\t\"onload\" : Tone.noOp,\n\t\t\"baseUrl\" : \"\",\n\t\t\"curve\" : \"exponential\"\n\t};\n\n\t/**\n\t * Returns the difference in steps between the given midi note at the closets sample.\n\t * @param  {Midi} midi\n\t * @return {Interval}\n\t * @private\n\t */\n\tTone.Sampler.prototype._findClosest = function(midi){\n\t\t//searches within 8 octaves of the given midi note\n\t\tvar MAX_INTERVAL = 96; \n\t\tvar interval = 0;\n\t\twhile (interval < MAX_INTERVAL){\n\t\t\t// check above and below\n\t\t\tif (this._buffers.has(midi + interval)){\n\t\t\t\treturn -interval;\n\t\t\t} else if (this._buffers.has(midi - interval)){\n\t\t\t\treturn interval;\n\t\t\t}\n\t\t\tinterval++;\n\t\t}\n\t\treturn null;\n\t};\n\n\t/**\n\t * @param  {Frequency} note     The note to play\n\t * @param  {Time=} time     When to play the note\n\t * @param  {NormalRange=} velocity The velocity to play the sample back.\n\t * @return {Tone.Sampler}          this\n\t */\n\tTone.Sampler.prototype.triggerAttack = function(notes, time, velocity){\n\t\tthis.log(\"triggerAttack\", notes, time, velocity);\n\t\tif (!Array.isArray(notes)){\n\t\t\tnotes = [notes];\n\t\t}\n\t\tfor (var i = 0; i < notes.length; i++){ \n\t\t\tvar midi = Tone.Frequency(notes[i]).toMidi();\n\t\t\t// find the closest note pitch\n\t\t\tvar difference = this._findClosest(midi);\n\t\t\tif (difference !== null){\n\t\t\t\tvar closestNote = midi - difference;\n\t\t\t\tvar buffer = this._buffers.get(closestNote);\n\t\t\t\tvar playbackRate = Tone.intervalToFrequencyRatio(difference);\n\t\t\t\t// play that note\n\t\t\t\tvar source = new Tone.BufferSource({\n\t\t\t\t\t\"buffer\" : buffer,\n\t\t\t\t\t\"playbackRate\" : playbackRate,\n\t\t\t\t\t\"fadeIn\" : this.attack,\n\t\t\t\t\t\"fadeOut\" : this.release,\n\t\t\t\t\t\"curve\" : this.curve,\n\t\t\t\t}).connect(this.output);\n\t\t\t\tsource.start(time, 0, buffer.duration / playbackRate, velocity);\n\t\t\t\t// add it to the active sources\n\t\t\t\tif (!Tone.isArray(this._activeSources[midi])){\n\t\t\t\t\tthis._activeSources[midi] = [];\n\t\t\t\t}\n\t\t\t\tthis._activeSources[midi].push(source);\n\n\t\t\t\t//remove it when it's done\n\t\t\t\tsource.onended = function(){\n\t\t\t\t\tif (this._activeSources && this._activeSources[midi]){\n\t\t\t\t\t\tvar index = this._activeSources[midi].indexOf(source);\n\t\t\t\t\t\tif (index !== -1){\n\t\t\t\t\t\t\tthis._activeSources[midi].splice(index, 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}.bind(this);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * @param  {Frequency} note     The note to release.\n\t * @param  {Time=} time     \tWhen to release the note.\n\t * @return {Tone.Sampler}\tthis\n\t */\n\tTone.Sampler.prototype.triggerRelease = function(notes, time){\n\t\tthis.log(\"triggerRelease\", notes, time);\n\t\tif (!Array.isArray(notes)){\n\t\t\tnotes = [notes];\n\t\t}\n\t\tfor (var i = 0; i < notes.length; i++){  \n\t\t\tvar midi = Tone.Frequency(notes[i]).toMidi();\n\t\t\t// find the note\n\t\t\tif (this._activeSources[midi] && this._activeSources[midi].length){\n\t\t\t\tvar source = this._activeSources[midi].shift();\n\t\t\t\ttime = this.toSeconds(time);\n\t\t\t\tsource.stop(time);\n\t\t\t}\n\t\t}\n\n\t\treturn this;\n\t};\n\n\t/**\n\t * Release all currently active notes.\n\t * @param  {Time=} time     \tWhen to release the notes.\n\t * @return {Tone.Sampler}\tthis\n\t */\n\tTone.Sampler.prototype.releaseAll = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tfor (var note in this._activeSources){\n\t\t\tvar sources = this._activeSources[note];\n\t\t\twhile (sources.length){\n\t\t\t\tvar source = sources.shift();\n\t\t\t\tsource.stop(time);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Sync the instrument to the Transport. All subsequent calls of\n\t * [triggerAttack](#triggerattack) and [triggerRelease](#triggerrelease)\n\t * will be scheduled along the transport.\n\t * @example\n\t * synth.sync()\n\t * //schedule 3 notes when the transport first starts\n\t * synth.triggerAttackRelease('8n', 0)\n\t * synth.triggerAttackRelease('8n', '8n')\n\t * synth.triggerAttackRelease('8n', '4n')\n\t * //start the transport to hear the notes\n\t * Transport.start()\n\t * @returns {Tone.Instrument} this\n\t */\n\tTone.Sampler.prototype.sync = function(){\n\t\tthis._syncMethod(\"triggerAttack\", 1);\n\t\tthis._syncMethod(\"triggerRelease\", 1);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Invoke the attack phase, then after the duration, invoke the release.\n\t * @param  {Frequency} note     The note to play\n\t * @param  {Time} duration The time the note should be held\n\t * @param  {Time=} time     When to start the attack\n\t * @param  {NormalRange} [velocity=1] The velocity of the attack\n\t * @return {Tone.Sampler}          this\n\t */\n\tTone.Sampler.prototype.triggerAttackRelease = function(notes, duration, time, velocity){\n\t\ttime = this.toSeconds(time);\n\t\tthis.triggerAttack(notes, time, velocity);\n\t\tif (Tone.isArray(duration) && Tone.isArray(notes)){\n\t\t\tfor (var i = 0; i < notes.length; i++){\n\t\t\t\tvar d = duration[Math.min(i, duration.length - 1)];\n\t\t\t\tthis.triggerRelease(notes[i], time + this.toSeconds(d));\n\t\t\t}\n\t\t} else {\n\t\t\tthis.triggerRelease(notes, time + this.toSeconds(duration));\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Add a note to the sampler.\n\t *  @param  {Note|Midi}   note      The buffer's pitch.\n\t *  @param  {String|Tone.Buffer|Audiobuffer}  url  Either the url of the bufer,\n\t *                                                 or a buffer which will be added\n\t *                                                 with the given name.\n\t *  @param  {Function=}  callback  The callback to invoke\n\t *                                 when the url is loaded.\n\t */\n\tTone.Sampler.prototype.add = function(note, url, callback){\n\t\tif (Tone.isNote(note)){\n\t\t\t//convert the note name to MIDI\n\t\t\tvar mid = Tone.Frequency(note).toMidi();\n\t\t\tthis._buffers.add(mid, url, callback);\n\t\t} else if (!isNaN(parseFloat(note))){\n\t\t\t//otherwise if it's numbers assume it's midi\n\t\t\tthis._buffers.add(note, url, callback);\n\t\t} else {\n\t\t\tthrow new Error(\"Tone.Sampler: note must be the note's pitch. Instead got \"+note);\n\t\t}\n\t};\n\n\t/**\n\t * If the buffers are loaded or not\n\t * @memberOf Tone.Sampler#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Sampler.prototype, \"loaded\", {\n\t\t\"get\" : function(){\n\t\t\treturn this._buffers.loaded;\n\t\t}\n\t});\n\n\t/**\n\t * Clean up\n\t * @return {Tone.Sampler} this\n\t */\n\tTone.Sampler.prototype.dispose = function(){\n\t\tTone.Instrument.prototype.dispose.call(this);\n\t\tthis._buffers.dispose();\n\t\tthis._buffers = null;\n\t\tfor (var midi in this._activeSources){\n\t\t\tthis._activeSources[midi].forEach(function(source){\n\t\t\t\tsource.dispose();\n\t\t\t});\n\t\t}\n\t\tthis._activeSources = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Sampler;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/Sampler.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/instrument/Synth.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/instrument/Synth.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/AmplitudeEnvelope */ \"./node_modules/tone/Tone/component/AmplitudeEnvelope.js\"), __webpack_require__(/*! ../source/OmniOscillator */ \"./node_modules/tone/Tone/source/OmniOscillator.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/Tone/instrument/Monophonic.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Synth is composed simply of a Tone.OmniOscillator\n\t *          routed through a Tone.AmplitudeEnvelope.\n\t *          <img src=\"https://docs.google.com/drawings/d/1-1_0YW2Z1J2EPI36P8fNCMcZG7N1w1GZluPs4og4evo/pub?w=1163&h=231\">\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Monophonic}\n\t *  @param {Object} [options] the options available for the synth\n\t *                          see defaults below\n\t *  @example\n\t * var synth = new Tone.Synth().toMaster();\n\t * synth.triggerAttackRelease(\"C4\", \"8n\");\n\t */\n\tTone.Synth = function(options){\n\n\t\t//get the defaults\n\t\toptions = Tone.defaultArg(options, Tone.Synth.defaults);\n\t\tTone.Monophonic.call(this, options);\n\n\t\t/**\n\t\t *  The oscillator.\n\t\t *  @type {Tone.OmniOscillator}\n\t\t */\n\t\tthis.oscillator = new Tone.OmniOscillator(options.oscillator);\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this.oscillator.frequency;\n\n\t\t/**\n\t\t *  The detune control.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this.oscillator.detune;\n\n\t\t/**\n\t\t *  The amplitude envelope.\n\t\t *  @type {Tone.AmplitudeEnvelope}\n\t\t */\n\t\tthis.envelope = new Tone.AmplitudeEnvelope(options.envelope);\n\n\t\t//connect the oscillators to the output\n\t\tthis.oscillator.chain(this.envelope, this.output);\n\t\tthis._readOnly([\"oscillator\", \"frequency\", \"detune\", \"envelope\"]);\n\t};\n\n\tTone.extend(Tone.Synth, Tone.Monophonic);\n\n\t/**\n\t *  @const\n\t *  @static\n\t *  @type {Object}\n\t */\n\tTone.Synth.defaults = {\n\t\t\"oscillator\" : {\n\t\t\t\"type\" : \"triangle\"\n\t\t},\n\t\t\"envelope\" : {\n\t\t\t\"attack\" : 0.005,\n\t\t\t\"decay\" : 0.1,\n\t\t\t\"sustain\" : 0.3,\n\t\t\t\"release\" : 1\n\t\t}\n\t};\n\n\t/**\n\t *  start the attack portion of the envelope\n\t *  @param {Time} [time=now] the time the attack should start\n\t *  @param {number} [velocity=1] the velocity of the note (0-1)\n\t *  @returns {Tone.Synth} this\n\t *  @private\n\t */\n\tTone.Synth.prototype._triggerEnvelopeAttack = function(time, velocity){\n\t\t//the envelopes\n\t\tthis.envelope.triggerAttack(time, velocity);\n\t\tthis.oscillator.start(time);\n\t\t//if there is no release portion, stop the oscillator\n\t\tif (this.envelope.sustain === 0){\n\t\t\tthis.oscillator.stop(time + this.envelope.attack + this.envelope.decay);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  start the release portion of the envelope\n\t *  @param {Time} [time=now] the time the release should start\n\t *  @returns {Tone.Synth} this\n\t *  @private\n\t */\n\tTone.Synth.prototype._triggerEnvelopeRelease = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis.envelope.triggerRelease(time);\n\t\tthis.oscillator.stop(time + this.envelope.release);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Synth} this\n\t */\n\tTone.Synth.prototype.dispose = function(){\n\t\tTone.Monophonic.prototype.dispose.call(this);\n\t\tthis._writable([\"oscillator\", \"frequency\", \"detune\", \"envelope\"]);\n\t\tthis.oscillator.dispose();\n\t\tthis.oscillator = null;\n\t\tthis.envelope.dispose();\n\t\tthis.envelope = null;\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Synth;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/instrument/Synth.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/AnalyserNode.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/shim/AnalyserNode.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../shim/AudioContext */ \"./node_modules/tone/Tone/shim/AudioContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  AnalyserNode.getFloatTimeDomainData polyfill\n\t *  @private\n\t */\n\tif (Tone.supported){\n\t\tif (!AnalyserNode.prototype.getFloatTimeDomainData){\n\t\t\t//referenced https://github.com/mohayonao/get-float-time-domain-data\n\t\t\tAnalyserNode.prototype.getFloatTimeDomainData = function(array){\n\t\t\t\tvar uint8 = new Uint8Array(array.length);\n\t\t\t\tthis.getByteTimeDomainData(uint8);\n\t\t\t\tfor (var i = 0; i < uint8.length; i++){\n\t\t\t\t\tarray[i] = (uint8[i] - 128) / 128;\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t}\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/AnalyserNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/AudioBuffer.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/shim/AudioBuffer.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  AudioBuffer.copyTo/FromChannel polyfill\n\t *  @private\n\t */\n\tif (Tone.supported){\n\t\tif (!AudioBuffer.prototype.copyToChannel){\n\t\t\tAudioBuffer.prototype.copyToChannel = function(src, chanNum, start){\n\t\t\t\tvar channel = this.getChannelData(chanNum);\n\t\t\t\tstart = start || 0;\n\t\t\t\tfor (var i = 0; i < channel.length; i++){\n\t\t\t\t\tchannel[i+start] = src[i];\n\t\t\t\t}\n\t\t\t};\n\t\t\tAudioBuffer.prototype.copyFromChannel = function(dest, chanNum, start){\n\t\t\t\tvar channel = this.getChannelData(chanNum);\n\t\t\t\tstart = start || 0;\n\t\t\t\tfor (var i = 0; i < dest.length; i++){\n\t\t\t\t\tdest[i] = channel[i+start];\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t}\n\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/AudioBuffer.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/AudioContext.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/shim/AudioContext.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../shim/OfflineAudioContext */ \"./node_modules/tone/Tone/shim/OfflineAudioContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported){\n\t\tif (!Tone.global.hasOwnProperty(\"AudioContext\") && Tone.global.hasOwnProperty(\"webkitAudioContext\")){\n\t\t\tTone.global.AudioContext = Tone.global.webkitAudioContext;\n\t\t}\n\n\t\t//not functionally equivalent, but only an API placeholder\n\t\tif (!AudioContext.prototype.close){\n\t\t\tAudioContext.prototype.close = function(){\n\t\t\t\tif (Tone.isFunction(this.suspend)){\n\t\t\t\t\tthis.suspend();\n\t\t\t\t}\n\t\t\t\treturn Promise.resolve();\n\t\t\t};\n\t\t}\n\n\t\t//not functionally equivalent\n\t\tif (!AudioContext.prototype.resume){\n\t\t\tAudioContext.prototype.resume = function(){\n\t\t\t\t//play some silent audio to jumpstart the context\n\t\t\t\tvar buffer = this.createBuffer(1, 1, this.sampleRate);\n\t\t\t\tvar source = this.createBufferSource();\n\t\t\t\tsource.buffer = buffer;\n\t\t\t\tsource.connect(this.destination);\n\t\t\t\tsource.start(0);\n\t\t\t\treturn Promise.resolve();\n\t\t\t};\n\t\t}\n\n\t\t//createGain\n\t\tif (!AudioContext.prototype.createGain && AudioContext.prototype.createGainNode){\n\t\t\tAudioContext.prototype.createGain = AudioContext.prototype.createGainNode;\n\t\t}\n\n\t\t//createDelay\n\t\tif (!AudioContext.prototype.createDelay && AudioContext.prototype.createDelayNode){\n\t\t\tAudioContext.prototype.createDelay = AudioContext.prototype.createDelayNode;\n\t\t}\n\n\t\t//test decodeAudioData returns a promise\n\t\t// https://github.com/mohayonao/web-audio-api-shim/blob/master/src/AudioContext.js\n\t\t// MIT License (c) 2015 @mohayonao\n\t\tvar decodeAudioDataPromise = false;\n\t\tvar offlineContext = new OfflineAudioContext(1, 1, 44100);\n\t\tvar audioData = new Uint32Array([1179011410, 48, 1163280727, 544501094, 16, 131073, 44100, 176400, 1048580, 1635017060, 8, 0, 0, 0, 0]).buffer;\n\t\ttry {\n\t\t\tvar ret = offlineContext.decodeAudioData(audioData);\n\t\t\tif (ret && Tone.isFunction(ret.then)){\n\t\t\t\tdecodeAudioDataPromise = true;\n\t\t\t}\n\t\t} catch (e){\n\t\t\tdecodeAudioDataPromise = false;\n\t\t}\n\n\t\tif (!decodeAudioDataPromise){\n\t\t\tAudioContext.prototype._native_decodeAudioData = AudioContext.prototype.decodeAudioData;\n\t\t\tAudioContext.prototype.decodeAudioData = function(audioData){\n\t\t\t\treturn new Promise(function(success, error){\n\t\t\t\t\tthis._native_decodeAudioData(audioData, success, error);\n\t\t\t\t}.bind(this));\n\t\t\t};\n\t\t}\n\t}\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/AudioContext.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/BufferSourceNode.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/shim/BufferSourceNode.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/OfflineContext */ \"./node_modules/tone/Tone/core/OfflineContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported){\n\n\t\tvar ua = navigator.userAgent.toLowerCase();\n\t\tvar isMobileSafari = ua.includes(\"safari\") && !ua.includes(\"chrome\") && ua.includes(\"mobile\");\n\t\tif (isMobileSafari){\n\t\t\t//mobile safari has a bizarre bug with the offline context\n\t\t\t//when a BufferSourceNode is started, it starts the offline context\n\t\t\t//\n\t\t\t//deferring all BufferSource starts till the last possible moment\n\t\t\t//reduces the likelihood of this happening\n\t\t\tTone.OfflineContext.prototype.createBufferSource = function(){\n\t\t\t\tvar bufferSource = this._context.createBufferSource();\n\t\t\t\tvar _native_start = bufferSource.start;\n\t\t\t\tbufferSource.start = function(time){\n\t\t\t\t\tthis.setTimeout(function(){\n\t\t\t\t\t\t_native_start.call(bufferSource, time);\n\t\t\t\t\t}.bind(this), 0);\n\t\t\t\t}.bind(this);\n\t\t\t\treturn bufferSource;\n\t\t\t};\n\t\t}\n\t}\n\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/BufferSourceNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/ConstantSourceNode.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/Tone/shim/ConstantSourceNode.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../shim/AudioContext */ \"./node_modules/tone/Tone/shim/AudioContext.js\"), __webpack_require__(/*! ../shim/BufferSourceNode */ \"./node_modules/tone/Tone/shim/BufferSourceNode.js\"),\n\t__webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported && !Tone.global.AudioContext.prototype.createConstantSource){\n\n\t\tvar ConstantSourceNode = function(context){\n\t\t\tthis.context = context;\n\n\t\t\tvar buffer = context.createBuffer(1, 128, context.sampleRate);\n\t\t\tvar arr = buffer.getChannelData(0);\n\t\t\tfor (var i = 0; i < arr.length; i++){\n\t\t\t\tarr[i] = 1;\n\t\t\t}\n\n\t\t\tthis._bufferSource = context.createBufferSource();\n\t\t\tthis._bufferSource.channelCount = 1;\n\t\t\tthis._bufferSource.channelCountMode = \"explicit\";\n\t\t\tthis._bufferSource.buffer = buffer;\n\t\t\tthis._bufferSource.loop = true;\n\n\t\t\tvar gainNode = this._output = context.createGain();\n\t\t\tthis.offset = gainNode.gain;\n\n\t\t\tthis._bufferSource.connect(gainNode);\n\t\t};\n\n\t\tConstantSourceNode.prototype.start = function(time){\n\t\t\tthis._bufferSource.start(time);\n\t\t\treturn this;\n\t\t};\n\n\t\tConstantSourceNode.prototype.stop = function(time){\n\t\t\tthis._bufferSource.stop(time);\n\t\t\treturn this;\n\t\t};\n\n\t\tConstantSourceNode.prototype.connect = function(){\n\t\t\tthis._output.connect.apply(this._output, arguments);\n\t\t\treturn this;\n\t\t};\n\n\t\tConstantSourceNode.prototype.disconnect = function(){\n\t\t\tthis._output.disconnect.apply(this._output, arguments);\n\t\t\treturn this;\n\t\t};\n\n\t\tAudioContext.prototype.createConstantSource = function(){\n\t\t\treturn new ConstantSourceNode(this);\n\t\t};\n\n\t\tTone.Context.prototype.createConstantSource = function(){\n\t\t\treturn new ConstantSourceNode(this);\n\t\t};\n\t}\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/ConstantSourceNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/OfflineAudioContext.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/Tone/shim/OfflineAudioContext.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\tif (Tone.supported){\n\n\t\tif (!Tone.global.hasOwnProperty(\"OfflineAudioContext\") && Tone.global.hasOwnProperty(\"webkitOfflineAudioContext\")){\n\t\t\tTone.global.OfflineAudioContext = Tone.global.webkitOfflineAudioContext;\n\t\t}\n\n\t\t//returns promise?\n\t\tvar context = new OfflineAudioContext(1, 1, 44100);\n\t\tvar ret = context.startRendering();\n\t\tif (!(ret && Tone.isFunction(ret.then))){\n\t\t\tOfflineAudioContext.prototype._native_startRendering = OfflineAudioContext.prototype.startRendering;\n\t\t\tOfflineAudioContext.prototype.startRendering = function(){\n\t\t\t\treturn new Promise(function(done){\n\t\t\t\t\tthis.oncomplete = function(e){\n\t\t\t\t\t\tdone(e.renderedBuffer);\n\t\t\t\t\t};\n\t\t\t\t\tthis._native_startRendering();\n\t\t\t\t}.bind(this));\n\t\t\t};\n\t\t}\n\t}\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/OfflineAudioContext.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/OscillatorNode.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/shim/OscillatorNode.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported){\n\t\tif (!OscillatorNode.prototype.setPeriodicWave){\n\t\t\tOscillatorNode.prototype.setPeriodicWave = OscillatorNode.prototype.setWaveTable;\n\t\t}\n\t\tif (!AudioContext.prototype.createPeriodicWave){\n\t\t\tAudioContext.prototype.createPeriodicWave = AudioContext.prototype.createWaveTable;\n\t\t}\n\t}\n\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/OscillatorNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/StereoPannerNode.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/shim/StereoPannerNode.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../component/Merge */ \"./node_modules/tone/Tone/component/Merge.js\"), __webpack_require__(/*! ../signal/Zero */ \"./node_modules/tone/Tone/signal/Zero.js\"),\n\t__webpack_require__(/*! ../component/Split */ \"./node_modules/tone/Tone/component/Split.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported && !Tone.global.AudioContext.prototype.createStereoPanner){\n\n\t\t/**\n\t\t * @class Shimmed StereoPannerNode\n\t\t * @param  {AudioContext} context\n\t\t * @private\n\t\t */\n\t\tvar StereoPannerNode = function(context){\n\n\t\t\t/**\n\t\t\t * The audio context\n\t\t\t * @type {AudioContext}\n\t\t\t */\n\t\t\tthis.context = context;\n\n\t\t\t/**\n\t\t\t * The left/right panning. [-1, 1]\n\t\t\t * @type {AudioRange}\n\t\t\t * @signal\n\t\t\t */\n\t\t\tthis.pan = new Tone.Signal(0, Tone.Type.AudioRange);\n\n\t\t\t/**\n\t\t\t * Equal power scaling of the right gain\n\t\t\t * @type {Tone.WaveShaper}\n\t\t\t */\n\t\t\tvar rightWaveShaper = new Tone.WaveShaper(function(val){\n\t\t\t\treturn Tone.equalPowerScale((val+1)/2);\n\t\t\t}, 4096);\n\n\t\t\t/**\n\t\t\t * Equal power scaling of the left gain\n\t\t\t * @type {Tone.WaveShaper}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar leftWaveShaper = new Tone.WaveShaper(function(val){\n\t\t\t\treturn Tone.equalPowerScale(1 - (val+1)/2);\n\t\t\t}, 4096);\n\n\t\t\t/**\n\t\t\t * The left gain value\n\t\t\t * @type {Tone.Gain}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar leftGain = new Tone.Gain();\n\n\t\t\t/**\n\t\t\t * The right gain value\n\t\t\t * @type {Tone.Gain}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar rightGain = new Tone.Gain();\n\n\t\t\t/**\n\t\t\t * Split the incoming signal\n\t\t\t * @type {Tone.Split}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar split = this.input = new Tone.Split();\n\t\t\t//fixes safari issue with splitting audio\n\t\t\tsplit._splitter.channelCountMode = \"explicit\";\n\n\t\t\t/**\n\t\t\t * Keeps the waveshapers from optimizing 0s\n\t\t\t * @type {Tone.Zero}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar zero = new Tone.Zero();\n\t\t\tzero.fan(rightWaveShaper, leftWaveShaper);\n\n\t\t\t/**\n\t\t\t * Merge the outgoing signal\n\t\t\t * @type {Tone.Merge}\n\t\t\t * @private\n\t\t\t */\n\t\t\tvar merge = this.output = new Tone.Merge();\n\n\t\t\t//connections\n\t\t\tsplit.left.chain(leftGain, merge.left);\n\t\t\tsplit.right.chain(rightGain, merge.right);\n\t\t\tthis.pan.chain(leftWaveShaper, leftGain.gain);\n\t\t\tthis.pan.chain(rightWaveShaper, rightGain.gain);\n\t\t};\n\n\t\tStereoPannerNode.prototype.disconnect = function(){\n\t\t\tthis.output.disconnect.apply(this.output, arguments);\n\t\t};\n\n\t\tStereoPannerNode.prototype.connect = function(){\n\t\t\tthis.output.connect.apply(this.output, arguments);\n\t\t};\n\n\t\t//add it to the AudioContext\n\t\tAudioContext.prototype.createStereoPanner = function(){\n\t\t\treturn new StereoPannerNode(this);\n\t\t};\n\t\tTone.Context.prototype.createStereoPanner = function(){\n\t\t\treturn new StereoPannerNode(this);\n\t\t};\n\t}\n\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/StereoPannerNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/shim/WaveShaperNode.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/shim/WaveShaperNode.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../shim/AudioContext */ \"./node_modules/tone/Tone/shim/AudioContext.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\tif (Tone.supported && !Tone.global.AudioContext.prototype._native_createWaveShaper){\n\n\t\t//fixes safari only bug which is still present in 11\n\t\tvar ua = navigator.userAgent.toLowerCase();\n\t\tvar isSafari = ua.includes(\"safari\") && !ua.includes(\"chrome\");\n\t\tif (isSafari){\n\n\t\t\tvar WaveShaperNode = function(context){\n\n\t\t\t\tthis._internalNode = this.input = this.output = context._native_createWaveShaper();\n\n\t\t\t\tthis._curve = null;\n\n\t\t\t\tfor (var prop in this._internalNode){\n\t\t\t\t\tthis._defineProperty(this._internalNode, prop);\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tObject.defineProperty(WaveShaperNode.prototype, \"curve\", {\n\t\t\t\t\"get\" : function(){\n\t\t\t\t\treturn this._curve;\n\t\t\t\t},\n\t\t\t\t\"set\" : function(curve){\n\t\t\t\t\tthis._curve = curve;\n\t\t\t\t\tvar array = new Float32Array(curve.length+1);\n\t\t\t\t\tarray.set(curve, 1);\n\t\t\t\t\tarray[0] = curve[0];\n\t\t\t\t\tthis._internalNode.curve = array;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tWaveShaperNode.prototype._defineProperty = function(context, prop){\n\t\t\t\tif (Tone.isUndef(this[prop])){\n\t\t\t\t\tObject.defineProperty(this, prop, {\n\t\t\t\t\t\t\"get\" : function(){\n\t\t\t\t\t\t\tif (typeof context[prop] === \"function\"){\n\t\t\t\t\t\t\t\treturn context[prop].bind(context);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\treturn context[prop];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"set\" : function(val){\n\t\t\t\t\t\t\tcontext[prop] = val;\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tTone.global.AudioContext.prototype._native_createWaveShaper = Tone.global.AudioContext.prototype.createWaveShaper;\n\t\t\tTone.global.AudioContext.prototype.createWaveShaper = function(){\n\t\t\t\treturn new WaveShaperNode(this);\n\t\t\t};\n\t\t}\n\t}\n\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/shim/WaveShaperNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Abs.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/signal/Abs.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../signal/SignalBase */ \"./node_modules/tone/Tone/signal/SignalBase.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Return the absolute value of an incoming signal.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @example\n\t * var signal = new Tone.Signal(-1);\n\t * var abs = new Tone.Abs();\n\t * signal.connect(abs);\n\t * //the output of abs is 1.\n\t */\n\tTone.Abs = function(){\n\t\tTone.SignalBase.call(this);\n\t\t/**\n\t\t *  @type {Tone.LessThan}\n\t\t *  @private\n\t\t */\n\t\tthis._abs = this.input = this.output = new Tone.WaveShaper(function(val){\n\t\t\tif (Math.abs(val) < 0.001){\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\treturn Math.abs(val);\n\t\t\t}\n\t\t}, 1024);\n\t};\n\n\tTone.extend(Tone.Abs, Tone.SignalBase);\n\n\t/**\n\t *  dispose method\n\t *  @returns {Tone.Abs} this\n\t */\n\tTone.Abs.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._abs.dispose();\n\t\tthis._abs = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Abs;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Abs.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Add.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/signal/Add.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Add a signal and a number or two signals. When no value is\n\t *         passed into the constructor, Tone.Add will sum <code>input[0]</code>\n\t *         and <code>input[1]</code>. If a value is passed into the constructor, \n\t *         the it will be added to the input.\n\t *  \n\t *  @constructor\n\t *  @extends {Tone.Signal}\n\t *  @param {number=} value If no value is provided, Tone.Add will sum the first\n\t *                         and second inputs. \n\t *  @example\n\t * var signal = new Tone.Signal(2);\n\t * var add = new Tone.Add(2);\n\t * signal.connect(add);\n\t * //the output of add equals 4\n\t *  @example\n\t * //if constructed with no arguments\n\t * //it will add the first and second inputs\n\t * var add = new Tone.Add();\n\t * var sig0 = new Tone.Signal(3).connect(add, 0, 0);\n\t * var sig1 = new Tone.Signal(4).connect(add, 0, 1);\n\t * //the output of add equals 7. \n\t */\n\tTone.Add = function(value){\n\n\t\tTone.Signal.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  the summing node\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis._sum = this.input[0] = this.input[1] = this.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  @private\n\t\t *  @type {Tone.Signal}\n\t\t */\n\t\tthis._param = this.input[1] = new Tone.Signal(value);\n\n\t\tthis._param.connect(this._sum);\n\t\tthis.proxy = false;\n\t};\n\n\tTone.extend(Tone.Add, Tone.Signal);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Add} this\n\t */\n\tTone.Add.prototype.dispose = function(){\n\t\tTone.Signal.prototype.dispose.call(this);\n\t\tthis._sum.dispose();\n\t\tthis._sum = null;\n\t\treturn this;\n\t}; \n\n\treturn Tone.Add;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Add.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/AudioToGain.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/signal/AudioToGain.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1]. \n\t *         See Tone.GainToAudio.\n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @example\n\t *  var a2g = new Tone.AudioToGain();\n\t */\n\tTone.AudioToGain = function(){\n\n\t\tTone.SignalBase.call(this);\n\t\t/**\n\t\t *  @type {WaveShaperNode}\n\t\t *  @private\n\t\t */\n\t\tthis._norm = this.input = this.output = new Tone.WaveShaper(function(x){\n\t\t\treturn (x + 1) / 2;\n\t\t});\n\t};\n\n\tTone.extend(Tone.AudioToGain, Tone.SignalBase);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.AudioToGain} this\n\t */\n\tTone.AudioToGain.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._norm.dispose();\n\t\tthis._norm = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AudioToGain;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/AudioToGain.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/EqualPowerGain.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/signal/EqualPowerGain.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Convert an incoming signal between 0, 1 to an equal power gain scale.\n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @example\n\t * var eqPowGain = new Tone.EqualPowerGain();\n\t */\n\tTone.EqualPowerGain = function(){\n\n\t\tTone.SignalBase.call(this);\n\t\t/**\n\t\t *  @type {Tone.WaveShaper}\n\t\t *  @private\n\t\t */\n\t\tthis._eqPower = this.input = this.output = new Tone.WaveShaper(function(val){\n\t\t\tif (Math.abs(val) < 0.001){\n\t\t\t\t//should output 0 when input is 0\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\treturn Tone.equalPowerScale(val);\n\t\t\t}\n\t\t}.bind(this), 4096);\n\t};\n\n\tTone.extend(Tone.EqualPowerGain, Tone.SignalBase);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.EqualPowerGain} this\n\t */\n\tTone.EqualPowerGain.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._eqPower.dispose();\n\t\tthis._eqPower = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.EqualPowerGain;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/EqualPowerGain.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/GainToAudio.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/signal/GainToAudio.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Maps a NormalRange [0, 1] to an AudioRange [-1, 1]. \n\t *         See also Tone.AudioToGain. \n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @example\n\t * var g2a = new Tone.GainToAudio();\n\t */\n\tTone.GainToAudio = function(){\n\n\t\tTone.SignalBase.call(this);\n\t\t\n\t\t/**\n\t\t *  @type {WaveShaperNode}\n\t\t *  @private\n\t\t */\n\t\tthis._norm = this.input = this.output = new Tone.WaveShaper(function(x){\n\t\t\treturn Math.abs(x) * 2 - 1;\n\t\t});\n\t};\n\n\tTone.extend(Tone.GainToAudio, Tone.SignalBase);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.GainToAudio} this\n\t */\n\tTone.GainToAudio.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._norm.dispose();\n\t\tthis._norm = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.GainToAudio;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/GainToAudio.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/GreaterThan.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/signal/GreaterThan.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/GreaterThanZero */ \"./node_modules/tone/Tone/signal/GreaterThanZero.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Output 1 if the signal is greater than the value, otherwise outputs 0.\n\t *          can compare two signals or a signal and a number.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Signal}\n\t *  @param {number} [value=0] the value to compare to the incoming signal\n\t *  @example\n\t * var gt = new Tone.GreaterThan(2);\n\t * var sig = new Tone.Signal(4).connect(gt);\n\t * //output of gt is equal 1.\n\t */\n\tTone.GreaterThan = function(value){\n\n\t\tTone.Signal.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  subtract the amount from the incoming signal\n\t\t *  @type {Tone.Subtract}\n\t\t *  @private\n\t\t */\n\t\tthis._param = this.input[0] = new Tone.Subtract(value);\n\t\tthis.input[1] = this._param.input[1];\n\n\t\t/**\n\t\t *  compare that amount to zero\n\t\t *  @type {Tone.GreaterThanZero}\n\t\t *  @private\n\t\t */\n\t\tthis._gtz = this.output = new Tone.GreaterThanZero();\n\n\t\t//connect\n\t\tthis._param.connect(this._gtz);\n\t\tthis.proxy = false;\n\t};\n\n\tTone.extend(Tone.GreaterThan, Tone.Signal);\n\n\t/**\n\t *  dispose method\n\t *  @returns {Tone.GreaterThan} this\n\t */\n\tTone.GreaterThan.prototype.dispose = function(){\n\t\tTone.Signal.prototype.dispose.call(this);\n\t\tthis._gtz.dispose();\n\t\tthis._gtz = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.GreaterThan;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/GreaterThan.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/GreaterThanZero.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/Tone/signal/GreaterThanZero.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  GreaterThanZero outputs 1 when the input is strictly greater than zero\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @example\n\t * var gt0 = new Tone.GreaterThanZero();\n\t * var sig = new Tone.Signal(0.01).connect(gt0);\n\t * //the output of gt0 is 1.\n\t * sig.value = 0;\n\t * //the output of gt0 is 0.\n\t */\n\tTone.GreaterThanZero = function(){\n\n\t\tTone.SignalBase.call(this);\n\n\t\t/**\n\t\t *  @type {Tone.WaveShaper}\n\t\t *  @private\n\t\t */\n\t\tthis._thresh = this.output = new Tone.WaveShaper(function(val){\n\t\t\tif (val <= 0){\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}, 127);\n\n\t\t/**\n\t\t *  scale the first thresholded signal by a large value.\n\t\t *  this will help with values which are very close to 0\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._scale = this.input = new Tone.Multiply(10000);\n\n\t\t//connections\n\t\tthis._scale.connect(this._thresh);\n\t};\n\n\tTone.extend(Tone.GreaterThanZero, Tone.SignalBase);\n\n\t/**\n\t *  dispose method\n\t *  @returns {Tone.GreaterThanZero} this\n\t */\n\tTone.GreaterThanZero.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._scale.dispose();\n\t\tthis._scale = null;\n\t\tthis._thresh.dispose();\n\t\tthis._thresh = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.GreaterThanZero;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/GreaterThanZero.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Modulo.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Modulo.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/Tone/signal/Subtract.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Signal-rate modulo operator. Only works in AudioRange [-1, 1] and for modulus\n\t *         values in the NormalRange.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @param {NormalRange} modulus The modulus to apply.\n\t *  @example\n\t * var mod = new Tone.Modulo(0.2)\n\t * var sig = new Tone.Signal(0.5).connect(mod);\n\t * //mod outputs 0.1\n\t */\n\tTone.Modulo = function(modulus){\n\n\t\tTone.SignalBase.call(this);\n\t\tthis.createInsOuts(1, 0);\n\n\t\t/**\n\t\t *  A waveshaper gets the integer multiple of\n\t\t *  the input signal and the modulus.\n\t\t *  @private\n\t\t *  @type {Tone.WaveShaper}\n\t\t */\n\t\tthis._shaper = new Tone.WaveShaper(Math.pow(2, 16));\n\n\t\t/**\n\t\t *  the integer multiple is multiplied by the modulus\n\t\t *  @type  {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._multiply = new Tone.Multiply();\n\n\t\t/**\n\t\t *  and subtracted from the input signal\n\t\t *  @type  {Tone.Subtract}\n\t\t *  @private\n\t\t */\n\t\tthis._subtract = this.output = new Tone.Subtract();\n\n\t\t/**\n\t\t *  the modulus signal\n\t\t *  @type  {Tone.Signal}\n\t\t *  @private\n\t\t */\n\t\tthis._modSignal = new Tone.Signal(modulus);\n\n\t\t//connections\n\t\tthis.input.fan(this._shaper, this._subtract);\n\t\tthis._modSignal.connect(this._multiply, 0, 0);\n\t\tthis._shaper.connect(this._multiply, 0, 1);\n\t\tthis._multiply.connect(this._subtract, 0, 1);\n\t\tthis._setWaveShaper(modulus);\n\t};\n\n\tTone.extend(Tone.Modulo, Tone.SignalBase);\n\n\t/**\n\t *  @param  {number}  mod  the modulus to apply\n\t *  @private\n\t */\n\tTone.Modulo.prototype._setWaveShaper = function(mod){\n\t\tthis._shaper.setMap(function(val){\n\t\t\tvar multiple = Math.floor((val + 0.0001) / mod);\n\t\t\treturn multiple;\n\t\t});\n\t};\n\n\t/**\n\t * The modulus value.\n\t * @memberOf Tone.Modulo#\n\t * @type {NormalRange}\n\t * @name value\n\t */\n\tObject.defineProperty(Tone.Modulo.prototype, \"value\", {\n\t\tget : function(){\n\t\t\treturn this._modSignal.value;\n\t\t},\n\t\tset : function(mod){\n\t\t\tthis._modSignal.value = mod;\n\t\t\tthis._setWaveShaper(mod);\n\t\t}\n\t});\n\n\t/**\n\t * clean up\n\t *  @returns {Tone.Modulo} this\n\t */\n\tTone.Modulo.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._shaper.dispose();\n\t\tthis._shaper = null;\n\t\tthis._multiply.dispose();\n\t\tthis._multiply = null;\n\t\tthis._subtract.dispose();\n\t\tthis._subtract = null;\n\t\tthis._modSignal.dispose();\n\t\tthis._modSignal = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Modulo;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Modulo.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Multiply.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Multiply.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../signal/SignalBase */ \"./node_modules/tone/Tone/signal/SignalBase.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Multiply two incoming signals. Or, if a number is given in the constructor,\n\t *          multiplies the incoming signal by that value.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Signal}\n\t *  @param {number=} value Constant value to multiple. If no value is provided,\n\t *                         it will return the product of the first and second inputs\n\t *  @example\n\t * var mult = new Tone.Multiply();\n\t * var sigA = new Tone.Signal(3);\n\t * var sigB = new Tone.Signal(4);\n\t * sigA.connect(mult, 0, 0);\n\t * sigB.connect(mult, 0, 1);\n\t * //output of mult is 12.\n\t *  @example\n\t * var mult = new Tone.Multiply(10);\n\t * var sig = new Tone.Signal(2).connect(mult);\n\t * //the output of mult is 20.\n\t */\n\tTone.Multiply = function(value){\n\n\t\tTone.Signal.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  the input node is the same as the output node\n\t\t *  it is also the GainNode which handles the scaling of incoming signal\n\t\t *\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis._mult = this.input[0] = this.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  the scaling parameter\n\t\t *  @type {AudioParam}\n\t\t *  @private\n\t\t */\n\t\tthis._param = this.input[1] = this.output.gain;\n\t\tthis.value = Tone.defaultArg(value, 0);\n\t\tthis.proxy = false;\n\t};\n\n\tTone.extend(Tone.Multiply, Tone.Signal);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Multiply} this\n\t */\n\tTone.Multiply.prototype.dispose = function(){\n\t\tTone.Signal.prototype.dispose.call(this);\n\t\tthis._mult.dispose();\n\t\tthis._mult = null;\n\t\tthis._param = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Multiply;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Multiply.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Negate.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Negate.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Negate the incoming signal. i.e. an input signal of 10 will output -10\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @example\n\t * var neg = new Tone.Negate();\n\t * var sig = new Tone.Signal(-2).connect(neg);\n\t * //output of neg is positive 2. \n\t */\n\tTone.Negate = function(){\n\n\t\tTone.SignalBase.call(this);\n\t\t/**\n\t\t *  negation is done by multiplying by -1\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._multiply = this.input = this.output = new Tone.Multiply(-1);\n\t};\n\n\tTone.extend(Tone.Negate, Tone.SignalBase);\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Negate} this\n\t */\n\tTone.Negate.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._multiply.dispose();\n\t\tthis._multiply = null;\n\t\treturn this;\n\t}; \n\n\treturn Tone.Negate;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Negate.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Normalize.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Normalize.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/Tone/signal/Add.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Normalize takes an input min and max and maps it linearly to NormalRange [0,1]\n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @param {number} inputMin the min input value\n\t *  @param {number} inputMax the max input value\n\t *  @example\n\t * var norm = new Tone.Normalize(2, 4);\n\t * var sig = new Tone.Signal(3).connect(norm);\n\t * //output of norm is 0.5. \n\t */\n\tTone.Normalize = function(inputMin, inputMax){\n\n\t\tTone.SignalBase.call(this);\n\t\t\n\t\t/**\n\t\t *  the min input value\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._inputMin = Tone.defaultArg(inputMin, 0);\n\n\t\t/**\n\t\t *  the max input value\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._inputMax = Tone.defaultArg(inputMax, 1);\n\n\t\t/**\n\t\t *  subtract the min from the input\n\t\t *  @type {Tone.Add}\n\t\t *  @private\n\t\t */\n\t\tthis._sub = this.input = new Tone.Add(0);\n\n\t\t/**\n\t\t *  divide by the difference between the input and output\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._div = this.output = new Tone.Multiply(1);\n\n\t\tthis._sub.connect(this._div);\n\t\tthis._setRange();\n\t};\n\n\tTone.extend(Tone.Normalize, Tone.SignalBase);\n\n\t/**\n\t * The minimum value the input signal will reach.\n\t * @memberOf Tone.Normalize#\n\t * @type {number}\n\t * @name min\n\t */\n\tObject.defineProperty(Tone.Normalize.prototype, \"min\", {\n\t\tget : function(){\n\t\t\treturn this._inputMin;\n\t\t},\n\t\tset : function(min){\n\t\t\tthis._inputMin = min;\n\t\t\tthis._setRange();\n\t\t}\n\t});\n\n\t/**\n\t * The maximum value the input signal will reach.\n\t * @memberOf Tone.Normalize#\n\t * @type {number}\n\t * @name max\n\t */\n\tObject.defineProperty(Tone.Normalize.prototype, \"max\", {\n\t\tget : function(){\n\t\t\treturn this._inputMax;\n\t\t},\n\t\tset : function(max){\n\t\t\tthis._inputMax = max;\n\t\t\tthis._setRange();\n\t\t}\n\t});\n\n\t/**\n\t *  set the values\n\t *  @private\n\t */\n\tTone.Normalize.prototype._setRange = function(){\n\t\tthis._sub.value = -this._inputMin;\n\t\tthis._div.value = 1 / (this._inputMax - this._inputMin);\n\t};\n\n\t/**\n\t *  clean up\n\t *  @returns {Tone.Normalize} this\n\t */\n\tTone.Normalize.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._sub.dispose();\n\t\tthis._sub = null;\n\t\tthis._div.dispose();\n\t\tthis._div = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Normalize;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Normalize.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Pow.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/signal/Pow.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Pow applies an exponent to the incoming signal. The incoming signal\n\t *         must be AudioRange.\n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @param {Positive} exp The exponent to apply to the incoming signal, must be at least 2. \n\t *  @example\n\t * var pow = new Tone.Pow(2);\n\t * var sig = new Tone.Signal(0.5).connect(pow);\n\t * //output of pow is 0.25. \n\t */\n\tTone.Pow = function(exp){\n\n\t\tTone.SignalBase.call(this);\n\t\t\n\t\t/**\n\t\t * the exponent\n\t\t * @private\n\t\t * @type {number}\n\t\t */\n\t\tthis._exp = Tone.defaultArg(exp, 1);\n\n\t\t/**\n\t\t *  @type {WaveShaperNode}\n\t\t *  @private\n\t\t */\n\t\tthis._expScaler = this.input = this.output = new Tone.WaveShaper(this._expFunc(this._exp), 8192);\n\t};\n\n\tTone.extend(Tone.Pow, Tone.SignalBase);\n\n\t/**\n\t * The value of the exponent.\n\t * @memberOf Tone.Pow#\n\t * @type {number}\n\t * @name value\n\t */\n\tObject.defineProperty(Tone.Pow.prototype, \"value\", {\n\t\tget : function(){\n\t\t\treturn this._exp;\n\t\t},\n\t\tset : function(exp){\n\t\t\tthis._exp = exp;\n\t\t\tthis._expScaler.setMap(this._expFunc(this._exp));\n\t\t}\n\t});\n\n\t/**\n\t *  the function which maps the waveshaper\n\t *  @param   {number} exp\n\t *  @return {function}\n\t *  @private\n\t */\n\tTone.Pow.prototype._expFunc = function(exp){\n\t\treturn function(val){\n\t\t\treturn Math.pow(Math.abs(val), exp);\n\t\t};\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Pow} this\n\t */\n\tTone.Pow.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._expScaler.dispose();\n\t\tthis._expScaler = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Pow;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Pow.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Scale.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Scale.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/Tone/signal/Add.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\t\n\t/**\n\t *  @class  Performs a linear scaling on an input signal.\n\t *          Scales a NormalRange input to between\n\t *          outputMin and outputMax.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @param {number} [outputMin=0] The output value when the input is 0. \n\t *  @param {number} [outputMax=1]\tThe output value when the input is 1. \n\t *  @example\n\t * var scale = new Tone.Scale(50, 100);\n\t * var signal = new Tone.Signal(0.5).connect(scale);\n\t * //the output of scale equals 75\n\t */\n\tTone.Scale = function(outputMin, outputMax){\n\n\t\tTone.SignalBase.call(this);\n\t\t\n\t\t/** \n\t\t *  @private\n\t\t *  @type {number}\n\t\t */\n\t\tthis._outputMin = Tone.defaultArg(outputMin, 0);\n\n\t\t/** \n\t\t *  @private\n\t\t *  @type {number}\n\t\t */\n\t\tthis._outputMax = Tone.defaultArg(outputMax, 1);\n\n\t\t/** \n\t\t *  @private\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._scale = this.input = new Tone.Multiply(1);\n\t\t\n\t\t/** \n\t\t *  @private\n\t\t *  @type {Tone.Add}\n\t\t *  @private\n\t\t */\n\t\tthis._add = this.output = new Tone.Add(0);\n\n\t\tthis._scale.connect(this._add);\n\t\tthis._setRange();\n\t};\n\n\tTone.extend(Tone.Scale, Tone.SignalBase);\n\n\t/**\n\t * The minimum output value. This number is output when \n\t * the value input value is 0. \n\t * @memberOf Tone.Scale#\n\t * @type {number}\n\t * @name min\n\t */\n\tObject.defineProperty(Tone.Scale.prototype, \"min\", {\n\t\tget : function(){\n\t\t\treturn this._outputMin;\n\t\t},\n\t\tset : function(min){\n\t\t\tthis._outputMin = min;\n\t\t\tthis._setRange();\n\t\t}\n\t});\n\n\t/**\n\t * The maximum output value. This number is output when \n\t * the value input value is 1. \n\t * @memberOf Tone.Scale#\n\t * @type {number}\n\t * @name max\n\t */\n\tObject.defineProperty(Tone.Scale.prototype, \"max\", {\n\t\tget : function(){\n\t\t\treturn this._outputMax;\n\t\t},\n\t\tset : function(max){\n\t\t\tthis._outputMax = max;\n\t\t\tthis._setRange();\n\t\t}\n\t});\n\n\t/**\n\t *  set the values\n\t *  @private\n\t */\n\tTone.Scale.prototype._setRange = function(){\n\t\tthis._add.value = this._outputMin;\n\t\tthis._scale.value = this._outputMax - this._outputMin;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Scale} this\n\t */\n\tTone.Scale.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._add.dispose();\n\t\tthis._add = null;\n\t\tthis._scale.dispose();\n\t\tthis._scale = null;\n\t\treturn this;\n\t}; \n\n\treturn Tone.Scale;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Scale.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/ScaleExp.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/signal/ScaleExp.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/Tone/signal/Scale.js\"), __webpack_require__(/*! ../signal/Pow */ \"./node_modules/tone/Tone/signal/Pow.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class  Performs an exponential scaling on an input signal.\n\t *          Scales a NormalRange value [0,1] exponentially\n\t *          to the output range of outputMin to outputMax.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.SignalBase}\n\t *  @param {number} [outputMin=0] The output value when the input is 0.\n\t *  @param {number} [outputMax=1]\tThe output value when the input is 1.\n\t *  @param {number} [exponent=2] The exponent which scales the incoming signal.\n\t *  @example\n\t * var scaleExp = new Tone.ScaleExp(0, 100, 2);\n\t * var signal = new Tone.Signal(0.5).connect(scaleExp);\n\t */\n\tTone.ScaleExp = function(outputMin, outputMax, exponent){\n\n\t\tTone.SignalBase.call(this);\n\n\t\t/**\n\t\t *  scale the input to the output range\n\t\t *  @type {Tone.Scale}\n\t\t *  @private\n\t\t */\n\t\tthis._scale = this.output = new Tone.Scale(outputMin, outputMax);\n\n\t\t/**\n\t\t *  @private\n\t\t *  @type {Tone.Pow}\n\t\t *  @private\n\t\t */\n\t\tthis._exp = this.input = new Tone.Pow(Tone.defaultArg(exponent, 2));\n\n\t\tthis._exp.connect(this._scale);\n\t};\n\n\tTone.extend(Tone.ScaleExp, Tone.SignalBase);\n\n\t/**\n\t * Instead of interpolating linearly between the <code>min</code> and\n\t * <code>max</code> values, setting the exponent will interpolate between\n\t * the two values with an exponential curve.\n\t * @memberOf Tone.ScaleExp#\n\t * @type {number}\n\t * @name exponent\n\t */\n\tObject.defineProperty(Tone.ScaleExp.prototype, \"exponent\", {\n\t\tget : function(){\n\t\t\treturn this._exp.value;\n\t\t},\n\t\tset : function(exp){\n\t\t\tthis._exp.value = exp;\n\t\t}\n\t});\n\n\t/**\n\t * The minimum output value. This number is output when\n\t * the value input value is 0.\n\t * @memberOf Tone.ScaleExp#\n\t * @type {number}\n\t * @name min\n\t */\n\tObject.defineProperty(Tone.ScaleExp.prototype, \"min\", {\n\t\tget : function(){\n\t\t\treturn this._scale.min;\n\t\t},\n\t\tset : function(min){\n\t\t\tthis._scale.min = min;\n\t\t}\n\t});\n\n\t/**\n\t * The maximum output value. This number is output when\n\t * the value input value is 1.\n\t * @memberOf Tone.ScaleExp#\n\t * @type {number}\n\t * @name max\n\t */\n\tObject.defineProperty(Tone.ScaleExp.prototype, \"max\", {\n\t\tget : function(){\n\t\t\treturn this._scale.max;\n\t\t},\n\t\tset : function(max){\n\t\t\tthis._scale.max = max;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.ScaleExp} this\n\t */\n\tTone.ScaleExp.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._scale.dispose();\n\t\tthis._scale = null;\n\t\tthis._exp.dispose();\n\t\tthis._exp = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.ScaleExp;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/ScaleExp.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Signal.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Signal.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\"),\n\t__webpack_require__(/*! ../shim/ConstantSourceNode */ \"./node_modules/tone/Tone/shim/ConstantSourceNode.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  A signal is an audio-rate value. Tone.Signal is a core component of the library.\n\t *          Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n\t *          has all of the methods available to native Web Audio\n\t *          [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n\t *          as well as additional conveniences. Read more about working with signals\n\t *          [here](https://github.com/Tonejs/Tone.js/wiki/Signals).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Param}\n\t *  @param {Number|AudioParam} [value] Initial value of the signal. If an AudioParam\n\t *                                     is passed in, that parameter will be wrapped\n\t *                                     and controlled by the Signal.\n\t *  @param {string} [units=Number] unit The units the signal is in.\n\t *  @example\n\t * var signal = new Tone.Signal(10);\n\t */\n\tTone.Signal = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"value\", \"units\"], Tone.Signal);\n\t\tTone.Param.call(this, options);\n\n\t\t/**\n\t\t * The constant source node which generates the signal\n\t\t * @type {ConstantSourceNode}\n\t\t * @private\n\t\t */\n\t\tthis._constantSource = this.context.createConstantSource();\n\t\tthis._constantSource.start(0);\n\t\tthis._param = this._constantSource.offset;\n\t\tthis.value = options.value;\n\n\t\t/**\n\t\t * The node where the constant signal value is scaled.\n\t\t * @type {GainNode}\n\t\t * @private\n\t\t */\n\t\tthis.output = this._constantSource;\n\n\t\t/**\n\t\t * The node where the value is set.\n\t\t * @type {Tone.Param}\n\t\t * @private\n\t\t */\n\t\tthis.input = this._param = this.output.offset;\n\t};\n\n\tTone.extend(Tone.Signal, Tone.Param);\n\n\t/**\n\t *  The default values\n\t *  @type  {Object}\n\t *  @static\n\t *  @const\n\t */\n\tTone.Signal.defaults = {\n\t\t\"value\" : 0,\n\t\t\"units\" : Tone.Type.Default,\n\t\t\"convert\" : true,\n\t};\n\n\t//use SignalBase's connect/disconnect methods\n\tTone.Signal.prototype.connect = Tone.SignalBase.prototype.connect;\n\tTone.Signal.prototype.disconnect = Tone.SignalBase.prototype.disconnect;\n\n\t/**\n\t * Return the current signal value at the given time.\n\t * @param  {Time} time When to get the signal value\n\t * @return {Number}\n\t */\n\tTone.Signal.prototype.getValueAtTime = function(time){\n\t\tif (this._param.getValueAtTime){\n\t\t\treturn this._param.getValueAtTime(time);\n\t\t} else {\n\t\t\treturn Tone.Param.prototype.getValueAtTime.call(this, time);\n\t\t}\n\t};\n\n\t/**\n\t *  dispose and disconnect\n\t *  @returns {Tone.Signal} this\n\t */\n\tTone.Signal.prototype.dispose = function(){\n\t\tTone.Param.prototype.dispose.call(this);\n\t\tthis._constantSource.disconnect();\n\t\tthis._constantSource = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Signal;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Signal.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/SignalBase.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/signal/SignalBase.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Base class for all Signals. Used Internally.\n\t *\n\t *  @constructor\n\t *  @extends {Tone}\n\t */\n\tTone.SignalBase = function(){\n\t\tTone.AudioNode.call(this);\n\t};\n\n\tTone.extend(Tone.SignalBase, Tone.AudioNode);\n\n\t/**\n\t *  When signals connect to other signals or AudioParams,\n\t *  they take over the output value of that signal or AudioParam.\n\t *  For all other nodes, the behavior is the same as a default <code>connect</code>.\n\t *\n\t *  @override\n\t *  @param {AudioParam|AudioNode|Tone.Signal|Tone} node\n\t *  @param {number} [outputNumber=0] The output number to connect from.\n\t *  @param {number} [inputNumber=0] The input number to connect to.\n\t *  @returns {Tone.SignalBase} this\n\t */\n\tTone.SignalBase.prototype.connect = function(node, outputNumber, inputNumber){\n\t\t//zero it out so that the signal can have full control\n\t\tif ((Tone.Signal && Tone.Signal === node.constructor) ||\n\t\t\t\t(Tone.Param && Tone.Param === node.constructor)){\n\t\t\t//cancel changes\n\t\t\tnode._param.cancelScheduledValues(0);\n\t\t\t//reset the value\n\t\t\tnode._param.setValueAtTime(0, 0);\n\t\t\t//mark the value as overridden\n\t\t\tnode.overridden = true;\n\t\t} else if (node instanceof AudioParam){\n\t\t\tnode.cancelScheduledValues(0);\n\t\t\tnode.setValueAtTime(0, 0);\n\t\t}\n\t\tTone.AudioNode.prototype.connect.call(this, node, outputNumber, inputNumber);\n\t\treturn this;\n\t};\n\n\treturn Tone.SignalBase;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/SignalBase.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Subtract.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/Tone/signal/Subtract.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/Tone/signal/Add.js\"), __webpack_require__(/*! ../signal/Negate */ \"./node_modules/tone/Tone/signal/Negate.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Subtract the signal connected to <code>input[1]</code> from the signal connected \n\t *         to <code>input[0]</code>. If an argument is provided in the constructor, the \n\t *         signals <code>.value</code> will be subtracted from the incoming signal.\n\t *\n\t *  @extends {Tone.Signal}\n\t *  @constructor\n\t *  @param {number=} value The value to subtract from the incoming signal. If the value\n\t *                         is omitted, it will subtract the second signal from the first.\n\t *  @example\n\t * var sub = new Tone.Subtract(1);\n\t * var sig = new Tone.Signal(4).connect(sub);\n\t * //the output of sub is 3. \n\t *  @example\n\t * var sub = new Tone.Subtract();\n\t * var sigA = new Tone.Signal(10);\n\t * var sigB = new Tone.Signal(2.5);\n\t * sigA.connect(sub, 0, 0);\n\t * sigB.connect(sub, 0, 1);\n\t * //output of sub is 7.5\n\t */\n\tTone.Subtract = function(value){\n\n\t\tTone.Signal.call(this);\n\t\tthis.createInsOuts(2, 0);\n\n\t\t/**\n\t\t *  the summing node\n\t\t *  @type {GainNode}\n\t\t *  @private\n\t\t */\n\t\tthis._sum = this.input[0] = this.output = new Tone.Gain();\n\n\t\t/**\n\t\t *  negate the input of the second input before connecting it\n\t\t *  to the summing node.\n\t\t *  @type {Tone.Negate}\n\t\t *  @private\n\t\t */\n\t\tthis._neg = new Tone.Negate();\n\n\t\t/**\n\t\t *  the node where the value is set\n\t\t *  @private\n\t\t *  @type {Tone.Signal}\n\t\t */\n\t\tthis._param = this.input[1] = new Tone.Signal(value);\n\t\tthis._param.chain(this._neg, this._sum);\n\t\tthis.proxy = false;\n\t};\n\n\tTone.extend(Tone.Subtract, Tone.Signal);\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.SignalBase} this\n\t */\n\tTone.Subtract.prototype.dispose = function(){\n\t\tTone.Signal.prototype.dispose.call(this);\n\t\tthis._neg.dispose();\n\t\tthis._neg = null;\n\t\tthis._sum.disconnect();\n\t\tthis._sum = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Subtract;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Subtract.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/TickSignal.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/signal/TickSignal.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t * @class Tone.TickSignal extends Tone.Signal, but adds the capability\n\t *        to calculate the number of elapsed ticks. exponential and target curves\n\t *        are approximated with multiple linear ramps.\n\t *\n\t *        Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos, for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n\t *        describing integrating timing functions for tempo calculations.\n\t *\n\t * @param {Number} value The initial value of the signal\n\t * @extends {Tone.Signal}\n\t */\n\tTone.TickSignal = function(value){\n\n\t\tvalue = Tone.defaultArg(value, 1);\n\n\t\tTone.Signal.call(this, {\n\t\t\t\"units\" : Tone.Type.Ticks,\n\t\t\t\"value\" : value\n\t\t});\n\n\t\t//extend the memory\n\t\tthis._events.memory = Infinity;\n\n\t\t//clear the clock from the beginning\n\t\tthis.cancelScheduledValues(0);\n\t\t//set an initial event\n\t\tthis._events.add({\n\t\t\t\"type\" : Tone.Param.AutomationType.SetValue,\n\t\t\t\"time\" : 0,\n\t\t\t\"value\" : value\n\t\t});\n\t};\n\n\tTone.extend(Tone.TickSignal, Tone.Signal);\n\t\n\t/**\n\t * Wraps Tone.Signal methods so that they also\n\t * record the ticks.\n\t * @param  {Function} method\n\t * @return {Function}\n\t * @private\n\t */\n\tfunction _wrapScheduleMethods(method){\n\t\treturn function(value, time){\n\t\t\ttime = this.toSeconds(time);\n\t\t\tmethod.apply(this, arguments);\n\t\t\tvar event = this._events.get(time);\n\t\t\tvar previousEvent = this._events.previousEvent(event);\n\t\t\tvar ticksUntilTime = this._getTicksUntilEvent(previousEvent, time);\n\t\t\tevent.ticks = Math.max(ticksUntilTime, 0);\n\t\t\treturn this;\n\t\t};\n\t}\n\n\tTone.TickSignal.prototype.setValueAtTime = _wrapScheduleMethods(Tone.Signal.prototype.setValueAtTime);\n\tTone.TickSignal.prototype.linearRampToValueAtTime = _wrapScheduleMethods(Tone.Signal.prototype.linearRampToValueAtTime);\n\n\t/**\n\t *  Start exponentially approaching the target value at the given time with\n\t *  a rate having the given time constant.\n\t *  @param {number} value\n\t *  @param {Time} startTime\n\t *  @param {number} timeConstant\n\t *  @returns {Tone.TickSignal} this\n\t */\n\tTone.TickSignal.prototype.setTargetAtTime = function(value, time, constant){\n\t\t//aproximate it with multiple linear ramps\n\t\ttime = this.toSeconds(time);\n\t\tthis.setRampPoint(time);\n\t\tvalue = this._fromUnits(value);\n\n\t\t//start from previously scheduled value\n\t\tvar prevEvent = this._events.get(time);\n\t\tvar segments = Math.round(Math.max(1 / constant, 1));\n\t\tfor (var i = 0; i <= segments; i++){\n\t\t\tvar segTime = constant * i + time;\n\t\t\tvar rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, value, constant, segTime);\n\t\t\tthis.linearRampToValueAtTime(this._toUnits(rampVal), segTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Schedules an exponential continuous change in parameter value from\n\t *  the previous scheduled parameter value to the given value.\n\t *  @param  {number} value\n\t *  @param  {Time} endTime\n\t *  @returns {Tone.TickSignal} this\n\t */\n\tTone.TickSignal.prototype.exponentialRampToValueAtTime = function(value, time){\n\t\t//aproximate it with multiple linear ramps\n\t\ttime = this.toSeconds(time);\n\t\tvalue = this._fromUnits(value);\n\n\t\t//start from previously scheduled value\n\t\tvar prevEvent = this._events.get(time);\n\t\tif (prevEvent === null){\n\t\t\tprevEvent = {\n\t\t\t\t\"value\" : this._initialValue,\n\t\t\t\t\"time\" : 0\n\t\t\t};\n\t\t}\n\t\t//approx 10 segments per second\n\t\tvar segments = Math.round(Math.max((time - prevEvent.time)*10, 1));\n\t\tvar segmentDur = ((time - prevEvent.time)/segments);\n\t\tfor (var i = 0; i <= segments; i++){\n\t\t\tvar segTime = segmentDur * i + prevEvent.time;\n\t\t\tvar rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, value, segTime);\n\t\t\tthis.linearRampToValueAtTime(this._toUnits(rampVal), segTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Returns the tick value at the time. Takes into account\n\t * any automation curves scheduled on the signal.\n\t * @private\n\t * @param  {Time} time The time to get the tick count at\n\t * @return {Ticks}      The number of ticks which have elapsed at the time\n\t *                          given any automations.\n\t */\n\tTone.TickSignal.prototype._getTicksUntilEvent = function(event, time){\n\t\tif (event === null){\n\t\t\tevent = {\n\t\t\t\t\"ticks\" : 0,\n\t\t\t\t\"time\" : 0\n\t\t\t};\n\t\t} else if (Tone.isUndef(event.ticks)){\n\t\t\tvar previousEvent = this._events.previousEvent(event);\n\t\t\tevent.ticks = this._getTicksUntilEvent(previousEvent, event.time);\n\t\t}\n\t\tvar val0 = this.getValueAtTime(event.time);\n\t\tvar val1 = this.getValueAtTime(time);\n\t\t//if it's right on the line, take the previous value\n\t\tif (this._events.get(time).time === time && this._events.get(time).type === Tone.Param.AutomationType.SetValue){\n\t\t\tval1 = this.getValueAtTime(time - this.sampleTime);\n\t\t}\n\t\treturn 0.5 * (time - event.time) * (val0 + val1) + event.ticks;\n\t};\n\n\t/**\n\t * Returns the tick value at the time. Takes into account\n\t * any automation curves scheduled on the signal.\n\t * @param  {Time} time The time to get the tick count at\n\t * @return {Ticks}      The number of ticks which have elapsed at the time\n\t *                          given any automations.\n\t */\n\tTone.TickSignal.prototype.getTicksAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tvar event = this._events.get(time);\n\t\treturn Math.max(this._getTicksUntilEvent(event, time), 0);\n\t};\n\n\t/**\n\t * Return the elapsed time of the number of ticks from the given time\n\t * @param {Ticks} ticks The number of ticks to calculate\n\t * @param  {Time} time The time to get the next tick from\n\t * @return {Seconds} The duration of the number of ticks from the given time in seconds\n\t */\n\tTone.TickSignal.prototype.getDurationOfTicks = function(ticks, time){\n\t\ttime = this.toSeconds(time);\n\t\tvar currentTick = this.getTicksAtTime(time);\n\t\treturn this.getTimeOfTick(currentTick + ticks) - time;\n\t};\n\n\t/**\n\t * Given a tick, returns the time that tick occurs at.\n\t * @param  {Ticks} tick\n\t * @return {Time}      The time that the tick occurs.\n\t */\n\tTone.TickSignal.prototype.getTimeOfTick = function(tick){\n\t\tvar before = this._events.get(tick, \"ticks\");\n\t\tvar after = this._events.getAfter(tick, \"ticks\");\n\t\tif (before && before.ticks === tick){\n\t\t\treturn before.time;\n\t\t} else if (before && after &&\n\t\t\tafter.type === Tone.Param.AutomationType.Linear &&\n\t\t\tbefore.value !== after.value){\n\t\t\tvar val0 = this.getValueAtTime(before.time);\n\t\t\tvar val1 = this.getValueAtTime(after.time);\n\t\t\tvar delta = (val1 - val0) / (after.time - before.time);\n\t\t\tvar k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));\n\t\t\tvar sol1 = (-val0 + k) / delta;\n\t\t\tvar sol2 = (-val0 - k) / delta;\n\t\t\treturn (sol1 > 0 ? sol1 : sol2) + before.time;\n\t\t} else if (before){\n\t\t\tif (before.value === 0){\n\t\t\t\treturn Infinity;\n\t\t\t} else {\n\t\t\t\treturn before.time + (tick - before.ticks) / before.value;\n\t\t\t}\n\t\t} else {\n\t\t\treturn tick / this._initialValue;\n\t\t}\n\t};\n\n\t/**\n\t * Convert some number of ticks their the duration in seconds accounting\n\t * for any automation curves starting at the given time.\n\t * @param  {Ticks} ticks The number of ticks to convert to seconds.\n\t * @param  {Time} [when=now]  When along the automation timeline to convert the ticks.\n\t * @return {Tone.Time}       The duration in seconds of the ticks.\n\t */\n\tTone.TickSignal.prototype.ticksToTime = function(ticks, when){\n\t\twhen = this.toSeconds(when);\n\t\treturn new Tone.Time(this.getDurationOfTicks(ticks, when));\n\t};\n\n\t/**\n\t * The inverse of [ticksToTime](#tickstotime). Convert a duration in\n\t * seconds to the corresponding number of ticks accounting for any\n\t * automation curves starting at the given time.\n\t * @param  {Time} duration The time interval to convert to ticks.\n\t * @param  {Time} [when=now]     When along the automation timeline to convert the ticks.\n\t * @return {Tone.Ticks}          The duration in ticks.\n\t */\n\tTone.TickSignal.prototype.timeToTicks = function(duration, when){\n\t\twhen = this.toSeconds(when);\n\t\tduration = this.toSeconds(duration);\n\t\tvar startTicks = this.getTicksAtTime(when);\n\t\tvar endTicks = this.getTicksAtTime(when + duration);\n\t\treturn new Tone.Ticks(endTicks - startTicks);\n\t};\n\n\treturn Tone.TickSignal;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/TickSignal.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/TransportTimelineSignal.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/Tone/signal/TransportTimelineSignal.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/Tone/type/TransportTime.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t * @class Tone.TransportTimelineSignal extends Tone.Signal, but adds the ability to synchronize the signal to the signal to the Tone.Transport\n\t * @extends {Tone.Signal}\n\t */\n\tTone.TransportTimelineSignal = function(){\n\t\tTone.Signal.apply(this, arguments);\n\n\t\t/**\n\t\t * The real signal output\n\t\t * @type {Tone.Signal}\n\t\t * @private\n\t\t */\n\t\tthis.output = this._outputSig = new Tone.Signal(this._initialValue);\n\n\t\t/**\n\t\t * Keep track of the last value. (small optimization)\n\t\t * @private\n\t\t * @type {Number}\n\t\t */\n\t\tthis._lastVal = this.value;\n\n\t\t/**\n\t\t * The event id of the tick update loop\n\t\t * @private\n\t\t * @type {Number}\n\t\t */\n\t\tthis._synced = Tone.Transport.scheduleRepeat(this._onTick.bind(this), \"1i\");\n\n\t\t/**\n\t\t * A bound version of the anchor value methods\n\t\t * @type {Function}\n\t\t * @private\n\t\t */\n\t\tthis._bindAnchorValue = this._anchorValue.bind(this);\n\t\tTone.Transport.on(\"start stop pause\", this._bindAnchorValue);\n\n\t\tthis._events.memory = Infinity;\n\t};\n\n\tTone.extend(Tone.TransportTimelineSignal, Tone.Signal);\n\n\t/**\n\t * Callback which is invoked every tick.\n\t * @private\n\t * @param  {Number} time\n\t * @return {Tone.TransportTimelineSignal}      this\n\t */\n\tTone.TransportTimelineSignal.prototype._onTick = function(time){\n\t\tvar val = this.getValueAtTime(Tone.Transport.seconds);\n\t\tif (this._lastVal !== val){\n\t\t\tthis._lastVal = val;\n\t\t\t//approximate ramp curves with linear ramps\n\t\t\tthis._outputSig.linearRampToValueAtTime(val, time);\n\t\t}\n\t};\n\n\t/**\n\t * Anchor the value at the start and stop of the Transport\n\t * @param  {Number} time The time of the event\n\t * @return {Tone.TransportTimelineSignal}      this\n\t * @private\n\t */\n\tTone.TransportTimelineSignal.prototype._anchorValue = function(time){\n\t\tvar val = this.getValueAtTime(Tone.Transport.seconds);\n\t\tthis._lastVal = val;\n\t\tthis._outputSig.cancelScheduledValues(time);\n\t\tthis._outputSig.setValueAtTime(val, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the scheduled value at the given time. This will\n\t *  return the unconverted (raw) value.\n\t *  @param  {TransportTime}  time  The time in seconds.\n\t *  @return  {Number}  The scheduled value at the given time.\n\t */\n\tTone.TransportTimelineSignal.prototype.getValueAtTime = function(time){\n\t\ttime = Tone.TransportTime(time);\n\t\treturn Tone.Signal.prototype.getValueAtTime.call(this, time);\n\t};\n\n\t/**\n\t * Set the output of the signal at the given time\n\t * @param  {Number} value The value to change to at the given time\n\t * @param  {TransportTime} time  The time to change the signal\n\t * @return {Tone.TransportTimelineSignal}       this\n\t */\n\tTone.TransportTimelineSignal.prototype.setValueAtTime = function(value, time){\n\t\ttime = Tone.TransportTime(time);\n\t\tTone.Signal.prototype.setValueAtTime.call(this, value, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Linear ramp to the given value from the previous scheduled point to the given value\n\t * @param  {Number} value The value to change to at the given time\n\t * @param  {TransportTime} time  The time to change the signal\n\t * @return {Tone.TransportTimelineSignal}       this\n\t */\n\tTone.TransportTimelineSignal.prototype.linearRampToValueAtTime = function(value, time){\n\t\ttime = Tone.TransportTime(time);\n\t\tTone.Signal.prototype.linearRampToValueAtTime.call(this, value, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Exponential ramp to the given value from the previous scheduled point to the given value\n\t * @param  {Number} value The value to change to at the given time\n\t * @param  {TransportTime} time  The time to change the signal\n\t * @return {Tone.TransportTimelineSignal}       this\n\t */\n\tTone.TransportTimelineSignal.prototype.exponentialRampToValueAtTime = function(value, time){\n\t\ttime = Tone.TransportTime(time);\n\t\tTone.Signal.prototype.exponentialRampToValueAtTime.call(this, value, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Start exponentially approaching the target value at the given time with\n\t *  a rate having the given time constant.\n\t *  @param {number} value\n\t *  @param {TransportTime} startTime\n\t *  @param {number} timeConstant\n\t * @return {Tone.TransportTimelineSignal}       this\n\t */\n\tTone.TransportTimelineSignal.prototype.setTargetAtTime = function(value, startTime, timeConstant){\n\t\tstartTime = Tone.TransportTime(startTime);\n\t\tTone.Signal.prototype.setTargetAtTime.call(this, value, startTime, timeConstant);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancels all scheduled parameter changes with times greater than or\n\t *  equal to startTime.\n\t *  @param  {TransportTime} startTime\n\t *  @returns {Tone.Param} this\n\t */\n\tTone.TransportTimelineSignal.prototype.cancelScheduledValues = function(startTime){\n\t\tstartTime = Tone.TransportTime(startTime);\n\t\tTone.Signal.prototype.cancelScheduledValues.call(this, startTime);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Set an array of arbitrary values starting at the given time for the given duration.\n\t *  @param {Float32Array} values\n\t *  @param {Time} startTime\n\t *  @param {Time} duration\n\t *  @param {NormalRange} [scaling=1] If the values in the curve should be scaled by some value\n\t *  @returns {Tone.Signal} this\n\t */\n\tTone.TransportTimelineSignal.prototype.setValueCurveAtTime = function(values, startTime, duration, scaling){\n\t\tstartTime = Tone.TransportTime(startTime);\n\t\tduration = Tone.TransportTime(duration);\n\t\tTone.Signal.prototype.setValueCurveAtTime.call(this, values, startTime, duration, scaling);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  This is similar to [cancelScheduledValues](#cancelScheduledValues) except\n\t *  it holds the automated value at time until the next automated event.\n\t *  @param  {Time} time\n\t *  @returns {Tone.TransportTimelineSignal} this\n\t */\n\tTone.TransportTimelineSignal.prototype.cancelAndHoldAtTime = function(time){\n\t\treturn Tone.Signal.prototype.cancelAndHoldAtTime.call(this, Tone.TransportTime(time));\n\t};\n\n\t/**\n\t * Dispose and disconnect\n\t * @return {Tone.TransportTimelineSignal} this\n\t */\n\tTone.TransportTimelineSignal.prototype.dispose = function(){\n\t\tTone.Transport.clear(this._synced);\n\t\tTone.Transport.off(\"start stop pause\", this._syncedCallback);\n\t\tthis._events.cancel(0);\n\t\tTone.Signal.prototype.dispose.call(this);\n\t\tthis._outputSig.dispose();\n\t\tthis._outputSig = null;\n\t};\n\n\treturn Tone.TransportTimelineSignal;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/TransportTimelineSignal.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/WaveShaper.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/signal/WaveShaper.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/SignalBase */ \"./node_modules/tone/Tone/signal/SignalBase.js\"), __webpack_require__(/*! ../shim/WaveShaperNode */ \"./node_modules/tone/Tone/shim/WaveShaperNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Wraps the native Web Audio API\n\t *         [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).\n\t *\n\t *  @extends {Tone.SignalBase}\n\t *  @constructor\n\t *  @param {function|Array|Number} mapping The function used to define the values.\n\t *                                    The mapping function should take two arguments:\n\t *                                    the first is the value at the current position\n\t *                                    and the second is the array position.\n\t *                                    If the argument is an array, that array will be\n\t *                                    set as the wave shaping function. The input\n\t *                                    signal is an AudioRange [-1, 1] value and the output\n\t *                                    signal can take on any numerical values.\n\t *\n\t *  @param {Number} [bufferLen=1024] The length of the WaveShaperNode buffer.\n\t *  @example\n\t * var timesTwo = new Tone.WaveShaper(function(val){\n\t * \treturn val * 2;\n\t * }, 2048);\n\t *  @example\n\t * //a waveshaper can also be constructed with an array of values\n\t * var invert = new Tone.WaveShaper([1, -1]);\n\t */\n\tTone.WaveShaper = function(mapping, bufferLen){\n\n\t\tTone.SignalBase.call(this);\n\n\t\t/**\n\t\t *  the waveshaper\n\t\t *  @type {WaveShaperNode}\n\t\t *  @private\n\t\t */\n\t\tthis._shaper = this.input = this.output = this.context.createWaveShaper();\n\n\t\t/**\n\t\t *  the waveshapers curve\n\t\t *  @type {Float32Array}\n\t\t *  @private\n\t\t */\n\t\tthis._curve = null;\n\n\t\tif (Array.isArray(mapping)){\n\t\t\tthis.curve = mapping;\n\t\t} else if (isFinite(mapping) || Tone.isUndef(mapping)){\n\t\t\tthis._curve = new Float32Array(Tone.defaultArg(mapping, 1024));\n\t\t} else if (Tone.isFunction(mapping)){\n\t\t\tthis._curve = new Float32Array(Tone.defaultArg(bufferLen, 1024));\n\t\t\tthis.setMap(mapping);\n\t\t}\n\t};\n\n\tTone.extend(Tone.WaveShaper, Tone.SignalBase);\n\n\t/**\n\t *  Uses a mapping function to set the value of the curve.\n\t *  @param {function} mapping The function used to define the values.\n\t *                            The mapping function take two arguments:\n\t *                            the first is the value at the current position\n\t *                            which goes from -1 to 1 over the number of elements\n\t *                            in the curve array. The second argument is the array position.\n\t *  @returns {Tone.WaveShaper} this\n\t *  @example\n\t * //map the input signal from [-1, 1] to [0, 10]\n\t * shaper.setMap(function(val, index){\n\t * \treturn (val + 1) * 5;\n\t * })\n\t */\n\tTone.WaveShaper.prototype.setMap = function(mapping){\n\t\tvar array = new Array(this._curve.length);\n\t\tfor (var i = 0, len = this._curve.length; i < len; i++){\n\t\t\tvar normalized = (i / (len - 1)) * 2 - 1;\n\t\t\tarray[i] = mapping(normalized, i);\n\t\t}\n\t\tthis.curve = array;\n\t\treturn this;\n\t};\n\n\t/**\n\t * The array to set as the waveshaper curve. For linear curves\n\t * array length does not make much difference, but for complex curves\n\t * longer arrays will provide smoother interpolation.\n\t * @memberOf Tone.WaveShaper#\n\t * @type {Array}\n\t * @name curve\n\t */\n\tObject.defineProperty(Tone.WaveShaper.prototype, \"curve\", {\n\t\tget : function(){\n\t\t\treturn this._shaper.curve;\n\t\t},\n\t\tset : function(mapping){\n\t\t\tthis._curve = new Float32Array(mapping);\n\t\t\tthis._shaper.curve = this._curve;\n\t\t}\n\t});\n\n\t/**\n\t * Specifies what type of oversampling (if any) should be used when\n\t * applying the shaping curve. Can either be \"none\", \"2x\" or \"4x\".\n\t * @memberOf Tone.WaveShaper#\n\t * @type {string}\n\t * @name oversample\n\t */\n\tObject.defineProperty(Tone.WaveShaper.prototype, \"oversample\", {\n\t\tget : function(){\n\t\t\treturn this._shaper.oversample;\n\t\t},\n\t\tset : function(oversampling){\n\t\t\tif ([\"none\", \"2x\", \"4x\"].includes(oversampling)){\n\t\t\t\tthis._shaper.oversample = oversampling;\n\t\t\t} else {\n\t\t\t\tthrow new RangeError(\"Tone.WaveShaper: oversampling must be either 'none', '2x', or '4x'\");\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.WaveShaper} this\n\t */\n\tTone.WaveShaper.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._shaper.disconnect();\n\t\tthis._shaper = null;\n\t\tthis._curve = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.WaveShaper;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/WaveShaper.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/signal/Zero.js":
/*!***********************************************!*\
  !*** ./node_modules/tone/Tone/signal/Zero.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../signal/SignalBase */ \"./node_modules/tone/Tone/signal/SignalBase.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Zero outputs 0's at audio-rate. The reason this has to be\n\t *         it's own class is that many browsers optimize out Tone.Signal\n\t *         with a value of 0 and will not process nodes further down the graph.\n\t *  @extends {Tone.SignalBase}\n\t */\n\tTone.Zero = function(){\n\n\t\tTone.SignalBase.call(this);\n\n\t\t/**\n\t\t *  The gain node\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._gain = this.input = this.output = new Tone.Gain();\n\n\t\tthis.context.getConstant(0).connect(this._gain);\n\t};\n\n\tTone.extend(Tone.Zero, Tone.SignalBase);\n\n\t/**\n\t *  clean up\n\t *  @return  {Tone.Zero}  this\n\t */\n\tTone.Zero.prototype.dispose = function(){\n\t\tTone.SignalBase.prototype.dispose.call(this);\n\t\tthis._gain.dispose();\n\t\tthis._gain = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Zero;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/signal/Zero.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/AMOscillator.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/source/AMOscillator.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"),\n\t__webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"), __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/Tone/signal/AudioToGain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.AMOscillator\n\t *\n\t *  @extends {Tone.Oscillator}\n\t *  @constructor\n\t *  @param {Frequency} frequency The starting frequency of the oscillator.\n\t *  @param {String} type The type of the carrier oscillator.\n\t *  @param {String} modulationType The type of the modulator oscillator.\n\t *  @example\n\t * //a sine oscillator frequency-modulated by a square wave\n\t * var fmOsc = new Tone.AMOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();\n\t */\n\tTone.AMOscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\", \"modulationType\"], Tone.AMOscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The carrier oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._carrier = new Tone.Oscillator(options.frequency, options.type);\n\n\t\t/**\n\t\t *  The oscillator's frequency\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._carrier.frequency;\n\n\t\t/**\n\t\t *  The detune control signal.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this._carrier.detune;\n\t\tthis.detune.value = options.detune;\n\n\t\t/**\n\t\t *  The modulating oscillator\n\t\t *  @type  {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._modulator = new Tone.Oscillator(options.frequency, options.modulationType);\n\n\t\t/**\n\t\t *  convert the -1,1 output to 0,1\n\t\t *  @type {Tone.AudioToGain}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationScale = new Tone.AudioToGain();\n\n\t\t/**\n\t\t *  Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n\t\t *  A harmonicity of 1 gives both oscillators the same frequency.\n\t\t *  Harmonicity = 2 means a change of an octave.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t *  @example\n\t\t * //pitch the modulator an octave below carrier\n\t\t * synth.harmonicity.value = 0.5;\n\t\t */\n\t\tthis.harmonicity = new Tone.Multiply(options.harmonicity);\n\t\tthis.harmonicity.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  the node where the modulation happens\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationNode = new Tone.Gain(0);\n\n\t\t//connections\n\t\tthis.frequency.chain(this.harmonicity, this._modulator.frequency);\n\t\tthis.detune.connect(this._modulator.detune);\n\t\tthis._modulator.chain(this._modulationScale, this._modulationNode.gain);\n\t\tthis._carrier.chain(this._modulationNode, this.output);\n\n\t\tthis.phase = options.phase;\n\n\t\tthis._readOnly([\"frequency\", \"detune\", \"harmonicity\"]);\n\t};\n\n\tTone.extend(Tone.AMOscillator, Tone.Oscillator);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.AMOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"type\" : \"sine\",\n\t\t\"modulationType\" : \"square\",\n\t\t\"harmonicity\" : 1\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.AMOscillator.prototype._start = function(time){\n\t\tthis._modulator.start(time);\n\t\tthis._carrier.start(time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.AMOscillator.prototype._stop = function(time){\n\t\tthis._modulator.stop(time);\n\t\tthis._carrier.stop(time);\n\t};\n\n\t/**\n\t *  restart the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.AMOscillator.prototype.restart = function(time){\n\t\tthis._modulator.restart(time);\n\t\tthis._carrier.restart(time);\n\t};\n\n\t/**\n\t * The type of the carrier oscillator\n\t * @memberOf Tone.AMOscillator#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._carrier.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The oscillator type without the partialsCount appended to the end\n\t * @memberOf Tone.AMOscillator#\n\t * @type {string}\n\t * @name baseType\n\t * @example\n\t * osc.type = 'sine2'\n\t * osc.baseType //'sine'\n\t * osc.partialCount = 2\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.baseType;\n\t\t},\n\t\tset : function(baseType){\n\t\t\tthis._carrier.baseType = baseType;\n\t\t}\n\t});\n\n\t/**\n\t * 'partialCount' offers an alternative way to set the number of used partials. \n\t * When partialCount is 0, the maximum number of partials are used when representing\n\t * the waveform using the periodicWave. When 'partials' is set, this value is \n\t * not settable, but equals the length of the partials array.\n\t * @memberOf Tone.AMOscillator#\n\t * @type {Number}\n\t * @name partialCount\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"partialCount\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.partialCount;\n\t\t},\n\t\tset : function(partialCount){\n\t\t\tthis._carrier.partialCount = partialCount;\n\t\t}\n\t});\n\n\t/**\n\t * The type of the modulator oscillator\n\t * @memberOf Tone.AMOscillator#\n\t * @type {string}\n\t * @name modulationType\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"modulationType\", {\n\t\tget : function(){\n\t\t\treturn this._modulator.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._modulator.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.AMOscillator#\n\t * @type {number}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._carrier.phase = phase;\n\t\t\tthis._modulator.phase = phase;\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the carrier waveform. A partial represents\n\t * the amplitude at a harmonic. The first harmonic is the\n\t * fundamental frequency, the second is the octave and so on\n\t * following the harmonic series.\n\t * Setting this value will automatically set the type to \"custom\".\n\t * The value is an empty array when the type is not \"custom\".\n\t * @memberOf Tone.AMOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @example\n\t * osc.partials = [1, 0.2, 0.01];\n\t */\n\tObject.defineProperty(Tone.AMOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.partials;\n\t\t},\n\t\tset : function(partials){\n\t\t\tthis._carrier.partials = partials;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.AMOscillator} this\n\t */\n\tTone.AMOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"detune\", \"harmonicity\"]);\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\tthis.harmonicity.dispose();\n\t\tthis.harmonicity = null;\n\t\tthis._carrier.dispose();\n\t\tthis._carrier = null;\n\t\tthis._modulator.dispose();\n\t\tthis._modulator = null;\n\t\tthis._modulationNode.dispose();\n\t\tthis._modulationNode = null;\n\t\tthis._modulationScale.dispose();\n\t\tthis._modulationScale = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.AMOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/AMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/BufferSource.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/source/BufferSource.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"),\n\t__webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\"), __webpack_require__(/*! ../shim/BufferSourceNode */ \"./node_modules/tone/Tone/shim/BufferSourceNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Wrapper around the native BufferSourceNode.\n\t *  @extends {Tone.AudioNode}\n\t *  @param  {AudioBuffer|Tone.Buffer}  buffer   The buffer to play\n\t *  @param  {Function}  onload  The callback to invoke when the\n\t *                               buffer is done playing.\n\t */\n\tTone.BufferSource = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"buffer\", \"onload\"], Tone.BufferSource);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The callback to invoke after the\n\t\t *  buffer source is done playing.\n\t\t *  @type  {Function}\n\t\t */\n\t\tthis.onended = options.onended;\n\n\t\t/**\n\t\t *  The time that the buffer was started.\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._startTime = -1;\n\n\t\t/**\n\t\t *  An additional flag if the actual BufferSourceNode\n\t\t *  has been started. b/c stopping an unstarted buffer\n\t\t *  will throw it into an invalid state\n\t\t *  @type  {Boolean}\n\t\t *  @private\n\t\t */\n\t\tthis._sourceStarted = false;\n\n\t\t/**\n\t\t *  Flag if the source has already been stopped\n\t\t *  @type  {Boolean}\n\t\t *  @private\n\t\t */\n\t\tthis._sourceStopped = false;\n\n\t\t/**\n\t\t *  The time that the buffer is scheduled to stop.\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._stopTime = -1;\n\n\t\t/**\n\t\t *  The gain node which envelopes the BufferSource\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._gainNode = this.output = new Tone.Gain(0);\n\n\t\t/**\n\t\t *  The buffer source\n\t\t *  @type  {AudioBufferSourceNode}\n\t\t *  @private\n\t\t */\n\t\tthis._source = this.context.createBufferSource();\n\t\tthis._source.connect(this._gainNode);\n\t\tthis._source.onended = this._onended.bind(this);\n\n\t\t/**\n\t\t * The private buffer instance\n\t\t * @type {Tone.Buffer}\n\t\t * @private\n\t\t */\n\t\tthis._buffer = new Tone.Buffer(options.buffer, options.onload);\n\n\t\t/**\n\t\t *  The playbackRate of the buffer\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t */\n\t\tthis.playbackRate = new Tone.Param({\n\t\t\tparam : this._source.playbackRate,\n\t\t\tunits : Tone.Type.Positive,\n\t\t\tvalue : options.playbackRate\n\t\t});\n\n\t\t/**\n\t\t *  The fadeIn time of the amplitude envelope.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.fadeIn = options.fadeIn;\n\n\t\t/**\n\t\t *  The fadeOut time of the amplitude envelope.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.fadeOut = options.fadeOut;\n\n\t\t/**\n\t\t * The curve applied to the fades, either \"linear\" or \"exponential\"\n\t\t * @type {String}\n\t\t */\n\t\tthis.curve = options.curve;\n\n\t\t/**\n\t\t * The onended timeout\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._onendedTimeout = -1;\n\n\t\t//set some values initially\n\t\tthis.loop = options.loop;\n\t\tthis.loopStart = options.loopStart;\n\t\tthis.loopEnd = options.loopEnd;\n\t};\n\n\tTone.extend(Tone.BufferSource, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.BufferSource.defaults = {\n\t\t\"onended\" : Tone.noOp,\n\t\t\"onload\" : Tone.noOp,\n\t\t\"loop\" : false,\n\t\t\"loopStart\" : 0,\n\t\t\"loopEnd\" : 0,\n\t\t\"fadeIn\" : 0,\n\t\t\"fadeOut\" : 0,\n\t\t\"curve\" : \"linear\",\n\t\t\"playbackRate\" : 1\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\" or \"stopped\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.BufferSource#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.BufferSource.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this.getStateAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Get the playback state at the given time\n\t *  @param  {Time}  time  The time to test the state at\n\t *  @return  {Tone.State}  The playback state. \n\t */\n\tTone.BufferSource.prototype.getStateAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._startTime !== -1 && \n\t\t\tthis._startTime <= time && \n\t\t\t(this._stopTime === -1 || time < this._stopTime) && \n\t\t\t!this._sourceStopped){\n\t\t\treturn Tone.State.Started;\n\t\t} else {\n\t\t\treturn Tone.State.Stopped;\n\t\t}\n\t};\n\n\t/**\n\t *  Start the buffer\n\t *  @param  {Time} [startTime=now] When the player should start.\n\t *  @param  {Time} [offset=0] The offset from the beginning of the sample\n\t *                                 to start at.\n\t *  @param  {Time=} duration How long the sample should play. If no duration\n\t *                                is given, it will default to the full length\n\t *                                of the sample (minus any offset)\n\t *  @param  {Gain}  [gain=1]  The gain to play the buffer back at.\n\t *  @param  {Time=}  fadeInTime  The optional fadeIn ramp time.\n\t *  @return  {Tone.BufferSource}  this\n\t */\n\tTone.BufferSource.prototype.start = function(time, offset, duration, gain){\n\t\tthis.log(\"start\", time, offset, duration, gain);\n\t\tthis.assert(this._startTime === -1, \"can only be started once\");\n\t\tthis.assert(this.buffer.loaded, \"buffer is either not set or not loaded\");\n\t\tthis.assert(!this._sourceStopped, \"source is already stopped\");\n\n\t\ttime = this.toSeconds(time);\n\t\t//if it's a loop the default offset is the loopstart point\n\t\tif (this.loop){\n\t\t\toffset = Tone.defaultArg(offset, this.loopStart);\n\t\t} else {\n\t\t\t//otherwise the default offset is 0\n\t\t\toffset = Tone.defaultArg(offset, 0);\n\t\t}\n\t\toffset = this.toSeconds(offset);\n\t\t//make sure the offset is not less than 0\n\t\toffset = Math.max(offset, 0);\n\n\t\tgain = Tone.defaultArg(gain, 1);\n\n\t\t//apply a fade in envelope\n\t\tvar fadeInTime = this.toSeconds(this.fadeIn);\n\t\tif (fadeInTime > 0){\n\t\t\tthis._gainNode.gain.setValueAtTime(0, time);\n\t\t\tif (this.curve === \"linear\"){\n\t\t\t\tthis._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);\n\t\t\t} else {\n\t\t\t\tthis._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);\n\t\t\t}\n\t\t} else {\n\t\t\tthis._gainNode.gain.setValueAtTime(gain, time);\n\t\t}\n\n\t\tthis._startTime = time;\n\n\t\t//if a duration is given, schedule a stop\n\t\tif (Tone.isDefined(duration)){\n\t\t\tvar computedDur = this.toSeconds(duration);\n\t\t\t//make sure it's never negative\n\t\t\tcomputedDur = Math.max(computedDur, 0);\n\n\t\t\tthis.stop(time + computedDur);\n\t\t}\n\n\t\t//start the buffer source\n\t\tif (this.loop){\n\t\t\t//modify the offset if it's greater than the loop time\n\t\t\tvar loopEnd = this.loopEnd || this.buffer.duration;\n\t\t\tvar loopStart = this.loopStart;\n\t\t\tvar loopDuration = loopEnd - loopStart;\n\t\t\t//move the offset back\n\t\t\tif (offset >= loopEnd){\n\t\t\t\toffset = ((offset - loopStart) % loopDuration) + loopStart;\n\t\t\t}\n\t\t}\n\t\tthis._source.buffer = this.buffer.get();\n\t\tthis._source.loopEnd = this.loopEnd || this.buffer.duration;\n\t\tif (offset < this.buffer.duration){\n\t\t\tthis._sourceStarted = true;\n\t\t\tthis._source.start(time, offset);\n\t\t}\n\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the buffer. Optionally add a ramp time to fade the\n\t *  buffer out. If there is a fadeOut ramp, the ramp starts at \n\t *  the given time and ends at time + fadeOut. \n\t *  @param  {Time=}  time         The time the buffer should stop.\n\t *  @return  {Tone.BufferSource}  this\n\t */\n\tTone.BufferSource.prototype.stop = function(time){\n\t\tthis.log(\"stop\", time);\n\t\tthis.assert(this.buffer.loaded, \"buffer is either not set or not loaded\");\n\t\tthis.assert(!this._sourceStopped, \"source is already stopped\");\n\n\t\ttime = this.toSeconds(time);\n\n\t\t//if the event has already been scheduled, clear it\n\t\tif (this._stopTime !== -1){\n\t\t\tthis.cancelStop();\n\t\t}\n\n\t\t//the fadeOut time\n\t\tvar fadeOutTime = this.toSeconds(this.fadeOut);\n\n\t\t//cancel the previous curve\n\t\tthis._stopTime = time + fadeOutTime;\n\n\t\tif (fadeOutTime > 0){\n\t\t\t//start the fade out curve at the given time\n\t\t\tif (this.curve === \"linear\"){\n\t\t\t\tthis._gainNode.gain.linearRampTo(0, fadeOutTime, time);\n\t\t\t} else {\n\t\t\t\tthis._gainNode.gain.targetRampTo(0, fadeOutTime, time);\n\t\t\t}\n\t\t} else {\n\t\t\t//stop any ongoing ramps, and set the value to 0\n\t\t\tthis._gainNode.gain.cancelAndHoldAtTime(time);\n\t\t\tthis._gainNode.gain.setValueAtTime(0, time);\n\t\t}\n\n\t\tTone.context.clearTimeout(this._onendedTimeout);\n\t\tthis._onendedTimeout = Tone.context.setTimeout(this._onended.bind(this), this._stopTime - this.now());\n\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel a scheduled stop event\n\t *  @return  {Tone.BufferSource}  this\n\t */\n\tTone.BufferSource.prototype.cancelStop = function(){\n\t\tif (this._startTime !== -1 && !this._sourceStopped){\n\t\t\t//cancel the stop envelope\n\t\t\tvar fadeInTime = this.toSeconds(this.fadeIn);\n\t\t\tthis._gainNode.gain.cancelScheduledValues(this._startTime + fadeInTime + this.sampleTime);\n\t\t\tthis.context.clearTimeout(this._onendedTimeout);\n\t\t\tthis._stopTime = -1;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Internal callback when the buffer is ended.\n\t *  Invokes `onended` and disposes the node.\n\t *  @private\n\t */\n\tTone.BufferSource.prototype._onended = function(){\n\t\tif (!this._sourceStopped){\n\t\t\tthis._sourceStopped = true;\n\t\t\t//allow additional time for the exponential curve to fully decay\n\t\t\tvar additionalTail = this.curve === \"exponential\" ? this.fadeOut * 2 : 0;\n\t\t\tif (this._sourceStarted && this._stopTime !== -1){\n\t\t\t\tthis._source.stop(this._stopTime + additionalTail);\n\t\t\t}\n\t\t\tthis.onended(this);\n\t\t}\n\t};\n\n\t/**\n\t * If loop is true, the loop will start at this position.\n\t * @memberOf Tone.BufferSource#\n\t * @type {Time}\n\t * @name loopStart\n\t */\n\tObject.defineProperty(Tone.BufferSource.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn this._source.loopStart;\n\t\t},\n\t\tset : function(loopStart){\n\t\t\tthis._source.loopStart = this.toSeconds(loopStart);\n\t\t}\n\t});\n\n\t/**\n\t * If loop is true, the loop will end at this position.\n\t * @memberOf Tone.BufferSource#\n\t * @type {Time}\n\t * @name loopEnd\n\t */\n\tObject.defineProperty(Tone.BufferSource.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn this._source.loopEnd;\n\t\t},\n\t\tset : function(loopEnd){\n\t\t\tthis._source.loopEnd = this.toSeconds(loopEnd);\n\t\t}\n\t});\n\n\t/**\n\t * The audio buffer belonging to the player.\n\t * @memberOf Tone.BufferSource#\n\t * @type {Tone.Buffer}\n\t * @name buffer\n\t */\n\tObject.defineProperty(Tone.BufferSource.prototype, \"buffer\", {\n\t\tget : function(){\n\t\t\treturn this._buffer;\n\t\t},\n\t\tset : function(buffer){\n\t\t\tthis._buffer.set(buffer);\n\t\t}\n\t});\n\n\t/**\n\t * If the buffer should loop once it's over.\n\t * @memberOf Tone.BufferSource#\n\t * @type {Boolean}\n\t * @name loop\n\t */\n\tObject.defineProperty(Tone.BufferSource.prototype, \"loop\", {\n\t\tget : function(){\n\t\t\treturn this._source.loop;\n\t\t},\n\t\tset : function(loop){\n\t\t\tthis._source.loop = loop;\n\t\t\tthis.cancelStop();\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.BufferSource}  this\n\t */\n\tTone.BufferSource.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.onended = null;\n\t\tthis._source.onended = null;\n\t\tthis._source.disconnect();\n\t\tthis._source = null;\n\t\tthis._gainNode.dispose();\n\t\tthis._gainNode = null;\n\t\tthis._buffer.dispose();\n\t\tthis._buffer = null;\n\t\tthis._startTime = -1;\n\t\tthis.playbackRate = null;\n\t\tTone.context.clearTimeout(this._onendedTimeout);\n\t\treturn this;\n\t};\n\n\treturn Tone.BufferSource;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/BufferSource.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/FMOscillator.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/Tone/source/FMOscillator.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"),\n\t__webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.FMOscillator\n\t *\n\t *  @extends {Tone.Source}\n\t *  @constructor\n\t *  @param {Frequency} frequency The starting frequency of the oscillator.\n\t *  @param {String} type The type of the carrier oscillator.\n\t *  @param {String} modulationType The type of the modulator oscillator.\n\t *  @example\n\t * //a sine oscillator frequency-modulated by a square wave\n\t * var fmOsc = new Tone.FMOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();\n\t */\n\tTone.FMOscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\", \"modulationType\"], Tone.FMOscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The carrier oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._carrier = new Tone.Oscillator(options.frequency, options.type);\n\n\t\t/**\n\t\t *  The oscillator's frequency\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune control signal.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this._carrier.detune;\n\t\tthis.detune.value = options.detune;\n\n\t\t/**\n\t\t *  The modulation index which is in essence the depth or amount of the modulation. In other terms it is the\n\t\t *  ratio of the frequency of the modulating signal (mf) to the amplitude of the\n\t\t *  modulating signal (ma) -- as in ma/mf.\n\t\t *\t@type {Positive}\n\t\t *\t@signal\n\t\t */\n\t\tthis.modulationIndex = new Tone.Multiply(options.modulationIndex);\n\t\tthis.modulationIndex.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  The modulating oscillator\n\t\t *  @type  {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._modulator = new Tone.Oscillator(options.frequency, options.modulationType);\n\n\t\t/**\n\t\t *  Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n\t\t *  A harmonicity of 1 gives both oscillators the same frequency.\n\t\t *  Harmonicity = 2 means a change of an octave.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t *  @example\n\t\t * //pitch the modulator an octave below carrier\n\t\t * synth.harmonicity.value = 0.5;\n\t\t */\n\t\tthis.harmonicity = new Tone.Multiply(options.harmonicity);\n\t\tthis.harmonicity.units = Tone.Type.Positive;\n\n\t\t/**\n\t\t *  the node where the modulation happens\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._modulationNode = new Tone.Gain(0);\n\n\t\t//connections\n\t\tthis.frequency.connect(this._carrier.frequency);\n\t\tthis.frequency.chain(this.harmonicity, this._modulator.frequency);\n\t\tthis.frequency.chain(this.modulationIndex, this._modulationNode);\n\t\tthis._modulator.connect(this._modulationNode.gain);\n\t\tthis._modulationNode.connect(this._carrier.frequency);\n\t\tthis._carrier.connect(this.output);\n\t\tthis.detune.connect(this._modulator.detune);\n\n\t\tthis.phase = options.phase;\n\n\t\tthis._readOnly([\"modulationIndex\", \"frequency\", \"detune\", \"harmonicity\"]);\n\t};\n\n\tTone.extend(Tone.FMOscillator, Tone.Source);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.FMOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"type\" : \"sine\",\n\t\t\"modulationIndex\" : 2,\n\t\t\"modulationType\" : \"square\",\n\t\t\"harmonicity\" : 1\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.FMOscillator.prototype._start = function(time){\n\t\tthis._modulator.start(time);\n\t\tthis._carrier.start(time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.FMOscillator.prototype._stop = function(time){\n\t\tthis._modulator.stop(time);\n\t\tthis._carrier.stop(time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.FMOscillator.prototype.restart = function(time){\n\t\tthis._modulator.restart(time);\n\t\tthis._carrier.restart(time);\n\t};\n\n\t/**\n\t * The type of the carrier oscillator\n\t * @memberOf Tone.FMOscillator#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._carrier.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The oscillator type without the partialsCount appended to the end\n\t * @memberOf Tone.FMOscillator#\n\t * @type {string}\n\t * @name baseType\n\t * @example\n\t * osc.type = 'sine2'\n\t * osc.baseType //'sine'\n\t * osc.partialCount = 2\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.baseType;\n\t\t},\n\t\tset : function(baseType){\n\t\t\tthis._carrier.baseType = baseType;\n\t\t}\n\t});\n\n\t/**\n\t * 'partialCount' offers an alternative way to set the number of used partials. \n\t * When partialCount is 0, the maximum number of partials are used when representing\n\t * the waveform using the periodicWave. When 'partials' is set, this value is \n\t * not settable, but equals the length of the partials array.\n\t * @memberOf Tone.FMOscillator#\n\t * @type {Number}\n\t * @name partialCount\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"partialCount\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.partialCount;\n\t\t},\n\t\tset : function(partialCount){\n\t\t\tthis._carrier.partialCount = partialCount;\n\t\t}\n\t});\n\n\t/**\n\t * The type of the modulator oscillator\n\t * @memberOf Tone.FMOscillator#\n\t * @type {String}\n\t * @name modulationType\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"modulationType\", {\n\t\tget : function(){\n\t\t\treturn this._modulator.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._modulator.type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.FMOscillator#\n\t * @type {number}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._carrier.phase = phase;\n\t\t\tthis._modulator.phase = phase;\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the carrier waveform. A partial represents\n\t * the amplitude at a harmonic. The first harmonic is the\n\t * fundamental frequency, the second is the octave and so on\n\t * following the harmonic series.\n\t * Setting this value will automatically set the type to \"custom\".\n\t * The value is an empty array when the type is not \"custom\".\n\t * @memberOf Tone.FMOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @example\n\t * osc.partials = [1, 0.2, 0.01];\n\t */\n\tObject.defineProperty(Tone.FMOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn this._carrier.partials;\n\t\t},\n\t\tset : function(partials){\n\t\t\tthis._carrier.partials = partials;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.FMOscillator} this\n\t */\n\tTone.FMOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._writable([\"modulationIndex\", \"frequency\", \"detune\", \"harmonicity\"]);\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\tthis.harmonicity.dispose();\n\t\tthis.harmonicity = null;\n\t\tthis._carrier.dispose();\n\t\tthis._carrier = null;\n\t\tthis._modulator.dispose();\n\t\tthis._modulator = null;\n\t\tthis._modulationNode.dispose();\n\t\tthis._modulationNode = null;\n\t\tthis.modulationIndex.dispose();\n\t\tthis.modulationIndex = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FMOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/FMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/FatOscillator.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/source/FatOscillator.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"),\n\t__webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.FatOscillator\n\t *\n\t *  @extends {Tone.Source}\n\t *  @constructor\n\t *  @param {Frequency} frequency The starting frequency of the oscillator.\n\t *  @param {String} type The type of the carrier oscillator.\n\t *  @param {String} modulationType The type of the modulator oscillator.\n\t *  @example\n\t * //a sine oscillator frequency-modulated by a square wave\n\t * var fmOsc = new Tone.FatOscillator(\"Ab3\", \"sine\", \"square\").toMaster().start();\n\t */\n\tTone.FatOscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\", \"spread\"], Tone.FatOscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The oscillator's frequency\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune control signal.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  The array of oscillators\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillators = [];\n\n\t\t/**\n\t\t *  The total spread of the oscillators\n\t\t *  @type  {Cents}\n\t\t *  @private\n\t\t */\n\t\tthis._spread = options.spread;\n\n\t\t/**\n\t\t *  The type of the oscillator\n\t\t *  @type {String}\n\t\t *  @private\n\t\t */\n\t\tthis._type = options.type;\n\n\t\t/**\n\t\t *  The phase of the oscillators\n\t\t *  @type {Degrees}\n\t\t *  @private\n\t\t */\n\t\tthis._phase = options.phase;\n\n\t\t/**\n\t\t *  The partials array\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._partials = options.partials;\n\n\t\t/**\n\t\t *  The number of partials to use\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._partialCount = options.partialCount;\n\n\t\t//set the count initially\n\t\tthis.count = options.count;\n\t\tthis._readOnly([\"frequency\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.FatOscillator, Tone.Source);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.FatOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"spread\" : 20,\n\t\t\"count\" : 3,\n\t\t\"type\" : \"sawtooth\",\n\t\t\"partials\" : [],\n\t\t\"partialCount\" : 0\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.FatOscillator.prototype._start = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._forEach(function(osc){\n\t\t\tosc.start(time);\n\t\t});\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.FatOscillator.prototype._stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._forEach(function(osc){\n\t\t\tosc.stop(time);\n\t\t});\n\t};\n\n\t/**\n\t *  restart the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.FatOscillator.prototype.restart = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._forEach(function(osc){\n\t\t\tosc.restart(time);\n\t\t});\n\t};\n\n\t/**\n\t *  Iterate over all of the oscillators\n\t *  @param  {Function}  iterator  The iterator function\n\t *  @private\n\t */\n\tTone.FatOscillator.prototype._forEach = function(iterator){\n\t\tfor (var i = 0; i < this._oscillators.length; i++){\n\t\t\titerator.call(this, this._oscillators[i], i);\n\t\t}\n\t};\n\n\t/**\n\t * The type of the carrier oscillator\n\t * @memberOf Tone.FatOscillator#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._type = type;\n\t\t\tthis._forEach(function(osc){\n\t\t\t\tosc.type = type;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The detune spread between the oscillators. If \"count\" is\n\t * set to 3 oscillators and the \"spread\" is set to 40,\n\t * the three oscillators would be detuned like this: [-20, 0, 20]\n\t * for a total detune spread of 40 cents.\n\t * @memberOf Tone.FatOscillator#\n\t * @type {Cents}\n\t * @name spread\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"spread\", {\n\t\tget : function(){\n\t\t\treturn this._spread;\n\t\t},\n\t\tset : function(spread){\n\t\t\tthis._spread = spread;\n\t\t\tif (this._oscillators.length > 1){\n\t\t\t\tvar start = -spread/2;\n\t\t\t\tvar step = spread / (this._oscillators.length - 1);\n\t\t\t\tthis._forEach(function(osc, i){\n\t\t\t\t\tosc.detune.value = start + step * i;\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The number of detuned oscillators\n\t * @memberOf Tone.FatOscillator#\n\t * @type {Number}\n\t * @name count\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"count\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators.length;\n\t\t},\n\t\tset : function(count){\n\t\t\tcount = Math.max(count, 1);\n\t\t\tif (this._oscillators.length !== count){\n\t\t\t\t//dispose the previous oscillators\n\t\t\t\tthis._forEach(function(osc){\n\t\t\t\t\tosc.dispose();\n\t\t\t\t});\n\t\t\t\tthis._oscillators = [];\n\t\t\t\tfor (var i = 0; i < count; i++){\n\t\t\t\t\tvar osc = new Tone.Oscillator();\n\t\t\t\t\tif (this.type === Tone.Oscillator.Type.Custom){\n\t\t\t\t\t\tosc.partials = this._partials;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tosc.type = this._type;\n\t\t\t\t\t}\n\t\t\t\t\tosc.partialCount = this._partialCount;\n\t\t\t\t\tosc.phase = this._phase + (i / count) * 360;\n\t\t\t\t\tosc.volume.value = -6 - count*1.1;\n\t\t\t\t\tthis.frequency.connect(osc.frequency);\n\t\t\t\t\tthis.detune.connect(osc.detune);\n\t\t\t\t\tosc.connect(this.output);\n\t\t\t\t\tthis._oscillators[i] = osc;\n\t\t\t\t}\n\t\t\t\t//set the spread\n\t\t\t\tthis.spread = this._spread;\n\t\t\t\tif (this.state === Tone.State.Started){\n\t\t\t\t\tthis._forEach(function(osc){\n\t\t\t\t\t\tosc.start();\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.FatOscillator#\n\t * @type {Number}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._phase = phase;\n\t\t\tthis._forEach(function(osc){\n\t\t\t\tosc.phase = phase;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The oscillator type without the partialsCount appended to the end\n\t * @memberOf Tone.FatOscillator#\n\t * @type {string}\n\t * @name baseType\n\t * @example\n\t * osc.type = 'sine2'\n\t * osc.baseType //'sine'\n\t * osc.partialCount = 2\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators[0].baseType;\n\t\t},\n\t\tset : function(baseType){\n\t\t\tthis._forEach(function(osc){\n\t\t\t\tosc.baseType = baseType;\n\t\t\t});\n\t\t\tthis._type = this._oscillators[0].type;\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the carrier waveform. A partial represents\n\t * the amplitude at a harmonic. The first harmonic is the\n\t * fundamental frequency, the second is the octave and so on\n\t * following the harmonic series.\n\t * Setting this value will automatically set the type to \"custom\".\n\t * The value is an empty array when the type is not \"custom\".\n\t * @memberOf Tone.FatOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @example\n\t * osc.partials = [1, 0.2, 0.01];\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators[0].partials;\n\t\t},\n\t\tset : function(partials){\n\t\t\tthis._partials = partials;\n\t\t\tthis._type = Tone.Oscillator.Type.Custom;\n\t\t\tthis._forEach(function(osc){\n\t\t\t\tosc.partials = partials;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * 'partialCount' offers an alternative way to set the number of used partials. \n\t * When partialCount is 0, the maximum number of partials are used when representing\n\t * the waveform using the periodicWave. When 'partials' is set, this value is \n\t * not settable, but equals the length of the partials array.\n\t * @memberOf Tone.FatOscillator#\n\t * @type {Number}\n\t * @name partialCount\n\t */\n\tObject.defineProperty(Tone.FatOscillator.prototype, \"partialCount\", {\n\t\tget : function(){\n\t\t\treturn this._oscillators[0].partialCount;\n\t\t},\n\t\tset : function(partialCount){\n\t\t\tthis._partialCount = partialCount;\n\t\t\tthis._forEach(function(osc){\n\t\t\t\tosc.partialCount = partialCount;\n\t\t\t});\n\t\t\tthis._type = this._oscillators[0].type;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.FatOscillator} this\n\t */\n\tTone.FatOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"detune\"]);\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis._forEach(function(osc){\n\t\t\tosc.dispose();\n\t\t});\n\t\tthis._oscillators = null;\n\t\tthis._partials = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.FatOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/FatOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/GrainPlayer.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/source/GrainPlayer.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../source/BufferSource */ \"./node_modules/tone/Tone/source/BufferSource.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t * @class Tone.GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n\t *        Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n\t *        amount of time each small chunk of audio is played for and the overlap is the\n\t *        amount of crossfading transition time between successive grains.\n\t * @extends {Tone.Source}\n\t * @param {String|Tone.Buffer} url\tThe url to load, or the Tone.Buffer to play.\n\t * @param {Function=} callback The callback to invoke after the url is loaded.\n\t */\n\tTone.GrainPlayer = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"url\", \"onload\"], Tone.GrainPlayer);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The audio buffer belonging to the player.\n\t\t *  @type  {Tone.Buffer}\n\t\t */\n\t\tthis.buffer = new Tone.Buffer(options.url, options.onload);\n\n\t\t/**\n\t\t *  Create a repeating tick to schedule\n\t\t *  the grains.\n\t\t *  @type  {Tone.Clock}\n\t\t *  @private\n\t\t */\n\t\tthis._clock = new Tone.Clock(this._tick.bind(this), options.grainSize);\n\n\t\t/**\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._loopStart = 0;\n\n\t\t/**\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._loopEnd = 0;\n\n\t\t/**\n\t\t * All of the currently playing BufferSources\n\t\t * @type {Array}\n\t\t * @private\n\t\t */\n\t\tthis._activeSources = [];\n\n\t\t/**\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._playbackRate = options.playbackRate;\n\n\t\t/**\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._grainSize = options.grainSize;\n\n\t\t/**\n\t\t *  @private\n\t\t *  @type {Number}\n\t\t */\n\t\tthis._overlap = options.overlap;\n\n\t\t/**\n\t\t *  Adjust the pitch independently of the playbackRate.\n\t\t *  @type  {Cents}\n\t\t */\n\t\tthis.detune = options.detune;\n\n\t\t//setup\n\t\tthis.overlap = options.overlap;\n\t\tthis.loop = options.loop;\n\t\tthis.playbackRate = options.playbackRate;\n\t\tthis.grainSize = options.grainSize;\n\t\tthis.loopStart = options.loopStart;\n\t\tthis.loopEnd = options.loopEnd;\n\t\tthis.reverse = options.reverse;\n\n\t\tthis._clock.on(\"stop\", this._onstop.bind(this));\n\t};\n\n\tTone.extend(Tone.GrainPlayer, Tone.Source);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.GrainPlayer.defaults = {\n\t\t\"onload\" : Tone.noOp,\n\t\t\"overlap\" : 0.1,\n\t\t\"grainSize\" : 0.2,\n\t\t\"playbackRate\" : 1,\n\t\t\"detune\" : 0,\n\t\t\"loop\" : false,\n\t\t\"loopStart\" : 0,\n\t\t\"loopEnd\" : 0,\n\t\t\"reverse\" : false\n\t};\n\n\t/**\n\t *  Play the buffer at the given startTime. Optionally add an offset\n\t *  and/or duration which will play the buffer from a position\n\t *  within the buffer for the given duration.\n\t *\n\t *  @param  {Time} [startTime=now] When the player should start.\n\t *  @param  {Time} [offset=0] The offset from the beginning of the sample\n\t *                                 to start at.\n\t *  @param  {Time=} duration How long the sample should play. If no duration\n\t *                                is given, it will default to the full length\n\t *                                of the sample (minus any offset)\n\t *  @returns {Tone.GrainPlayer} this\n\t *  @memberOf Tone.GrainPlayer#\n\t *  @method start\n\t *  @name start\n\t */\n\n\t/**\n\t *  Internal start method\n\t *  @param {Time} time\n\t *  @param {Time} offset\n\t *  @private\n\t */\n\tTone.GrainPlayer.prototype._start = function(time, offset, duration){\n\t\toffset = Tone.defaultArg(offset, 0);\n\t\toffset = this.toSeconds(offset);\n\t\ttime = this.toSeconds(time);\n\n\t\tthis._offset = offset;\n\t\tthis._clock.start(time);\n\n\t\tif (duration){\n\t\t\tthis.stop(time + this.toSeconds(duration));\n\t\t}\n\t};\n\n\t/**\n\t *  Internal start method\n\t *  @param {Time} time\n\t *  @private\n\t */\n\tTone.GrainPlayer.prototype._stop = function(time){\n\t\tthis._clock.stop(time);\n\t};\n\n\t/**\n\t * Invoked when the clock is stopped\n\t * @param  {Number} time\n\t * @private\n\t */\n\tTone.GrainPlayer.prototype._onstop = function(time){\n\t\t//stop the players\n\t\tthis._activeSources.forEach(function(source){\n\t\t\tsource.fadeOut = 0;\n\t\t\tsource.stop(time);\n\t\t});\n\t};\n\n\t/**\n\t *  Invoked on each clock tick. scheduled a new\n\t *  grain at this time.\n\t *  @param  {Time}  time\n\t *  @private\n\t */\n\tTone.GrainPlayer.prototype._tick = function(time){\n\n\t\t//check if it should stop looping\n\t\tif (!this.loop && this._offset > this.buffer.duration){\n\t\t\tthis.stop(time);\n\t\t\treturn;\n\t\t}\n\n\t\t//at the beginning of the file, the fade in should be 0\n\t\tvar fadeIn = this._offset < this._overlap ? 0 : this._overlap;\n\n\t\t//create a buffer source\n\t\tvar source = new Tone.BufferSource({\n\t\t\t\"buffer\" : this.buffer,\n\t\t\t\"fadeIn\" : fadeIn,\n\t\t\t\"fadeOut\" : this._overlap,\n\t\t\t\"loop\" : this.loop,\n\t\t\t\"loopStart\" : this._loopStart,\n\t\t\t\"loopEnd\" : this._loopEnd,\n\t\t\t//compute the playbackRate based on the detune\n\t\t\t\"playbackRate\" : Tone.intervalToFrequencyRatio(this.detune / 100)\n\t\t}).connect(this.output);\n\n\t\tsource.start(time, this._offset);\n\t\tthis._offset += this.grainSize;\n\t\tsource.stop(time + this.grainSize / this.playbackRate);\n\n\t\t//add it to the active sources\n\t\tthis._activeSources.push(source);\n\t\t//remove it when it's done\n\t\tsource.onended = function(){\n\t\t\tvar index = this._activeSources.indexOf(source);\n\t\t\tif (index !== -1){\n\t\t\t\tthis._activeSources.splice(index, 1);\n\t\t\t}\n\t\t}.bind(this);\n\t};\n\n\t/**\n\t * The playback rate of the sample\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Positive}\n\t * @name playbackRate\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._playbackRate = rate;\n\t\t\tthis.grainSize = this._grainSize;\n\t\t}\n\t});\n\n\t/**\n\t * The loop start time.\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Time}\n\t * @name loopStart\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn this._loopStart;\n\t\t},\n\t\tset : function(time){\n\t\t\tthis._loopStart = this.toSeconds(time);\n\t\t}\n\t});\n\n\t/**\n\t * The loop end time.\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Time}\n\t * @name loopEnd\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn this._loopEnd;\n\t\t},\n\t\tset : function(time){\n\t\t\tthis._loopEnd = this.toSeconds(time);\n\t\t}\n\t});\n\n\t/**\n\t * The direction the buffer should play in\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {boolean}\n\t * @name reverse\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"reverse\", {\n\t\tget : function(){\n\t\t\treturn this.buffer.reverse;\n\t\t},\n\t\tset : function(rev){\n\t\t\tthis.buffer.reverse = rev;\n\t\t}\n\t});\n\n\t/**\n\t * The size of each chunk of audio that the\n\t * buffer is chopped into and played back at.\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Time}\n\t * @name grainSize\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"grainSize\", {\n\t\tget : function(){\n\t\t\treturn this._grainSize;\n\t\t},\n\t\tset : function(size){\n\t\t\tthis._grainSize = this.toSeconds(size);\n\t\t\tthis._clock.frequency.value = this._playbackRate / this._grainSize;\n\t\t}\n\t});\n\n\t/**\n\t * This is the duration of the cross-fade between\n\t * sucessive grains.\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Time}\n\t * @name overlap\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"overlap\", {\n\t\tget : function(){\n\t\t\treturn this._overlap;\n\t\t},\n\t\tset : function(time){\n\t\t\tthis._overlap = this.toSeconds(time);\n\t\t}\n\t});\n\n\t/**\n\t * If all the buffer is loaded\n\t * @memberOf Tone.GrainPlayer#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.GrainPlayer.prototype, \"loaded\", {\n\t\tget : function(){\n\t\t\treturn this.buffer.loaded;\n\t\t}\n\t});\n\n\t/**\n\t * Clean up\n\t * @return {Tone.GrainPlayer} this\n\t */\n\tTone.GrainPlayer.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis.buffer.dispose();\n\t\tthis.buffer = null;\n\t\tthis._clock.dispose();\n\t\tthis._clock = null;\n\t\tthis._activeSources.forEach(function(source){\n\t\t\tsource.dispose();\n\t\t});\n\t\tthis._activeSources = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.GrainPlayer;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/GrainPlayer.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/Noise.js":
/*!************************************************!*\
  !*** ./node_modules/tone/Tone/source/Noise.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"),\n\t__webpack_require__(/*! ../source/BufferSource */ \"./node_modules/tone/Tone/source/BufferSource.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Noise is a noise generator. It uses looped noise buffers to save on performance.\n\t *          Tone.Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n\t *          colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Source}\n\t *  @param {string} type the noise type (white|pink|brown)\n\t *  @example\n\t * //initialize the noise and start\n\t * var noise = new Tone.Noise(\"pink\").start();\n\t *\n\t * //make an autofilter to shape the noise\n\t * var autoFilter = new Tone.AutoFilter({\n\t * \t\"frequency\" : \"8m\",\n\t * \t\"min\" : 800,\n\t * \t\"max\" : 15000\n\t * }).connect(Tone.Master);\n\t *\n\t * //connect the noise\n\t * noise.connect(autoFilter);\n\t * //start the autofilter LFO\n\t * autoFilter.start()\n\t */\n\tTone.Noise = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"type\"], Tone.Noise);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  @private\n\t\t *  @type {AudioBufferSourceNode}\n\t\t */\n\t\tthis._source = null;\n\n\t\t/**\n\t\t *  the buffer\n\t\t *  @private\n\t\t *  @type {AudioBuffer}\n\t\t */\n\t\tthis._type = options.type;\n\n\t\t/**\n\t\t *  The playback rate of the noise. Affects\n\t\t *  the \"frequency\" of the noise.\n\t\t *  @type {Positive}\n\t\t *  @signal\n\t\t */\n\t\tthis._playbackRate = options.playbackRate;\n\t};\n\n\tTone.extend(Tone.Noise, Tone.Source);\n\n\t/**\n\t *  the default parameters\n\t *\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Noise.defaults = {\n\t\t\"type\" : \"white\",\n\t\t\"playbackRate\" : 1\n\t};\n\n\t/**\n\t * The type of the noise. Can be \"white\", \"brown\", or \"pink\".\n\t * @memberOf Tone.Noise#\n\t * @type {string}\n\t * @name type\n\t * @example\n\t * noise.type = \"white\";\n\t */\n\tObject.defineProperty(Tone.Noise.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tif (this._type !== type){\n\t\t\t\tif (type in _noiseBuffers){\n\t\t\t\t\tthis._type = type;\n\t\t\t\t\t//if it's playing, stop and restart it\n\t\t\t\t\tif (this.state === Tone.State.Started){\n\t\t\t\t\t\tvar now = this.now();\n\t\t\t\t\t\tthis._stop(now);\n\t\t\t\t\t\tthis._start(now);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tthrow new TypeError(\"Tone.Noise: invalid type: \"+type);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  The playback rate of the noise. Affects\n\t *  the \"frequency\" of the noise.\n\t *  @type {Positive}\n\t *  @signal\n\t */\n\tObject.defineProperty(Tone.Noise.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._playbackRate = rate;\n\t\t\tif (this._source){\n\t\t\t\tthis._source.playbackRate.value = rate;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  internal start method\n\t *\n\t *  @param {Time} time\n\t *  @private\n\t */\n\tTone.Noise.prototype._start = function(time){\n\t\tvar buffer = _noiseBuffers[this._type];\n\t\tthis._source = new Tone.BufferSource(buffer).connect(this.output);\n\t\tthis._source.loop = true;\n\t\tthis._source.playbackRate.value = this._playbackRate;\n\t\tthis._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));\n\t};\n\n\t/**\n\t *  internal stop method\n\t *\n\t *  @param {Time} time\n\t *  @private\n\t */\n\tTone.Noise.prototype._stop = function(time){\n\t\tif (this._source){\n\t\t\tthis._source.stop(this.toSeconds(time));\n\t\t\tthis._source = null;\n\t\t}\n\t};\n\n\t/**\n\t * Restarts the noise.\n\t * @param  {Time} time When to restart the noise.\n\t * @return {Tone.Noise}      this\n\t */\n\tTone.Noise.prototype.restart = function(time){\n\t\t//TODO could be optimized by cancelling the buffer source 'stop'\n\t\t//stop and restart\n\t\tthis._stop(time);\n\t\tthis._start(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up.\n\t *  @returns {Tone.Noise} this\n\t */\n\tTone.Noise.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tif (this._source !== null){\n\t\t\tthis._source.disconnect();\n\t\t\tthis._source = null;\n\t\t}\n\t\tthis._buffer = null;\n\t\treturn this;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// THE BUFFERS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t//Noise buffer stats\n\tvar bufferLength = 44100 * 5;\n\tvar channels = 2;\n\n\t/**\n\t *\tThe noise arrays. Generated on initialization.\n\t *  borrowed heavily from https://github.com/zacharydenton/noise.js\n\t *  (c) 2013 Zach Denton (MIT)\n\t *  @static\n\t *  @private\n\t *  @type {Array}\n\t */\n\tvar _noiseBuffers = {};\n\tvar _noiseCache = {};\n\n\tObject.defineProperty(_noiseBuffers, \"pink\", {\n\t\tget : function(){\n\t\t\tif (!_noiseCache.pink){\n\t\t\t\tvar buffer = [];\n\t\t\t\tfor (var channelNum = 0; channelNum < channels; channelNum++){\n\t\t\t\t\tvar channel = new Float32Array(bufferLength);\n\t\t\t\t\tbuffer[channelNum] = channel;\n\t\t\t\t\tvar b0, b1, b2, b3, b4, b5, b6;\n\t\t\t\t\tb0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;\n\t\t\t\t\tfor (var i = 0; i < bufferLength; i++){\n\t\t\t\t\t\tvar white = Math.random() * 2 - 1;\n\t\t\t\t\t\tb0 = 0.99886 * b0 + white * 0.0555179;\n\t\t\t\t\t\tb1 = 0.99332 * b1 + white * 0.0750759;\n\t\t\t\t\t\tb2 = 0.96900 * b2 + white * 0.1538520;\n\t\t\t\t\t\tb3 = 0.86650 * b3 + white * 0.3104856;\n\t\t\t\t\t\tb4 = 0.55000 * b4 + white * 0.5329522;\n\t\t\t\t\t\tb5 = -0.7616 * b5 - white * 0.0168980;\n\t\t\t\t\t\tchannel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;\n\t\t\t\t\t\tchannel[i] *= 0.11; // (roughly) compensate for gain\n\t\t\t\t\t\tb6 = white * 0.115926;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_noiseCache.pink = new Tone.Buffer().fromArray(buffer);\n\t\t\t}\n\t\t\treturn _noiseCache.pink;\n\t\t}\n\t});\n\n\tObject.defineProperty(_noiseBuffers, \"brown\", {\n\t\tget : function(){\n\t\t\tif (!_noiseCache.brown){\n\t\t\t\tvar buffer = [];\n\t\t\t\tfor (var channelNum = 0; channelNum < channels; channelNum++){\n\t\t\t\t\tvar channel = new Float32Array(bufferLength);\n\t\t\t\t\tbuffer[channelNum] = channel;\n\t\t\t\t\tvar lastOut = 0.0;\n\t\t\t\t\tfor (var i = 0; i < bufferLength; i++){\n\t\t\t\t\t\tvar white = Math.random() * 2 - 1;\n\t\t\t\t\t\tchannel[i] = (lastOut + (0.02 * white)) / 1.02;\n\t\t\t\t\t\tlastOut = channel[i];\n\t\t\t\t\t\tchannel[i] *= 3.5; // (roughly) compensate for gain\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_noiseCache.brown = new Tone.Buffer().fromArray(buffer);\n\t\t\t}\n\t\t\treturn _noiseCache.brown;\n\t\t}\n\t});\n\n\tObject.defineProperty(_noiseBuffers, \"white\", {\n\t\tget : function(){\n\t\t\tif (!_noiseCache.white){\n\t\t\t\tvar buffer = [];\n\t\t\t\tfor (var channelNum = 0; channelNum < channels; channelNum++){\n\t\t\t\t\tvar channel = new Float32Array(bufferLength);\n\t\t\t\t\tbuffer[channelNum] = channel;\n\t\t\t\t\tfor (var i = 0; i < bufferLength; i++){\n\t\t\t\t\t\tchannel[i] = Math.random() * 2 - 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_noiseCache.white = new Tone.Buffer().fromArray(buffer);\n\t\t\t}\n\t\t\treturn _noiseCache.white;\n\t\t}\n\t});\n\n\treturn Tone.Noise;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/Noise.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/OmniOscillator.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/source/OmniOscillator.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"), __webpack_require__(/*! ../source/PulseOscillator */ \"./node_modules/tone/Tone/source/PulseOscillator.js\"), __webpack_require__(/*! ../source/PWMOscillator */ \"./node_modules/tone/Tone/source/PWMOscillator.js\"),\n\t__webpack_require__(/*! ../source/FMOscillator */ \"./node_modules/tone/Tone/source/FMOscillator.js\"), __webpack_require__(/*! ../source/AMOscillator */ \"./node_modules/tone/Tone/source/AMOscillator.js\"), __webpack_require__(/*! ../source/FatOscillator */ \"./node_modules/tone/Tone/source/FatOscillator.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.OmniOscillator aggregates Tone.Oscillator, Tone.PulseOscillator,\n\t *         Tone.PWMOscillator, Tone.FMOscillator, Tone.AMOscillator, and Tone.FatOscillator\n\t *         into one class. The oscillator class can be changed by setting the `type`.\n\t *         `omniOsc.type = \"pwm\"` will set it to the Tone.PWMOscillator. Prefixing\n\t *         any of the basic types (\"sine\", \"square4\", etc.) with \"fm\", \"am\", or \"fat\"\n\t *         will use the FMOscillator, AMOscillator or FatOscillator respectively.\n\t *         For example: `omniOsc.type = \"fatsawtooth\"` will create set the oscillator\n\t *         to a FatOscillator of type \"sawtooth\".\n\t *\n\t *  @extends {Tone.Source}\n\t *  @constructor\n\t *  @param {Frequency} frequency The initial frequency of the oscillator.\n\t *  @param {String} type The type of the oscillator.\n\t *  @example\n\t *  var omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\");\n\t */\n\tTone.OmniOscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\"], Tone.OmniOscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune control\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  the type of the oscillator source\n\t\t *  @type {String}\n\t\t *  @private\n\t\t */\n\t\tthis._sourceType = undefined;\n\n\t\t/**\n\t\t *  the oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillator = null;\n\n\t\t//set the oscillator\n\t\tthis.type = options.type;\n\t\tthis._readOnly([\"frequency\", \"detune\"]);\n\t\t//set the options\n\t\tthis.set(options);\n\t};\n\n\tTone.extend(Tone.OmniOscillator, Tone.Source);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.OmniOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"type\" : \"sine\",\n\t\t\"phase\" : 0\n\t};\n\n\t/**\n\t *  @enum {String}\n\t *  @private\n\t */\n\tvar OmniOscType = {\n\t\tPulse : \"PulseOscillator\",\n\t\tPWM : \"PWMOscillator\",\n\t\tOsc : \"Oscillator\",\n\t\tFM : \"FMOscillator\",\n\t\tAM : \"AMOscillator\",\n\t\tFat : \"FatOscillator\"\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param {Time} [time=now] the time to start the oscillator\n\t *  @private\n\t */\n\tTone.OmniOscillator.prototype._start = function(time){\n\t\tthis._oscillator.start(time);\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param {Time} [time=now] the time to start the oscillator\n\t *  @private\n\t */\n\tTone.OmniOscillator.prototype._stop = function(time){\n\t\tthis._oscillator.stop(time);\n\t};\n\n\tTone.OmniOscillator.prototype.restart = function(time){\n\t\tthis._oscillator.restart(time);\n\t};\n\n\t/**\n\t * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or\n\t * prefix the basic types with \"fm\", \"am\", or \"fat\" to use the FMOscillator, AMOscillator or FatOscillator\n\t * types. The oscillator could also be set to \"pwm\" or \"pulse\". All of the parameters of the\n\t * oscillator's class are accessible when the oscillator is set to that type, but throws an error\n\t * when it's not.\n\t *\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {String}\n\t * @name type\n\t * @example\n\t * omniOsc.type = \"pwm\";\n\t * //modulationFrequency is parameter which is available\n\t * //only when the type is \"pwm\".\n\t * omniOsc.modulationFrequency.value = 0.5;\n\t * @example\n\t * //an square wave frequency modulated by a sawtooth\n\t * omniOsc.type = \"fmsquare\";\n\t * omniOsc.modulationType = \"sawtooth\";\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\tvar prefix = \"\";\n\t\t\tif (this._sourceType === OmniOscType.FM){\n\t\t\t\tprefix = \"fm\";\n\t\t\t} else if (this._sourceType === OmniOscType.AM){\n\t\t\t\tprefix = \"am\";\n\t\t\t} else if (this._sourceType === OmniOscType.Fat){\n\t\t\t\tprefix = \"fat\";\n\t\t\t}\n\t\t\treturn prefix + this._oscillator.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tif (type.substr(0, 2) === \"fm\"){\n\t\t\t\tthis._createNewOscillator(OmniOscType.FM);\n\t\t\t\tthis._oscillator.type = type.substr(2);\n\t\t\t} else if (type.substr(0, 2) === \"am\"){\n\t\t\t\tthis._createNewOscillator(OmniOscType.AM);\n\t\t\t\tthis._oscillator.type = type.substr(2);\n\t\t\t} else if (type.substr(0, 3) === \"fat\"){\n\t\t\t\tthis._createNewOscillator(OmniOscType.Fat);\n\t\t\t\tthis._oscillator.type = type.substr(3);\n\t\t\t} else if (type === \"pwm\"){\n\t\t\t\tthis._createNewOscillator(OmniOscType.PWM);\n\t\t\t} else if (type === \"pulse\"){\n\t\t\t\tthis._createNewOscillator(OmniOscType.Pulse);\n\t\t\t} else {\n\t\t\t\tthis._createNewOscillator(OmniOscType.Osc);\n\t\t\t\tthis._oscillator.type = type;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the waveform. A partial represents\n\t * the amplitude at a harmonic. The first harmonic is the\n\t * fundamental frequency, the second is the octave and so on\n\t * following the harmonic series.\n\t * Setting this value will automatically set the type to \"custom\".\n\t * The value is an empty array when the type is not \"custom\".\n\t * This is not available on \"pwm\" and \"pulse\" oscillator types.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @example\n\t * osc.partials = [1, 0.2, 0.01];\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.partials;\n\t\t},\n\t\tset : function(partials){\n\t\t\tthis._oscillator.partials = partials;\n\t\t}\n\t});\n\n\t/**\n\t * The partial count of the oscillator. This is not available on \"pwm\" and \"pulse\" oscillator types.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Number}\n\t * @name partialCount\n\t * @example\n\t * //set the maximum number of partials\n\t * osc.partialCount = 0;\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"partialCount\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.partialCount;\n\t\t},\n\t\tset : function(partialCount){\n\t\t\tthis._oscillator.partialCount = partialCount;\n\t\t}\n\t});\n\n\t/**\n\t *  Set a member/attribute of the oscillator.\n\t *  @param {Object|String} params\n\t *  @param {number=} value\n\t *  @param {Time=} rampTime\n\t *  @returns {Tone.OmniOscillator} this\n\t */\n\tTone.OmniOscillator.prototype.set = function(params, value){\n\t\t//make sure the type is set first\n\t\tif (params === \"type\"){\n\t\t\tthis.type = value;\n\t\t} else if (Tone.isObject(params) && params.hasOwnProperty(\"type\")){\n\t\t\tthis.type = params.type;\n\t\t}\n\t\t//then set the rest\n\t\tTone.prototype.set.apply(this, arguments);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Get the object's attributes. Given no arguments get\n\t *  will return all available object properties and their corresponding\n\t *  values. Pass in a single attribute to retrieve or an array\n\t *  of attributes. The attribute strings can also include a \".\"\n\t *  to access deeper properties.\n\t *  @param {Array=|string|undefined} params the parameters to get, otherwise will return\n\t *  \t\t\t\t\t                  all available.\n\t *  @returns {Object}\n\t */\n\tTone.OmniOscillator.prototype.get = function(params){\n\t\tvar options = this._oscillator.get(params);\n\t\toptions.type = this.type;\n\t\treturn options;\n\t};\n\n\t/**\n\t *  connect the oscillator to the frequency and detune signals\n\t *  @private\n\t */\n\tTone.OmniOscillator.prototype._createNewOscillator = function(oscType){\n\t\tif (oscType !== this._sourceType){\n\t\t\tthis._sourceType = oscType;\n\t\t\tvar OscillatorConstructor = Tone[oscType];\n\t\t\t//short delay to avoid clicks on the change\n\t\t\tvar now = this.now();\n\t\t\tif (this._oscillator !== null){\n\t\t\t\tvar oldOsc = this._oscillator;\n\t\t\t\toldOsc.stop(now);\n\t\t\t\t//dispose the old one\n\t\t\t\tthis.context.setTimeout(function(){\n\t\t\t\t\toldOsc.dispose();\n\t\t\t\t\toldOsc = null;\n\t\t\t\t}, this.blockTime);\n\t\t\t}\n\t\t\tthis._oscillator = new OscillatorConstructor();\n\t\t\tthis.frequency.connect(this._oscillator.frequency);\n\t\t\tthis.detune.connect(this._oscillator.detune);\n\t\t\tthis._oscillator.connect(this.output);\n\t\t\tif (this.state === Tone.State.Started){\n\t\t\t\tthis._oscillator.start(now);\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Degrees}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._oscillator.phase = phase;\n\t\t}\n\t});\n\n\t/**\n\t * The source type names\n\t * @private\n\t * @type {Object}\n\t */\n\tvar SourceTypeNames = {\n\t\tPulseOscillator : \"pulse\",\n\t\tPWMOscillator : \"pwm\",\n\t\tOscillator : \"oscillator\",\n\t\tFMOscillator : \"fm\",\n\t\tAMOscillator : \"am\",\n\t\tFatOscillator : \"fat\"\n\t};\n\n\t/**\n\t * The source type of the oscillator. \n\t * @memberOf Tone.OmniOscillator#\n\t * @type {String}\n\t * @name sourceType\n\t * @example\n\t * var omniOsc = new Tone.OmniOscillator(440, \"fmsquare\");\n\t * omniOsc.sourceType // 'fm'\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"sourceType\", {\n\t\tget : function(){\n\t\t\treturn SourceTypeNames[this._sourceType];\n\t\t},\n\t\tset : function(sType){\n\t\t\t//the basetype defaults to sine\n\t\t\tvar baseType = \"sine\";\n\t\t\tif (this._oscillator.type !== \"pwm\" && this._oscillator.type !== \"pulse\"){\n\t\t\t\tbaseType = this._oscillator.type;\n\t\t\t} \n\n\t\t\t//set the type\n\t\t\tif (sType === SourceTypeNames.FMOscillator){\n\t\t\t\tthis.type = \"fm\" + baseType;\n\t\t\t} else if (sType === SourceTypeNames.AMOscillator){\n\t\t\t\tthis.type = \"am\" + baseType;\n\t\t\t} else if (sType === SourceTypeNames.FatOscillator){\n\t\t\t\tthis.type = \"fat\" + baseType;\n\t\t\t} else if (sType === SourceTypeNames.Oscillator){\n\t\t\t\tthis.type = baseType;\n\t\t\t} else if (sType === SourceTypeNames.PulseOscillator){\n\t\t\t\tthis.type = \"pulse\";\n\t\t\t} else if (sType === SourceTypeNames.PWMOscillator){\n\t\t\t\tthis.type = \"pwm\";\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The base type of the oscillator.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {String}\n\t * @name baseType\n\t * @example\n\t * var omniOsc = new Tone.OmniOscillator(440, \"fmsquare4\");\n\t * omniOsc.sourceType // 'fm'\n\t * omniOsc.baseType //'square'\n\t * omniOsc.partialCount //4\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.baseType;\n\t\t},\n\t\tset : function(baseType){\n\t\t\tif (this.sourceType !== SourceTypeNames.PulseOscillator && this.sourceType !== SourceTypeNames.PWMOscillator){\n\t\t\t\tthis._oscillator.baseType = baseType;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The width of the oscillator (only if the oscillator is set to \"pulse\")\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {NormalRange}\n\t * @signal\n\t * @name width\n\t * @example\n\t * var omniOsc = new Tone.OmniOscillator(440, \"pulse\");\n\t * //can access the width attribute only if type === \"pulse\"\n\t * omniOsc.width.value = 0.2;\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"width\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.Pulse){\n\t\t\t\treturn this._oscillator.width;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The number of detuned oscillators\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Number}\n\t * @name count\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"count\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.Fat){\n\t\t\t\treturn this._oscillator.count;\n\t\t\t}\n\t\t},\n\t\tset : function(count){\n\t\t\tif (this._sourceType === OmniOscType.Fat){\n\t\t\t\tthis._oscillator.count = count;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The detune spread between the oscillators. If \"count\" is\n\t * set to 3 oscillators and the \"spread\" is set to 40,\n\t * the three oscillators would be detuned like this: [-20, 0, 20]\n\t * for a total detune spread of 40 cents. See Tone.FatOscillator\n\t * for more info.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Cents}\n\t * @name spread\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"spread\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.Fat){\n\t\t\t\treturn this._oscillator.spread;\n\t\t\t}\n\t\t},\n\t\tset : function(spread){\n\t\t\tif (this._sourceType === OmniOscType.Fat){\n\t\t\t\tthis._oscillator.spread = spread;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The type of the modulator oscillator. Only if the oscillator\n\t * is set to \"am\" or \"fm\" types. see. Tone.AMOscillator or Tone.FMOscillator\n\t * for more info.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {String}\n\t * @name modulationType\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"modulationType\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.FM || this._sourceType === OmniOscType.AM){\n\t\t\t\treturn this._oscillator.modulationType;\n\t\t\t}\n\t\t},\n\t\tset : function(mType){\n\t\t\tif (this._sourceType === OmniOscType.FM || this._sourceType === OmniOscType.AM){\n\t\t\t\tthis._oscillator.modulationType = mType;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The modulation index which is in essence the depth or amount of the modulation. In other terms it is the\n\t * ratio of the frequency of the modulating signal (mf) to the amplitude of the\n\t * modulating signal (ma) -- as in ma/mf.\n\t * See Tone.FMOscillator for more info.\n\t * @type {Positive}\n\t * @signal\n\t * @name modulationIndex\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"modulationIndex\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.FM){\n\t\t\t\treturn this._oscillator.modulationIndex;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n\t *  A harmonicity of 1 gives both oscillators the same frequency.\n\t *  Harmonicity = 2 means a change of an octave. See Tone.AMOscillator or Tone.FMOscillator\n\t *  for more info.\n\t *  @memberOf Tone.OmniOscillator#\n\t *  @signal\n\t *  @type {Positive}\n\t *  @name harmonicity\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"harmonicity\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.FM || this._sourceType === OmniOscType.AM){\n\t\t\t\treturn this._oscillator.harmonicity;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The modulationFrequency Signal of the oscillator\n\t * (only if the oscillator type is set to pwm). See\n\t * Tone.PWMOscillator for more info.\n\t * @memberOf Tone.OmniOscillator#\n\t * @type {Frequency}\n\t * @signal\n\t * @name modulationFrequency\n\t * @example\n\t * var omniOsc = new Tone.OmniOscillator(440, \"pwm\");\n\t * //can access the modulationFrequency attribute only if type === \"pwm\"\n\t * omniOsc.modulationFrequency.value = 0.2;\n\t */\n\tObject.defineProperty(Tone.OmniOscillator.prototype, \"modulationFrequency\", {\n\t\tget : function(){\n\t\t\tif (this._sourceType === OmniOscType.PWM){\n\t\t\t\treturn this._oscillator.modulationFrequency;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.OmniOscillator} this\n\t */\n\tTone.OmniOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._writable([\"frequency\", \"detune\"]);\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis._oscillator.dispose();\n\t\tthis._oscillator = null;\n\t\tthis._sourceType = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.OmniOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/OmniOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/Oscillator.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/source/Oscillator.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"),\n\t__webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\"), __webpack_require__(/*! ../source/OscillatorNode */ \"./node_modules/tone/Tone/source/OscillatorNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.Oscillator supports a number of features including\n\t *         phase rotation, multiple oscillator types (see Tone.Oscillator.type),\n\t *         and Transport syncing (see Tone.Oscillator.syncFrequency).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Source}\n\t *  @param {Frequency} [frequency] Starting frequency\n\t *  @param {string} [type] The oscillator type. Read more about type below.\n\t *  @example\n\t * //make and start a 440hz sine tone\n\t * var osc = new Tone.Oscillator(440, \"sine\").toMaster().start();\n\t */\n\tTone.Oscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\"], Tone.Oscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  the main oscillator\n\t\t *  @type {OscillatorNode}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillator = null;\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Signal(options.frequency, Tone.Type.Frequency);\n\n\t\t/**\n\t\t *  The detune control signal.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Signal(options.detune, Tone.Type.Cents);\n\n\t\t/**\n\t\t *  the periodic wave\n\t\t *  @type {PeriodicWave}\n\t\t *  @private\n\t\t */\n\t\tthis._wave = null;\n\n\t\t/**\n\t\t *  The partials of the oscillator\n\t\t *  @type {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._partials = options.partials;\n\n\t\t/**\n\t\t *  The number of partials to limit or extend the periodic wave by\n\t\t *  @type {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._partialCount = options.partialCount;\n\n\t\t/**\n\t\t *  the phase of the oscillator\n\t\t *  between 0 - 360\n\t\t *  @type {number}\n\t\t *  @private\n\t\t */\n\t\tthis._phase = options.phase;\n\n\t\t/**\n\t\t *  the type of the oscillator\n\t\t *  @type {string}\n\t\t *  @private\n\t\t */\n\t\tthis._type = options.type;\n\n\t\t//setup\n\t\tif (options.partialCount && options.type !== Tone.Oscillator.Type.Custom){\n\t\t\tthis._type = this.baseType + options.partialCount.toString();\n\t\t}\n\t\tthis.phase = this._phase;\n\t\tthis._readOnly([\"frequency\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.Oscillator, Tone.Source);\n\n\t/**\n\t *  the default parameters\n\t *  @type {Object}\n\t */\n\tTone.Oscillator.defaults = {\n\t\t\"type\" : \"sine\",\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"partials\" : [],\n\t\t\"partialCount\" : 0\n\t};\n\n\t/**\n\t *  The Oscillator types\n\t *  @enum {String}\n\t */\n\tTone.Oscillator.Type = {\n\t\tSine : \"sine\",\n\t\tTriangle : \"triangle\",\n\t\tSawtooth : \"sawtooth\",\n\t\tSquare : \"square\",\n\t\tCustom : \"custom\"\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.Oscillator.prototype._start = function(time){\n\t\tthis.log(\"start\", time);\n\t\t//new oscillator with previous values\n\t\tthis._oscillator = new Tone.OscillatorNode();\n\t\tif (this._wave){\n\t\t\tthis._oscillator.setPeriodicWave(this._wave);\n\t\t} else {\n\t\t\tthis._oscillator.type = this._type;\n\t\t}\n\t\t//connect the control signal to the oscillator frequency & detune\n\t\tthis._oscillator.connect(this.output);\n\t\tthis.frequency.connect(this._oscillator.frequency);\n\t\tthis.detune.connect(this._oscillator.detune);\n\t\t//start the oscillator\n\t\ttime = this.toSeconds(time);\n\t\tthis._oscillator.start(time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @private\n\t *  @param  {Time} [time=now] (optional) timing parameter\n\t *  @returns {Tone.Oscillator} this\n\t */\n\tTone.Oscillator.prototype._stop = function(time){\n\t\tthis.log(\"stop\", time);\n\t\tif (this._oscillator){\n\t\t\ttime = this.toSeconds(time);\n\t\t\tthis._oscillator.stop(time);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * Restart the oscillator. Does not stop the oscillator, but instead\n\t * just cancels any scheduled 'stop' from being invoked.\n\t * @param  {Time=} time\n\t * @return {Tone.Oscillator}      this\n\t */\n\tTone.Oscillator.prototype.restart = function(time){\n\t\tif (this._oscillator){\n\t\t\tthis._oscillator.cancelStop();\n\t\t}\n\t\tthis._state.cancel(this.toSeconds(time));\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sync the signal to the Transport's bpm. Any changes to the transports bpm,\n\t *  will also affect the oscillators frequency.\n\t *  @returns {Tone.Oscillator} this\n\t *  @example\n\t * Tone.Transport.bpm.value = 120;\n\t * osc.frequency.value = 440;\n\t * //the ration between the bpm and the frequency will be maintained\n\t * osc.syncFrequency();\n\t * Tone.Transport.bpm.value = 240;\n\t * // the frequency of the oscillator is doubled to 880\n\t */\n\tTone.Oscillator.prototype.syncFrequency = function(){\n\t\tTone.Transport.syncSignal(this.frequency);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Unsync the oscillator's frequency from the Transport.\n\t *  See Tone.Oscillator.syncFrequency\n\t *  @returns {Tone.Oscillator} this\n\t */\n\tTone.Oscillator.prototype.unsyncFrequency = function(){\n\t\tTone.Transport.unsyncSignal(this.frequency);\n\t\treturn this;\n\t};\n\n\t/**\n\t * The type of the oscillator: either sine, square, triangle, or sawtooth. Also capable of\n\t * setting the first x number of partials of the oscillator. For example: \"sine4\" would\n\t * set be the first 4 partials of the sine wave and \"triangle8\" would set the first\n\t * 8 partials of the triangle wave.\n\t * <br><br>\n\t * Uses PeriodicWave internally even for native types so that it can set the phase.\n\t * PeriodicWave equations are from the\n\t * [Webkit Web Audio implementation](https://code.google.com/p/chromium/codesearch#chromium/src/third_party/WebKit/Source/modules/webaudio/PeriodicWave.cpp&sq=package:chromium).\n\t *\n\t * @memberOf Tone.Oscillator#\n\t * @type {string}\n\t * @name type\n\t * @example\n\t * //set it to a square wave\n\t * osc.type = \"square\";\n\t * @example\n\t * //set the first 6 partials of a sawtooth wave\n\t * osc.type = \"sawtooth6\";\n\t */\n\tObject.defineProperty(Tone.Oscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._type;\n\t\t},\n\t\tset : function(type){\n\t\t\tvar coefs = this._getRealImaginary(type, this._phase);\n\t\t\tvar periodicWave = this.context.createPeriodicWave(coefs[0], coefs[1]);\n\t\t\tthis._wave = periodicWave;\n\t\t\tif (this._oscillator !== null){\n\t\t\t\tthis._oscillator.setPeriodicWave(this._wave);\n\t\t\t}\n\t\t\tthis._type = type;\n\t\t}\n\t});\n\n\t/**\n\t * The oscillator type without the partialsCount appended to the end\n\t * @memberOf Tone.Oscillator#\n\t * @type {string}\n\t * @name baseType\n\t * @example\n\t * osc.type = 'sine2'\n\t * osc.baseType //'sine'\n\t * osc.partialCount = 2\n\t */\n\tObject.defineProperty(Tone.Oscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn this._type.replace(this.partialCount, \"\");\n\t\t},\n\t\tset : function(baseType){\n\t\t\tif (this.partialCount && this._type !== Tone.Oscillator.Type.Custom && baseType !== Tone.Oscillator.Type.Custom){\n\t\t\t\tthis.type = baseType + this.partialCount;\n\t\t\t} else {\n\t\t\t\tthis.type = baseType;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * 'partialCount' offers an alternative way to set the number of used partials. \n\t * When partialCount is 0, the maximum number of partials are used when representing\n\t * the waveform using the periodicWave. When 'partials' is set, this value is \n\t * not settable, but equals the length of the partials array.\n\t * @example\n\t * osc.type = 'sine'\n\t * osc.partialCount = 3\n\t * //is equivalent to\n\t * osc.type = 'sine3'\n\t * @memberOf Tone.Oscillator#\n\t * @type {Number}\n\t * @name partialCount\n\t */\n\tObject.defineProperty(Tone.Oscillator.prototype, \"partialCount\", {\n\t\tget : function(){\n\t\t\treturn this._partialCount;\n\t\t},\n\t\tset : function(p){\n\t\t\tvar type = this._type;\n\t\t\tvar partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(this._type);\n\t\t\tif (partial){\n\t\t\t\ttype = partial[1];\n\t\t\t}\n\t\t\tif (this._type !== Tone.Oscillator.Type.Custom){\n\t\t\t\tif (p === 0){\n\t\t\t\t\tthis.type = type;\n\t\t\t\t} else {\n\t\t\t\t\tthis.type = type + p.toString();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Get the object's attributes. Given no arguments get\n\t *  will return all available object properties and their corresponding\n\t *  values. \n\t *  @memberOf Tone.Oscillator#\n\t *  @returns {Object}\n\t */\n\tTone.Oscillator.prototype.get = function(){\n\t\tconst values = Tone.prototype.get.apply(this, arguments);\n\t\tif (values.type !== Tone.Oscillator.Type.Custom){\n\t\t\tdelete values.partials;\n\t\t}\n\t\treturn values;\n\t};\n\n\t/**\n\t *  Returns the real and imaginary components based\n\t *  on the oscillator type.\n\t *  @returns {Array} [real, imaginary]\n\t *  @private\n\t */\n\tTone.Oscillator.prototype._getRealImaginary = function(type, phase){\n\t\tvar fftSize = 4096;\n\t\tvar periodicWaveSize = fftSize / 2;\n\n\t\tvar real = new Float32Array(periodicWaveSize);\n\t\tvar imag = new Float32Array(periodicWaveSize);\n\n\t\tvar partialCount = 1;\n\t\tif (type === Tone.Oscillator.Type.Custom){\n\t\t\tpartialCount = this._partials.length + 1;\n\t\t\tthis._partialCount = this._partials.length;\n\t\t\tperiodicWaveSize = partialCount;\n\t\t} else {\n\t\t\tvar partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(type);\n\t\t\tif (partial){\n\t\t\t\tpartialCount = parseInt(partial[2]) + 1;\n\t\t\t\tthis._partialCount = parseInt(partial[2]);\n\t\t\t\ttype = partial[1];\n\t\t\t\tpartialCount = Math.max(partialCount, 2);\n\t\t\t\tperiodicWaveSize = partialCount;\n\t\t\t} else {\n\t\t\t\tthis._partialCount = 0;\n\t\t\t}\n\t\t\tthis._partials = [];\n\t\t}\n\n\t\tfor (var n = 1; n < periodicWaveSize; ++n){\n\t\t\tvar piFactor = 2 / (n * Math.PI);\n\t\t\tvar b;\n\t\t\tswitch (type){\n\t\t\t\tcase Tone.Oscillator.Type.Sine:\n\t\t\t\t\tb = (n <= partialCount) ? 1 : 0;\n\t\t\t\t\tthis._partials[n-1] = b;\n\t\t\t\t\tbreak;\n\t\t\t\tcase Tone.Oscillator.Type.Square:\n\t\t\t\t\tb = (n & 1) ? 2 * piFactor : 0;\n\t\t\t\t\tthis._partials[n-1] = b;\n\t\t\t\t\tbreak;\n\t\t\t\tcase Tone.Oscillator.Type.Sawtooth:\n\t\t\t\t\tb = piFactor * ((n & 1) ? 1 : -1);\n\t\t\t\t\tthis._partials[n-1] = b;\n\t\t\t\t\tbreak;\n\t\t\t\tcase Tone.Oscillator.Type.Triangle:\n\t\t\t\t\tif (n & 1){\n\t\t\t\t\t\tb = 2 * (piFactor * piFactor) * ((((n - 1) >> 1) & 1) ? -1 : 1);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tb = 0;\n\t\t\t\t\t}\n\t\t\t\t\tthis._partials[n-1] = b;\n\t\t\t\t\tbreak;\n\t\t\t\tcase Tone.Oscillator.Type.Custom:\n\t\t\t\t\tb = this._partials[n - 1];\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new TypeError(\"Tone.Oscillator: invalid type: \"+type);\n\t\t\t}\n\t\t\tif (b !== 0){\n\t\t\t\treal[n] = -b * Math.sin(phase * n);\n\t\t\t\timag[n] = b * Math.cos(phase * n);\n\t\t\t} else {\n\t\t\t\treal[n] = 0;\n\t\t\t\timag[n] = 0;\n\t\t\t}\n\t\t}\n\t\treturn [real, imag];\n\t};\n\n\t/**\n\t *  Compute the inverse FFT for a given phase.\n\t *  @param  {Float32Array}  real\n\t *  @param  {Float32Array}  imag\n\t *  @param  {NormalRange}  phase\n\t *  @return  {AudioRange}\n\t *  @private\n\t */\n\tTone.Oscillator.prototype._inverseFFT = function(real, imag, phase){\n\t\tvar sum = 0;\n\t\tvar len = real.length;\n\t\tfor (var i = 0; i < len; i++){\n\t\t\tsum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);\n\t\t}\n\t\treturn sum;\n\t};\n\n\t/**\n\t *  Returns the initial value of the oscillator.\n\t *  @return  {AudioRange}\n\t *  @private\n\t */\n\tTone.Oscillator.prototype._getInitialValue = function(){\n\t\tvar coefs = this._getRealImaginary(this._type, 0);\n\t\tvar real = coefs[0];\n\t\tvar imag = coefs[1];\n\t\tvar maxValue = 0;\n\t\tvar twoPi = Math.PI * 2;\n\t\t//check for peaks in 8 places\n\t\tfor (var i = 0; i < 8; i++){\n\t\t\tmaxValue = Math.max(this._inverseFFT(real, imag, (i / 8) * twoPi), maxValue);\n\t\t}\n\t\treturn -this._inverseFFT(real, imag, this._phase) / maxValue;\n\t};\n\n\t/**\n\t * The partials of the waveform. A partial represents\n\t * the amplitude at a harmonic. The first harmonic is the\n\t * fundamental frequency, the second is the octave and so on\n\t * following the harmonic series.\n\t * Setting this value will automatically set the type to \"custom\".\n\t * The value is an empty array when the type is not \"custom\".\n\t * @memberOf Tone.Oscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @example\n\t * osc.partials = [1, 0.2, 0.01];\n\t */\n\tObject.defineProperty(Tone.Oscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn this._partials;\n\t\t},\n\t\tset : function(partials){\n\t\t\tthis._partials = partials;\n\t\t\tthis.type = Tone.Oscillator.Type.Custom;\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.Oscillator#\n\t * @type {Degrees}\n\t * @name phase\n\t * @example\n\t * osc.phase = 180; //flips the phase of the oscillator\n\t */\n\tObject.defineProperty(Tone.Oscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._phase * (180 / Math.PI);\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._phase = phase * Math.PI / 180;\n\t\t\t//reset the type\n\t\t\tthis.type = this._type;\n\t\t}\n\t});\n\n\t/**\n\t *  Dispose and disconnect.\n\t *  @return {Tone.Oscillator} this\n\t */\n\tTone.Oscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tif (this._oscillator !== null){\n\t\t\tthis._oscillator.dispose();\n\t\t\tthis._oscillator = null;\n\t\t}\n\t\tthis._wave = null;\n\t\tthis._writable([\"frequency\", \"detune\"]);\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\tthis._partials = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Oscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/Oscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/OscillatorNode.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/Tone/source/OscillatorNode.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\"),\n\t__webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Wrapper around the native fire-and-forget OscillatorNode. Adds the\n\t *     ability to reschedule the stop method. ***[Tone.Oscillator](Oscillator) is better \n\t *     for most use-cases***\n\t *  @extends {Tone.AudioNode}\n\t *  @param  {AudioBuffer|Tone.Buffer}  buffer   The buffer to play\n\t *  @param  {Function}  onload  The callback to invoke when the\n\t *                               buffer is done playing.\n\t */\n\tTone.OscillatorNode = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"type\"], Tone.OscillatorNode);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The callback to invoke after the\n\t\t *  buffer source is done playing.\n\t\t *  @type  {Function}\n\t\t */\n\t\tthis.onended = options.onended;\n\n\t\t/**\n\t\t *  The oscillator start time\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._startTime = -1;\n\n\t\t/**\n\t\t *  The oscillator stop time\n\t\t *  @type  {Number}\n\t\t *  @private\n\t\t */\n\t\tthis._stopTime = -1;\n\n\t\t/**\n\t\t *  The gain node which envelopes the OscillatorNode\n\t\t *  @type  {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._gainNode = this.output = new Tone.Gain(0);\n\n\t\t/**\n\t\t *  The oscillator\n\t\t *  @type  {OscillatorNode}\n\t\t *  @private\n\t\t */\n\t\tthis._oscillator = this.context.createOscillator();\n\t\tthis._oscillator.connect(this._gainNode);\n\t\tthis.type = options.type;\n\n\t\t/**\n\t\t *  The frequency of the oscillator\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.Param({\n\t\t\tparam : this._oscillator.frequency, \n\t\t\tunits : Tone.Type.Frequency,\n\t\t\tvalue : options.frequency\n\t\t});\n\n\t\t/**\n\t\t *  The detune of the oscillator\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = new Tone.Param({\n\t\t\tparam : this._oscillator.detune,\n\t\t\tunits : Tone.Type.Cents,\n\t\t\tvalue : options.detune\n\t\t});\n\n\t\t/**\n\t\t *  The value that the buffer ramps to\n\t\t *  @type {Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._gain = 1;\n\t};\n\n\tTone.extend(Tone.OscillatorNode, Tone.AudioNode);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.OscillatorNode.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"type\" : \"sine\",\n\t\t\"onended\" : Tone.noOp\n\t};\n\n\t/**\n\t *  Returns the playback state of the oscillator, either \"started\" or \"stopped\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.OscillatorNode#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.OscillatorNode.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this.getStateAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Get the playback state at the given time\n\t *  @param  {Time}  time  The time to test the state at\n\t *  @return  {Tone.State}  The playback state. \n\t */\n\tTone.OscillatorNode.prototype.getStateAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._startTime !== -1 && time >= this._startTime && (this._stopTime === -1 || time <= this._stopTime)){\n\t\t\treturn Tone.State.Started;\n\t\t} else {\n\t\t\treturn Tone.State.Stopped;\n\t\t}\n\t};\n\n\t/**\n     * Start the oscillator node at the given time\n     * @param  {Time=} time When to start the oscillator\n     * @return {OscillatorNode}      this\n     */\n\tTone.OscillatorNode.prototype.start = function(time){\n\t\tthis.log(\"start\", time);\n\t\tif (this._startTime === -1){\n\t\t\tthis._startTime = this.toSeconds(time);\n\t\t\tthis._oscillator.start(this._startTime);\n\t\t\tthis._gainNode.gain.setValueAtTime(1, this._startTime);\n\t\t} else {\n\t\t\tthrow new Error(\"cannot call OscillatorNode.start more than once\");\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n     * Sets an arbitrary custom periodic waveform given a PeriodicWave.\n     * @param  {PeriodicWave} periodicWave PeriodicWave should be created with context.createPeriodicWave\n     * @return {OscillatorNode} this\n     */\n\tTone.OscillatorNode.prototype.setPeriodicWave = function(periodicWave){\n\t\tthis._oscillator.setPeriodicWave(periodicWave);\n\t\treturn this;\n\t};\n\n\t/**\n     * Stop the oscillator node at the given time\n     * @param  {Time=} time When to stop the oscillator\n     * @return {OscillatorNode}      this\n     */\n\tTone.OscillatorNode.prototype.stop = function(time){\n\t\tthis.log(\"stop\", time);\n\t\tthis.assert(this._startTime !== -1, \"'start' must be called before 'stop'\");\n\t\t//cancel the previous stop\n\t\tthis.cancelStop();\n\t\t//reschedule it\n\t\tthis._stopTime = this.toSeconds(time);\n\t\tif (this._stopTime > this._startTime){\n\t\t\tthis._gainNode.gain.setValueAtTime(0, this._stopTime);\n\t\t\tthis.context.clearTimeout(this._timeout);\n\t\t\tthis._timeout = this.context.setTimeout(function(){\n\t\t\t\tthis._oscillator.stop(this.now());\n\t\t\t\tthis.onended();\n\t\t\t}.bind(this), this._stopTime - this.context.currentTime);\n\t\t} else {\n\t\t\t//cancel the stop envelope\n\t\t\tthis._gainNode.gain.cancelScheduledValues(this._startTime);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel a scheduled stop event\n\t *  @return  {Tone.OscillatorNode}  this\n\t */\n\tTone.OscillatorNode.prototype.cancelStop = function(){\n\t\tif (this._startTime !== -1){\n\t\t\t//cancel the stop envelope\n\t\t\tthis._gainNode.gain.cancelScheduledValues(this._startTime+this.sampleTime);\n\t\t\tthis.context.clearTimeout(this._timeout);\n\t\t\tthis._stopTime = -1;\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'\n\t * @memberOf Tone.OscillatorNode#\n\t * @type {Time}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.OscillatorNode.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn this._oscillator.type;\n\t\t},\n\t\tset : function(type){\n\t\t\tthis._oscillator.type = type;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return  {Tone.OscillatorNode}  this\n\t */\n\tTone.OscillatorNode.prototype.dispose = function(){\n\t\tthis.context.clearTimeout(this._timeout);\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.onended = null;\n\t\tthis._oscillator.disconnect();\n\t\tthis._oscillator = null;\n\t\tthis._gainNode.dispose();\n\t\tthis._gainNode = null;\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\tthis.detune.dispose();\n\t\tthis.detune = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.OscillatorNode;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/OscillatorNode.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/PWMOscillator.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/Tone/source/PWMOscillator.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/PulseOscillator */ \"./node_modules/tone/Tone/source/PulseOscillator.js\"),\n\t__webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"), __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/Tone/signal/Multiply.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.PWMOscillator modulates the width of a Tone.PulseOscillator\n\t *         at the modulationFrequency. This has the effect of continuously\n\t *         changing the timbre of the oscillator by altering the harmonics\n\t *         generated.\n\t *\n\t *  @extends {Tone.Source}\n\t *  @constructor\n\t *  @param {Frequency} frequency The starting frequency of the oscillator.\n\t *  @param {Frequency} modulationFrequency The modulation frequency of the width of the pulse.\n\t *  @example\n\t *  var pwm = new Tone.PWMOscillator(\"Ab3\", 0.3).toMaster().start();\n\t */\n\tTone.PWMOscillator = function(){\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"modulationFrequency\"], Tone.PWMOscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  the pulse oscillator\n\t\t *  @type {Tone.PulseOscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._pulse = new Tone.PulseOscillator(options.modulationFrequency);\n\t\t//change the pulse oscillator type\n\t\tthis._pulse._sawtooth.type = \"sine\";\n\n\t\t/**\n\t\t *  the modulator\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._modulator = new Tone.Oscillator({\n\t\t\t\"frequency\" : options.frequency,\n\t\t\t\"detune\" : options.detune,\n\t\t\t\"phase\" : options.phase\n\t\t});\n\n\t\t/**\n\t\t *  Scale the oscillator so it doesn't go silent\n\t\t *  at the extreme values.\n\t\t *  @type {Tone.Multiply}\n\t\t *  @private\n\t\t */\n\t\tthis._scale = new Tone.Multiply(2);\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._modulator.frequency;\n\n\t\t/**\n\t\t *  The detune of the oscillator.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this._modulator.detune;\n\n\t\t/**\n\t\t *  The modulation rate of the oscillator.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.modulationFrequency = this._pulse.frequency;\n\n\t\t//connections\n\t\tthis._modulator.chain(this._scale, this._pulse.width);\n\t\tthis._pulse.connect(this.output);\n\t\tthis._readOnly([\"modulationFrequency\", \"frequency\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.PWMOscillator, Tone.Source);\n\n\t/**\n\t *  default values\n\t *  @static\n\t *  @type {Object}\n\t *  @const\n\t */\n\tTone.PWMOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"modulationFrequency\" : 0.4,\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} [time=now]\n\t *  @private\n\t */\n\tTone.PWMOscillator.prototype._start = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._modulator.start(time);\n\t\tthis._pulse.start(time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.PWMOscillator.prototype._stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._modulator.stop(time);\n\t\tthis._pulse.stop(time);\n\t};\n\n\t/**\n\t *  restart the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.PWMOscillator.prototype.restart = function(time){\n\t\tthis._modulator.restart(time);\n\t\tthis._pulse.restart(time);\n\t};\n\n\t/**\n\t * The type of the oscillator. Always returns \"pwm\".\n\t * @readOnly\n\t * @memberOf Tone.PWMOscillator#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.PWMOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn \"pwm\";\n\t\t}\n\t});\n\n\t/**\n\t * The baseType of the oscillator. Always returns \"pwm\".\n\t * @readOnly\n\t * @memberOf Tone.PWMOscillator#\n\t * @type {string}\n\t * @name baseType\n\t */\n\tObject.defineProperty(Tone.PWMOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn \"pwm\";\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the waveform. Cannot set partials for this waveform type\n\t * @memberOf Tone.PWMOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @private\n\t */\n\tObject.defineProperty(Tone.PWMOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn [];\n\t\t}\n\t});\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.PWMOscillator#\n\t * @type {number}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.PWMOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._modulator.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._modulator.phase = phase;\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up.\n\t *  @return {Tone.PWMOscillator} this\n\t */\n\tTone.PWMOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._pulse.dispose();\n\t\tthis._pulse = null;\n\t\tthis._scale.dispose();\n\t\tthis._scale = null;\n\t\tthis._modulator.dispose();\n\t\tthis._modulator = null;\n\t\tthis._writable([\"modulationFrequency\", \"frequency\", \"detune\"]);\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\tthis.modulationFrequency = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PWMOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/PWMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/Player.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/source/Player.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Buffer */ \"./node_modules/tone/Tone/core/Buffer.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/TickSource */ \"./node_modules/tone/Tone/source/TickSource.js\"),\n\t__webpack_require__(/*! ../source/BufferSource */ \"./node_modules/tone/Tone/source/BufferSource.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Player is an audio file player with start, loop, and stop functions.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Source}\n\t *  @param {string|AudioBuffer} url Either the AudioBuffer or the url from\n\t *                                  which to load the AudioBuffer\n\t *  @param {Function=} onload The function to invoke when the buffer is loaded.\n\t *                            Recommended to use Tone.Buffer.on('load') instead.\n\t *  @example\n\t * var player = new Tone.Player(\"./path/to/sample.mp3\").toMaster();\n\t * //play as soon as the buffer is loaded\n\t * player.autostart = true;\n\t */\n\tTone.Player = function(url){\n\n\t\tvar options;\n\t\tif (url instanceof Tone.Buffer && url.loaded){\n\t\t\turl = url.get();\n\t\t\toptions = Tone.Player.defaults;\n\t\t} else {\n\t\t\toptions = Tone.defaults(arguments, [\"url\", \"onload\"], Tone.Player);\n\t\t}\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  If the file should play as soon\n\t\t *  as the buffer is loaded.\n\t\t *  @type {Boolean}\n\t\t *  @example\n\t\t * //will play as soon as it's loaded\n\t\t * var player = new Tone.Player({\n\t\t * \t\"url\" : \"./path/to/sample.mp3\",\n\t\t * \t\"autostart\" : true,\n\t\t * }).toMaster();\n\t\t */\n\t\tthis.autostart = options.autostart;\n\n\t\t/**\n\t\t *  the buffer\n\t\t *  @private\n\t\t *  @type {Tone.Buffer}\n\t\t */\n\t\tthis._buffer = new Tone.Buffer({\n\t\t\t\"url\" : options.url,\n\t\t\t\"onload\" : this._onload.bind(this, options.onload),\n\t\t\t\"reverse\" : options.reverse\n\t\t});\n\t\tif (url instanceof AudioBuffer){\n\t\t\tthis._buffer.set(url);\n\t\t}\n\n\t\t/**\n\t\t *  if the buffer should loop once it's over\n\t\t *  @type {Boolean}\n\t\t *  @private\n\t\t */\n\t\tthis._loop = options.loop;\n\n\t\t/**\n\t\t *  if 'loop' is true, the loop will start at this position\n\t\t *  @type {Time}\n\t\t *  @private\n\t\t */\n\t\tthis._loopStart = options.loopStart;\n\n\t\t/**\n\t\t *  if 'loop' is true, the loop will end at this position\n\t\t *  @type {Time}\n\t\t *  @private\n\t\t */\n\t\tthis._loopEnd = options.loopEnd;\n\n\t\t/**\n\t\t *  the playback rate\n\t\t *  @private\n\t\t *  @type {Number}\n\t\t */\n\t\tthis._playbackRate = options.playbackRate;\n\n\t\t/**\n\t\t *  All of the active buffer source nodes\n\t\t *  @type {Array<Tone.BufferSource>}\n\t\t *  @private\n\t\t */\n\t\tthis._activeSources = [];\n\n\t\t/**\n\t\t *  The fadeIn time of the amplitude envelope.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.fadeIn = options.fadeIn;\n\n\t\t/**\n\t\t *  The fadeOut time of the amplitude envelope.\n\t\t *  @type {Time}\n\t\t */\n\t\tthis.fadeOut = options.fadeOut;\n\t};\n\n\tTone.extend(Tone.Player, Tone.Source);\n\n\t/**\n\t *  the default parameters\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Player.defaults = {\n\t\t\"onload\" : Tone.noOp,\n\t\t\"playbackRate\" : 1,\n\t\t\"loop\" : false,\n\t\t\"autostart\" : false,\n\t\t\"loopStart\" : 0,\n\t\t\"loopEnd\" : 0,\n\t\t\"reverse\" : false,\n\t\t\"fadeIn\" : 0,\n\t\t\"fadeOut\" : 0\n\t};\n\n\t/**\n\t *  Load the audio file as an audio buffer.\n\t *  Decodes the audio asynchronously and invokes\n\t *  the callback once the audio buffer loads.\n\t *  Note: this does not need to be called if a url\n\t *  was passed in to the constructor. Only use this\n\t *  if you want to manually load a new url.\n\t * @param {string} url The url of the buffer to load.\n\t *                     Filetype support depends on the\n\t *                     browser.\n\t *  @param  {Function=} callback The function to invoke once\n\t *                               the sample is loaded.\n\t *  @returns {Promise}\n\t */\n\tTone.Player.prototype.load = function(url, callback){\n\t\treturn this._buffer.load(url, this._onload.bind(this, callback));\n\t};\n\n\t/**\n\t * Internal callback when the buffer is loaded.\n\t * @private\n\t */\n\tTone.Player.prototype._onload = function(callback){\n\t\tcallback = Tone.defaultArg(callback, Tone.noOp);\n\t\tcallback(this);\n\t\tif (this.autostart){\n\t\t\tthis.start();\n\t\t}\n\t};\n\n\t/**\n\t * Internal callback when the buffer is done playing.\n\t * @private\n\t */\n\tTone.Player.prototype._onSourceEnd = function(source){\n\t\tvar index = this._activeSources.indexOf(source);\n\t\tthis._activeSources.splice(index, 1);\n\t\tif (this._activeSources.length === 0 && !this._synced){\n\t\t\tthis._state.setStateAtTime(Tone.State.Stopped, Tone.now());\n\t\t}\n\t};\n\n\t/**\n\t *  Play the buffer at the given startTime. Optionally add an offset\n\t *  and/or duration which will play the buffer from a position\n\t *  within the buffer for the given duration.\n\t *\n\t *  @param  {Time} [startTime=now] When the player should start.\n\t *  @param  {Time} [offset=0] The offset from the beginning of the sample\n\t *                                 to start at.\n\t *  @param  {Time=} duration How long the sample should play. If no duration\n\t *                                is given, it will default to the full length\n\t *                                of the sample (minus any offset)\n\t *  @returns {Tone.Player} this\n\t *  @memberOf Tone.Player#\n\t *  @method start\n\t *  @name start\n\t */\n\n\t/**\n\t *  Internal start method\n\t *  @private\n\t */\n\tTone.Player.prototype._start = function(startTime, offset, duration){\n\t\t//if it's a loop the default offset is the loopstart point\n\t\tif (this._loop){\n\t\t\toffset = Tone.defaultArg(offset, this._loopStart);\n\t\t} else {\n\t\t\t//otherwise the default offset is 0\n\t\t\toffset = Tone.defaultArg(offset, 0);\n\t\t}\n\n\t\t//compute the values in seconds\n\t\toffset = this.toSeconds(offset);\n\t\tvar computedDuration = Tone.defaultArg(duration, Math.max(this._buffer.duration - offset, 0));\n\t\tcomputedDuration = this.toSeconds(computedDuration);\n\t\t//scale it by the playback rate\n\t\tcomputedDuration = computedDuration / this._playbackRate;\n\n\t\t//get the start time\n\t\tstartTime = this.toSeconds(startTime);\n\n\t\t//make the source\n\t\tvar source = new Tone.BufferSource({\n\t\t\t\"buffer\" : this._buffer,\n\t\t\t\"loop\" : this._loop,\n\t\t\t\"loopStart\" : this._loopStart,\n\t\t\t\"loopEnd\" : this._loopEnd,\n\t\t\t\"onended\" : this._onSourceEnd.bind(this),\n\t\t\t\"playbackRate\" : this._playbackRate,\n\t\t\t\"fadeIn\" : this.fadeIn,\n\t\t\t\"fadeOut\" : this.fadeOut,\n\t\t}).connect(this.output);\n\n\t\t//set the looping properties\n\t\tif (!this._loop && !this._synced){\n\t\t\t//if it's not looping, set the state change at the end of the sample\n\t\t\tthis._state.setStateAtTime(Tone.State.Stopped, startTime + computedDuration);\n\t\t}\n\n\t\t//add it to the array of active sources\n\t\tthis._activeSources.push(source);\n\n\t\t//start it\n\t\tif (this._loop && Tone.isUndef(duration)){\n\t\t\tsource.start(startTime, offset);\n\t\t} else {\n\t\t\t//subtract the fade out time\n\t\t\tsource.start(startTime, offset, computedDuration - this.toSeconds(this.fadeOut));\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop playback.\n\t *  @private\n\t *  @param  {Time} [time=now]\n\t *  @returns {Tone.Player} this\n\t */\n\tTone.Player.prototype._stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._activeSources.forEach(function(source){\n\t\t\tsource.stop(time);\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t * Stop and then restart the player from the beginning (or offset)\n\t *  @param  {Time} [startTime=now] When the player should start.\n\t *  @param  {Time} [offset=0] The offset from the beginning of the sample\n\t *                                 to start at.\n\t *  @param  {Time=} duration How long the sample should play. If no duration\n\t *                                is given, it will default to the full length\n\t *                                of the sample (minus any offset)\n\t *  @returns {Tone.Player} this\n\t */\n\tTone.Player.prototype.restart = function(time, offset, duration){\n\t\tthis._stop(time);\n\t\tthis._start(time, offset, duration);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Seek to a specific time in the player's buffer. If the\n\t *  source is no longer playing at that time, it will stop.\n\t *  If you seek to a time that\n\t *  @param {Time} offset The time to seek to.\n\t *  @param {Time=} time The time for the seek event to occur.\n\t *  @return {Tone.Player} this\n\t *  @example\n\t * source.start(0.2);\n\t * source.stop(0.4);\n\t */\n\tTone.Player.prototype.seek = function(offset, time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Started){\n\t\t\toffset = this.toSeconds(offset);\n\t\t\t// if it's currently playing, stop it\n\t\t\tthis._stop(time);\n\t\t\t//restart it at the given time\n\t\t\tthis._start(time, offset);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Set the loop start and end. Will only loop if loop is\n\t *  set to true.\n\t *  @param {Time} loopStart The loop end time\n\t *  @param {Time} loopEnd The loop end time\n\t *  @returns {Tone.Player} this\n\t *  @example\n\t * //loop 0.1 seconds of the file.\n\t * player.setLoopPoints(0.2, 0.3);\n\t * player.loop = true;\n\t */\n\tTone.Player.prototype.setLoopPoints = function(loopStart, loopEnd){\n\t\tthis.loopStart = loopStart;\n\t\tthis.loopEnd = loopEnd;\n\t\treturn this;\n\t};\n\n\t/**\n\t * If loop is true, the loop will start at this position.\n\t * @memberOf Tone.Player#\n\t * @type {Time}\n\t * @name loopStart\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"loopStart\", {\n\t\tget : function(){\n\t\t\treturn this._loopStart;\n\t\t},\n\t\tset : function(loopStart){\n\t\t\tthis._loopStart = loopStart;\n\t\t\t//get the current source\n\t\t\tthis._activeSources.forEach(function(source){\n\t\t\t\tsource.loopStart = loopStart;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * If loop is true, the loop will end at this position.\n\t * @memberOf Tone.Player#\n\t * @type {Time}\n\t * @name loopEnd\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"loopEnd\", {\n\t\tget : function(){\n\t\t\treturn this._loopEnd;\n\t\t},\n\t\tset : function(loopEnd){\n\t\t\tthis._loopEnd = loopEnd;\n\t\t\t//get the current source\n\t\t\tthis._activeSources.forEach(function(source){\n\t\t\t\tsource.loopEnd = loopEnd;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The audio buffer belonging to the player.\n\t * @memberOf Tone.Player#\n\t * @type {Tone.Buffer}\n\t * @name buffer\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"buffer\", {\n\t\tget : function(){\n\t\t\treturn this._buffer;\n\t\t},\n\t\tset : function(buffer){\n\t\t\tthis._buffer.set(buffer);\n\t\t}\n\t});\n\n\t/**\n\t * If the buffer should loop once it's over.\n\t * @memberOf Tone.Player#\n\t * @type {Boolean}\n\t * @name loop\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"loop\", {\n\t\tget : function(){\n\t\t\treturn this._loop;\n\t\t},\n\t\tset : function(loop){\n\t\t\t//if no change, do nothing\n\t\t\tif (this._loop === loop){\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tthis._loop = loop;\n\t\t\t//set the loop of all of the sources\n\t\t\tthis._activeSources.forEach(function(source){\n\t\t\t\tsource.loop = loop;\n\t\t\t});\n\t\t\tif (loop){\n\t\t\t\t//remove the next stopEvent\n\t\t\t\tvar stopEvent = this._state.getNextState(Tone.State.Stopped, this.now());\n\t\t\t\tif (stopEvent){\n\t\t\t\t\tthis._state.cancel(stopEvent.time);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * The playback speed. 1 is normal speed. This is not a signal because\n\t * Safari and iOS currently don't support playbackRate as a signal.\n\t * @memberOf Tone.Player#\n\t * @type {Number}\n\t * @name playbackRate\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"playbackRate\", {\n\t\tget : function(){\n\t\t\treturn this._playbackRate;\n\t\t},\n\t\tset : function(rate){\n\t\t\tthis._playbackRate = rate;\n\t\t\tvar now = this.now();\n\n\t\t\t//cancel the stop event since it's at a different time now\n\t\t\tvar stopEvent = this._state.getNextState(Tone.State.Stopped, now);\n\t\t\tif (stopEvent){\n\t\t\t\tthis._state.cancel(stopEvent.time);\n\t\t\t}\n\n\t\t\t//set all the sources\n\t\t\tthis._activeSources.forEach(function(source){\n\t\t\t\tsource.cancelStop();\n\t\t\t\tsource.playbackRate.setValueAtTime(rate, now);\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The direction the buffer should play in\n\t * @memberOf Tone.Player#\n\t * @type {Boolean}\n\t * @name reverse\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"reverse\", {\n\t\tget : function(){\n\t\t\treturn this._buffer.reverse;\n\t\t},\n\t\tset : function(rev){\n\t\t\tthis._buffer.reverse = rev;\n\t\t}\n\t});\n\n\t/**\n\t * If all the buffer is loaded\n\t * @memberOf Tone.Player#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Player.prototype, \"loaded\", {\n\t\tget : function(){\n\t\t\treturn this._buffer.loaded;\n\t\t}\n\t});\n\n\t/**\n\t *  Dispose and disconnect.\n\t *  @return {Tone.Player} this\n\t */\n\tTone.Player.prototype.dispose = function(){\n\t\t//disconnect all of the players\n\t\tthis._activeSources.forEach(function(source){\n\t\t\tsource.dispose();\n\t\t});\n\t\tthis._activeSources = null;\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._buffer.dispose();\n\t\tthis._buffer = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Player;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/Player.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/Players.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/source/Players.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Player */ \"./node_modules/tone/Tone/source/Player.js\"), __webpack_require__(/*! ../component/Volume */ \"./node_modules/tone/Tone/component/Volume.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.Players combines multiple [Tone.Player](Player) objects.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Object} urls An object mapping a name to a url.\n\t *  @param {function=} onload The function to invoke when all buffers are loaded.\n\t */\n\tTone.Players = function(urls){\n\n\t\tvar args = Array.prototype.slice.call(arguments);\n\t\targs.shift();\n\t\tvar options = Tone.defaults(args, [\"onload\"], Tone.Players);\n\t\tTone.AudioNode.call(this, options);\n\n\t\t/**\n\t\t *  The output volume node\n\t\t *  @type  {Tone.Volume}\n\t\t *  @private\n\t\t */\n\t\tthis._volume = this.output = new Tone.Volume(options.volume);\n\n\t\t/**\n\t\t * The volume of the output in decibels.\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t * @example\n\t\t * source.volume.value = -6;\n\t\t */\n\t\tthis.volume = this._volume.volume;\n\t\tthis._readOnly(\"volume\");\n\n\t\t//make the output explicitly stereo\n\t\tthis._volume.output.output.channelCount = 2;\n\t\tthis._volume.output.output.channelCountMode = \"explicit\";\n\t\t//mute initially\n\t\tthis.mute = options.mute;\n\n\t\t/**\n\t\t * The container of all of the players\n\t\t * @type {Object}\n\t\t * @private\n\t\t */\n\t\tthis._players = {};\n\n\t\t/**\n\t\t * The loading count\n\t\t * @type {Number}\n\t\t * @private\n\t\t */\n\t\tthis._loadingCount = 0;\n\n\t\t/**\n\t\t * private holder of the fadeIn time\n\t\t * @type {Time}\n\t\t * @private\n\t\t */\n\t\tthis._fadeIn = options.fadeIn;\n\n\t\t/**\n\t\t * private holder of the fadeOut time\n\t\t * @type {Time}\n\t\t * @private\n\t\t */\n\t\tthis._fadeOut = options.fadeOut;\n\n\t\t//add all of the players\n\t\tfor (var name in urls){\n\t\t\tthis._loadingCount++;\n\t\t\tthis.add(name, urls[name], this._bufferLoaded.bind(this, options.onload));\n\t\t}\n\t};\n\n\tTone.extend(Tone.Players, Tone.AudioNode);\n\n\t/**\n\t * The default values\n\t * @type {Object}\n\t */\n\tTone.Players.defaults = {\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false,\n\t\t\"onload\" : Tone.noOp,\n\t\t\"fadeIn\" : 0,\n\t\t\"fadeOut\" : 0\n\t};\n\n\t/**\n\t *  A buffer was loaded. decrement the counter.\n\t *  @param  {Function}  callback\n\t *  @private\n\t */\n\tTone.Players.prototype._bufferLoaded = function(callback){\n\t\tthis._loadingCount--;\n\t\tif (this._loadingCount === 0 && callback){\n\t\t\tcallback(this);\n\t\t}\n\t};\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.Source#\n\t * @type {boolean}\n\t * @name mute\n\t * @example\n\t * //mute the output\n\t * source.mute = true;\n\t */\n\tObject.defineProperty(Tone.Players.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._volume.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._volume.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t * The fadeIn time of the amplitude envelope.\n\t * @memberOf Tone.Source#\n\t * @type {Time}\n\t * @name fadeIn\n\t */\n\tObject.defineProperty(Tone.Players.prototype, \"fadeIn\", {\n\t\tget : function(){\n\t\t\treturn this._fadeIn;\n\t\t},\n\t\tset : function(fadeIn){\n\t\t\tthis._fadeIn = fadeIn;\n\t\t\tthis._forEach(function(player){\n\t\t\t\tplayer.fadeIn = fadeIn;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The fadeOut time of the amplitude envelope.\n\t * @memberOf Tone.Source#\n\t * @type {Time}\n\t * @name fadeOut\n\t */\n\tObject.defineProperty(Tone.Players.prototype, \"fadeOut\", {\n\t\tget : function(){\n\t\t\treturn this._fadeOut;\n\t\t},\n\t\tset : function(fadeOut){\n\t\t\tthis._fadeOut = fadeOut;\n\t\t\tthis._forEach(function(player){\n\t\t\t\tplayer.fadeOut = fadeOut;\n\t\t\t});\n\t\t}\n\t});\n\n\t/**\n\t * The state of the players object. Returns \"started\" if any of the players are playing.\n\t * @memberOf Tone.Players#\n\t * @type {String}\n\t * @name state\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Players.prototype, \"state\", {\n\t\tget : function(){\n\t\t\tvar playing = false;\n\t\t\tthis._forEach(function(player){\n\t\t\t\tplaying = playing || player.state === Tone.State.Started;\n\t\t\t});\n\t\t\treturn playing ? Tone.State.Started : Tone.State.Stopped;\n\t\t}\n\t});\n\n\t/**\n\t *  True if the buffers object has a buffer by that name.\n\t *  @param  {String|Number}  name  The key or index of the\n\t *                                 buffer.\n\t *  @return  {Boolean}\n\t */\n\tTone.Players.prototype.has = function(name){\n\t\treturn this._players.hasOwnProperty(name);\n\t};\n\n\t/**\n\t *  Get a player by name.\n\t *  @param  {String}  name  The players name as defined in\n\t *                          the constructor object or `add` method.\n\t *  @return  {Tone.Player}\n\t */\n\tTone.Players.prototype.get = function(name){\n\t\tif (this.has(name)){\n\t\t\treturn this._players[name];\n\t\t} else {\n\t\t\tthrow new Error(\"Tone.Players: no player named \"+name);\n\t\t}\n\t};\n\n\t/**\n\t * Iterate over all of the players\n\t * @param  {Function} callback\n\t * @return {Tone.Players}            this\n\t * @private\n\t */\n\tTone.Players.prototype._forEach = function(callback){\n\t\tfor (var playerName in this._players){\n\t\t\tcallback(this._players[playerName], playerName);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t * If all the buffers are loaded or not\n\t * @memberOf Tone.Players#\n\t * @type {Boolean}\n\t * @name loaded\n\t * @readOnly\n\t */\n\tObject.defineProperty(Tone.Players.prototype, \"loaded\", {\n\t\tget : function(){\n\t\t\tvar isLoaded = true;\n\t\t\tthis._forEach(function(player){\n\t\t\t\tisLoaded = isLoaded && player.loaded;\n\t\t\t});\n\t\t\treturn isLoaded;\n\t\t}\n\t});\n\n\t/**\n\t *  Add a player by name and url to the Players\n\t *  @param  {String}    name      A unique name to give the player\n\t *  @param  {String|Tone.Buffer|Audiobuffer}  url  Either the url of the bufer,\n\t *                                                 or a buffer which will be added\n\t *                                                 with the given name.\n\t *  @param  {Function=}  callback  The callback to invoke\n\t *                                 when the url is loaded.\n\t */\n\tTone.Players.prototype.add = function(name, url, callback){\n\t\tthis._players[name] = new Tone.Player(url, callback).connect(this.output);\n\t\tthis._players[name].fadeIn = this._fadeIn;\n\t\tthis._players[name].fadeOut = this._fadeOut;\n\t\treturn this;\n\t};\n\n\t/**\n\t * Stop all of the players at the given time\n\t * @param {Time} time The time to stop all of the players.\n\t * @return {Tone.Players} this\n\t */\n\tTone.Players.prototype.stopAll = function(time){\n\t\tthis._forEach(function(player){\n\t\t\tplayer.stop(time);\n\t\t});\n\t};\n\n\t/**\n\t *  Dispose and disconnect.\n\t *  @return {Tone.Players} this\n\t */\n\tTone.Players.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis._writable(\"volume\");\n\t\tthis.volume = null;\n\t\tthis.output = null;\n\t\tthis._forEach(function(player){\n\t\t\tplayer.dispose();\n\t\t});\n\t\tthis._players = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.Players;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/Players.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/PulseOscillator.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/Tone/source/PulseOscillator.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/Tone/source/Source.js\"), __webpack_require__(/*! ../source/Oscillator */ \"./node_modules/tone/Tone/source/Oscillator.js\"),\n\t__webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/Tone/signal/WaveShaper.js\"), __webpack_require__(/*! ../core/Gain */ \"./node_modules/tone/Tone/core/Gain.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class Tone.PulseOscillator is a pulse oscillator with control over pulse width,\n\t *         also known as the duty cycle. At 50% duty cycle (width = 0.5) the wave is\n\t *         a square and only odd-numbered harmonics are present. At all other widths\n\t *         even-numbered harmonics are present. Read more\n\t *         [here](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).\n\t *\n\t *  @constructor\n\t *  @extends {Tone.Source}\n\t *  @param {Frequency} [frequency] The frequency of the oscillator\n\t *  @param {NormalRange} [width] The width of the pulse\n\t *  @example\n\t * var pulse = new Tone.PulseOscillator(\"E5\", 0.4).toMaster().start();\n\t */\n\tTone.PulseOscillator = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\", \"width\"], Tone.Oscillator);\n\t\tTone.Source.call(this, options);\n\n\t\t/**\n\t\t *  The width of the pulse.\n\t\t *  @type {NormalRange}\n\t\t *  @signal\n\t\t */\n\t\tthis.width = new Tone.Signal(options.width, Tone.Type.NormalRange);\n\n\t\t/**\n\t\t *  gate the width amount\n\t\t *  @type {Tone.Gain}\n\t\t *  @private\n\t\t */\n\t\tthis._widthGate = new Tone.Gain(0);\n\n\t\t/**\n\t\t *  the sawtooth oscillator\n\t\t *  @type {Tone.Oscillator}\n\t\t *  @private\n\t\t */\n\t\tthis._sawtooth = new Tone.Oscillator({\n\t\t\tfrequency : options.frequency,\n\t\t\tdetune : options.detune,\n\t\t\ttype : \"sawtooth\",\n\t\t\tphase : options.phase\n\t\t});\n\n\t\t/**\n\t\t *  The frequency control.\n\t\t *  @type {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = this._sawtooth.frequency;\n\n\t\t/**\n\t\t *  The detune in cents.\n\t\t *  @type {Cents}\n\t\t *  @signal\n\t\t */\n\t\tthis.detune = this._sawtooth.detune;\n\n\t\t/**\n\t\t *  Threshold the signal to turn it into a square\n\t\t *  @type {Tone.WaveShaper}\n\t\t *  @private\n\t\t */\n\t\tthis._thresh = new Tone.WaveShaper(function(val){\n\t\t\tif (val < 0){\n\t\t\t\treturn -1;\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t});\n\n\t\t//connections\n\t\tthis._sawtooth.chain(this._thresh, this.output);\n\t\tthis.width.chain(this._widthGate, this._thresh);\n\t\tthis._readOnly([\"width\", \"frequency\", \"detune\"]);\n\t};\n\n\tTone.extend(Tone.PulseOscillator, Tone.Source);\n\n\t/**\n\t *  The default parameters.\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.PulseOscillator.defaults = {\n\t\t\"frequency\" : 440,\n\t\t\"detune\" : 0,\n\t\t\"phase\" : 0,\n\t\t\"width\" : 0.2,\n\t};\n\n\t/**\n\t *  start the oscillator\n\t *  @param  {Time} time\n\t *  @private\n\t */\n\tTone.PulseOscillator.prototype._start = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._sawtooth.start(time);\n\t\tthis._widthGate.gain.setValueAtTime(1, time);\n\t};\n\n\t/**\n\t *  stop the oscillator\n\t *  @param  {Time} time\n\t *  @private\n\t */\n\tTone.PulseOscillator.prototype._stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._sawtooth.stop(time);\n\t\t//the width is still connected to the output.\n\t\t//that needs to be stopped also\n\t\tthis._widthGate.gain.setValueAtTime(0, time);\n\t};\n\n\t/**\n\t *  restart the oscillator\n\t *  @param  {Time} time (optional) timing parameter\n\t *  @private\n\t */\n\tTone.PulseOscillator.prototype.restart = function(time){\n\t\tthis._sawtooth.restart(time);\n\t\tthis._widthGate.gain.cancelScheduledValues(time);\n\t\tthis._widthGate.gain.setValueAtTime(1, time);\n\t};\n\n\t/**\n\t * The phase of the oscillator in degrees.\n\t * @memberOf Tone.PulseOscillator#\n\t * @type {Degrees}\n\t * @name phase\n\t */\n\tObject.defineProperty(Tone.PulseOscillator.prototype, \"phase\", {\n\t\tget : function(){\n\t\t\treturn this._sawtooth.phase;\n\t\t},\n\t\tset : function(phase){\n\t\t\tthis._sawtooth.phase = phase;\n\t\t}\n\t});\n\n\t/**\n\t * The type of the oscillator. Always returns \"pulse\".\n\t * @readOnly\n\t * @memberOf Tone.PulseOscillator#\n\t * @type {string}\n\t * @name type\n\t */\n\tObject.defineProperty(Tone.PulseOscillator.prototype, \"type\", {\n\t\tget : function(){\n\t\t\treturn \"pulse\";\n\t\t}\n\t});\n\n\t/**\n\t * The baseType of the oscillator. Always returns \"pulse\".\n\t * @readOnly\n\t * @memberOf Tone.PulseOscillator#\n\t * @type {string}\n\t * @name baseType\n\t */\n\tObject.defineProperty(Tone.PulseOscillator.prototype, \"baseType\", {\n\t\tget : function(){\n\t\t\treturn \"pulse\";\n\t\t}\n\t});\n\n\t/**\n\t * The partials of the waveform. Cannot set partials for this waveform type\n\t * @memberOf Tone.PulseOscillator#\n\t * @type {Array}\n\t * @name partials\n\t * @private\n\t */\n\tObject.defineProperty(Tone.PulseOscillator.prototype, \"partials\", {\n\t\tget : function(){\n\t\t\treturn [];\n\t\t}\n\t});\n\n\t/**\n\t *  Clean up method.\n\t *  @return {Tone.PulseOscillator} this\n\t */\n\tTone.PulseOscillator.prototype.dispose = function(){\n\t\tTone.Source.prototype.dispose.call(this);\n\t\tthis._sawtooth.dispose();\n\t\tthis._sawtooth = null;\n\t\tthis._writable([\"width\", \"frequency\", \"detune\"]);\n\t\tthis.width.dispose();\n\t\tthis.width = null;\n\t\tthis._widthGate.dispose();\n\t\tthis._widthGate = null;\n\t\tthis._thresh.dispose();\n\t\tthis._thresh = null;\n\t\tthis.frequency = null;\n\t\tthis.detune = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.PulseOscillator;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/PulseOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/Source.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/source/Source.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../core/Transport */ \"./node_modules/tone/Tone/core/Transport.js\"), __webpack_require__(/*! ../component/Volume */ \"./node_modules/tone/Tone/component/Volume.js\"), __webpack_require__(/*! ../core/Master */ \"./node_modules/tone/Tone/core/Master.js\"), __webpack_require__(/*! ../type/Type */ \"./node_modules/tone/Tone/type/Type.js\"),\n\t__webpack_require__(/*! ../core/TimelineState */ \"./node_modules/tone/Tone/core/TimelineState.js\"), __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/Tone/signal/Signal.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Base class for sources. Sources have start/stop methods\n\t *          and the ability to be synced to the\n\t *          start/stop of Tone.Transport.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @example\n\t * //Multiple state change events can be chained together,\n\t * //but must be set in the correct order and with ascending times\n\t *\n\t * // OK\n\t * state.start().stop(\"+0.2\");\n\t * // AND\n\t * state.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n\t *\n\t * // BAD\n\t * state.stop(\"+0.2\").start();\n\t * // OR\n\t * state.start(\"+0.3\").stop(\"+0.2\");\n\t *\n\t */\n\tTone.Source = function(options){\n\n\t\toptions = Tone.defaultArg(options, Tone.Source.defaults);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The output volume node\n\t\t *  @type  {Tone.Volume}\n\t\t *  @private\n\t\t */\n\t\tthis._volume = this.output = new Tone.Volume(options.volume);\n\n\t\t/**\n\t\t * The volume of the output in decibels.\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t * @example\n\t\t * source.volume.value = -6;\n\t\t */\n\t\tthis.volume = this._volume.volume;\n\t\tthis._readOnly(\"volume\");\n\n\t\t/**\n\t\t * \tKeep track of the scheduled state.\n\t\t *  @type {Tone.TimelineState}\n\t\t *  @private\n\t\t */\n\t\tthis._state = new Tone.TimelineState(Tone.State.Stopped);\n\t\tthis._state.memory = 100;\n\n\t\t/**\n\t\t *  The synced `start` callback function from the transport\n\t\t *  @type {Function}\n\t\t *  @private\n\t\t */\n\t\tthis._synced = false;\n\n\t\t/**\n\t\t *  Keep track of all of the scheduled event ids\n\t\t *  @type  {Array}\n\t\t *  @private\n\t\t */\n\t\tthis._scheduled = [];\n\n\t\t//make the output explicitly stereo\n\t\tthis._volume.output.output.channelCount = 2;\n\t\tthis._volume.output.output.channelCountMode = \"explicit\";\n\t\t//mute initially\n\t\tthis.mute = options.mute;\n\t};\n\n\tTone.extend(Tone.Source, Tone.AudioNode);\n\n\t/**\n\t *  The default parameters\n\t *  @static\n\t *  @const\n\t *  @type {Object}\n\t */\n\tTone.Source.defaults = {\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\" or \"stopped\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.Source#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.Source.prototype, \"state\", {\n\t\tget : function(){\n\t\t\tif (this._synced){\n\t\t\t\tif (Tone.Transport.state === Tone.State.Started){\n\t\t\t\t\treturn this._state.getValueAtTime(Tone.Transport.seconds);\n\t\t\t\t} else {\n\t\t\t\t\treturn Tone.State.Stopped;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn this._state.getValueAtTime(this.now());\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.Source#\n\t * @type {boolean}\n\t * @name mute\n\t * @example\n\t * //mute the output\n\t * source.mute = true;\n\t */\n\tObject.defineProperty(Tone.Source.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._volume.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._volume.mute = mute;\n\t\t}\n\t});\n\n\t//overwrite these functions\n\tTone.Source.prototype._start = Tone.noOp;\n\tTone.Source.prototype.restart = Tone.noOp;\n\tTone.Source.prototype._stop = Tone.noOp;\n\n\t/**\n\t *  Start the source at the specified time. If no time is given,\n\t *  start the source now.\n\t *  @param  {Time} [time=now] When the source should be started.\n\t *  @returns {Tone.Source} this\n\t *  @example\n\t * source.start(\"+0.5\"); //starts the source 0.5 seconds from now\n\t */\n\tTone.Source.prototype.start = function(time, offset, duration){\n\t\tif (Tone.isUndef(time) && this._synced){\n\t\t\ttime = Tone.Transport.seconds;\n\t\t} else {\n\t\t\ttime = this.toSeconds(time);\n\t\t}\n\t\t//if it's started, stop it and restart it\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Started){\n\t\t\tthis._state.cancel(time);\n\t\t\tthis._state.setStateAtTime(Tone.State.Started, time);\n\t\t\tthis.restart(time, offset, duration);\n\t\t} else {\n\t\t\tthis._state.setStateAtTime(Tone.State.Started, time);\n\t\t\tif (this._synced){\n\t\t\t\t// add the offset time to the event\n\t\t\t\tvar event = this._state.get(time);\n\t\t\t\tevent.offset = Tone.defaultArg(offset, 0);\n\t\t\t\tevent.duration = duration;\n\t\t\t\tvar sched = Tone.Transport.schedule(function(t){\n\t\t\t\t\tthis._start(t, offset, duration);\n\t\t\t\t}.bind(this), time);\n\t\t\t\tthis._scheduled.push(sched);\n\n\t\t\t\t//if it's already started\n\t\t\t\tif (Tone.Transport.state === Tone.State.Started){\n\t\t\t\t\tthis._syncedStart(this.now(), Tone.Transport.seconds);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis._start.apply(this, arguments);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the source at the specified time. If no time is given,\n\t *  stop the source now.\n\t *  @param  {Time} [time=now] When the source should be stopped.\n\t *  @returns {Tone.Source} this\n\t *  @example\n\t * source.stop(); // stops the source immediately\n\t */\n\tTone.Source.prototype.stop = function(time){\n\t\tif (Tone.isUndef(time) && this._synced){\n\t\t\ttime = Tone.Transport.seconds;\n\t\t} else {\n\t\t\ttime = this.toSeconds(time);\n\t\t}\n\t\tif (!this._synced){\n\t\t\tthis._stop.apply(this, arguments);\n\t\t} else {\n\t\t\tvar sched = Tone.Transport.schedule(this._stop.bind(this), time);\n\t\t\tthis._scheduled.push(sched);\n\t\t}\n\t\tthis._state.cancel(time);\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Sync the source to the Transport so that all subsequent\n\t *  calls to `start` and `stop` are synced to the TransportTime\n\t *  instead of the AudioContext time.\n\t *\n\t *  @returns {Tone.Source} this\n\t *  @example\n\t * //sync the source so that it plays between 0 and 0.3 on the Transport's timeline\n\t * source.sync().start(0).stop(0.3);\n\t * //start the transport.\n\t * Tone.Transport.start();\n\t *\n\t *  @example\n\t * //start the transport with an offset and the sync'ed sources\n\t * //will start in the correct position\n\t * source.sync().start(0.1);\n\t * //the source will be invoked with an offset of 0.4\n\t * Tone.Transport.start(\"+0.5\", 0.5);\n\t */\n\tTone.Source.prototype.sync = function(){\n\t\tthis._synced = true;\n\t\tthis._syncedStart = function(time, offset){\n\t\t\tif (offset > 0){\n\t\t\t\t// get the playback state at that time\n\t\t\t\tvar stateEvent = this._state.get(offset);\n\t\t\t\t// listen for start events which may occur in the middle of the sync'ed time\n\t\t\t\tif (stateEvent && stateEvent.state === Tone.State.Started && stateEvent.time !== offset){\n\t\t\t\t\t// get the offset\n\t\t\t\t\tvar startOffset = offset - this.toSeconds(stateEvent.time);\n\t\t\t\t\tvar duration;\n\t\t\t\t\tif (stateEvent.duration){\n\t\t\t\t\t\tduration = this.toSeconds(stateEvent.duration) - startOffset;\n\t\t\t\t\t}\n\t\t\t\t\tthis._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);\n\t\t\t\t}\n\t\t\t}\n\t\t}.bind(this);\n\t\tthis._syncedStop = function(time){\n\t\t\tvar seconds = Tone.Transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));\n\t\t\tif (this._state.getValueAtTime(seconds) === Tone.State.Started){\n\t\t\t\tthis._stop(time);\n\t\t\t}\n\t\t}.bind(this);\n\t\tTone.Transport.on(\"start loopStart\", this._syncedStart);\n\t\tTone.Transport.on(\"stop pause loopEnd\", this._syncedStop);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Unsync the source to the Transport. See Tone.Source.sync\n\t *  @returns {Tone.Source} this\n\t */\n\tTone.Source.prototype.unsync = function(){\n\t\tif (this._synced){\n\t\t\tTone.Transport.off(\"stop pause loopEnd\", this._syncedStop);\n\t\t\tTone.Transport.off(\"start loopStart\", this._syncedStart);\n\t\t}\n\t\tthis._synced = false;\n\t\t// clear all of the scheduled ids\n\t\tfor (var i = 0; i < this._scheduled.length; i++){\n\t\t\tvar id = this._scheduled[i];\n\t\t\tTone.Transport.clear(id);\n\t\t}\n\t\tthis._scheduled = [];\n\t\tthis._state.cancel(0);\n\t\treturn this;\n\t};\n\n\t/**\n\t *\tClean up.\n\t *  @return {Tone.Source} this\n\t */\n\tTone.Source.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.unsync();\n\t\tthis._scheduled = null;\n\t\tthis._writable(\"volume\");\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis.volume = null;\n\t\tthis._state.dispose();\n\t\tthis._state = null;\n\t};\n\n\treturn Tone.Source;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/Source.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/TickSource.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/Tone/source/TickSource.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../signal/TickSignal */ \"./node_modules/tone/Tone/signal/TickSignal.js\"), __webpack_require__(/*! ../core/TimelineState */ \"./node_modules/tone/Tone/core/TimelineState.js\"),\n\t__webpack_require__(/*! ../core/Timeline */ \"./node_modules/tone/Tone/core/Timeline.js\"), __webpack_require__(/*! ../core/Param */ \"./node_modules/tone/Tone/core/Param.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Uses [Tone.TickSignal](TickSignal) to track elapsed ticks with\n\t *  \t\tcomplex automation curves.\n\t *\n\t * \t@constructor\n     *  @param {Frequency} frequency The initial frequency that the signal ticks at\n     *  @param {Tone.Param=} param A parameter to control (such as playbackRate)\n\t *  @extends {Tone}\n\t */\n\tTone.TickSource = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"frequency\"], Tone.TickSource);\n\n\t\t/**\n\t\t *  The frequency the callback function should be invoked.\n\t\t *  @type  {Frequency}\n\t\t *  @signal\n\t\t */\n\t\tthis.frequency = new Tone.TickSignal(options.frequency);\n\t\tthis._readOnly(\"frequency\");\n\n\t\t/**\n\t\t *  The state timeline\n\t\t *  @type {Tone.TimelineState}\n\t\t *  @private\n\t\t */\n\t\tthis._state = new Tone.TimelineState(Tone.State.Stopped);\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, 0);\n\n\t\t/**\n\t\t * The offset values of the ticks\n\t\t * @type {Tone.Timeline}\n\t\t * @private\n\t\t */\n\t\tthis._tickOffset = new Tone.Timeline();\n\t\t//add the first event\n\t\tthis.setTicksAtTime(0, 0);\n\t};\n\n\tTone.extend(Tone.TickSource);\n\n\t/**\n\t *  The defaults\n\t *  @const\n\t *  @type  {Object}\n\t */\n\tTone.TickSource.defaults = {\n\t\t\"frequency\" : 1,\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.TickSource#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.TickSource.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._state.getValueAtTime(this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  Start the clock at the given time. Optionally pass in an offset\n\t *  of where to start the tick counter from.\n\t *  @param  {Time=}  time    The time the clock should start\n\t *  @param {Ticks} [offset=0] The number of ticks to start the source at\n\t *  @return  {Tone.TickSource}  this\n\t */\n\tTone.TickSource.prototype.start = function(time, offset){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._state.getValueAtTime(time) !== Tone.State.Started){\n\t\t\tthis._state.setStateAtTime(Tone.State.Started, time);\n\t\t\tif (Tone.isDefined(offset)){\n\t\t\t\tthis.setTicksAtTime(offset, time);\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Stop the clock. Stopping the clock resets the tick counter to 0.\n\t *  @param {Time} [time=now] The time when the clock should stop.\n\t *  @returns {Tone.TickSource} this\n\t *  @example\n\t * clock.stop();\n\t */\n\tTone.TickSource.prototype.stop = function(time){\n\t\ttime = this.toSeconds(time);\n\t\t//cancel the previous stop\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Stopped){\n\t\t\tvar event = this._state.get(time);\n\t\t\tif (event.time > 0){\n\t\t\t\tthis._tickOffset.cancel(event.time);\n\t\t\t\tthis._state.cancel(event.time);\n\t\t\t}\n\t\t}\n\t\tthis._state.cancel(time);\n\t\tthis._state.setStateAtTime(Tone.State.Stopped, time);\n\t\tthis.setTicksAtTime(0, time);\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Pause the clock. Pausing does not reset the tick counter.\n\t *  @param {Time} [time=now] The time when the clock should stop.\n\t *  @returns {Tone.TickSource} this\n\t */\n\tTone.TickSource.prototype.pause = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tif (this._state.getValueAtTime(time) === Tone.State.Started){\n\t\t\tthis._state.setStateAtTime(Tone.State.Paused, time);\n\t\t}\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Cancel start/stop/pause and setTickAtTime events scheduled after the given time.\n\t *  @param {Time} [time=now] When to clear the events after\n\t *  @returns {Tone.TickSource} this\n\t */\n\tTone.TickSource.prototype.cancel = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._state.cancel(time);\n\t\tthis._tickOffset.cancel(time);\n\t\treturn this;\n\t};\n\n\t/**\n\t * Get the elapsed ticks at the given time\n\t * @param  {Time} time  When to get the tick value\n\t * @return {Ticks}     The number of ticks\n\t */\n\tTone.TickSource.prototype.getTicksAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tvar stopEvent = this._state.getLastState(Tone.State.Stopped, time);\n\t\t//this event allows forEachBetween to iterate until the current time\n\t\tvar tmpEvent = { state : Tone.State.Paused, time : time };\n\t\tthis._state.add(tmpEvent);\n\n\t\t//keep track of the previous offset event\n\t\tvar lastState = stopEvent;\n\t\tvar elapsedTicks = 0;\n\n\t\t//iterate through all the events since the last stop\n\t\tthis._state.forEachBetween(stopEvent.time, time + this.sampleTime, function(e){\n\t\t\tvar periodStartTime = lastState.time;\n\t\t\t//if there is an offset event in this period use that\n\t\t\tvar offsetEvent = this._tickOffset.get(e.time);\n\t\t\tif (offsetEvent.time >= lastState.time){\n\t\t\t\telapsedTicks = offsetEvent.ticks;\n\t\t\t\tperiodStartTime = offsetEvent.time;\n\t\t\t}\n\t\t\tif (lastState.state === Tone.State.Started && e.state !== Tone.State.Started){\n\t\t\t\telapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);\n\t\t\t} \n\t\t\tlastState = e;\n\t\t}.bind(this));\n\n\t\t//remove the temporary event\n\t\tthis._state.remove(tmpEvent);\n\n\t\t//return the ticks\n\t\treturn elapsedTicks;\n\t};\n\n\t/**\n\t *  The number of times the callback was invoked. Starts counting at 0\n\t *  and increments after the callback was invoked. Returns -1 when stopped.\n\t *  @memberOf Tone.TickSource#\n\t *  @name ticks\n\t *  @type {Ticks}\n\t */\n\tObject.defineProperty(Tone.TickSource.prototype, \"ticks\", {\n\t\tget : function(){\n\t\t\treturn this.getTicksAtTime(this.now());\n\t\t},\n\t\tset : function(t){\n\t\t\tthis.setTicksAtTime(t, this.now());\n\t\t}\n\t});\n\n\t/**\n\t *  The time since ticks=0 that the TickSource has been running. Accounts\n\t *  for tempo curves\n\t *  @memberOf Tone.TickSource#\n\t *  @name seconds\n\t *  @type {Seconds}\n\t */\n\tObject.defineProperty(Tone.TickSource.prototype, \"seconds\", {\n\t\tget : function(){\n\t\t\treturn this.getSecondsAtTime(this.now());\n\t\t},\n\t\tset : function(s){\n\t\t\tvar now = this.now();\n\t\t\tvar ticks = this.frequency.timeToTicks(s, now);\n\t\t\tthis.setTicksAtTime(ticks, now);\n\t\t}\n\t});\n\n\t/**\n\t *  Return the elapsed seconds at the given time.\n\t *  @param  {Time}  time  When to get the elapsed seconds\n\t *  @return  {Seconds}  The number of elapsed seconds\n\t */\n\tTone.TickSource.prototype.getSecondsAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\tvar stopEvent = this._state.getLastState(Tone.State.Stopped, time);\n\t\t//this event allows forEachBetween to iterate until the current time\n\t\tvar tmpEvent = { state : Tone.State.Paused, time : time };\n\t\tthis._state.add(tmpEvent);\n\n\t\t//keep track of the previous offset event\n\t\tvar lastState = stopEvent;\n\t\tvar elapsedSeconds = 0;\n\n\t\t//iterate through all the events since the last stop\n\t\tthis._state.forEachBetween(stopEvent.time, time + this.sampleTime, function(e){\n\t\t\tvar periodStartTime = lastState.time;\n\t\t\t//if there is an offset event in this period use that\n\t\t\tvar offsetEvent = this._tickOffset.get(e.time);\n\t\t\tif (offsetEvent.time >= lastState.time){\n\t\t\t\telapsedSeconds = offsetEvent.seconds;\n\t\t\t\tperiodStartTime = offsetEvent.time;\n\t\t\t}\n\t\t\tif (lastState.state === Tone.State.Started && e.state !== Tone.State.Started){\n\t\t\t\telapsedSeconds += e.time - periodStartTime;\n\t\t\t} \n\t\t\tlastState = e;\n\t\t}.bind(this));\n\n\t\t//remove the temporary event\n\t\tthis._state.remove(tmpEvent);\n\n\t\t//return the ticks\n\t\treturn elapsedSeconds;\n\t};\n\n\t/**\n\t * Set the clock's ticks at the given time.\n\t * @param  {Ticks} ticks The tick value to set\n\t * @param  {Time} time  When to set the tick value\n\t * @return {Tone.TickSource}       this\n\t */\n\tTone.TickSource.prototype.setTicksAtTime = function(ticks, time){\n\t\ttime = this.toSeconds(time);\n\t\tthis._tickOffset.cancel(time);\n\t\tthis._tickOffset.add({\n\t\t\t\"time\" : time,\n\t\t\t\"ticks\" : ticks,\n\t\t\t\"seconds\" : this.frequency.getDurationOfTicks(ticks, time)\n\t\t});\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Returns the scheduled state at the given time.\n\t *  @param  {Time}  time  The time to query.\n\t *  @return  {String}  The name of the state input in setStateAtTime.\n\t *  @example\n\t * source.start(\"+0.1\");\n\t * source.getStateAtTime(\"+0.1\"); //returns \"started\"\n\t */\n\tTone.TickSource.prototype.getStateAtTime = function(time){\n\t\ttime = this.toSeconds(time);\n\t\treturn this._state.getValueAtTime(time);\n\t};\n\n\t/**\n\t * Get the time of the given tick. The second argument\n\t * is when to test before. Since ticks can be set (with setTicksAtTime)\n\t * there may be multiple times for a given tick value. \n\t * @param  {Ticks} ticks The tick number.\n\t * @param  {Time=} before When to measure the tick value from. \n\t * @return {Time}       The time of the tick\n\t */\n\tTone.TickSource.prototype.getTimeOfTick = function(tick, before){\n\t\tbefore = Tone.defaultArg(before, this.now());\n\t\tvar offset = this._tickOffset.get(before);\n\t\tvar event = this._state.get(before);\n\t\tvar startTime = Math.max(offset.time, event.time);\n\t\tvar absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;\n\t\treturn this.frequency.getTimeOfTick(absoluteTicks);\n\t};\n\n\t/**\n\t *  Invoke the callback event at all scheduled ticks between the \n\t *  start time and the end time\n\t *  @param  {Time}    startTime  The beginning of the search range\n\t *  @param  {Time}    endTime    The end of the search range\n\t *  @param  {Function<Time,Ticks>}  callback   The callback to invoke with each tick\n\t *  @return  {Tone.TickSource}    this\n\t */\n\tTone.TickSource.prototype.forEachTickBetween = function(startTime, endTime, callback){\n\n\t\t//only iterate through the sections where it is \"started\"\n\t\tvar lastStateEvent = this._state.get(startTime);\n\t\tthis._state.forEachBetween(startTime, endTime, function(event){\n\t\t\tif (lastStateEvent.state === Tone.State.Started && event.state !== Tone.State.Started){\n\t\t\t\tthis.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);\n\t\t\t}\n\t\t\tlastStateEvent = event;\n\t\t}.bind(this));\n\n\t\tstartTime = Math.max(lastStateEvent.time, startTime);\n\n\t\tif (lastStateEvent.state === Tone.State.Started && this._state){\n\t\t\t//figure out the difference between the frequency ticks and the \n\t\t\tvar startTicks = this.frequency.getTicksAtTime(startTime);\n\t\t\tvar ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);\n\t\t\tvar diff = startTicks - ticksAtStart;\n\t\t\tvar offset = diff % 1;\n\t\t\tif (offset !== 0){\n\t\t\t\toffset = 1 - offset;\n\t\t\t}\n\t\t\tvar nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);\n\t\t\tvar error = null;\n\t\t\twhile (nextTickTime < endTime && this._state){\n\t\t\t\ttry {\n\t\t\t\t\tcallback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));\n\t\t\t\t} catch (e){\n\t\t\t\t\terror = e;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (this._state){\n\t\t\t\t\tnextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);\n\t\t\t\t} \n\t\t\t}\n\t\t}\n\n\t\tif (error){\n\t\t\tthrow error;\n\t\t}\n\t\t\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @returns {Tone.TickSource} this\n\t */\n\tTone.TickSource.prototype.dispose = function(){\n\t\tTone.Param.prototype.dispose.call(this);\n\t\tthis._state.dispose();\n\t\tthis._state = null;\n\t\tthis._tickOffset.dispose();\n\t\tthis._tickOffset = null;\n\t\tthis._writable(\"frequency\");\n\t\tthis.frequency.dispose();\n\t\tthis.frequency = null;\n\t\treturn this;\n\t};\n\n\treturn Tone.TickSource;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/TickSource.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/source/UserMedia.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/Tone/source/UserMedia.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../component/Volume */ \"./node_modules/tone/Tone/component/Volume.js\"), __webpack_require__(/*! ../core/AudioNode */ \"./node_modules/tone/Tone/core/AudioNode.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t\"use strict\";\n\n\t/**\n\t *  @class  Tone.UserMedia uses MediaDevices.getUserMedia to open up\n\t *          and external microphone or audio input. Check\n\t *          [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n\t *          to see which browsers are supported. Access to an external input\n\t *          is limited to secure (HTTPS) connections.\n\t *\n\t *  @constructor\n\t *  @extends {Tone.AudioNode}\n\t *  @param {Decibels=} volume The level of the input\n\t *  @example\n\t * //list the inputs and open the third one\n\t * var motu = new Tone.UserMedia();\n\t *\n\t * //opening the input asks the user to activate their mic\n\t * motu.open().then(function(){\n\t * \t//promise resolves when input is available\n\t * });\n\t */\n\n\tTone.UserMedia = function(){\n\n\t\tvar options = Tone.defaults(arguments, [\"volume\"], Tone.UserMedia);\n\t\tTone.AudioNode.call(this);\n\n\t\t/**\n\t\t *  The MediaStreamNode\n\t\t *  @type {MediaStreamAudioSourceNode}\n\t\t *  @private\n\t\t */\n\t\tthis._mediaStream = null;\n\n\t\t/**\n\t\t *  The media stream created by getUserMedia.\n\t\t *  @type {LocalMediaStream}\n\t\t *  @private\n\t\t */\n\t\tthis._stream = null;\n\n\t\t/**\n\t\t *  The open device\n\t\t *  @type  {MediaDeviceInfo}\n\t\t *  @private\n\t\t */\n\t\tthis._device = null;\n\n\t\t/**\n\t\t *  The output volume node\n\t\t *  @type  {Tone.Volume}\n\t\t *  @private\n\t\t */\n\t\tthis._volume = this.output = new Tone.Volume(options.volume);\n\n\t\t/**\n\t\t * The volume of the output in decibels.\n\t\t * @type {Decibels}\n\t\t * @signal\n\t\t * @example\n\t\t * input.volume.value = -6;\n\t\t */\n\t\tthis.volume = this._volume.volume;\n\t\tthis._readOnly(\"volume\");\n\n\t\tthis.mute = options.mute;\n\t};\n\n\tTone.extend(Tone.UserMedia, Tone.AudioNode);\n\n\t/**\n\t * the default parameters\n\t * @type {Object}\n\t */\n\tTone.UserMedia.defaults = {\n\t\t\"volume\" : 0,\n\t\t\"mute\" : false\n\t};\n\n\t/**\n\t *  Open the media stream. If a string is passed in, it is assumed\n\t *  to be the label or id of the stream, if a number is passed in,\n\t *  it is the input number of the stream.\n\t *  @param  {String|Number} [labelOrId=\"default\"] The label or id of the audio input media device.\n\t *                                                With no argument, the default stream is opened.\n\t *  @return {Promise} The promise is resolved when the stream is open.\n\t */\n\tTone.UserMedia.prototype.open = function(labelOrId){\n\t\t//close the previous stream\n\t\tif (this.state === Tone.State.Started){\n\t\t\tthis.close();\n\t\t}\n\t\treturn Tone.UserMedia.enumerateDevices().then(function(devices){\n\t\t\tvar device;\n\t\t\tif (Tone.isNumber(labelOrId)){\n\t\t\t\tdevice = devices[labelOrId];\n\t\t\t} else {\n\t\t\t\tdevice = devices.find(function(device){\n\t\t\t\t\treturn device.label === labelOrId || device.deviceId === labelOrId;\n\t\t\t\t});\n\t\t\t\t//didn't find a matching device\n\t\t\t\tif (!device && devices.length > 0){\n\t\t\t\t\tdevice = devices[0];\n\t\t\t\t} else if (!device && Tone.isDefined(labelOrId)){\n\t\t\t\t\tthrow new Error(\"Tone.UserMedia: no matching device: \"+labelOrId);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._device = device;\n\t\t\t//do getUserMedia\n\t\t\tvar constraints = {\n\t\t\t\taudio : {\n\t\t\t\t\t\"echoCancellation\" : false,\n\t\t\t\t\t\"sampleRate\" : this.context.sampleRate,\n\t\t\t\t\t\"noiseSuppression\" : false,\n\t\t\t\t\t\"mozNoiseSuppression\" : false,\n\t\t\t\t}\n\t\t\t};\n\t\t\tif (device){\n\t\t\t\tconstraints.audio.deviceId = device.deviceId;\t\t\t\t\n\t\t\t}\n\t\t\treturn navigator.mediaDevices.getUserMedia(constraints).then(function(stream){\n\t\t\t\t//start a new source only if the previous one is closed\n\t\t\t\tif (!this._stream){\n\t\t\t\t\tthis._stream = stream;\n\t\t\t\t\t//Wrap a MediaStreamSourceNode around the live input stream.\n\t\t\t\t\tthis._mediaStream = this.context.createMediaStreamSource(stream);\n\t\t\t\t\t//Connect the MediaStreamSourceNode to a gate gain node\n\t\t\t\t\tthis._mediaStream.connect(this.output);\n\t\t\t\t}\n\t\t\t\treturn this;\n\t\t\t}.bind(this));\n\t\t}.bind(this));\n\t};\n\n\t/**\n\t *  Close the media stream\n\t *  @return {Tone.UserMedia} this\n\t */\n\tTone.UserMedia.prototype.close = function(){\n\t\tif (this._stream){\n\t\t\tthis._stream.getAudioTracks().forEach(function(track){\n\t\t\t\ttrack.stop();\n\t\t\t});\n\t\t\tthis._stream = null;\n\t\t\t//remove the old media stream\n\t\t\tthis._mediaStream.disconnect();\n\t\t\tthis._mediaStream = null;\n\t\t}\n\t\tthis._device = null;\n\t\treturn this;\n\t};\n\n\t/**\n\t *  Returns a promise which resolves with the list of audio input devices available.\n\t *  @return {Promise} The promise that is resolved with the devices\n\t *  @static\n\t *  @example\n\t * Tone.UserMedia.enumerateDevices().then(function(devices){\n\t * \tconsole.log(devices)\n\t * })\n\t */\n\tTone.UserMedia.enumerateDevices = function(){\n\t\treturn navigator.mediaDevices.enumerateDevices().then(function(devices){\n\t\t\treturn devices.filter(function(device){\n\t\t\t\treturn device.kind === \"audioinput\";\n\t\t\t});\n\t\t});\n\t};\n\n\t/**\n\t *  Returns the playback state of the source, \"started\" when the microphone is open\n\t *  and \"stopped\" when the mic is closed.\n\t *  @type {Tone.State}\n\t *  @readOnly\n\t *  @memberOf Tone.UserMedia#\n\t *  @name state\n\t */\n\tObject.defineProperty(Tone.UserMedia.prototype, \"state\", {\n\t\tget : function(){\n\t\t\treturn this._stream && this._stream.active ? Tone.State.Started : Tone.State.Stopped;\n\t\t}\n\t});\n\n\t/**\n\t * \tReturns an identifier for the represented device that is\n\t * \tpersisted across sessions. It is un-guessable by other applications and\n\t * \tunique to the origin of the calling application. It is reset when the\n\t * \tuser clears cookies (for Private Browsing, a different identifier is\n\t * \tused that is not persisted across sessions). Returns undefined when the\n\t * \tdevice is not open.\n\t *  @type {String}\n\t *  @readOnly\n\t *  @memberOf Tone.UserMedia#\n\t *  @name deviceId\n\t */\n\tObject.defineProperty(Tone.UserMedia.prototype, \"deviceId\", {\n\t\tget : function(){\n\t\t\tif (this._device){\n\t\t\t\treturn this._device.deviceId;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * \tReturns a group identifier. Two devices have the\n\t * \tsame group identifier if they belong to the same physical device.\n\t * \tReturns undefined when the device is not open.\n\t *  @type {String}\n\t *  @readOnly\n\t *  @memberOf Tone.UserMedia#\n\t *  @name groupId\n\t */\n\tObject.defineProperty(Tone.UserMedia.prototype, \"groupId\", {\n\t\tget : function(){\n\t\t\tif (this._device){\n\t\t\t\treturn this._device.groupId;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * \tReturns a label describing this device (for example \"Built-in Microphone\").\n\t * \tReturns undefined when the device is not open or label is not available\n\t * \tbecause of permissions.\n\t *  @type {String}\n\t *  @readOnly\n\t *  @memberOf Tone.UserMedia#\n\t *  @name groupId\n\t */\n\tObject.defineProperty(Tone.UserMedia.prototype, \"label\", {\n\t\tget : function(){\n\t\t\tif (this._device){\n\t\t\t\treturn this._device.label;\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t * Mute the output.\n\t * @memberOf Tone.UserMedia#\n\t * @type {boolean}\n\t * @name mute\n\t * @example\n\t * //mute the output\n\t * userMedia.mute = true;\n\t */\n\tObject.defineProperty(Tone.UserMedia.prototype, \"mute\", {\n\t\tget : function(){\n\t\t\treturn this._volume.mute;\n\t\t},\n\t\tset : function(mute){\n\t\t\tthis._volume.mute = mute;\n\t\t}\n\t});\n\n\t/**\n\t * Clean up.\n\t * @return {Tone.UserMedia} this\n\t */\n\tTone.UserMedia.prototype.dispose = function(){\n\t\tTone.AudioNode.prototype.dispose.call(this);\n\t\tthis.close();\n\t\tthis._writable(\"volume\");\n\t\tthis._volume.dispose();\n\t\tthis._volume = null;\n\t\tthis.volume = null;\n\t\treturn this;\n\t};\n\n\t/**\n\t *  If getUserMedia is supported by the browser.\n\t *  @type  {Boolean}\n\t *  @memberOf Tone.UserMedia#\n\t *  @name supported\n\t *  @static\n\t *  @readOnly\n\t */\n\tObject.defineProperty(Tone.UserMedia, \"supported\", {\n\t\tget : function(){\n\t\t\treturn Tone.isDefined(navigator.mediaDevices) && Tone.isFunction(navigator.mediaDevices.getUserMedia);\n\t\t}\n\t});\n\n\treturn Tone.UserMedia;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/source/UserMedia.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/Frequency.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/Tone/type/Frequency.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/TimeBase */ \"./node_modules/tone/Tone/type/TimeBase.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Frequency is a primitive type for encoding Frequency values.\n\t *         Eventually all time values are evaluated to hertz\n\t *         using the `eval` method.\n\t *  @constructor\n\t *  @extends {Tone.TimeBase}\n\t *  @param  {String|Number}  val    The time value.\n\t *  @param  {String=}  units  The units of the value.\n\t *  @example\n\t * Tone.Frequency(\"C3\") // 261\n\t * Tone.Frequency(38, \"midi\") //\n\t * Tone.Frequency(\"C3\").transpose(4);\n\t */\n\tTone.Frequency = function(val, units){\n\t\tif (this instanceof Tone.Frequency){\n\n\t\t\tTone.TimeBase.call(this, val, units);\n\n\t\t} else {\n\t\t\treturn new Tone.Frequency(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Frequency, Tone.TimeBase);\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tAUGMENT BASE EXPRESSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\tTone.Frequency.prototype._expressions = Object.assign({}, Tone.TimeBase.prototype._expressions, {\n\t\t\"midi\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?midi)/,\n\t\t\tmethod : function(value){\n\t\t\t\tif (this._defaultUnits === \"midi\"){\n\t\t\t\t\treturn value;\n\t\t\t\t} else {\n\t\t\t\t\treturn Tone.Frequency.mtof(value);\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"note\" : {\n\t\t\tregexp : /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,\n\t\t\tmethod : function(pitch, octave){\n\t\t\t\tvar index = noteToScaleIndex[pitch.toLowerCase()];\n\t\t\t\tvar noteNumber = index + (parseInt(octave) + 1) * 12;\n\t\t\t\tif (this._defaultUnits === \"midi\"){\n\t\t\t\t\treturn noteNumber;\n\t\t\t\t} else {\n\t\t\t\t\treturn Tone.Frequency.mtof(noteNumber);\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"tr\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,\n\t\t\tmethod : function(m, q, s){\n\t\t\t\tvar total = 1;\n\t\t\t\tif (m && m !== \"0\"){\n\t\t\t\t\ttotal *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n\t\t\t\t}\n\t\t\t\tif (q && q !== \"0\"){\n\t\t\t\t\ttotal *= this._beatsToUnits(parseFloat(q));\n\t\t\t\t}\n\t\t\t\tif (s && s !== \"0\"){\n\t\t\t\t\ttotal *= this._beatsToUnits(parseFloat(s) / 4);\n\t\t\t\t}\n\t\t\t\treturn total;\n\t\t\t}\n\t\t}\n\t});\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tEXPRESSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Transposes the frequency by the given number of semitones.\n\t *  @param  {Interval}  interval\n\t *  @return  {Tone.Frequency} A new transposed frequency\n\t *  @example\n\t * Tone.Frequency(\"A4\").transpose(3); //\"C5\"\n\t */\n\tTone.Frequency.prototype.transpose = function(interval){\n\t\treturn new this.constructor(this.valueOf() * Tone.intervalToFrequencyRatio(interval));\n\t};\n\n\t/**\n\t *  Takes an array of semitone intervals and returns\n\t *  an array of frequencies transposed by those intervals.\n\t *  @param  {Array}  intervals\n\t *  @return  {Array<Tone.Frequency>} Returns an array of Frequencies\n\t *  @example\n\t * Tone.Frequency(\"A4\").harmonize([0, 3, 7]); //[\"A4\", \"C5\", \"E5\"]\n\t */\n\tTone.Frequency.prototype.harmonize = function(intervals){\n\t\treturn intervals.map(function(interval){\n\t\t\treturn this.transpose(interval);\n\t\t}.bind(this));\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tUNIT CONVERSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Return the value of the frequency as a MIDI note\n\t *  @return  {MIDI}\n\t *  @example\n\t * Tone.Frequency(\"C4\").toMidi(); //60\n\t */\n\tTone.Frequency.prototype.toMidi = function(){\n\t\treturn Tone.Frequency.ftom(this.valueOf());\n\t};\n\n\t/**\n\t *  Return the value of the frequency in Scientific Pitch Notation\n\t *  @return  {Note}\n\t *  @example\n\t * Tone.Frequency(69, \"midi\").toNote(); //\"A4\"\n\t */\n\tTone.Frequency.prototype.toNote = function(){\n\t\tvar freq = this.toFrequency();\n\t\tvar log = Math.log2(freq / Tone.Frequency.A4);\n\t\tvar noteNumber = Math.round(12 * log) + 57;\n\t\tvar octave = Math.floor(noteNumber/12);\n\t\tif (octave < 0){\n\t\t\tnoteNumber += -12 * octave;\n\t\t}\n\t\tvar noteName = scaleIndexToNote[noteNumber % 12];\n\t\treturn noteName + octave.toString();\n\t};\n\n\t/**\n\t *  Return the duration of one cycle in seconds.\n\t *  @return  {Seconds}\n\t */\n\tTone.Frequency.prototype.toSeconds = function(){\n\t\treturn 1 / Tone.TimeBase.prototype.toSeconds.call(this);\n\t};\n\n\t/**\n\t *  Return the value in Hertz\n\t *  @return  {Frequency}\n\t */\n\tTone.Frequency.prototype.toFrequency = function(){\n\t\treturn Tone.TimeBase.prototype.toFrequency.call(this);\n\t};\n\n\t/**\n\t *  Return the duration of one cycle in ticks\n\t *  @return  {Ticks}\n\t */\n\tTone.Frequency.prototype.toTicks = function(){\n\t\tvar quarterTime = this._beatsToUnits(1);\n\t\tvar quarters = this.valueOf() / quarterTime;\n\t\treturn Math.floor(quarters * Tone.Transport.PPQ);\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tUNIT CONVERSIONS HELPERS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  With no arguments, return 0\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Frequency.prototype._noArg = function(){\n\t\treturn 0;\n\t};\n\n\t/**\n\t *  Returns the value of a frequency in the current units\n\t *  @param {Frequency} freq\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Frequency.prototype._frequencyToUnits = function(freq){\n\t\treturn freq;\n\t};\n\n\t/**\n\t *  Returns the value of a tick in the current time units\n\t *  @param {Ticks} ticks\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Frequency.prototype._ticksToUnits = function(ticks){\n\t\treturn 1 / ((ticks * 60) / (Tone.Transport.bpm.value * Tone.Transport.PPQ));\n\t};\n\n\t/**\n\t *  Return the value of the beats in the current units\n\t *  @param {Number} beats\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Frequency.prototype._beatsToUnits = function(beats){\n\t\treturn 1 / Tone.TimeBase.prototype._beatsToUnits.call(this, beats);\n\t};\n\n\t/**\n\t *  Returns the value of a second in the current units\n\t *  @param {Seconds} seconds\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Frequency.prototype._secondsToUnits = function(seconds){\n\t\treturn 1 / seconds;\n\t};\n\n\t/**\n\t *  The default units if none are given.\n\t *  @private\n\t */\n\tTone.Frequency.prototype._defaultUnits = \"hz\";\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tFREQUENCY CONVERSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Note to scale index\n\t *  @type  {Object}\n\t */\n\tvar noteToScaleIndex = {\n\t\t\"cbb\" : -2, \"cb\" : -1, \"c\" : 0, \"c#\" : 1, \"cx\" : 2,\n\t\t\"dbb\" : 0, \"db\" : 1, \"d\" : 2, \"d#\" : 3, \"dx\" : 4,\n\t\t\"ebb\" : 2, \"eb\" : 3, \"e\" : 4, \"e#\" : 5, \"ex\" : 6,\n\t\t\"fbb\" : 3, \"fb\" : 4, \"f\" : 5, \"f#\" : 6, \"fx\" : 7,\n\t\t\"gbb\" : 5, \"gb\" : 6, \"g\" : 7, \"g#\" : 8, \"gx\" : 9,\n\t\t\"abb\" : 7, \"ab\" : 8, \"a\" : 9, \"a#\" : 10, \"ax\" : 11,\n\t\t\"bbb\" : 9, \"bb\" : 10, \"b\" : 11, \"b#\" : 12, \"bx\" : 13,\n\t};\n\n\t/**\n\t *  scale index to note (sharps)\n\t *  @type  {Array}\n\t */\n\tvar scaleIndexToNote = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"];\n\n\t/**\n\t *  The [concert pitch](https://en.wikipedia.org/wiki/Concert_pitch)\n\t *  A4's values in Hertz.\n\t *  @type {Frequency}\n\t *  @static\n\t */\n\tTone.Frequency.A4 = 440;\n\n\t/**\n\t *  Convert a MIDI note to frequency value.\n\t *  @param  {MIDI} midi The midi number to convert.\n\t *  @return {Frequency} the corresponding frequency value\n\t *  @static\n\t *  @example\n\t * Tone.Frequency.mtof(69); // returns 440\n\t */\n\tTone.Frequency.mtof = function(midi){\n\t\treturn Tone.Frequency.A4 * Math.pow(2, (midi - 69) / 12);\n\t};\n\n\t/**\n\t *  Convert a frequency value to a MIDI note.\n\t *  @param {Frequency} frequency The value to frequency value to convert.\n\t *  @returns  {MIDI}\n\t *  @static\n\t *  @example\n\t * Tone.Frequency.ftom(440); // returns 69\n\t */\n\tTone.Frequency.ftom = function(frequency){\n\t\treturn 69 + Math.round(12 * Math.log2(frequency / Tone.Frequency.A4));\n\t};\n\n\treturn Tone.Frequency;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/Frequency.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/Midi.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/type/Midi.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Frequency */ \"./node_modules/tone/Tone/type/Frequency.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Midi is a primitive type for encoding Time values.\n\t *         Tone.Midi can be constructed with or without the `new` keyword. Tone.Midi can be passed\n\t *         into the parameter of any method which takes time as an argument.\n\t *  @constructor\n\t *  @extends {Tone.Frequency}\n\t *  @param  {String|Number}  val    The time value.\n\t *  @param  {String=}  units  The units of the value.\n\t *  @example\n\t * var t = Tone.Midi(\"4n\");//a quarter note\n\t */\n\tTone.Midi = function(val, units){\n\t\tif (this instanceof Tone.Midi){\n\n\t\t\tTone.Frequency.call(this, val, units);\n\n\t\t} else {\n\t\t\treturn new Tone.Midi(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Midi, Tone.Frequency);\n\n\t/**\n\t *  The default units if none are given.\n\t *  @type {String}\n\t *  @private\n\t */\n\tTone.Midi.prototype._defaultUnits = \"midi\";\n\n\t/**\n\t *  Returns the value of a frequency in the current units\n\t *  @param {Frequency} freq\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Midi.prototype._frequencyToUnits = function(freq){\n\t\treturn Tone.Frequency.ftom(Tone.Frequency.prototype._frequencyToUnits.call(this, freq));\n\t};\n\n\t/**\n\t *  Returns the value of a tick in the current time units\n\t *  @param {Ticks} ticks\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Midi.prototype._ticksToUnits = function(ticks){\n\t\treturn Tone.Frequency.ftom(Tone.Frequency.prototype._ticksToUnits.call(this, ticks));\n\t};\n\n\t/**\n\t *  Return the value of the beats in the current units\n\t *  @param {Number} beats\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Midi.prototype._beatsToUnits = function(beats){\n\t\treturn Tone.Frequency.ftom(Tone.Frequency.prototype._beatsToUnits.call(this, beats));\n\t};\n\n\t/**\n\t *  Returns the value of a second in the current units\n\t *  @param {Seconds} seconds\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Midi.prototype._secondsToUnits = function(seconds){\n\t\treturn Tone.Frequency.ftom(Tone.Frequency.prototype._secondsToUnits.call(this, seconds));\n\t};\n\n\t/**\n\t *  Return the value of the frequency as a MIDI note\n\t *  @return  {MIDI}\n\t *  @example\n\t * Tone.Midi(60).toMidi(); //60\n\t */\n\tTone.Midi.prototype.toMidi = function(){\n\t\treturn this.valueOf();\n\t};\n\n\t/**\n\t *  Return the value of the frequency as a MIDI note\n\t *  @return  {MIDI}\n\t *  @example\n\t * Tone.Midi(60).toFrequency(); //261.6255653005986\n\t */\n\tTone.Midi.prototype.toFrequency = function(){\n\t\treturn Tone.Frequency.mtof(this.toMidi());\n\t};\n\n\t/**\n\t *  Transposes the frequency by the given number of semitones.\n\t *  @param  {Interval}  interval\n\t *  @return  {Tone.Frequency} A new transposed frequency\n\t *  @example\n\t * Tone.Midi(\"A4\").transpose(3); //\"C5\"\n\t */\n\tTone.Midi.prototype.transpose = function(interval){\n\t\treturn new this.constructor(this.toMidi() + interval);\n\t};\n\n\treturn Tone.Midi;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/Midi.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/Ticks.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/Tone/type/Ticks.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/Tone/type/TransportTime.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Ticks is a primitive type for encoding Time values.\n\t *         Tone.Ticks can be constructed with or without the `new` keyword. Tone.Ticks can be passed\n\t *         into the parameter of any method which takes time as an argument.\n\t *  @constructor\n\t *  @extends {Tone.TransportTime}\n\t *  @param  {String|Number}  val    The time value.\n\t *  @param  {String=}  units  The units of the value.\n\t *  @example\n\t * var t = Tone.Ticks(\"4n\");//a quarter note\n\t */\n\tTone.Ticks = function(val, units){\n\t\tif (this instanceof Tone.Ticks){\n\n\t\t\tTone.TransportTime.call(this, val, units);\n\n\t\t} else {\n\t\t\treturn new Tone.Ticks(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Ticks, Tone.TransportTime);\n\n\t/**\n\t *  The default units if none are given.\n\t *  @type {String}\n\t *  @private\n\t */\n\tTone.Ticks.prototype._defaultUnits = \"i\";\n\n\t/**\n\t * Get the current time in the given units\n\t * @return {Ticks}\n\t * @private\n\t */\n\tTone.Ticks.prototype._now = function(){\n\t\treturn Tone.Transport.ticks;\n\t};\n\n\t/**\n\t *  Return the value of the beats in the current units\n\t *  @param {Number} beats\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Ticks.prototype._beatsToUnits = function(beats){\n\t\treturn this._getPPQ() * beats;\n\t};\n\n\t/**\n\t *  Returns the value of a second in the current units\n\t *  @param {Seconds} seconds\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Ticks.prototype._secondsToUnits = function(seconds){\n\t\treturn Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());\n\t};\n\n\t/**\n\t *  Returns the value of a tick in the current time units\n\t *  @param {Ticks} ticks\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.Ticks.prototype._ticksToUnits = function(ticks){\n\t\treturn ticks;\n\t};\n\n\t/**\n\t *  Return the time in ticks\n\t *  @return  {Ticks}\n\t */\n\tTone.Ticks.prototype.toTicks = function(){\n\t\treturn this.valueOf();\n\t};\n\n\t/**\n\t *  Return the time in ticks\n\t *  @return  {Ticks}\n\t */\n\tTone.Ticks.prototype.toSeconds = function(){\n\t\treturn (this.valueOf() / this._getPPQ()) * (60 / this._getBpm());\n\t};\n\n\treturn Tone.Ticks;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/Ticks.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/Time.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/type/Time.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/TimeBase */ \"./node_modules/tone/Tone/type/TimeBase.js\"), __webpack_require__(/*! ../type/Frequency */ \"./node_modules/tone/Tone/type/Frequency.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.Time is a primitive type for encoding Time values.\n\t *         Tone.Time can be constructed with or without the `new` keyword. Tone.Time can be passed\n\t *         into the parameter of any method which takes time as an argument.\n\t *  @constructor\n\t *  @extends {Tone.TimeBase}\n\t *  @param  {String|Number|Object}  val    The time value.\n\t *  @param  {String=}  units  The units of the value.\n\t *  @example\n\t * var t = Tone.Time(\"4n\");//a quarter note\n\t */\n\tTone.Time = function(val, units){\n\t\tif (this instanceof Tone.Time){\n\n\t\t\tTone.TimeBase.call(this, val, units);\n\n\t\t} else {\n\t\t\treturn new Tone.Time(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.Time, Tone.TimeBase);\n\n\t/**\n\t * Extend the base expressions\n\t */\n\tTone.Time.prototype._expressions = Object.assign({}, Tone.TimeBase.prototype._expressions, {\n\t\t\"quantize\" : {\n\t\t\tregexp : /^@(.+)/,\n\t\t\tmethod : function(capture){\n\t\t\t\tif (Tone.Transport){\n\t\t\t\t\tvar quantTo = new this.constructor(capture);\n\t\t\t\t\treturn this._secondsToUnits(Tone.Transport.nextSubdivision(quantTo));\n\t\t\t\t} else {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"now\" : {\n\t\t\tregexp : /^\\+(.+)/,\n\t\t\tmethod : function(capture){\n\t\t\t\treturn this._now() + (new this.constructor(capture));\n\t\t\t}\n\t\t}\n\t});\n\n\t/**\n\t *  Quantize the time by the given subdivision. Optionally add a\n\t *  percentage which will move the time value towards the ideal\n\t *  quantized value by that percentage.\n\t *  @param  {Number|Time}  val    The subdivision to quantize to\n\t *  @param  {NormalRange}  [percent=1]  Move the time value\n\t *                                   towards the quantized value by\n\t *                                   a percentage.\n\t *  @return  {Number}  this\n\t *  @example\n\t * Tone.Time(21).quantize(2) //returns 22\n\t * Tone.Time(0.6).quantize(\"4n\", 0.5) //returns 0.55\n\t */\n\tTone.Time.prototype.quantize = function(subdiv, percent){\n\t\tpercent = Tone.defaultArg(percent, 1);\n\t\tvar subdivision = new this.constructor(subdiv);\n\t\tvar value = this.valueOf();\n\t\tvar multiple = Math.round(value / subdivision);\n\t\tvar ideal = multiple * subdivision;\n\t\tvar diff = ideal - value;\n\t\treturn value + diff * percent;\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// CONVERSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Convert a Time to Notation. The notation values are will be the\n\t *  closest representation between 1m to 128th note.\n\t *  @return {Notation}\n\t *  @example\n\t * //if the Transport is at 120bpm:\n\t * Tone.Time(2).toNotation();//returns \"1m\"\n\t */\n\tTone.Time.prototype.toNotation = function(){\n\t\tvar time = this.toSeconds();\n\t\tvar testNotations = [\"1m\"];\n\t\tfor (var power = 1; power < 8; power++){\n\t\t\tvar subdiv = Math.pow(2, power);\n\t\t\ttestNotations.push(subdiv + \"n.\");\n\t\t\ttestNotations.push(subdiv + \"n\");\n\t\t\ttestNotations.push(subdiv + \"t\");\n\t\t}\n\t\ttestNotations.push(\"0\");\n\t\t//find the closets notation representation\n\t\tvar closest = testNotations[0];\n\t\tvar closestSeconds = Tone.Time(testNotations[0]).toSeconds();\n\t\ttestNotations.forEach(function(notation){\n\t\t\tvar notationSeconds = Tone.Time(notation).toSeconds();\n\t\t\tif (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)){\n\t\t\t\tclosest = notation;\n\t\t\t\tclosestSeconds = notationSeconds;\n\t\t\t}\n\t\t});\n\t\treturn closest;\n\t};\n\n\t/**\n\t *  Return the time encoded as Bars:Beats:Sixteenths.\n\t *  @return  {BarsBeatsSixteenths}\n\t */\n\tTone.Time.prototype.toBarsBeatsSixteenths = function(){\n\t\tvar quarterTime = this._beatsToUnits(1);\n\t\tvar quarters = this.valueOf() / quarterTime;\n\t\tquarters = parseFloat(quarters.toFixed(4));\n\t\tvar measures = Math.floor(quarters / this._getTimeSignature());\n\t\tvar sixteenths = (quarters % 1) * 4;\n\t\tquarters = Math.floor(quarters) % this._getTimeSignature();\n\t\tsixteenths = sixteenths.toString();\n\t\tif (sixteenths.length > 3){\n\t\t\t// the additional parseFloat removes insignificant trailing zeroes\n\t\t\tsixteenths = parseFloat(parseFloat(sixteenths).toFixed(3));\n\t\t}\n\t\tvar progress = [measures, quarters, sixteenths];\n\t\treturn progress.join(\":\");\n\t};\n\n\t/**\n\t *  Return the time in ticks.\n\t *  @return  {Ticks}\n\t */\n\tTone.Time.prototype.toTicks = function(){\n\t\tvar quarterTime = this._beatsToUnits(1);\n\t\tvar quarters = this.valueOf() / quarterTime;\n\t\treturn Math.round(quarters * this._getPPQ());\n\t};\n\n\t/**\n\t *  Return the time in seconds.\n\t *  @return  {Seconds}\n\t */\n\tTone.Time.prototype.toSeconds = function(){\n\t\treturn this.valueOf();\n\t};\n\n\t/**\n\t *  Return the value as a midi note.\n\t *  @return  {Midi}\n\t */\n\tTone.Time.prototype.toMidi = function(){\n\t\treturn Tone.Frequency.ftom(this.toFrequency());\n\t};\n\n\treturn Tone.Time;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/Time.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/TimeBase.js":
/*!*************************************************!*\
  !*** ./node_modules/tone/Tone/type/TimeBase.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.TimeBase is a flexible encoding of time\n\t *         which can be evaluated to and from a string.\n\t *  @extends {Tone}\n\t *  @param  {Time}  val    The time value as a number, string or object\n\t *  @param  {String=}  units  Unit values\n\t *  @example\n\t * Tone.TimeBase(4, \"n\")\n\t * Tone.TimeBase(2, \"t\")\n\t * Tone.TimeBase(\"2t\")\n\t * Tone.TimeBase({\"2t\" : 2})\n\t * Tone.TimeBase(\"2t\") + Tone.TimeBase(\"4n\");\n\t */\n\tTone.TimeBase = function(val, units){\n\n\t\t//allows it to be constructed with or without 'new'\n\t\tif (this instanceof Tone.TimeBase){\n\n\t\t\t/**\n\t\t\t *  The value\n\t\t\t *  @type  {Number|String|Tone.TimeBase}\n\t\t\t *  @private\n\t\t\t */\n\t\t\tthis._val = val;\n\n\t\t\t/**\n\t\t\t * The units\n\t\t\t * @type {String?}\n\t\t\t * @private\n\t\t\t */\n\t\t\tthis._units = units;\n\n\t\t\t//test if the value is a string representation of a number\n\t\t\tif (Tone.isUndef(this._units) && Tone.isString(this._val) &&\n\t\t\t\t// eslint-disable-next-line eqeqeq\n\t\t\t\tparseFloat(this._val) == this._val && this._val.charAt(0) !== \"+\"){\n\t\t\t\tthis._val = parseFloat(this._val);\n\t\t\t\tthis._units = this._defaultUnits;\n\t\t\t} else if (val && val.constructor === this.constructor){\n\t\t\t\t//if they're the same type, just copy values over\n\t\t\t\tthis._val = val._val;\n\t\t\t\tthis._units = val._units;\n\t\t\t} else if (val instanceof Tone.TimeBase){\n\t\t\t\tswitch (this._defaultUnits){\n\t\t\t\t\tcase \"s\" :\n\t\t\t\t\t\tthis._val = val.toSeconds();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"i\" :\n\t\t\t\t\t\tthis._val = val.toTicks();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"hz\" :\n\t\t\t\t\t\tthis._val = val.toFrequency();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase \"midi\" :\n\t\t\t\t\t\tthis._val = val.toMidi();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault :\n\t\t\t\t\t\tthrow new Error(\"Unrecognized default units \"+this._defaultUnits);\n\t\t\t\t}\n\t\t\t}\n\n\t\t} else {\n\n\t\t\treturn new Tone.TimeBase(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.TimeBase);\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tABSTRACT SYNTAX TREE PARSER\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  All the primary expressions.\n\t *  @private\n\t *  @type  {Object}\n\t */\n\tTone.TimeBase.prototype._expressions = {\n\t\t\"n\" : {\n\t\t\tregexp : /^(\\d+)n(\\.?)$/i,\n\t\t\tmethod : function(value, dot){\n\t\t\t\tvalue = parseInt(value);\n\t\t\t\tvar scalar = dot === \".\" ? 1.5 : 1;\n\t\t\t\tif (value === 1){\n\t\t\t\t\treturn this._beatsToUnits(this._getTimeSignature())*scalar;\n\t\t\t\t} else {\n\t\t\t\t\treturn this._beatsToUnits(4 / value)*scalar;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t\"t\" : {\n\t\t\tregexp : /^(\\d+)t$/i,\n\t\t\tmethod : function(value){\n\t\t\t\tvalue = parseInt(value);\n\t\t\t\treturn this._beatsToUnits(8 / (parseInt(value) * 3));\n\t\t\t}\n\t\t},\n\t\t\"m\" : {\n\t\t\tregexp : /^(\\d+)m$/i,\n\t\t\tmethod : function(value){\n\t\t\t\treturn this._beatsToUnits(parseInt(value) * this._getTimeSignature());\n\t\t\t}\n\t\t},\n\t\t\"i\" : {\n\t\t\tregexp : /^(\\d+)i$/i,\n\t\t\tmethod : function(value){\n\t\t\t\treturn this._ticksToUnits(parseInt(value));\n\t\t\t}\n\t\t},\n\t\t\"hz\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?)hz$/i,\n\t\t\tmethod : function(value){\n\t\t\t\treturn this._frequencyToUnits(parseFloat(value));\n\t\t\t}\n\t\t},\n\t\t\"tr\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?$/,\n\t\t\tmethod : function(m, q, s){\n\t\t\t\tvar total = 0;\n\t\t\t\tif (m && m !== \"0\"){\n\t\t\t\t\ttotal += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n\t\t\t\t}\n\t\t\t\tif (q && q !== \"0\"){\n\t\t\t\t\ttotal += this._beatsToUnits(parseFloat(q));\n\t\t\t\t}\n\t\t\t\tif (s && s !== \"0\"){\n\t\t\t\t\ttotal += this._beatsToUnits(parseFloat(s) / 4);\n\t\t\t\t}\n\t\t\t\treturn total;\n\t\t\t}\n\t\t},\n\t\t\"s\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?)s$/,\n\t\t\tmethod : function(value){\n\t\t\t\treturn this._secondsToUnits(parseFloat(value));\n\t\t\t}\n\t\t},\n\t\t\"samples\" : {\n\t\t\tregexp : /^(\\d+)samples$/,\n\t\t\tmethod : function(value){\n\t\t\t\treturn parseInt(value) / this.context.sampleRate;\n\t\t\t}\n\t\t},\n\t\t\"default\" : {\n\t\t\tregexp : /^(\\d+(?:\\.\\d+)?)$/,\n\t\t\tmethod : function(value){\n\t\t\t\treturn this._expressions[this._defaultUnits].method.call(this, value);\n\t\t\t}\n\t\t}\n\t};\n\n\t/**\n\t *  The default units if none are given.\n\t *  @type {String}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._defaultUnits = \"s\";\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tTRANSPORT FALLBACKS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t * Return the bpm, or 120 if Transport is not available\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.TimeBase.prototype._getBpm = function(){\n\t\tif (Tone.Transport){\n\t\t\treturn Tone.Transport.bpm.value;\n\t\t} else {\n\t\t\treturn 120;\n\t\t}\n\t};\n\n\t/**\n\t * Return the timeSignature or 4 if Transport is not available\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.TimeBase.prototype._getTimeSignature = function(){\n\t\tif (Tone.Transport){\n\t\t\treturn Tone.Transport.timeSignature;\n\t\t} else {\n\t\t\treturn 4;\n\t\t}\n\t};\n\n\t/**\n\t * Return the PPQ or 192 if Transport is not available\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.TimeBase.prototype._getPPQ = function(){\n\t\tif (Tone.Transport){\n\t\t\treturn Tone.Transport.PPQ;\n\t\t} else {\n\t\t\treturn 192;\n\t\t}\n\t};\n\n\t/**\n\t * Return the current time in whichever context is relevant\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.TimeBase.prototype._now = function(){\n\t\treturn this.now();\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tUNIT CONVERSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Returns the value of a frequency in the current units\n\t *  @param {Frequency} freq\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._frequencyToUnits = function(freq){\n\t\treturn 1/freq;\n\t};\n\n\t/**\n\t *  Return the value of the beats in the current units\n\t *  @param {Number} beats\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._beatsToUnits = function(beats){\n\t\treturn (60 / this._getBpm()) * beats;\n\t};\n\n\t/**\n\t *  Returns the value of a second in the current units\n\t *  @param {Seconds} seconds\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._secondsToUnits = function(seconds){\n\t\treturn seconds;\n\t};\n\n\t/**\n\t *  Returns the value of a tick in the current time units\n\t *  @param {Ticks} ticks\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._ticksToUnits = function(ticks){\n\t\treturn ticks * (this._beatsToUnits(1) / this._getPPQ());\n\t};\n\n\t/**\n\t * With no arguments, return 'now'\n\t *  @return  {Number}\n\t *  @private\n\t */\n\tTone.TimeBase.prototype._noArg = function(){\n\t\treturn this._now();\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tEXPRESSIONS\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Evaluate the time value. Returns the time\n\t *  in seconds.\n\t *  @return  {Seconds}\n\t */\n\tTone.TimeBase.prototype.valueOf = function(){\n\t\tif (Tone.isUndef(this._val)){\n\t\t\treturn this._noArg();\n\t\t} else if (Tone.isString(this._val) && Tone.isUndef(this._units)){\n\t\t\tfor (var units in this._expressions){\n\t\t\t\tif (this._expressions[units].regexp.test(this._val.trim())){\n\t\t\t\t\tthis._units = units;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (Tone.isObject(this._val)){\n\t\t\tvar total = 0;\n\t\t\tfor (var typeName in this._val){\n\t\t\t\tvar quantity = this._val[typeName];\n\t\t\t\tvar time = (new this.constructor(typeName)).valueOf() * quantity;\n\t\t\t\ttotal += time;\n\t\t\t}\n\t\t\treturn total;\n\t\t}\n\t\tif (Tone.isDefined(this._units)){\n\t\t\tvar expr = this._expressions[this._units];\n\t\t\tvar matching = this._val.toString().trim().match(expr.regexp);\n\t\t\tif (matching){\n\t\t\t\treturn expr.method.apply(this, matching.slice(1));\n\t\t\t} else {\n\t\t\t\treturn expr.method.call(this, parseFloat(this._val));\n\t\t\t}\n\t\t} else {\n\t\t\treturn this._val;\n\t\t}\n\t};\n\n\t/**\n\t *  Return the value in seconds\n\t *  @return {Seconds}\n\t */\n\tTone.TimeBase.prototype.toSeconds = function(){\n\t\treturn this.valueOf();\n\t};\n\n\t/**\n\t *  Return the value in hertz\n\t *  @return {Frequency}\n\t */\n\tTone.TimeBase.prototype.toFrequency = function(){\n\t\treturn 1 / this.toSeconds();\n\t};\n\n\t/**\n\t *  Return the time in samples\n\t *  @return  {Samples}\n\t */\n\tTone.TimeBase.prototype.toSamples = function(){\n\t\treturn this.toSeconds() * this.context.sampleRate;\n\t};\n\n\t/**\n\t *  Return the time in milliseconds.\n\t *  @return  {Milliseconds}\n\t */\n\tTone.TimeBase.prototype.toMilliseconds = function(){\n\t\treturn this.toSeconds() * 1000;\n\t};\n\n\t/**\n\t *  Clean up\n\t *  @return {Tone.TimeBase} this\n\t */\n\tTone.TimeBase.prototype.dispose = function(){\n\t\tthis._val = null;\n\t\tthis._units = null;\n\t};\n\n\treturn Tone.TimeBase;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/TimeBase.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/TransportTime.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/Tone/type/TransportTime.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Time */ \"./node_modules/tone/Tone/type/Time.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t/**\n\t *  @class Tone.TransportTime is a the time along the Transport's\n\t *         timeline. It is similar to Tone.Time, but instead of evaluating\n\t *         against the AudioContext's clock, it is evaluated against\n\t *         the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n\t *  @constructor\n\t *  @param  {Time}  val    The time value as a number or string\n\t *  @param  {String=}  units  Unit values\n\t *  @extends {Tone.Time}\n\t */\n\tTone.TransportTime = function(val, units){\n\t\tif (this instanceof Tone.TransportTime){\n\n\t\t\tTone.Time.call(this, val, units);\n\n\t\t} else {\n\t\t\treturn new Tone.TransportTime(val, units);\n\t\t}\n\t};\n\n\tTone.extend(Tone.TransportTime, Tone.Time);\n\n\t/**\n\t * Return the current time in whichever context is relevant\n\t * @type {Number}\n\t * @private\n\t */\n\tTone.TransportTime.prototype._now = function(){\n\t\treturn Tone.Transport.seconds;\n\t};\n\n\treturn Tone.TransportTime;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/TransportTime.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/type/Type.js":
/*!*********************************************!*\
  !*** ./node_modules/tone/Tone/type/Type.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;!(__WEBPACK_AMD_DEFINE_ARRAY__ = [__webpack_require__(/*! ../core/Tone */ \"./node_modules/tone/Tone/core/Tone.js\"), __webpack_require__(/*! ../type/Time */ \"./node_modules/tone/Tone/type/Time.js\"), __webpack_require__(/*! ../type/Frequency */ \"./node_modules/tone/Tone/type/Frequency.js\"), __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/Tone/type/TransportTime.js\"), __webpack_require__(/*! ../core/Context */ \"./node_modules/tone/Tone/core/Context.js\")], __WEBPACK_AMD_DEFINE_RESULT__ = (function(Tone){\n\n\t///////////////////////////////////////////////////////////////////////////\n\t//\tTYPES\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t * Units which a value can take on.\n\t * @enum {String}\n\t */\n\tTone.Type = {\n\t\t/**\n\t\t *  Default units\n\t\t *  @typedef {Default}\n\t\t */\n\t\tDefault : \"number\",\n\t\t/**\n\t\t *  Time can be described in a number of ways. Read more [Time](https://github.com/Tonejs/Tone.js/wiki/Time).\n\t\t *\n\t\t *  * Numbers, which will be taken literally as the time (in seconds).\n\t\t *  * Notation, (\"4n\", \"8t\") describes time in BPM and time signature relative values.\n\t\t *  * TransportTime, (\"4:3:2\") will also provide tempo and time signature relative times\n\t\t *  in the form BARS:QUARTERS:SIXTEENTHS.\n\t\t *  * Frequency, (\"8hz\") is converted to the length of the cycle in seconds.\n\t\t *  * Now-Relative, (\"+1\") prefix any of the above with \"+\" and it will be interpreted as\n\t\t *  \"the current time plus whatever expression follows\".\n\t\t *  * Object, ({\"4n\" : 3, \"8t\" : -1}). The resulting time is equal to the sum of all of the keys multiplied by the values in the object. \n\t\t *  * No Argument, for methods which accept time, no argument will be interpreted as\n\t\t *  \"now\" (i.e. the currentTime).\n\t\t *\n\t\t *  @typedef {Time}\n\t\t */\n\t\tTime : \"time\",\n\t\t/**\n\t\t *  Frequency can be described similar to time, except ultimately the\n\t\t *  values are converted to frequency instead of seconds. A number\n\t\t *  is taken literally as the value in hertz. Additionally any of the\n\t\t *  Time encodings can be used. Note names in the form\n\t\t *  of NOTE OCTAVE (i.e. C4) are also accepted and converted to their\n\t\t *  frequency value.\n\t\t *  @typedef {Frequency}\n\t\t */\n\t\tFrequency : \"frequency\",\n\t\t/**\n\t\t *  TransportTime describes a position along the Transport's timeline. It is\n\t\t *  similar to Time in that it uses all the same encodings, but TransportTime specifically\n\t\t *  pertains to the Transport's timeline, which is startable, stoppable, loopable, and seekable.\n\t\t *  [Read more](https://github.com/Tonejs/Tone.js/wiki/TransportTime)\n\t\t *  @typedef {TransportTime}\n\t\t */\n\t\tTransportTime : \"transportTime\",\n\t\t/**\n\t\t *  Ticks are the basic subunit of the Transport. They are\n\t\t *  the smallest unit of time that the Transport supports.\n\t\t *  @typedef {Ticks}\n\t\t */\n\t\tTicks : \"ticks\",\n\t\t/**\n\t\t *  Normal values are within the range [0, 1].\n\t\t *  @typedef {NormalRange}\n\t\t */\n\t\tNormalRange : \"normalRange\",\n\t\t/**\n\t\t *  AudioRange values are between [-1, 1].\n\t\t *  @typedef {AudioRange}\n\t\t */\n\t\tAudioRange : \"audioRange\",\n\t\t/**\n\t\t *  Decibels are a logarithmic unit of measurement which is useful for volume\n\t\t *  because of the logarithmic way that we perceive loudness. 0 decibels\n\t\t *  means no change in volume. -10db is approximately half as loud and 10db\n\t\t *  is twice is loud.\n\t\t *  @typedef {Decibels}\n\t\t */\n\t\tDecibels : \"db\",\n\t\t/**\n\t\t *  Half-step note increments, i.e. 12 is an octave above the root. and 1 is a half-step up.\n\t\t *  @typedef {Interval}\n\t\t */\n\t\tInterval : \"interval\",\n\t\t/**\n\t\t *  Beats per minute.\n\t\t *  @typedef {BPM}\n\t\t */\n\t\tBPM : \"bpm\",\n\t\t/**\n\t\t *  The value must be greater than or equal to 0.\n\t\t *  @typedef {Positive}\n\t\t */\n\t\tPositive : \"positive\",\n\t\t/**\n\t\t *  Gain is the ratio between input and output of a signal.\n\t\t *  A gain of 0 is the same as silencing the signal. A gain of\n\t\t *  1, causes no change to the incoming signal.\n\t\t *  @typedef {Gain}\n\t\t */\n\t\tGain : \"gain\",\n\t\t/**\n\t\t *  A cent is a hundredth of a semitone.\n\t\t *  @typedef {Cents}\n\t\t */\n\t\tCents : \"cents\",\n\t\t/**\n\t\t *  Angle between 0 and 360.\n\t\t *  @typedef {Degrees}\n\t\t */\n\t\tDegrees : \"degrees\",\n\t\t/**\n\t\t *  A number representing a midi note.\n\t\t *  @typedef {MIDI}\n\t\t */\n\t\tMIDI : \"midi\",\n\t\t/**\n\t\t *  A colon-separated representation of time in the form of\n\t\t *  Bars:Beats:Sixteenths.\n\t\t *  @typedef {BarsBeatsSixteenths}\n\t\t */\n\t\tBarsBeatsSixteenths : \"barsBeatsSixteenths\",\n\t\t/**\n\t\t *  Sampling is the reduction of a continuous signal to a discrete signal.\n\t\t *  Audio is typically sampled 44100 times per second.\n\t\t *  @typedef {Samples}\n\t\t */\n\t\tSamples : \"samples\",\n\t\t/**\n\t\t *  Hertz are a frequency representation defined as one cycle per second.\n\t\t *  @typedef {Hertz}\n\t\t */\n\t\tHertz : \"hertz\",\n\t\t/**\n\t\t *  A frequency represented by a letter name,\n\t\t *  accidental and octave. This system is known as\n\t\t *  [Scientific Pitch Notation](https://en.wikipedia.org/wiki/Scientific_pitch_notation).\n\t\t *  @typedef {Note}\n\t\t */\n\t\tNote : \"note\",\n\t\t/**\n\t\t *  One millisecond is a thousandth of a second.\n\t\t *  @typedef {Milliseconds}\n\t\t */\n\t\tMilliseconds : \"milliseconds\",\n\t\t/**\n\t\t *  Seconds are the time unit of the AudioContext. In the end,\n\t\t *  all values need to be evaluated to seconds.\n\t\t *  @typedef {Seconds}\n\t\t */\n\t\tSeconds : \"seconds\",\n\t\t/**\n\t\t *  A string representing a duration relative to a measure.\n\t\t *  * \"4n\" = quarter note\n\t\t *  * \"2m\" = two measures\n\t\t *  * \"8t\" = eighth-note triplet\n\t\t *  @typedef {Notation}\n\t\t */\n\t\tNotation : \"notation\",\n\t};\n\n\t///////////////////////////////////////////////////////////////////////////\n\t// AUGMENT TONE's PROTOTYPE\n\t///////////////////////////////////////////////////////////////////////////\n\n\t/**\n\t *  Convert Time into seconds.\n\t *\n\t *  Unlike the method which it overrides, this takes into account\n\t *  transporttime and musical notation.\n\t *\n\t *  Time : 1.40\n\t *  Notation: 4n or 1m or 2t\n\t *  Now Relative: +3n\n\t *\n\t *  @param  {Time} time\n\t *  @return {Seconds}\n\t */\n\tTone.prototype.toSeconds = function(time){\n\t\tif (Tone.isNumber(time)){\n\t\t\treturn time;\n\t\t} else if (Tone.isUndef(time)){\n\t\t\treturn this.now();\n\t\t} else if (Tone.isString(time) || Tone.isObject(time)){\n\t\t\treturn (new Tone.Time(time)).toSeconds();\n\t\t} else if (time instanceof Tone.TimeBase){\n\t\t\treturn time.toSeconds();\n\t\t}\n\t};\n\n\t/**\n\t *  Convert a frequency representation into a number.\n\t *  @param  {Frequency} freq\n\t *  @return {Hertz}      the frequency in hertz\n\t */\n\tTone.prototype.toFrequency = function(freq){\n\t\tif (Tone.isNumber(freq)){\n\t\t\treturn freq;\n\t\t} else if (Tone.isString(freq) || Tone.isUndef(freq) || Tone.isObject(freq)){\n\t\t\treturn (new Tone.Frequency(freq)).valueOf();\n\t\t} else if (freq instanceof Tone.TimeBase){\n\t\t\treturn freq.toFrequency();\n\t\t}\n\t};\n\n\t/**\n\t *  Convert a time representation into ticks.\n\t *  @param  {Time} time\n\t *  @return {Ticks}  the time in ticks\n\t */\n\tTone.prototype.toTicks = function(time){\n\t\tif (Tone.isNumber(time) || Tone.isString(time) || Tone.isObject(time)){\n\t\t\treturn (new Tone.TransportTime(time)).toTicks();\n\t\t} else if (Tone.isUndef(time)){\n\t\t\treturn Tone.Transport.ticks;\n\t\t} else if (time instanceof Tone.TimeBase){\n\t\t\treturn time.toTicks();\n\t\t}\n\t};\n\n\treturn Tone;\n}).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/type/Type.js?");

/***/ }),

/***/ "./node_modules/tone/Tone/version.js":
/*!*******************************************!*\
  !*** ./node_modules/tone/Tone/version.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"13.4.9\";\n\n\n//# sourceURL=webpack:///./node_modules/tone/Tone/version.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var tone_Tone_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tone/Tone/index.js */ \"./node_modules/tone/Tone/index.js\");\n/* harmony import */ var tone_Tone_index_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(tone_Tone_index_js__WEBPACK_IMPORTED_MODULE_0__);\n\nvar synth = new tone_Tone_index_js__WEBPACK_IMPORTED_MODULE_0___default.a.Synth().toMaster();\ndocument.getElementById(\"test\").addEventListener(\"click\", function () {\n  synth.triggerAttackRelease('C4', '8n');\n});\n\n//# sourceURL=webpack:///./src/index.js?");

/***/ })

/******/ });